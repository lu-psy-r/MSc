[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Psychologists",
    "section": "",
    "text": "Welcome\n\nWelcome to MSc statistics! Click on the button below to access your module: Term 1: PSYC411, Term 2: PSYC412.\n\n\n  \n    \n\n    \n      PSYC411\n    \n    \n      PSYC412"
  },
  {
    "objectID": "PSYC411/part1/Week5.html",
    "href": "PSYC411/part1/Week5.html",
    "title": "5. Testing differences between groups",
    "section": "",
    "text": "Watch Lecture week5 part 1, slides here\nPart 2, slides here. Please note I say week 6 in the lectures, but I mean week 5. Sorry about that! It is week 5, be assured.\nTake the quiz (not assessed) on the lecture materials.\nWork through the materials below.\nAttend the practical.\nPop into the drop in (optional). Please note this is in Levy Lab - do come along with any questions at all on the workbooks so far.\nOptionally, if you can give us your (anonymised) feedback on how the course is going from your perspective, that would be very welcome.\nAlso optionally, read the articles on the importance of statistical understanding and insights from good data visualisation.\n\nHow scientists can be better at statistics\nFlorence Nightingale and data visualisation",
    "crumbs": [
      "Home",
      "PSYC411",
      "5. Testing differences between groups"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week5.html#task-1-checklist-what-i-can-now-do",
    "href": "PSYC411/part1/Week5.html#task-1-checklist-what-i-can-now-do",
    "title": "5. Testing differences between groups",
    "section": "Task 1: Checklist: What I can now do",
    "text": "Task 1: Checklist: What I can now do\nYou should be able to answer yes to all the following. If you can’t yet, go back to the previous workbooks and repeat your working until you can answer yes, being able to type in and run the commands without referring to your notes.\n\nI can open R-studio\nI can open new libraries using library()\nI can make an R script file\nI can input a file into an object in R-studio using read_csv()\nI can join two files together using inner_join()\nI can select certain variables from an object using select()\nI can select subsets of data using filter() (e.g., I can select participants in two conditions from a data set containing participants in four conditions)\nI can make new variables using mutate()\nI can arrange data according to subsets using group_by()\nI can change format of data from wide to long format using pivot_longer\nI can change format of data from long to wide format using pivot_wider\nI can produce summaries of means and standard deviations for subsets of data after applying group_by() using summarise()\nI can draw histograms of single variables, point plots of two ratio/interval/ordinal variables, bar plots of counts, and box plots of one categorical and one ratio/interval/ordinal variable using ggplot()\nI can run a Chi-squared test and Cramer’s V test using chisq.test() and cramersV()\nI can interpret the results of a Chi-squared test and Cramer’s V test and write up a simple report of the results.\nI can save an R script file.",
    "crumbs": [
      "Home",
      "PSYC411",
      "5. Testing differences between groups"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week5.html#task-2-load-prepare-and-explore-the-data",
    "href": "PSYC411/part1/Week5.html#task-2-load-prepare-and-explore-the-data",
    "title": "5. Testing differences between groups",
    "section": "Task 2: Load, prepare, and explore the data",
    "text": "Task 2: Load, prepare, and explore the data\n\nClear out R using rm(list=ls())\nLoad again the data set on the Shipley and Gent vocabulary scores.\nSet the research question: do people who self-identify as male or female have different scores on the Gent vocabulary test? The research hypothesis is: “People who identify as male or female have different vocabulary scores”. What is the null hypothesis?\nTo test the research hypothesis, we will filter people who self-identify as male or female from the data set. To be inclusive, additional research questions would be part of your research project to analyse also people who self-identify as other gender. Run this command to extract a subset of the data (note that the | stands for “or”, and means Gender matches male or gender matches female:\n\n\ndat2 &lt;- filter(.data = dat, Gender == 'Male' | Gender == 'Female')\n\n\nDraw a box plot of Gent vocabulary test 1 scores by gender. For a box plot, note that we need data in “long format”, where each observation is on one line, and we have a column that indicates which condition (in this case Gender) the participant is in. Does it look like there might be a gender effect? What is the direction of the effect?\nNote that unless we had filtered the data, the box plot would contain ‘NA’ as well, which stands for missing data. In a data set it’s always a good idea to call missing data ‘NA’ rather than just leaving them blank because this could be interpreted as a zero or as an error of filling in data. Missing values make things untidy, so it’s good practice to focus only on the variables we need for the t-test and remove all other missing values. Use select() to get just the Gender and Gent_1_score variables, and put this in a new object called ‘dat3’.\nNext, in order to run a t-test we have to remove any rows of data which contain a ‘NA’ - either in the Gender or the Gent_1_score variables. We do this using drop_na(dat3), put the result in a new object called ‘dat4’. Run this command:\n\n\ndat4 &lt;- drop_na(dat3)\n\n\nNow, redraw the box plot from Step 21. Check there are just two groups.\nCompute mean and SDs for people who self-identify as male or female on Gent vocabulary test 1 scores.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse group_by() and summarise().",
    "crumbs": [
      "Home",
      "PSYC411",
      "5. Testing differences between groups"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week5.html#task-3-run-the-independent-t-test-and-measure-effect-size",
    "href": "PSYC411/part1/Week5.html#task-3-run-the-independent-t-test-and-measure-effect-size",
    "title": "5. Testing differences between groups",
    "section": "Task 3: Run the independent t-test and measure effect size",
    "text": "Task 3: Run the independent t-test and measure effect size\n\nConduct an independent t-test using this command:\n\n\nt.test(Gent_1_score ~ Gender, paired = FALSE, data = dat5 )\n\n\n‘Gent_1_score ~ Gender’ : the ~ can be interpreted as ‘by’, i.e., compute Gent_1_score by Gender\n‘paired = FALSE’ : this means we are doing an independent t-test (a paired t-test would have paired = TRUE)\n\n\nThe results should look like this, do yours?\n\nWelch Two Sample t-test\n\ndata:  Gent_1_score by Gender\nt = -1.7356, df = 62.409, p-value = 0.08756\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  -10.0862020   0.7105407\nsample estimates:\n  mean in group Female   mean in group Male \n57.57407             62.26190 \n\nThe key part of the results to look at is the one that has t = -1.7356, df = 62.409, p-value = 0.08756. This is the result that you report: t(62.41) = -1.74, p = .088.\n\nThe value is negative because the function includes Female before Male - and Female score is lower than Male score. What matters is how far away from zero the t-test is (either positively or negatively). The df value is slightly odd because the t.test() function figures out degrees of freedom in a technical way which takes into account differences in variance in the data between the two groups. We can just use the value that the t.test() function gives us.\n\nIs this a significant difference?\nNow we need to compute the effect size, using Cohen’s d. You need to load the library lsr then use this command:\n\n```{r}\n\ncohensD(Gent_1_score ~ Gender, method = \"unequal\", data = dat4)\n\n```\n\nIt’s pretty much the same as the t-test() command except that we use ‘method = ’unequal’ instead of ‘paired = FALSE’. For a paired t-test you would use ‘method = ’paired’\n\n\nWhat is the effect size? Make a brief report of the results - reporting means and SDs, the t-test, p-value, and Cohen’s d. Discuss your brief report in your group.\nMake sure all commands are in the source window, save them as a new R script file.",
    "crumbs": [
      "Home",
      "PSYC411",
      "5. Testing differences between groups"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week5.html#task-4-practise-running-another-independent-t-test",
    "href": "PSYC411/part1/Week5.html#task-4-practise-running-another-independent-t-test",
    "title": "5. Testing differences between groups",
    "section": "Task 4: Practise running another independent t-test",
    "text": "Task 4: Practise running another independent t-test\n\nNext research question: do people who are native English speakers have different vocabulary scores than those who learned English as a second language? What is the research hypothesis and the null hypothesis?\nRepeat the Steps 22-30 in Tasks 2 and 3 except using english_status in place of Gender throughout.\nWrite a brief report of the results, including means and SDs for native speakers and ESL speakers, t-test, p-value, and Cohen’s d. Discuss your report in your group.\nSave your R script file.\n\nPart 3: Conducting a paired t-test\nTask 5: Conducting a paired t-test\n\nClear out R-studio before we get started again using rm(list=ls())\nWe are going to investigate again the data from this paper: Woodworth, R.J., O’Brien-Malone, A., Diamond, M.R. and Schuez, B., 2018. Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness”. Journal of Open Psychology Data, 6(1).\n\nOur research question is whether happiness scores are affected by the interventions. We will look at the pre-test (occasion 0) and the first test after the intervention (occasion 1).\n\nWhat is the research hypothesis and what is the null hypothesis?\nFor a paired t-test we can only include data from people who have produced scores at both occasions of testing. So, we need a slightly different version of the data. Download the files here. Remind yourself what these data mean.\nOnce again, join the ahicesd.csv and participantinfo2.csv data in R-studio by aligning the names for the participant bumbers in these two data sets (see week 2 workbook for reminders about this).\nLet’s select only the relevant variables. Use select() to select only id, ahiTotal, and occasion variables, and save this as a new object called ‘summarydata’\nUse filter to pull out only occasion == 0 or occasion == 1 scores\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nuse occasion == 0 | occasion == 1'), save this as a new object called summarydata2\n\n\n\n\nHere is where we would usually remove all the NA values, but there aren’t any in this file (so we don’t need drop_na()).\nNow, we need to make sure occasion is treated as a categorical variable, rather than a continuous variable, so we need to convert it to a factor:\n\n```{r}\n\nsummarydata2$occasion &lt;-as.factor(summarydata2$occasion)\n\n```\n\nNow, draw a box plot of ahiTotal scores by occasion (why do we use a box plot?)\nCompute mean and SD for each occasion\nRun the paired t-test: it’s the same as for the independent t-test except that we use paired = TRUE in place of paired = FALSE:\n\n```{r}\n\nt.test(ahiTotal ~ occasion, paired = TRUE, data = summarydata2)\n\n```\nIs the result significant?\n\nBefore we run the Cohen’s d command for these data, we have to make sure we have a list of the participants in one condition, followed by the list of participants in the other condition. We can do this using the command arrange():\n\n```{r}\n\nsummarydata3 &lt;- arrange(.data = summarydata2, occasion)\n\n```\n\nNow run Cohen’s d: it’s the same as for the independent t-test except that we use ‘method = ’paired’:\n\n```{r}\n\ncohensD(ahiTotal ~ occasion, method = \"paired\", data = summarydata3)\n\n```\nWhat is the value for Cohen’s d?\n\nWrite up a brief report of the result and discuss in your group.\nSave your R script file.",
    "crumbs": [
      "Home",
      "PSYC411",
      "5. Testing differences between groups"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html",
    "href": "PSYC411/part1/Week3.html",
    "title": "3. Drawing graphs from data",
    "section": "",
    "text": "Watch Lecture week3 part1, slides here\nHave a go at the Gent Vocabulary test, and record your score.\nHave another go at the Gent Vocabulary test, and record your score again.\nHave a go at the Shipley Vocabulary test, and record your score. Scoring sheet here\nFill in your vocabulary scores into our course database: What is your vocabulary?\nWatch Lecture week3 part2, slides here.\nWatch Lecture week3 part3, slides here.\nDo the quick quiz.\nGo through the Practical week3 workbook below.\nAttend the practical.\nPop into the drop in (optional).\n\nAnd hey presto, that’s all done!",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-1-describe-and-load-the-data-set-you-found-for-your-take-home-task",
    "href": "PSYC411/part1/Week3.html#task-1-describe-and-load-the-data-set-you-found-for-your-take-home-task",
    "title": "3. Drawing graphs from data",
    "section": "Task 1: Describe and load the data set you found for your take-home task",
    "text": "Task 1: Describe and load the data set you found for your take-home task\n\nYour take-home task was to download a data set that accompanied a paper published in Psychological Science. Describe this data set to the rest of your group.\nLoad your data set into Rstudio.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nuse read_csv(), or one of the other read functions from the last part of the Practical week2 workbook. You may need to load library(tidyverse).\n\n\n\n\nView the data set, and then make a new data set from this data set, by selecting just two variables.\nIs it appropriate to draw a histogram or a scatter plot of the two variables? If so, draw it. If not, why not?\nMake sure these commands are in the source window, save them as a new R file, e.g., “mypsychscidata.r”\n\nPart 2: Reproduce the Lecture week3 part3 analyses",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-2-load-in-the-data-draw-a-histogram-find-means-and-standard-deviations",
    "href": "PSYC411/part1/Week3.html#task-2-load-in-the-data-draw-a-histogram-find-means-and-standard-deviations",
    "title": "3. Drawing graphs from data",
    "section": "Task 2: Load in the data, draw a histogram, find means and standard deviations",
    "text": "Task 2: Load in the data, draw a histogram, find means and standard deviations\n\nCreate a new r script, called psyc401_week3.r, and clear out R studio ready for a new script using rm(list=ls()).\nDownload the data files on the vocabulary tests here: PSYC401-shipley-scores-anonymous-17_18.zip. You should then upload the entire zip folder to the R server.\nLoad the data into an object called “dat” using read_csv(), what command line do you use? (remember to set the working directory)\nView the data. What command do you use?\nWe can make a histogram of the first time people took the Gent vocabulary test:\n\n\nhist(dat$Gent_1_score)\n\n\nAnd a histogram of the second time people took the Gent test, what command line do you use?\nWe can find out means and standard deviations. We will use the mean() and the sd() functions. However, we need to tell R studio what to do with the missing values (called NA in the View), to do that we have to add an extra bit to the command:\n\n\nmean(dat$Gent_1_score, na.rm=TRUE)\n\nThis tells R studio to remove the NA values before computing the mean. What happens if you don’t add na.rm=TRUE?\nWhat is the mean and standard deviation of Gent_1_score and Gent_2_score?",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-3-use-ggplot-to-draw-some-histograms",
    "href": "PSYC411/part1/Week3.html#task-3-use-ggplot-to-draw-some-histograms",
    "title": "3. Drawing graphs from data",
    "section": "Task 3: Use ggplot to draw some histograms:",
    "text": "Task 3: Use ggplot to draw some histograms:\n\nNow we are going to use another way of making graphs. This is more flexible than the hist function. Here is how to make a histogram of the Gent vocabulary scores:\n\n\nggplot(dat, aes(x = Gent_1_score) ) + geom_histogram(fill=\"blue\") + labs(title=\"Gent Vocabulary Test 1\", x = \"Vocabulary Score\", y = \"Frequency\")\n\n\nAnd for the second Gent test:\n\n\nggplot(dat, aes(x = Gent_2_score) ) + geom_histogram(fill=\"red\") + labs(title=\"Gent Vocabulary Test 2\", x = \"Vocabulary Score\", y = \"Frequency\")\n\n\n\n\n\n\n\nNote\n\n\n\nBreaking it down: ggplot(dat, aes(x = Gent_1_score)): this calls the plotting function ggplot we specify the data set we will use, dat and we set the data for the plot, in this case we say that the x value (so that’s what will be along the x-axis in the graph) is the Gent_1_score. We put this inside aes(), which stands for “aesthetic”. + geom_histogram(fill=\"blue\"): this adds a graph of type histogram and colours it blue + labs(title=\"Gent Vocabulary Test\", x = \"Vocabulary Score\", y = \"Frequency\"): this adds labels to the graph: title, the x-axis label and the y-axis label.",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-4-practise-manipulating-data",
    "href": "PSYC411/part1/Week3.html#task-4-practise-manipulating-data",
    "title": "3. Drawing graphs from data",
    "section": "Task 4: Practise manipulating data",
    "text": "Task 4: Practise manipulating data\n\nLet’s keep only some of the variables from the dataset dat - let’s remove Gender_code, and Dyslexia_diagnosis. Keep the other variables using select() and load this into summarydata\n\n\nsummarydata &lt;- select(.data = dat, subject_ID, Age, english_status, Gender, Shipley_Voc_Score, Gent_1_score, Gent_2_score, academic_year)\n\n\nNext we will have a bit more of a wander around the data to get a feel for it. We will first use the function arrange(), which changes the order of observations (rows):\n\n\narrange(.data = summarydata, Shipley_Voc_Score)\n\nWhat is the lowest score of a participant on the Shipley Vocabulary questionnaire? (You may like to make a new object, which is the result of the arrange function, then look at it in View).\n\nIf you want to order from highest to lowest, you have to use the desc() function:\n\n\narrange(.data = summarydata, desc(Shipley_Voc_Score))\n\nWhat is the highest value on the Shipley Vocabulary Test? How many participants have this highest score?\n\nNext we will use the filter() function. This includes or excludes certain observations (rows). Let’s just include the participants with English as a first language and put this into a new object, called summarydata_enl. What are the mean and SD values of the Shipley Vocabulary test for the native speakers?\n\n\nsummarydata_enl &lt;- filter(.data = summarydata, english_status == 'native')\n\n\nMake another variable with the z-scores of the Shipley Vocabulary test (see week 1 workbook). What are the maximum and minimum z-scores?\nRemember to save your script file.",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-5-graphing-data-using-histograms",
    "href": "PSYC411/part1/Week3.html#task-5-graphing-data-using-histograms",
    "title": "3. Drawing graphs from data",
    "section": "Task 5: graphing data using histograms",
    "text": "Task 5: graphing data using histograms\n\nPreviously we used plot to draw a scatter plot, and hist to draw a histogram. Now, we’re going to use ggplot which can draw all kinds of graphs, with a great deal more flexibility. We are going to represent the data to reflect the following relations:\n\n\nEnglish status and gender\nAge and vocabulary score\nGender and vocabulary score\nAcademic year and vocabulary score\nAcademic year and age\nEnglish status and vocabulary score\nEnglish status and age\n\nBut first, let’s repeat reproducing the histogram from the overhead slides to look at the distribution of variables:\n\nggplot(summarydata, aes(x = Gent_1_score)) +\n  geom_histogram(fill=\"blue\") + \n  labs(title=\"Gent Vocabulary Test 1\", x = \"Vocabulary Score\", y = \"Frequency\")\n\n\nNow draw a histogram with Shipley_Voc_Score as the variable and colour it orange. Remember to change the title to something appropriate.",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-6-graphing-data-using-bar-graphs",
    "href": "PSYC411/part1/Week3.html#task-6-graphing-data-using-bar-graphs",
    "title": "3. Drawing graphs from data",
    "section": "Task 6: graphing data using bar graphs",
    "text": "Task 6: graphing data using bar graphs\n\nNext let’s look at English status and gender. What types of variable are these? Nominal? Ordinal? Interval/ratio?\nWe will draw a bar graph of the counts. We use geom_bar() for this:\n\n\nFirst try this:\n\n\nggplot(summarydata, aes(x = Gender)) + \n  geom_bar()\n\n\nThis just draws counts of Gender\nNow let’s draw Gender and English Status together:\n\n\nggplot(summarydata, aes(x = Gender, fill = english_status)) + \n  geom_bar(position = \"dodge\")\n\nNote 1: We use position dodge so that it puts the bars next to each other (what happens if you leave out position = dodge?)\nNote 2: We use fill = english_status so that it fills the different bars with different colours according to different english statuses.\nWhat is the general pattern of counts? Are there proportional differences by English status according to gender?",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-7-graphing-data-using-scatterplot",
    "href": "PSYC411/part1/Week3.html#task-7-graphing-data-using-scatterplot",
    "title": "3. Drawing graphs from data",
    "section": "Task 7: graphing data using scatterplot",
    "text": "Task 7: graphing data using scatterplot\n\nNext we’ll look at Age and Shipley Vocabulary Score. What types of data are these?\nWe will draw a point plot of these values:\n\n\nggplot(summarydata, aes(x= Age, y = Shipley_Voc_Score)) + geom_point()\n\nWe can add + labs(title = \"Age by Shipley Vocabulary Score\", x = \"Age\", y = \"Shipley Vocabulary Score\") to tidy up presentation a bit.\n\nggplot(summarydata, aes(x= Age, y = Shipley_Voc_Score)) + \n  geom_point() + \n  labs(title = \"Age by Shipley Vocabulary Score\", x = \"Age\", y = \"Shipley Vocabulary Score\")\n\n\nWhat is the relation between age and Shipley Vocabulary score?",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week3.html#task-8-draw-and-interpret-a-box-plot",
    "href": "PSYC411/part1/Week3.html#task-8-draw-and-interpret-a-box-plot",
    "title": "3. Drawing graphs from data",
    "section": "Task 8: Draw and interpret a box plot",
    "text": "Task 8: Draw and interpret a box plot\n\nNext on the list of relations to check is gender and vocabulary score. Let’s look at Gent_1_score against Gender. What type of variables are these?\nWe will draw a box plot (you could draw a bar graph, but box plots tend to be preferred for these combinations of variables - use a bar graph for counts):\n\n\nggplot(summarydata, aes(x= Gender, y = Gent_1_score)) + \n  geom_boxplot() \n\n\nAgain we can tidy this up by adding labels:\n\n\nggplot(summarydata, aes(x= Gender, y = Gent_1_score)) + geom_boxplot() + labs(title = \"Vocabulary Score by Gender\", x = \"Gender\", y = \"Gent Vocabulary Score Test 1\")\n\n\nInterpreting box plots: The horizontal line indicates the median. The box indicates where 50% of the data lie. The lines indicate an estimate of the range of the data (minimum and maximum values). The dots indicate outliers. A large box indicates larger standard deviation. If the boxes don’t overlap much then this indicates there may be a difference between the groups.\n\n\nAre there differences in Vocabulary according to gender?\n\n\nNow for the other relations:\n\n\nAcademic year and vocabulary score\nAcademic year and age\nEnglish status and vocabulary score\nEnglish status and age\n\nAt the moment, R is interpreting Academic year as a number. We need to turn it into a nominal variable (called a “factor” in R studio):\n\nsummarydata$academic_year &lt;- as.factor(summarydata$academic_year)\n\nDraw a graph for each of these relations.\n\nSave your R script.",
    "crumbs": [
      "Home",
      "PSYC411",
      "3. Drawing graphs from data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html",
    "href": "PSYC411/part1/Week1.html",
    "title": "Statistics for Psychologists",
    "section": "",
    "text": "This week, there are three mini lectures, and then a practical workbook to get you going with R-studio.\nBefore the practical on Tuesday, please try to work through the practical workbook (in the first practical we will form groups of people to work together on the workbooks, for now you can work on the practical workbook individually or with anyone else on the course you are in touch with!).\nBring your questions (and/or answers) to the practical.",
    "crumbs": [
      "Home",
      "PSYC411",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-one-open-rstudio",
    "href": "PSYC411/part1/Week1.html#task-one-open-rstudio",
    "title": "Week 1. Introducing Data",
    "section": "Task One: Open Rstudio",
    "text": "Task One: Open Rstudio\nFrom a computer on the campus wifi (or from home via the University VPN), you can access R Studio at:\nLancaster Psychology R Studio Server\nAt the login screen, use your university username (e.g., bloggsj) and password.\n\nWhat does RStudio look like?\nWhen RStudio starts, it will look something like this: \nRStudio has three panels or windows: there are tabs for Console (taking up the left hand side), Environment (and History top right), Current file (bottom right). You will also see a 4th window for a script or set of commands you develop, also (on the left hand side).",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-two-using-the-console",
    "href": "PSYC411/part1/Week1.html#task-two-using-the-console",
    "title": "Week 1. Introducing Data",
    "section": "Task Two: using the console",
    "text": "Task Two: using the console\n\n\n\n\n\n\nTip\n\n\n\nText that is highlighted with a grey background denotes code, rather than typical prose. Code is different to other forms of writing, such as essays, because the syntax, order and words need to be quite specific. For some longer chunks of code, as you will see below, they are formatted slightly differently.\n\n\n\nIn the “console” part of the R window, next to the &gt;, type 10 + 30. Press return.\n\n\n10 + 40                        \n\n\n\n\n\n\n\nTip\n\n\n\nIf you hover your mouse over the box that includes the code snippet, a ‘copy to clipboard’ icon will appear in the top right corner of the box. Click that to copy the code. Now you can easily paste it into your script.\n\n\nIt should give you the answer 40.\n\nIn the console, type a &lt;- 40 and press Return.\n\n\na &lt;- 40                      \n\nNow type a and press return. It should give you the answer 40. a is called an object, think of it like a bucket that you can keep a number, or some numbers, or actually all kinds of stuff in.\n\nNow let’s look at a function, sqrt. sqrt is a function that takes the square root of whatever is inside the brackets. In the console, type sqrt(13). Press Return.\nNow find the square root of the object a by typing sqrt(a). Press return.",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-three-finding-distributions",
    "href": "PSYC411/part1/Week1.html#task-three-finding-distributions",
    "title": "Week 1. Introducing Data",
    "section": "Task Three: finding distributions",
    "text": "Task Three: finding distributions\n\nMake a new object b, and put the following list of children’s attachment scores into it\n\n\nb &lt;- c( 4, 1, 5, 3, 8, 2, 2, 6, 8, 5, 4, 1, 6, 5, 4, 5, 7, 9, 10, 1, 1, 3, 5, 4, 6, 4, 8, 6, 5, 5, 7, 8, 9, 8, 8, 2, 1, 4, 3, 2, 5, 1, 5, 6, 8, 6, 7, 2, 7)\n\n\nCheck it works by typing b, press return.\nFind the mean of these numbers by typing mean(b).\nFind the median of these numbers by typing median(b).\nFind the standard deviation of these numbers by typing sd(b).\nDraw a histogram of these numbers by typing hist(b).",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-four-z-scores",
    "href": "PSYC411/part1/Week1.html#task-four-z-scores",
    "title": "Week 1. Introducing Data",
    "section": "Task Four: z scores",
    "text": "Task Four: z scores\n\nMake a new object b_z and assign to it the z scores of the values from b: ``\n\n\nb_z &lt;- scale(b)\n\n\nCheck that it worked by typing b_z.\nDraw a histogram of b_z by typing hist(b_z).",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-five-investigating-distributions",
    "href": "PSYC411/part1/Week1.html#task-five-investigating-distributions",
    "title": "Week 1. Introducing Data",
    "section": "Task Five: investigating distributions",
    "text": "Task Five: investigating distributions\n\nLet’s make three new objects, with the marks from three people’s university masters courses. They are called annie, saj, and carrie and they took 10 courses each. We use the special notation c() to indicate a list, each number in the list is separated by a comma. Type the following into the console:\n\n\nannie &lt;- c(55, 95, 85, 65, 65, 85, 65, 95, 65, 75)\nsaj &lt;- c(65, 85, 95, 75, 65, 55, 55, 75, 95, 85)\ncarrie &lt;- c(75, 65, 95, 95, 55, 85, 75, 55, 95, 55)\n\n\nWho has the highest average (mean) score for their course?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nuse the mean() function\n\n\n\n\nWho has the most variable scores for their course?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nuse the sd() function\n\n\n\n\nWhat is the median score for each student?. What does this mean about the distribution of each students’ scores? Use the function hist() to draw the distributions to help you see.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nyou can use the summary() function, or the median() function",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-six-standardised-scores-z-scores",
    "href": "PSYC411/part1/Week1.html#task-six-standardised-scores-z-scores",
    "title": "Week 1. Introducing Data",
    "section": "Task Six: standardised scores: Z scores",
    "text": "Task Six: standardised scores: Z scores\n\nMake a new object called annie_z and use the function scale to convert annie’s scores to z-scores: in the console type:\n\n\nannie_z &lt;- scale(annie)\n\n\nYou can have a look at the standardised scores of annie, by just typing annie_z. To what did annie’s highest initial score of 95 convert to?\nWhat is the mean and standard deviation of annie_z’s standardised scores?\nDraw a histogram of annie’s standardised scores, in the console type hist(annie_z). What is the peak frequency value?\nBonus extra: If you want to find out the proportion of scores lower than a particular score you can do it like this in R-studio: pnorm(x) where x is the z-score you’re interested in. What is the proportion of scores lower than annie’s highest grade score?",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#task-seven-exploring-operators.",
    "href": "PSYC411/part1/Week1.html#task-seven-exploring-operators.",
    "title": "Week 1. Introducing Data",
    "section": "Task Seven: Exploring operators.",
    "text": "Task Seven: Exploring operators.\nSo far, we’ve just looked at + as an operator. Go to this page: https://www.statmethods.net/management/operators.html\n\nIn the console, assign the object d to be 100 multiplied by 246.\nIn the console, assign the object e to be 84 divided by 32.1.\nAssign the variable f to 8 to the power of 4 (in R this is called exponentiation).\nWhat is the result of d added to e all divided by f\n\nTask 9: Exploring functions\nSo far, we’ve just looked at the square root function sqrt(). Go to this page: https://www.statmethods.net/management/functions.html 27. What is the result of abs(-5.3)? What does the abs function do?\n\nUsing the seq() function, generate a sequence of numbers from 0 to 30 in intervals of 3.\nAssign the sequence generated in step 28 to a new object. Now compute the mean of the sequence of numbers. (remember that objects can be a single number, or a sequence of numbers (called an array or a vector) or anything you want to put into it – remember, think of objects as buckets).\n\n\n\n\n\n\n\nStuck? Here’s the solution\n\n\n\n\n\nTry out the following code, pay special attention to how the sentences above “convert” into R code.\n\nsequence &lt;- seq(0,30, 3)\nmean(sequence)\n\n\n\n\n\n1.4.2 Data\n\n\n1.4.3 Answers\nThe answers to the workbook will appear below each question after the practical has finished, so you can check your answers.\nIt’s really important for your learning that you have a go first of all at the workbook before looking at the answers.",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 1. Introducing Data"
    ]
  },
  {
    "objectID": "PSYC411/part2/ecosystem.html",
    "href": "PSYC411/part2/ecosystem.html",
    "title": "R knowledge",
    "section": "",
    "text": "R knowledge\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC411/part2/references.html",
    "href": "PSYC411/part2/references.html",
    "title": "References",
    "section": "",
    "text": "References\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC411/part2/visualization.html",
    "href": "PSYC411/part2/visualization.html",
    "title": "Data visualization",
    "section": "",
    "text": "In writing this chapter, I have two aims.\n\nThe first aim for this chapter is to expose students to an outline summary of some key ideas and techniques for data visualization in psychological science.\n\nThere is an extensive experimental and theoretical literature concerning data visualization, what choices we can or should make, and how these choices have more or less impact, in different circumstances or for different audiences. Here, we can only give you a flavour of the on-going discussion. If you are interested, you can follow-up the references in the cited articles. But, using this chapter, I hope that you will gain a sense of the reasons how or why we may choose to do different things when we produce visualizations.\n\nThe second aim is to provide materials, and to show visualizations, to raise an awareness of what results come from making different choices. This is because we hope to encourage students to make choices based on reasons and it is hard to know what choices count without first seeing what the results might look like.\n\nIn my experience, knowing that there are choices is the first step. In proprietary software packages like Excel and SPSS there are plenty of choices but these are limited by the menu systems to certain combinations of elements. Here, in using R to produce visualizations, there is much more freedom, and much more capacity to control what a plot shows and how it looks, but knowing where to start has to begin with seeing examples of what some of the choices result in.\nAt the end of the chapter, I highlight some resources you can use in independent learning for further development, see Section 1.9.\nSo, we are aiming to (1.) start to build insight into the choices we make and (2.) provide resources to enable making those choices in data visualization.\n\n\n\nData visualization is important. Building skills in visualization matters to you because, even if you do not go on to professional work in which you produce visualizations you will certainly be working in fields in which you need to work with, or read or evaluate, visualizations.\nYou have already been doing this: our cultural or visual environment is awash in visualizations, from weather maps to charts on the television news. It will empower you if you know a bit about how or why these visualizations are produced in the ways that they are produced. That is a complex development trajectory but we can get started here.\nIn the context of the research report exercise, see ?@sec-pipeline, I mention data visualization in relation to stages of the data analysis pipeline or workflow. But the reality is that, most of the time, visualization is useful and used at every stage of data analysis workflow.\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nAnalyze\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow\n\n\n\n\n\n\n\n\nI write this chapter with three kinds of honesty in mind.\n\nI will expose some of the process involved in thinking about and preparing for the production of plots.\n\n\nI can assure you that when a professional data analysis worker produces plots in R they will be looking for information about what to do, and how to do it, online. I will provide links to the information I used, when I wrote this chapter, in order to figure out the coding to produce the plots.\nI won’t pretend that I got the plots “right first time” or that I know all the coding steps by memory. Neither is true for me and they would not be true for most professionals if they were to write a chapter like this. Looking things up online is something we all do so showing you where the information can be found will help you grow your skills.\n\n\nI will show how we often prepare for the production of plots by processing the data that we must use to inform the plots.\n\n\nWe almost always have to process the data we collected or gathered together from our exerimental work or our observations.\nIn this chapter, some of the coding steps I will outline are done in advance of producing a plot, to give the plotting code something to work with.\nKnowing about these processing steps will ensure you have more flexibility or power in getting your plots ready.\n\n\nI am going to expose variation, as often as I can, in observations.\n\n\nWe typically collect data about or from people, about their responses to things we may present (stimuli) or, given tasks, under different conditions, or concerning individual differences on an array of dimensions.\nSources of variation will be everywhere in our data, even though we often work with statistical analyses (like the t-test) that focus our attention on the average participant or the average response.\nModern analysis methods (like mixed-effects models) enable us to account for sources of variation systematically, so it is good to begin thinking about, say, how people vary in their response to different experimental conditions from early in your development.\n\n\n\n\nThe approach we will take is to focus on step-by-step guides to coding. I will show plots and I will walk through the coding steps, explaining my reasons for the choices I make.\nWe will be working with plotting functions like ggplot() provided in libraries like ggplot2 [@R-ggplot2] which is part of the tidyverse [@R-tidyverse] collection of libraries.\nYou can access information about the tidyverse collection here.\n\n\nThe gg in ggplot stands for the “Grammar of Graphics”, and the ideas motivating the development of the ggplot2 library of functions are grounded in the ideas concerning the grammar of graphics, set out in the book of that name [@wilkinson2013].\nWhat is helpful to us, here, is the insight that the code elements (and how they result in visual elements) can be identified as building blocks, or layers, that we can add and adjust piece by piece when we are producing a visualization.\nA plot represents information and, critically, every time we write ggplot code we must specify somewhere the ways that our plot links data to something we see. In terms of ggplot, we specify aesthetic mappings using the aes() code to tell R what variables should be mapped e.g. to x-axis or y-axis location, to colour, or to group assignments. We then add elements to instruct R how to represent the aesthetic mappings as visual objects or attributes: geometric objects like a scatter of points geom_point() or a collection of bars geom_bar(); or visual features like colour, shape or size e.g. aes(colour = group). We can add visual elements in a series of layers, as shall see in the practical demonstrations of plot construction. We can adjust how scaling works. And we can add annotation, labels, and other elements to guide and inform the attention of the audience.\nYou can read more about mastering the grammar here.\n\n\n\nWe know that (some of) you want to see more use of pipes (represented as %&gt;% or |&gt;) in coding. There will be plenty of pipes in this chapter.\nIn using pipes in the code, I am structuring the code so that it works — and is presented — in a sequence of steps. There are different ways to write code but I find this way easier to work with and to read and I think you will too.\nLet’s take a small example:\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  summarise(average = mean(Reaction)) %&gt;%\n  ggplot(aes(x = average)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\nHere, we work through a series of steps:\n\nsleepstudy %&gt;% we first tell R we want to work with the dataset called sleepstudy and the %&gt;% pipe symbol at the end of the line tells R that we want it to pass that dataset on to the next step for what happens next.\ngroup_by(Subject) %&gt;% tells R that we want it to do something, here, group the rows of data according to the Subject (participant identity) coding variable, and pass the grouped data on to the next step for what happens following.\nsummarise(average = mean(Reaction)) %&gt;% tells R to take the grouped variable and calculate a summary, the mean Reaction score, for each group of observations for each participant. The %&gt;% pipe at the end of the line tells R to pass the summary dataset of mean Reaction scores on to the next process.\nggplot(aes(x = average)) + tells R that we want it to take these summary average Reaction scores and make a plot out of them.\ngeom_histogram() tells R that we want a histogram plot.\n\nWhat you can see is that each line ending in a %&gt; pipe passes something on to the next line. A following line takes the output of the process coded in the preceding line, and works with it.\nEach step is executed in turn, in strict sequence. This means that if I delete line 3 summarise(average = mean(Reaction)) %&gt;% then the following lines cannot work because the ggplot() function will be looking for a variable average that does not yet exist.\n\n\n\n\n\n\nWarning\n\n\n\n\nYou can see that in the data processing part of the code, successive steps in data processing end in a pipe %&gt;%.\nIn contrast, successive steps of the plotting code add ggplot elements line by line with each line (except the last) ending in a +.\n\n\n\nNotice that none of the processing steps actually changes the dataset called sleepstudy. The results of the process exist and can be used only within the sequence of steps that I have coded. If you want to keep the results of processing steps, you need to assign an object name to hold them, and I show how to do this, in the following.\nYou can read a clear explanation of pipes here.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the code you see:\n\nEach chunk of code is highlighted in the chapter.\nIf you hover a cursor over the highlighted code a little clipboard symbol appears in the top right of the code chunk.\nClick on the clipboard symbol to copy the code, paste it into your own R-Studio instance.\nThen experiment: try out things like removing or commmenting out lines, or changing lines, to see what effect that has.\nBreaking things, or changing things, helps to show what each bit of code does.\n\n\n\n\n\n\n\nData visualization is not really about coding, as about thinking.\n\nWhat are our goals?\nWhy do we make some choices instead of others?\n\n\n\n@gelman2013 outline the goals we may contemplate when we produce or evaluate visual data displays. In general, they argue, we are doing one or both of two things.\n\nDiscovery\nCommunication\n\nIn practice, this may involve the following (I paraphrase them, here).\n\nDiscovery goals\n\n\nGetting a sense of what is in a dataset, checking assumptions, confirming expectations, and looking for distinct patterns.\nMaking sense of the scale and complexity of the dataset.\nExploring the data to reveal unexpected aspects. As we will see, using small multiples (grids of plots) can often help with this.\n\n\nCommunication goals\n\n\nWe communicate about our data to ourselves and to others. The process of constructing and evaluating a plot is often one way we speak to ourselves about own data, developing an understanding of what we have got. Once we have done this for ourselves, we can better figure out how to do it to benefit the understanding of an audience.\nWe often use a plot to tell a story: the story of our study, our data, or our insight and how we get to it.\nWe can use visualizations to attract attention and stimulate interest. Often, in presenting data to an audience through a talk or a report we need to use effective visualizations to ensure we get attention and that we locate the attention of our audience in the right places.\n\n\n\n\nYou will see a rich variety of data visualizations in media and in the research literature. You will know that some choices, in the production of those visualizations, appear to work better than others.\nSome of the reasons why some choices work better will relate to what we can understand in terms of the psychological science of how visual data communication works. A useful recent review of relevant research is presented by @franconeri2021.\n@franconeri2021 provide a reason for working on visualizations: they allow us humans to process an array of information at once, often faster than if we were reading about the information, bit by bit. Effective visualization, then, is about harnessing the power of the human visual system, or visual cognition, for quick, efficient, information processing. Critically for science, in addition, visualizations can be more effective for discovering or communicating the critical features of data than summary statistics, as we shall see.\nIn producing visualizations, we often work with a vocabulary or palette of objects or visual elements. @franconeri2021 discuss how visualizations rely on visual channels to transform numbers into images that we can process visually.\n\nDot plots and scatterplots represent values as position.\nBar graphs represent values as position (the heights of the tops of bars) but also as lengths.\nAngles are presented when we connect points to form a line, allowing us to encode the differences between points.\nIntensity can be presented through variation in luminance contrast or colour saturation.\n\nThese channels can be ordered by how precisely they have been found to communicate different numeric values to the viewer. Your audience may more accurately perceive the difference between two quantities if you communicate that difference through the difference in the location of two points than if you ask your audience to compare the angles of two lines or the intensity of two colour spots.\nIn constructing data visualizations, we often work with conventions, established through common practice in a research tradition. For example, if you are producing a scatterplot, then most of the time your audience will expect to see the outcome (or dependent variable) represented by the vertical height (on the y-axis) of points. And your audience will expect that higher points represent larger quantities of the y-axis variable.\nIn constructing visualizations, we need to be aware of the cognitive work that we require the audience to do. Comparisons are harder, requiring more processing and imposing more load on working memory. You can help your reader by guiding their attention, by grouping or ordering visual elements to identify the most important comparisons. We can vary colour and shape to group or distinguish visual elements. We can add annotation or elements like lines or arrows to guide attention.\nVisualizations are presented in context, whether in presentations or in reports. This context should be provided, by you the producer, with the intention to support the communication of your key messages. A visual representation, a plot, will be presented with a title, maybe a title note, maybe with annotation in the plot, and maybe with accompanying text. You should use these textual elements to lead your audience, to help them make sense of what they are looking at.\nThe diversity of audiences means that we should habitually add alt text for data visualizations to help those who use screen readers by providing a summary description of what images show. This chapter has been written using Quarto and rendered to .html with alt text included along with all images. Please do let me know if you are using a screen reader and the alt text description is or is not so helpful.\nYou can read a helpful explanation of alt text here.\nIf you use colour in images then we should use colour bind colour palettes.\nYou can read about using colour blind palettes here or here.\nIn the following practical exercises, we work with many of the insights in our construction of visualizations.\n\n\n\n\nWe can get started before we understand in depth the key ideas or the coding steps. This will help to show where we are going. We will work with the sleepstudy dataset.\nI will model the process, to give you an example workflow:\n\nthe data, where they come from — what we can find out;\nhow we approach the data — what we expect to see;\nhow we visualize the data — discovery, communication.\n\n\n\nWhen we work with R, we usually work with functions like ggplot() provided in libraries like ggplot2 [@R-ggplot2]. These libraries typically provide not only functions but also datasets that we can use for demonstration and learning.\nThe lme4 library [@R-lme4] provides the sleepstudy dataset and we will take a look at these data to offer a taste of what we can learn to do. Usually, information about the R libraries we use will be located on the Comprehensive R Archive Network (CRAN) web pages, and we can find the technical reference information for lme4 in the CRAN reference manual for the library, where we see that the sleepstudy data are from a study reported by [@belenky2003]. The manual says that the sleepstudy dataset comprises:\n\nA data frame with 180 observations on the following 3 variables. [1.] Reaction – Average reaction time (ms) [2.] Days – Number of days of sleep deprivation [3.] Subject – Subject number on which the observation was made.\n\nWe can take a look at the first few rows of the dataset.\n\nsleepstudy %&gt;%\n    head(n = 4)\n\n  Reaction Days Subject\n1 249.5600    0     308\n2 258.7047    1     308\n3 250.8006    2     308\n4 321.4398    3     308\n\n\nWhat we are looking at are:\n\nThe average reaction time per day (in milliseconds) for subjects in a sleep deprivation study. Days 0-1 were adaptation and training (T1/T2), day 2 was baseline (B); sleep deprivation started after day 2.\n\nThe abstract for @belenky2003 tells us that participants were deprived of sleep and the impact of relative deprivation was tested using a cognitive vigilance task for which the reaction times of responses were recorded.\nSo, we can expect to find:\n\nA set of rows corresponding to multiple observations for each participant (Subject)\nA reaction time value for each participant (Reaction)\nRecorded on each Day\n\n\n\n\nIn data analysis work, we often begin with the objective to understand the structure or the nature of the data we are working with.\nYou can call this the discovery phase:\n\nwhat have we got?\ndoes it match our expectations?\n\nIf these are reaction time data (collected in an cognitive experiment) do they look like cognitive reaction time data should look? We would expect to see a skewed distribution of observed reaction times distributed around an average located somewhere in the range 200-700ms.\nFigure 2 represents the distribution of reaction times in the sleepstudy dataset.\nI provide notes on the code steps that result in the plot. Click on the Notes tab to see them. Later, I will discuss some of these elements.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Reaction)) +\n  geom_histogram(binwidth = 15) +\n  geom_vline(xintercept = mean(sleepstudy$Reaction), \n             colour = \"red\", linetype = 'dashed', size = 1.5) +\n  annotate(\"text\", x = 370, y =20, \n                    colour = \"red\", \n                    label = \"Average value shown in red\") +\n  theme_bw()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nFigure 2: Figure showing a histogram of sleepstudy reaction time data\n\n\n\n\n\n\n\nThe plotting code pipes the data into the plotting code steps to produce the plot. You can see some elements that will be familiar to you and some new elements.\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Reaction)) +\n  geom_histogram(binwidth = 15) +\n  geom_vline(xintercept = mean(sleepstudy$Reaction), \n             colour = \"red\", linetype = 'dashed', size = 1.5) +\n  annotate(\"text\", x = 370, y =20, \n                    colour = \"red\", \n                    label = \"Average value shown in red\") +\n  theme_bw()\n\nLet’s go through the code step-by-step:\n\nsleepstudy %&gt;% asks R to take the sleepstudy dataset and %&gt;% pipe it to the next steps for processing.\nggplot(aes(x = Reaction)) + takes the sleepstudy data and asks R to use the ggplot() function to produce a plot.\naes(x = Reaction) tells R that in the plot we want it to map the Reaction variable values to locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = 15) + tells R to produce a histogram then add a step.\ngeom_vline(...) + tells R we want to draw vertical line.\nxintercept = mean(sleepstudy$Reaction), ... tells R to draw the vertical line at the mean value of the variable Reaction in the sleepstudy dataset.\ncolour = \"red\", linetype = 'dashed', size = 1.5 tells R we want the vertical line to be red, dashed and 1.5 times the usual size.\nannotate(\"text\", ...) tells R we want to add a text note.\nx = 370, y =20, ... tells R we want the note added at the x,y coordinates given.\ncolour = \"red\", ..; and we want the text in red.\n...label = \"Average value shown in red\") + tells R we want the text note to say that this is where the average is.\ntheme_bw() lastly, we change the theme.\n\n\n\n\nFigure 2 shows a distribution of reaction times, ranging from about 200ms to 500ms. The distribution has a peak around 300ms. The location of the mean is shown with a dashed red line. The distribution includes a long tail of longer times. This is pretty much what we would expect to see.\nWe may wish to communicate the information we gain through using this histogram, in a presentation or in a report.\n\n\n\nLet us imagine that it is our study. (Here, we shall not concern ourselves too much — with apologies — with understanding what the original study authors actually did.)\nIf we are looking at the impact of sleep deprivation on cognitive performance, we might predict that reaction times got longer (responses slowed) as the study progressed. Is that what we see?\nTo examine the association between two variables, we often use scatterplots. Figure 3 is a scatterplot indicating the possible association between reaction time and days in the sleepstudy data. Points are ordered on x-axis from 0 to 9 days, on y-axis from 200 to 500 ms reaction time.\nI provide notes on the code steps that result in the plot. Click on the Notes tab to see them. Later, I will discuss some of these elements.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point(size = 1.5, alpha = .5) + \n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 3: Figure showing a scatterplot of the relation between reaction time and days in the sleepstudy data\n\n\n\n\n\n\n\nNotice the numbered steps in producing this plot.\n\nsleepstudy %&gt;% \n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  theme_bw()\n\n\nName the dataset: the dataset is called sleepstudy in the lme4 library which makes it available therefore we use this name to specify it.\nsleepstudy %&gt;% uses the %&gt;% pipe operator to pass this dataset to ggplot() to work with, in creating the plot. Because ggplot() now knows about the sleepstudy data, we can next specify what aesthetic mappings we need to use.\nggplot(aes(x = Days, y = Reaction)) + tells R that we want to map Days information to x-axis position and Reaction (response time) information to y-axis position.\ngeom_point() + tells R that we want to locate points – creating a scatterplot – at the paired x-axis and y-xis coordinates.\nscale_x_continuous(breaks = c(0, 3, 6, 9)) + is new: we tell R that we want the x-axis tick labels – the numbers R shows as labels on the x-axis – at the values 0, 3, 6, 9 only.\ntheme_bw() requires R to make the plot background white and the foreground plot elements black.\n\nYou can find more information on scale_ functions in the ggplot2 reference information.\nhttps://ggplot2.tidyverse.org/reference/scale_continuous.html\n\n\n\nThe plot suggests that reaction time increases with increasing number of days.\nIn producing this plot, we are both (1.) engaged in discovery and, potentially, (2.) able to do communication.\n\nDiscovery: is the relation between variables what we should expect, given our assumptions?\nCommunication: to ourselves and others, what relation do we observe, given our sample?\n\nAt this time, we have used and discussed scatterplots before, why we use them, how we write code to produce them, and how we read them.\nWith two additional steps we can significantly increase the power of the visualization. Figure 4 is a grid of scatterplots indicating the possible association between reaction time and days separately for each participant.\nAgain, I hide an explanation of the coding steps in the Notes tab: the interested reader can click on the tab to view the step-by-step guide to what is happening.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  mutate(average = mean(Reaction)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Subject = fct_reorder(Subject, average)) %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  geom_line() +\n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  facet_wrap(~ Subject) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 4: Figure showing a scatterplot of the relation between reaction time and days: here, we plot the data for each participant separately\n\n\n\n\n\n\n\nNotice the numbered steps in producing this plot.\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  mutate(average = mean(Reaction)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Subject = fct_reorder(Subject, average)) %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  geom_line() +\n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  facet_wrap(~ Subject) +\n  theme_bw()\n\nYou can see that the block of code combines data processing and data plotting steps. Let’s look at the data processing steps then the plotting steps in order.\nFirst: why are we doing this? My aim is to produce a plot in which I show the association between Days and Reaction for each Subject individually. I suspect that the association between Days and Reaction may be stronger – so the trend will be steeper – for participants who are slower overall. I suspect this because, given experience, I know that slower, less accurate, participants tend to show larger effects.\nSo: in order to get a grid of plots, one plot for each Subject, in order of the average Reaction for each individual Subject, I need to first calculate the average Reaction then order the dataset rows by those averages. I do that in steps, using pipes to feed information from one step to the next step, as follows.\n\nsleepstudy %&gt;% tells R what data I want to use, and pipe it to the next step.\ngroup_by(Subject) tells R I want it to work with data (rows) grouped by Subject identity code, %&gt;% piping the grouped form of the data forward to the next step\nmutate(average = mean(Reaction)) uses mutate() to create a new variable average which I calculate as the mean() of Reaction, piping the data with this additional variable %&gt;% forward to the next step.\nungroup() %&gt;% tells R I want it to go back to working with the data in rows not grouped rows, and pipe the now ungrouped form of the data to the next step.\nmutate(Subject = fct_reorder(Subject, average)) tells R I want it to sort the rows of the whole sleepstudy dataset in order, moving groups of rows identified by Subject so that data for Subject codes associated with faster times are located near the top of the dataset.\n\nThese data, ordered by Subject by the average Reaction for each participant, are then %&gt;% piped to ggplot to create a plot.\n\nggplot(aes(x = Days, y = Reaction)) + specifies the aesthetic mappings, as before.\ngeom_point() + asks R to locate points at the x-axis, y-axis coordinates, creating a scatterplot, as before.\ngeom_line() + is new: I want R to connect the points, showing the trend in the association between Days and Reaction for each person.\nscale_x_continuous(breaks = c(0, 3, 6, 9)) + fixes the x-axis labels, as before.\nfacet_wrap(~ Subject) + is the big new step: I ask R to plot a separate scatterplot for the data for each individual Subject.\n\nYou can see more information about facetting here:\nhttps://ggplot2.tidyverse.org/reference/facet_wrap.html\nIn short, with the facet_wrap(~ .) function, we are asking R to subset the data by a grouping variable, specified (~ .) by replacing the dot with the name of the variable.\nNotice that I use %&gt;% pipes to move the data processing forward, step by step. But I use + to add plot elements, layer by layer.\n\n\n\nFigure Figure 4 is a grid or lattice of scatterplots revealing how the possible association between reaction time and days varies quite substantially between the participants in the sleepstudy data. Most plots indicate that reaction time increases with increasing number of days. However, different participants show this trend to differing extents.\nWhat are the two additions I made to the conventional scatterplot code?\n\nI calculated the average reaction time per participant, and I ordered the data by those averages.\nI facetted the plots, breaking them out into separate scatterplots per participant.\n\nWhy would you do this? Variation between people or groups, in effects or in average outcomes, are often to be found in psychological data [@vasishth2021]. The variation between people that we see in these data — in the average response reaction time, and in how days affects times — would motivate the use of linear mixed-effects models to analyze the way that sleep patterns affect responses in the sleep study [@Pinheiro2000a].\n\n\n\n\n\n\nTip\n\n\n\nThe data processing and plotting functions in the tidyverse collection of libraries enable us to discover and to communicate variation in behaviours that should strengthen our and others’ scientific understanding.\n\n\n\n\n\nWhat we have seen, so far, is that we can make dramatic changes to the appearance of visualizations (e.g., through faceting) and also that we can exert fine control over the details (e.g., adjusting scale labels). What we need to stop and consider are what we want to do (and why), in what order.\nWe have seen how we can feed a data process into a plot to first prepare then produce the plot in a sequence of steps. In processing the data, we can take some original data and extract or calculate information that we can use for our plotting e.g. calculating the mean of a distribution in order to then highlight where that mean is located.\nWe have also seen the use of plots, and the editing of their appearance, to represent information visually. We can verbalize the thought process behind the production of these plots through a series of questions.\n\nAre we looking at the distribution of one variable (if yes: consider a histogram) or are we comparing the distributions of two or more variables (if yes: consider a scatterplot)?\nIs there a salient feature of the plot we want to draw the attention of the audience to? We can add a visual element (like a line) and annotation text to guide the audience.\nAre we interested in variation between sub-sets of the data? We can facet the plot to examine variation between sub-sets (facets) enabling the comparison of trends.\n\n\n\n\n\nIn this guide, we illustrate some of the ideas about visualization we discussed at the start, working with practical coding examples. We will be working with real data from a published research project. We are going to focus the practical coding examples on the data collected for the analysis reported by @ricketts2021.\n\nWe will focus on working with the data from one of the tasks, in one of the studies reported by @ricketts2021.\n\nThis means that you can consolidate your learning by applying the same code moves to data from the other task in the same study, or to data from the other study.\nIn applying code to other data, you will need to be aware of differences in, say, the way that some things like the outcome response variable are coded.\n\nYou can then further extend your development by trying out the coding moves for yourself using the data collected by @rodríguez-ferreiro2020.\n\nThese data are from a quite distinct kind of investigation, on a different research topic than the topic we will be exploring through our working examples.\nHowever, some aspects of the data structure are similar.\nCritically, the data are provided with comprehensive documentation.\n\n\n\n\nTo do our practical work, we will need functions and data. We get these at the start of our workflow.\n\n\nWe are going to need the lme4, patchwork, psych and tidyverse libraries of functions and data.\n\nlibrary(ggeffects)\nlibrary(patchwork)\nlibrary(psych)\nlibrary(tidyverse)\n\n\n\n\nYou can access the data we are going to use in two different ways.\n\n\nThe data associated with both [@ricketts2021] and [@rodríguez-ferreiro2020] are freely available through project repositories on the Open Science Framework web pages.\nYou can get the data from the @ricketts2021 paper through the repository located here.\nYou can get the data from the @rodríguez-ferreiro2020 paper through the repository located here.\nThese data are associated with full explanations of data collection methods, materials, data processing and data analysis code. You can review the papers and the repository material guides for further information.\nIn the following, I am going to abstract summary information about the @ricketts2021 study and data. I shall leave you to do the same for the @rodríguez-ferreiro2020 study.\n\n\n\nDownload the data.zip files folder and upload the files to RStudio Server.\nThe folder includes the @ricketts2021 data files:\n\nconcurrent.orth_2020-08-11.csv\nconcurrent.sem_2020-08-11.csv\nlong.orth_2020-08-11.csv\nlong.sem_2020-08-11.csv\n\nThe folder also includes the @rodríguez-ferreiro2020 data files:\n\nPrimDir-111019_English.csv\nPrimInd-111019_English.csv\n\n\n\n\n\n\n\nWarning\n\n\n\n\nThese data files are collected together in a folder for download, for your convenience, but the version of record for the data for each study comprise the files located on the OSF repositories associated with the original articles.\n\n\n\n\n\n\n\n\n@ricketts2021 conducted an investigation of word learning in school-aged children. They taught children 16 novel words in a study with a 2 x 2 factorial design. In this investigation, they tested whether word learning is helped by presenting targets for word learning with their spellings, and whether learning is helped by telling children that they would benefit from the presence of those spellings.\nThe presence of orthography (the word spelling) was manipulated within participants (orthography absent vs. orthography present): for all children, eight of the words were taught with orthography present and eight with orthography absent. Instructions (incidental vs. explicit) were manipulated between participants such that children in the explicit condition were alerted to the presence of orthography whereas children in the incidental condition were not.\nA pre-test was conducted to establish participants’ knowledge of the stimuli. Then, each child was seen for three 45-minute sessions to complete training (Sessions 1 and 2) and post-tests (Session 3). @ricketts2021 completed two studies: Study 1 and Study 2. All children, in both studies 1 and 2 completed the Session 3 post-tests.\nIn Study 1, longitudinal post-test data were collected because children were tested at two time points. Children were administered post-tests in Session 3, as noted: Time 1. Post-tests were then re-administered approximately eight months later at Time 2 (\\(M = 241.58\\) days from Session 3, \\(SD = 6.10\\)). In Study 2, the Study 1 sample was combined with an older sample of children. The additional Study 2 children were not tested at Time 2, and the analysis of Study 2 data did not incorporate test time as a factor.\nThe outcome data for both studies consisted of performance on post-tests.\nThe semantic post-test assessed knowledge for the meanings of newly trained words using a dynamic or sequential testing approach. I will not explain this approach in more detail, here, because the practical visualization exercises focus on the orthographic knowledge (spelling knowledge) post-test, explained next.\nThe orthographic post-test was included to ascertain the extent of orthographic knowledge after training. Children were asked to spell each word to dictation and spelling productions were transcribed for scoring. Responses were scored using a Levenshtein distance measure indexing the number of letter deletions, insertions and substitutions that distinguish between the target and child’s response. The maximum score is 0, with higher scores indicating less accurate responses.\nFor the Study 1 analysis, the files are:\n\nlong.orth_2020-08-11.csv\nlong.sem_2020-08-11.csv\n\nWhere long indicates the longitudinal nature of the data-set.\nFor the Study 2 analysis, the files are:\n\nconcurrent.orth_2020-08-11.csv\nconcurrent.sem_2020-08-11.csv\n\nWhere concurrent indicates the inclusion of concurrent (younger and older) child participant samples.\nEach column in each data-set corresponds to a variable and each row corresponds to an observation (i.e., the data are tidy). Because the design of the study involves the collection of repeated observations, the data can be understood to be in a long format.\nEach child was asked to respond to 16 words and, for each of the 16 words, we collected post-test responses from multiple children. All words were presented to all children.\nWe explain what you will find when you inspect the .csv files, next.\n\n\nThe variables included in .csv files are listed, following, with information about value coding or calculation.\n\nParticipant — Participant identity codes were used to anonymize participation. Children included in studies 1 and 2 – participants in the longitudinal data collection – were coded “EOF[number]”. Children included in Study 2 only (i.e., the older, additional, sample) were coded “ND[number]”.\nTime — Test time was coded 1 (time 1) or 2 (time 2). For the Study 1 longitudinal data, it can be seen that each participant identity code is associated with observations taken at test times 1 and 2.\nStudy — Observations taken for children included in studies 1 and 2 – participants in the longitudinal data collection – were coded “Study1&2”. Children included in Study 2 only (i.e., the older, additional, sample) were coded “Study2”.\nInstructions — Variable coding for whether participants undertook training in the explicit or incidental conditions.\nVersion — Experiment administration coding\nWord — Letter string values show the words presented as stimuli to children.\nConsistency_H — Calculated orthography-to-phonology consistency value for each word.\nOrthography — Variable coding for whether participants had seen a word in training in the orthography absent or present conditions.\nMeasure — Variable coding for the post-test measure: Sem_all if the semantic post-test; Orth_sp if the orthographic post-test.\nScore — Variable coding for response category.\n\nFor the semantic (sequential or dynamic) post-test, responses were scored as corresponding to:\n\n3 – correct response in the definition task\n2 – correct response in the cued definition task\n1 – correct response in the recognition task\n0 – if the item wasn’t correctly defined or recognised\n\nFor the orthographic post-test, responses were scored as:\n\n1 – correct, if the target spelling was produced in full\n0 – incorrect\n\nHowever, the analysis reported by @ricketts2021 focused on the more sensitive Levenshtein distance measure (see following).\n\nWASImRS — Raw score – Matrix Reasoning subtest of the Wechsler Abbreviated Scale of Intelligence\nTOWREsweRS — Raw score – Sight Word Efficiency (SWE) subtest of the Test of Word Reading Efficiency; number of words read correctly in 45 seconds\nTOWREpdeRS — Raw score – Phonemic Decoding Efficiency (PDE) subtest of the Test of Word Reading Efficiency; number of nonwords read correctly in 45 seconds\nCC2regRS — Raw score – Castles and Coltheart Test 2; number of regular words read correctly\nCC2irregRS — Raw score – Castles and Coltheart Test 2; number of irregular words read correctly\nCC2nwRS — Raw score – Castles and Coltheart Test 2; number of nonwords read correctly\nWASIvRS — Raw score – vocabulary knowledge indexed by the Vocabulary subtest of the WASI-II\nBPVSRS — Raw score – vocabulary knowledge indexed by the British Picture Vocabulary Scale – Third Edition\nSpelling.transcription — Transcription of the spelling response produced by children in the orthographic post-test\nLevenshtein.Score — Children were asked to spell each word to dictation and spelling productions were transcribed for scoring. Responses were scored using a Levenshtein distance measure indexing the number of letter deletions, insertions and substitutions that distinguish between the target and child’s response. For example, the response ‘epegram’ for target ‘epigram’ attracts a Levenshtein score of 1 (one substitution). Thus, this score gives credit for partially correct responses, as well as entirely correct responses. The maximum score is 0, with higher scores indicating less accurate responses.\n\n(Notice that, for the sake of brevity, I do not list the z_ variables but these are explained in the study OSF repository materials.)\n\n\n\n\n\n\nWarning\n\n\n\nLevenshtein distance scores are higher if a child makes more errors in producing the letters in a spelling response.\n\nThis means that if we want to see what factors help a child to learn a word, including its spelling, then we want to see that helpful factors are associated with lower Levenshtein scores.\n\n\n\nTo demonstrate some of the processes we can enact to process and visualize data, and some of the benefits of doing so, we are going to work with the concurrent.orth_2020-08-11.csv dataset. These are data corresponding to the @ricketts2021 Study 2. concurrent refers to the analysis (a concurrent comparison) of data from younger and older children.\n\n\n\n\nAssuming you have downloaded the data files, we first read the dataset into the R environment: concurrent.orth_2020-08-11.csv. We do the data read in a bit differently than you have seen it done before; we will come back to what is going on (in Section 1.7.4.1).\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\",\n\n                      col_types = cols(\n\n                        Participant = col_factor(),\n                        Time = col_factor(),\n                        Study = col_factor(),\n                        Instructions = col_factor(),\n                        Version = col_factor(),\n                        Word = col_factor(),\n                        Orthography = col_factor(),\n                        Measure = col_factor(),\n                        Spelling.transcription = col_factor()\n\n                      ))\n\nWe can inspect these data using summary().\n\nsummary(conc.orth)\n\n  Participant   Time          Study         Instructions Version\n EOF001 :  16   1:1167   Study1&2:655   explicit  :592   a:543  \n EOF002 :  16            Study2  :512   incidental:575   b:624  \n EOF004 :  16                                                   \n EOF006 :  16                                                   \n EOF007 :  16                                                   \n EOF008 :  16                                                   \n (Other):1071                                                   \n         Word     Consistency_H     Orthography     Measure    \n Accolade  : 73   Min.   :0.9048   absent :583   Orth_sp:1167  \n Cataclysm : 73   1st Qu.:1.5043   present:584                 \n Contrition: 73   Median :1.9142                               \n Debacle   : 73   Mean   :2.3253                               \n Dormancy  : 73   3rd Qu.:3.0436                               \n Epigram   : 73   Max.   :3.9681                               \n (Other)   :729                                                \n     Score           WASImRS     TOWREsweRS      TOWREpdeRS       CC2regRS    \n Min.   :0.0000   Min.   : 5   Min.   :51.00   Min.   :19.00   Min.   :28.00  \n 1st Qu.:0.0000   1st Qu.:13   1st Qu.:69.00   1st Qu.:35.00   1st Qu.:36.00  \n Median :0.0000   Median :17   Median :74.00   Median :41.00   Median :38.00  \n Mean   :0.2913   Mean   :16   Mean   :74.23   Mean   :41.59   Mean   :36.91  \n 3rd Qu.:1.0000   3rd Qu.:19   3rd Qu.:80.00   3rd Qu.:50.00   3rd Qu.:39.00  \n Max.   :1.0000   Max.   :25   Max.   :93.00   Max.   :59.00   Max.   :40.00  \n                                                                              \n   CC2irregRS       CC2nwRS         WASIvRS          BPVSRS     \n Min.   :17.00   Min.   :13.00   Min.   :16.00   Min.   :103.0  \n 1st Qu.:23.00   1st Qu.:29.00   1st Qu.:25.00   1st Qu.:119.0  \n Median :25.00   Median :33.00   Median :29.00   Median :133.0  \n Mean   :25.24   Mean   :32.01   Mean   :29.12   Mean   :130.9  \n 3rd Qu.:27.00   3rd Qu.:37.00   3rd Qu.:33.00   3rd Qu.:142.0  \n Max.   :35.00   Max.   :40.00   Max.   :39.00   Max.   :158.0  \n                                                                \n Spelling.transcription Levenshtein.Score  zTOWREsweRS        zTOWREpdeRS      \n Epigram   : 57         Min.   :0.000     Min.   :-2.67807   Min.   :-2.33900  \n Platitude : 43         1st Qu.:0.000     1st Qu.:-0.60283   1st Qu.:-0.68243  \n Contrition: 42         Median :1.000     Median :-0.02638   Median :-0.06122  \n fracar    : 39         Mean   :1.374     Mean   : 0.00000   Mean   : 0.00000  \n Nonentity : 39         3rd Qu.:2.000     3rd Qu.: 0.66537   3rd Qu.: 0.87061  \n raconter  : 35         Max.   :7.000     Max.   : 2.16415   Max.   : 1.80243  \n (Other)   :912                                                                \n   zCC2regRS        zCC2irregRS          zCC2nwRS          zWASIvRS       \n Min.   :-3.3636   Min.   :-2.22727   Min.   :-3.1053   Min.   :-2.63031  \n 1st Qu.:-0.3435   1st Qu.:-0.60461   1st Qu.:-0.4920   1st Qu.:-0.82633  \n Median : 0.4115   Median :-0.06373   Median : 0.1614   Median :-0.02456  \n Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.00000  \n 3rd Qu.: 0.7890   3rd Qu.: 0.47716   3rd Qu.: 0.8147   3rd Qu.: 0.77721  \n Max.   : 1.1665   Max.   : 2.64070   Max.   : 1.3047   Max.   : 1.97986  \n                                                                          \n    zBPVSRS         mean_z_vocab       mean_z_read       zConsistency_H   \n Min.   :-1.9946   Min.   :-2.06910   Min.   :-2.39045   Min.   :-1.4153  \n 1st Qu.:-0.8495   1st Qu.:-0.85941   1st Qu.:-0.43321   1st Qu.:-0.8181  \n Median : 0.1525   Median :-0.01483   Median : 0.08829   Median :-0.4096  \n Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.0000  \n 3rd Qu.: 0.7967   3rd Qu.: 0.72964   3rd Qu.: 0.68438   3rd Qu.: 0.7157  \n Max.   : 1.9418   Max.   : 1.96083   Max.   : 1.52690   Max.   : 1.6368  \n                                                                          \n\n\nYou should notice one key bit of information in the summary. Focus on the summary for what is in the Participant column. You can see that we have a number of participants in this dataset, listed by Participant identity code in the summary() view e.g. EOF001. For each participant, we have 16 rows of data.\nWhen we ask R for a summary of a nominal variable or factor it will show us the levels of each factor (i.e., each category or class of objects encoded by the categorical variable), and a count for the number of observations for each level.\nTake a look at the rows of data for EOF001.\n\n\n\n\n\nParticipant\nTime\nStudy\nInstructions\nVersion\nWord\nConsistency_H\nOrthography\nMeasure\nScore\nWASImRS\nTOWREsweRS\nTOWREpdeRS\nCC2regRS\nCC2irregRS\nCC2nwRS\nWASIvRS\nBPVSRS\nSpelling.transcription\nLevenshtein.Score\nzTOWREsweRS\nzTOWREpdeRS\nzCC2regRS\nzCC2irregRS\nzCC2nwRS\nzWASIvRS\nzBPVSRS\nmean_z_vocab\nmean_z_read\nzConsistency_H\n\n\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nAccolade\n1.9142393\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nacalade\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.4095955\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nCataclysm\n3.5060075\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nCataclysm\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.1763372\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nContrition\n1.7486898\nabsent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nContrition\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.5745381\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nDebacle\n2.9008386\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\ndibarcle\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.5733869\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nDormancy\n1.6263089\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\ndoormensy\n3\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.6964704\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nEpigram\n1.3822337\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nEpigram\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.9396508\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nFoible\n2.7051987\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nFoible\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.3784641\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nFracas\n3.1443345\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nfracar\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.8159901\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nLassitude\n0.9048202\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nlacitude\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.4153141\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nLuminary\n1.0985931\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nloomenery\n4\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.2222516\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nNonentity\n3.9681391\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nnonenterty\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.6367746\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nPlatitude\n0.9048202\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nPlatitude\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.4153141\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nPropensity\n1.6861898\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\npropencity\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.6368090\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nRaconteur\n3.8245334\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nraconter\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.4936954\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nSyncopation\n3.0436450\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nsincipation\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.7156697\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nVeracity\n2.8693837\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nvaracity\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.5420473\n\n\n\n\n\n\n\nYou can see that for EOF001, as for every participant, we have information on the conditions under which we observed their responses (Instructions, Orthography), as well as information about the stimuli that we asked participants to respond to (e.g., Word, Consistency_H), information about the responses or outcomes we recorded (Measure, Score, Spelling.transcription,  Levenshtein.Score), and information about the participants themselves (e.g., TOWREsweRS, TOWREpdeRS).\n\n\n\nWe almost always need to process data in order to render the information ready for discovery or communication data visualization.\n\n\nYou will have seen that data processing began when we first read the data in for use. Let’s go back and take a look at the code steps.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\",\n\n                      col_types = cols(\n\n                        Participant = col_factor(),\n                        Time = col_factor(),\n                        Study = col_factor(),\n                        Instructions = col_factor(),\n                        Version = col_factor(),\n                        Word = col_factor(),\n                        Orthography = col_factor(),\n                        Measure = col_factor(),\n                        Spelling.transcription = col_factor()\n\n                        )\n                      )\n\nThe chunk of code is doing two things: first, we tell R what .csv file we want to read into the environment, and what we want to call the dataset; and then we tell R how we want to classify the data variable columns.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\" first reads the named .csv file, creating an object I will call conc.orth: a dataset or tibble we can now work with in R.\n\n\nYou have been using the read.csv() function to read in data files.\nThe read_csv() function is the more modern tidyverse form of the function you were introduced to.\nBoth versions work in similar ways but read_csv() is a bit more efficient, and it allows us to do what we do next.\n\n\ncol_types = cols( ... ) tells R how to interpret some of the columns in the .csv.\n\n\nThe read_csv() function is excellent at working out what types of data are held in each column but sometimes we have to tell it what to do.\nHere, I am specifying with e.g. Participant = col_factor() that the Participant column should be treated as a categorical or nominal variable, a factor.\n\nUsing the col_types = cols( ... ) argument saves me from having to first read the data in then using code like the following to require, technically, coerce R into recognizing the nominal nature of variables like Participant with code like\n\nconc.orth$Participant &lt;- as.factor(conc.orth$Participant)\n\n\n\nI do not have to do step 2 of the read-in process, here. What happens if we use just read_csv()? Try it.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\")\n\n\n\n\nYou can read more about read_csv() here\nYou can read more about col_types = cols() here\n\n\n\n\nThe @ricketts2021 dataset orth.conc is a moderately sized and rich dataset with several observations, on multiple variables, for each of many participants. Sometimes, we want to extract information from a more complex dataset because we want to understand or present a part of it, or a relatively simple account of it. We look at an example of how you might do that now.\nAs you saw when you looked at the summary of the orth.conc dataset, we have multiple rows of data for each participant. Recall the design of the study. For each participant, we recorded their response to a stimulus word, in a test of word learning, for 16 words.\nFor each participant, we have a separate row for each response the participant made to each word. But you will have noticed that information about the participant is repeated. So, for participant EOF001, we have data about their performance e.g. on the BPVSRS vocabulary test (they scored 126). Notice that that score is repeated: the same value is copied for each row, for this participant, in the BPVSRS column. The reason the data are structured like this are not relevant here 1 but it does require us to do some data processing, as I explain next.\nIt is a very common task to want to present a summary of the attributes of your participants or stimuli when you are reporting data in a report of a psychological research project. We could get a summary of the participant attributes using the psych library describe function as follows.\n\nconc.orth %&gt;%\n  select(WASImRS:BPVSRS) %&gt;%\n  describe(ranges = FALSE, skew = FALSE)\n\n           vars    n   mean    sd   se\nWASImRS       1 1167  16.00  4.30 0.13\nTOWREsweRS    2 1167  74.23  8.67 0.25\nTOWREpdeRS    3 1167  41.59  9.66 0.28\nCC2regRS      4 1167  36.91  2.65 0.08\nCC2irregRS    5 1167  25.24  3.70 0.11\nCC2nwRS       6 1167  32.01  6.12 0.18\nWASIvRS       7 1167  29.12  4.99 0.15\nBPVSRS        8 1167 130.87 13.97 0.41\n\n\nBut you can see that part of the information in the summary does not appear to make sense at first glance. We do not have 1167 participants in this dataset, as @ricketts2021 report.\nHow do we extract the participant attribute variable data for each unique participant code for the participants in our dataset?\n\nconc.orth.subjs &lt;- conc.orth %&gt;%\n  group_by(Participant) %&gt;%\n  mutate(mean.score = mean(Levenshtein.Score)) %&gt;%\n  ungroup() %&gt;%\n  distinct(Participant, .keep_all = TRUE) %&gt;%\n  select(WASImRS:BPVSRS, mean.score, Participant)\n\nWe create a new dataset conc.orth.subjs by taking conc.orth and piping it through a series of processing steps. As part of the process, we want to extract the data for each unique unique Participant identity code using distinct(). Along the way, we want to calculate the mean accuracy of response on the outcome measure (Score), that is, the average number of edits separating a child’s spelling of a target word from the correct spelling.\nThis is how we do it.\n\nconc.orth.subjs &lt;- ... tells R to create a new dataset conc.orth.subjs.\nconc.orth %&gt;% ... we do this by telling R to take conc.orth and pipe it through the following steps.\ngroup_by(Participant) %&gt;% first we group the data by Participant identity code.\nmutate(mean.score = mean(Score)) %&gt;% then we use mutate() to create the new variable mean.score by calculating the mean() of the Score variable values (i.e. the average score) for each participant. We then pipe to the next step.\nungroup() %&gt;% we tell R to ungroup the data because we want to work with all rows for what comes next, and we then pipe to the next step.\ndistinct(Participant, .keep_all = TRUE) %&gt;% requires R to extract from the full orth.conc dataset the set of (here, 16) data rows we have for each distinct (uniquely identified) Participant. We use the argument .keep_all = TRUE to tell R that we want to keep all columns. This requires the next step, so we tell R to pipe %&gt;% the data.\nselect(WASImRS:BPVSRS, mean.score, Participant) then tells R to select just the columns with information about participant attributes. (WASImRS:BPVSRS tells R to select every column between WASImRS and BPVSRS inclusive. mean.score, Participant tells R we also want those columns, specified by name, including the mean.score column of average response scores we calculated just earlier.\n\nWe can now get a sensible summary of the descriptive statistics for the participants in Study 2 of the @ricketts2021 investigation.\n\nconc.orth.subjs %&gt;%\n  select(-Participant) %&gt;%\n  describe(ranges = FALSE, skew = FALSE)\n\n           vars  n   mean    sd   se\nWASImRS       1 73  16.00  4.33 0.51\nTOWREsweRS    2 73  74.22  8.73 1.02\nTOWREpdeRS    3 73  41.58  9.73 1.14\nCC2regRS      4 73  36.90  2.67 0.31\nCC2irregRS    5 73  25.23  3.72 0.44\nCC2nwRS       6 73  32.00  6.17 0.72\nWASIvRS       7 73  29.12  5.02 0.59\nBPVSRS        8 73 130.88 14.06 1.65\nmean.score    9 73   1.38  0.62 0.07\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis is exactly the kind of tabled summary of descriptive statistics we would expect to produce in a report, in a presentation of the participant characteristics for a study sample (in e.g., the Methods section).\nNotice:\n\nThe table has not yet been formatted according to APA rules.\nWe would prefer to use real words for row name labels instead of dataset variable column labels, e.g, replace TOWREsweRS with: “TOWRE word reading score”.\n\n\n\n\n\nIn these bits of demonstration code, we extract information relating just to participants. However, in this study, we recorded the responses participants made to 16 stimulus words, and we include in the dataset information about the word properties Consistency_H.\n\nCan you adapt the code you see here in order to calculate a mean score for each word, and then extract the word-level information for each distinct stimulus word identity?\n\n\n\n\nYou can read more about the psych library, which is often useful, here. You can read more about the distinct() function here.\n\n\n\n\n\nIt has taken us a while but now we are ready to examine the data using visualizations. Remember, we are engaging in visualization to (1.) do discovery, to get a sense of our data, and maybe reveal unexpected aspects, and (2.) potentially to communicate to ourselves and others what we have observed or perhaps what insights we can gain.\nWe have been learning to use histograms, in other classes, so let’s start there.\n\n\n\nWe can use histograms to visualize the distribution of observed values for a numeric variable. Let’s start simple, and then explore how to elaborate the plotting code, in a series of edits, to polish the plot presentation.\n\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram()\n\n\n\n\n\n\n\nFigure 5: Distribution of WASImRS intelligence scores\n\n\n\n\n\nThis is how the code works.\n\nggplot(data = conc.orth.subjs, ... tells R what function to use ggplot() and what data to work with data = conc.orth.subjs.\naes(x = WASImRS) tells R what aesthetic mapping to use: we want to map values on the WASImRS variable (small to large) to locations on the x-axis (left to right).\ngeom_histogram() tells R to construct a histogram, presenting a statistical summary of the distribution of intelligence scores.\n\nWith histograms, we are visualizing the distribution of a single continuous variable by dividing the variable values into bins (i.e. subsets) and counting the number of observations in each bin. Histograms display the counts with bars.\nYou can see more information about geom_histogram here.\nFigure 5 shows how intelligence (WASImRS) scores vary in the Ricketts Study 2 dataset. Scores peak around 17, with a long tail of lower scores towards 5, and a maximum around 25.\n\nWhere I use the word “peak” I am talking about the tallest bar in the plot (or, later the highest point in a density curve). At this point, we have the most observations of the value under the bar. Here, we observed the score WASImRS \\(= 17\\) for the most children in this sample.\n\nA primary function of discovery visualization is to assess whether the distribution of scores on a variable is consistent with expectations, granted assumptions about a sample (e.g., that the children are typically developing). We would normally use research area knowledge to assess whether this distribution fits expectations for a sample of typically developing school-aged children in the UK. However, I shall leave that concern aside, here, so that we can focus on enriching the plot presentation, next.\nThere are two main problems with the plot:\n\nThe bars are “gappy” in the histogram, suggesting we have not grouped observed values in sufficiently wide subsets (bins). This is a problem because it weakens our ability to gain or communicate a visual sense of the distribution of scores.\nThe axis labeling uses the dataset variable name WASImRS but if we were to present the plot to others we could not expect them to know what that means.\n\nWe can fix both these problems, and polish the plot for presentation, through the following code steps.\n\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"Scores on the Wechsler Abbreviated Scale of Intelligence\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 6: Distribution of WASImRS intelligence scores\n\n\n\n\n\nFigure 6 shows the same data, and furnishes us with the same picture of the distribution of intelligence scores but it is a bit easier to read. We achieve this by making three edits.\n\ngeom_histogram(binwidth = 2) + we change the binwidth.\n\n\nThis is so that more different observed values of the data variable are included in bins (subsets corresponding to bars) so that the bars correspond to information about a wider range of values.\nThis makes the bars bigger, wider, and closes the gaps.\nAnd this means we can focus the eyes of the audience for our plot on the visual impression we wish to communicate: the skewed distribution of intelligence scores.\n\n\nlabs(x = \"Scores on the Wechsler Abbreviated Scale of Intelligence\") + changes the label to something that should be understandable by people, in our audience, who do not have access to variable information (as we do) about the dataset.\ntheme_bw() we change the overall appearance of the plot by changing the theme.\n\n\n\nWe could, if we wanted, add a line and annotation to indicate the mean value, as you saw in Figure 2.\n\nCan you add the necessary code to indicate the mean value of WASI scores, for this plot?\n\nWe can, of course, plot histograms to indicate the distributions of other variables.\n\nCan you apply the histogram code to plot histograms of other variables?\n\n\n\n\n\nWe may wish to discover or communicate how values vary on dataset variables in two different ways. Sometimes, we need to examine how values vary on different variables. And sometimes, we need to examine how values vary on the same variable but in different groups of participants (or stimuli) or under different conditions. We look at this next. We begin by looking at how you might compare how values vary on different variables.\n\n\nIt can be useful to compare the distributions of different variables. Why?\nConsider the @ricketts2021 investigation dataset. Like many developmental investigations (see also clinical investigations), we tested children and recorded their scores on a series of standardized measures, here, measures of ability on a range of dimensions. We did this, in part, to establish that the children in our sample are operating at about the level one might expect for typically developing children in cognitive ability dimensions of interest: dimensions like intelligence, reading ability or spelling ability. So, one of the aspects of the data we are considering is whether scores on these dimensions are higher or lower than typical threshold levels. But we also want to examine the distributions of scores because we want to find out:\n\nif participants are varied in ability (wide distribution) or if maybe they are all similar (narrow distribution) as would be the case if the ability measures are too easy (so all scores are at ceiling) or too hard (so all scores are at floor);\nif there are subgroups within the sample, maybe reflected by two or more peaks;\nif there are unusual scores, maybe reflected by small peaks at very low or very high scores.\n\nWe could look at each variable, one plot at a time. Instead, next, I will show you how to produce a set of histogram plots, and present them all as a single grid of plots.\n\n\n\n\n\n\nWarning\n\n\n\nI have to warn you that the way I write the code is not good practice. The code is written with repeats of the ggplot() block of code to produce each plot. This repetition is inefficient and leaves the coding vulnerable to errors because it is hard to spot a mistake in more code. What I should do is encapsulate the code as a function (see here). The reason I do not, here, is because I want to focus our attention on just the plotting.\n\n\nFigure 7 presents a grid of plots showing how scores vary for each ability test measure, for the children in the @ricketts2021 investigation dataset. We need to go through the code steps, next, and discuss what the plots show us (discovery and communication).\n\np.WASImRS &lt;- ggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"WASI matrix\") +\n  theme_bw()\n\np.TOWREsweRS &lt;- ggplot(data = conc.orth.subjs, aes(x = TOWREsweRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"TOWRE words\") +\n  theme_bw()\n\np.TOWREpdeRS &lt;- ggplot(data = conc.orth.subjs, aes(x = TOWREpdeRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"TOWRE phonemic\") +\n  theme_bw()\n\np.CC2regRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2regRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC regular words\") +\n  theme_bw()\n\np.CC2irregRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2irregRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC irregular words\") +\n  theme_bw()\n\np.CC2nwRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2nwRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC nonwords\") +\n  theme_bw()\n\np.WASIvRS &lt;- ggplot(data = conc.orth.subjs, aes(x = WASIvRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"WASI vocabulary\") +\n  theme_bw()\n\np.BPVSRS &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS)) +\n  geom_histogram(binwidth = 3) +\n  labs(x = \"BPVS vocabulary\") +\n  theme_bw()\n\np.mean.score &lt;- ggplot(data = conc.orth.subjs, aes(x = mean.score)) +\n  geom_histogram(binwidth = .25) +\n  labs(x = \"Mean orthographic test score\") +\n  theme_bw()\n\np.mean.score + p.BPVSRS + p.WASIvRS + p.WASImRS +\n  p.CC2nwRS + p.CC2irregRS + p.CC2regRS + \n  p.TOWREpdeRS + p.TOWREsweRS + plot_layout(ncol = 3)\n\n\n\n\n\n\n\nFigure 7: Distribution of childrens’ scores on ability measures\n\n\n\n\n\nThis is how the code works, step by step:\n\np.WASImRS &lt;- ggplot(...) first creates a plot object, which we call p.WASImRS.\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) + tells R what data to use, and what aesthetic mapping to work with mapping the variable WASImRS here to the x-axis location.\ngeom_histogram(binwidth = 2) + tells R to sort the values of WASImRS scores into bins and create a histogram to show how many children in the sample present scores of different sizes.\nlabs(x = \"WASI matrix\") + changes the x-axis label to make it more informative.\ntheme_bw() changes the theme to make it a bit cleaner looking.\n\nWe do this bit of code separately for each variable. We change the plot object name, the x = variable specification, and the axis label text for each variable. We adjust the binwidth where it appears to be necessary.\nWe then use the following plot code to put all the plots together in a single grid.\n\np.mean.score + p.BPVSRS + p.WASIvRS + p.WASImRS +\n  p.CC2nwRS + p.CC2irregRS + p.CC2regRS + \n  p.TOWREpdeRS + p.TOWREsweRS + plot_layout(ncol = 3)\n\n\nIn the code, we add a series of plots together e.g. p.mean.score + p.BPVSRS + p.WASIvRS ...\nand then specify we want a grid of plots with a layout of three columns plot_layout(ncol = 3).\n\nThis syntax requires the library(patchwork) and more information about this very useful library can be found here.\nWhat do the plots show us?\nFigure 7 shows a grid of 9 histogram plots. Each plot presents the distribution of scores for the @ricketts2021 Study 2 participant sample on a separate ability measure, including scores on the BPVS vocabulary, WASI vocabulary, TOWRE words and TOWRE nonwords reading tests, as well as scores on the Castles and Coltheart regular words, irregular words and nonwords reading tests, and the mean Levenshtein distance (spelling score) outcome measure of performance for the experimental word learning post-test.\nTake a look, you may notice the following features.\n\nThe mean orthographic test score suggests that many children produced spellings to the words they learned in the @ricketts2021 study that, on average, were correct (0 edits) or were one or two edits (e.g., a letter deletion or replacement) away from the target word spelling. The children were learning the words, and most of the time, they learned the spellings of the words effectively. However, one or two children tended to produce spellings that were 2-3 edits distant from the target spelling.\n\n\nWe can see these features because we can see that the histogram peaks around 1 (at Levenshtein distance score \\(= 1\\)) but that there is a small bar of scores at around 3.\n\n\nWe can see that there are two peaks on the BPVS and WASI measures of vocabulary. What is going on there?\n\n\nIs it the case that we have two sub-groups of children within the overall sample? For example, on the BPVS test, maybe one sub-group of children has a distribution of vocabulary scores with a peak around 120 (the peak shows where most children have scores) while another sub-group of children has a distribution of vocabulary scores with a peak around 140.\n\n\nIf we look at the CC nonwords and CC regular words tests of reading ability, we may notice that while most children present relatively high scores on these tests (CC nonwords peak around 35, CC regular words peak around 37) there is a skewed distribution. Many of the children’s scores are piled up towards the maximum value in the data on the measures. But we can also see that, on both measures, there are long tails in the distributions because relatively small numbers of children have substantially lower scores.\n\n\nDevelopmental samples are often highly varied (just like clinical samples). Are all the children in the sample at the same developmental stage, or are they all typically developing?\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that in presenting a grid of plots like this, we offer a compact visual way to present the same summary information we might otherwise present using a table of descriptive statistics. In some ways, this grid of plots is more informative than the descriptive statistics because the mean and SD values do not tell you what you can see:\n\nthe characteristics of the variation in values, like the presence of two peaks;\nor the presence of unusually high or low scores (for this sample).\n\n\n\nGrids of plots like this can be helpful to inspect the distributions of variables in a concise approach. They are not really too useful for comparing the distributions because they require your eyes to move between plots, repeatedly, to do the comparison.\nHere is a more compact way to code the grid of histograms using the library(ggridges) function geom_density_ridges(). I do not discuss it in detail because I want to focus your attention on core tidyverse functions (I show you more information in the Notes tab).\nNotice that if you produce all the plots so that the are in line in the same column with a shared x-axis it becomes much easier to compare the distributions of scores. You lose some of the fine detail, discussed in relation to Figure 7, but this style allows you to gain an impression, quickly, of how for distributions of scores compare between measures. For example, we can see that within the Castles and Coltheart (CC) measures of reading ability, children do better on regular words than on nonwords, and on nonwords better than on irregular words.\n\nPlotNotes\n\n\n\nlibrary(ggridges)\nconc.orth.subjs %&gt;%\n  pivot_longer(names_to = \"task\", values_to = \"score\", cols = WASImRS:mean.score) %&gt;% \n  ggplot(aes(y = task, x = score)) +\n  geom_density_ridges(stat = \"binline\", bins = 20, scale = 0.95, draw_baseline = FALSE) +\n  theme_ridges()\n\n\n\n\n\n\n\nFigure 8: Distribution of childrens’ scores on ability measures\n\n\n\n\n\n\n\n\nlibrary(ggridges) get the library we need.\nconc.orth.subjs %&gt;% pipe the dataset for processing.\npivot_longer(names_to = \"task\", values_to = \"score\", cols = WASImRS:mean.score) %&gt;% pivot the data so all test scores are in the same column, “scores” wwith coding for “task” name, and pipe to the next step for plotting.\nggplot(aes(y = task, x = score)) + create a plot for the scores on each task.\ngeom_density_ridges(stat = \"binline\", bins = 20, scale = 0.95, draw_baseline = FALSE) + show the plots as histograms.\ntheme_ridges() change the theme to the specific theme suitable for showing a grid of ridges.\n\nYou can find more information on ggridges here.\n\n\n\n\n\n\nWe will often want to compare the distributions of variable values between groups or between conditions. This need may appear when, for example, we are conducting a between-groups manipulation of some condition and we want to check that the groups are approximately matched on dimensions that are potentially linked to outcomes (i.e., on potential confounds). The need may appear when, alternatively, we have recruited or selected participant (or stimulus) samples and we want to check that the sample sub-groups are approximately matched or detectably different on one or more dimensions of interest or of concern.\nAs a demonstration of the visualization work we can do in such contexts, let’s pick up on an observation we made earlier, that there are two peaks on the BPVS and WASI measures of vocabulary. I asked: Is it the case that we have two sub-groups of children within the overall sample? Actually, we know the answer to that question because @ricketts2021 state that they recruited one set of children for their Study 1 and then, for Study 2:\n\nThirty-three children from an additional three socially mixed schools in the South-East of England were added to the Study 1 sample (total N = 74). These additional children were older (\\(M_{age}\\) = 12.57, SD = 0.29, 17 female)\n\nDo the younger (Study 1) children differ in any way from the older (additional) children?\nWe can check this through data visualization. Our aim is to present the distributions of variables side-by-side or superimposed to ensure easy comparison. We can do this in different ways, so I will demonstrate one approach with an outline explanation of the actions, and offer suggestions for further approaches.\nI am going to process the data before I do the plotting. I will re-use the code I used before (see Section 1.7.4.2) with one additional change. I will add a line to create a group coding variable. This addition shows you how to do an action that is very often useful in the data processing part of your workflow.\n\n\nYou have seen that the @ricketts2021 report states that an additional group of children was recruited for the investigation’s second study. How do we know who they are? If you recall the summary view of the complete dataset, there is one variable we can use to code group identity.\n\nsummary(conc.orth$Study)\n\nStudy1&2   Study2 \n     655      512 \n\n\nThis summary tells us that we have 512 observations concerning the additional group of children recruited for Study 2, and 655 observations for the (younger) children whose data were analyzed for both Study 1 and Study 2 (i.e., coded as Study1&2 in the Study variable column). We can use this information to create a coding variable. (If we had age data, we could use that instead but we do not.) This is how we do that.\n\nconc.orth.subjs &lt;- conc.orth %&gt;%\n  group_by(Participant) %&gt;%\n  mutate(mean.score = mean(Levenshtein.Score)) %&gt;%\n  ungroup() %&gt;%\n  distinct(Participant, .keep_all = TRUE) %&gt;%\n  mutate(age.group = fct_recode(Study,\n    \n    \"young\" = \"Study1&2\",\n    \"old\" = \"Study2\"\n    \n  )) %&gt;%\n  select(WASImRS:BPVSRS, mean.score, Participant, age.group)\n\nThe code block is mostly the same as the code I used in Section Section 1.7.4.2 to extract the data for each participant, with two changes:\n\nFirst, mutate(age.group = fct_recode(...) tells R that I want to create a new variable age.group through the process of recoding, with fct_recode(...) the variable I specify next, in the way that I specify.\nfct_recode(Study, ...) tells R I want to recode the variable Study.\n\"young\" = \"Study1&2\", \"old\" = \"Study2\" specifies what I want recoded.\n\n\nI am telling R to look in the Study column and (a.) whenever it finds the value Study1&2 replace it with young whereas (b.) whenever it finds the value Study2 replace it with old.\nNotice that the syntax in recoding is fct_recode: “new name” = “old name”.\nHaving done that, I tell R to pipe the data, including the recoded variable, to the next step.\n\n\nselect(WASImRS:BPVSRS, mean.score, Participant, age.group) where I add the new recoded variable to the selection of variables I want to include in the new dataset conc.orth.subjs.\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that R handles categorical or nominal variables like Study (or, in other data, variables e.g. gender, education or ethnicity) as factors.\n\nWithin a classification scheme like education, we may have different classes or categories or groups e.g. “further, higher, school”. We can code these different classes with numbers (e.g. \\(school = 1\\)) or with words “further, higher, school”. Whatever we use, the different classes or groups are referred to as levels and each level has a name.\nIn factor recoding, we are changing level names while keeping the underlying data the same.\n\n\n\nThe tidyverse collection includes the forcats library of functions for working with categorical variables (forcats = factors). These functions are often very useful and you can read more about them here.\nChanging factors level coding by hand is, for many, a common task, and the fct_recode() function makes it easy. You can find the technical information on the function, with further examples, here.\n\n\n\nThere are different ways to examine the distributions of variables so that we can compare the distributions of the same variable between groups.\nFigure 9 presents some alternatives as a grid of 4 different kinds of plots designed to enable the same comparison. Each plot presents the distribution of scores for the @ricketts2021 Study 2 participant sample on the BPVS vocabulary measure so that we can compare the distribution of vocabulary scores between age groups.\nThe plots differ in method using:\n\nfacetted histograms showing the distribution of vocabulary scores, separately for each group, in side-by-side histograms for comparison;\nboxplots, showing the distribution of scores for each group, indicated by the y-axis locations of the edges of the boxes (25% and 75% quartiles) and the middle lines (medians);\nsuperimposed histograms, where the histograms for the separate groups are laid on top of each other but given different colours to allow comparison; and\nsuperimposed density plots where the densities for the separate groups are laid on top of each other but given different colours to allow comparison.\n\n\n\n\n\n\n\nTip\n\n\n\nThere is one thing you should notice about all these plots.\n\nIt looks like the BPVS vocabulary scores have their peak – most children show this value – at around 120 for the young group and at around 140 for the old group.\n\nWe return to this shortly.\n\n\n\nI am going to hide the coding and the explanation of the coding behind the Notes tab. Click on the tab to get a step-by-step explanation. Of these alternatives, I focus on one which I explain in more depth, following: d. Superimposed density plots.\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 9: Distribution of childrens’ scores on the BPVS vocabulary measure: distributions are compared between the younger and older age groups\n\n\n\n\n\n\n\n\np.facet.hist &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"BPVS vocabulary score\", title = \"a. Faceted histograms\") +\n  facet_wrap(~ age.group) +\n  theme_bw()\n\np.colour.boxplot &lt;- ggplot(data = conc.orth.subjs, aes(y = BPVSRS, colour = age.group)) +\n  geom_boxplot() +\n  labs(x = \"BPVS vocabulary score\", title = \"b. Boxplots\") +\n  theme_bw()\n\np.colour.hist &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"BPVS vocabulary score\", title = \"c. Superimposed histograms\") +\n  theme_bw()\n\np.colour.density &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  labs(x = \"BPVS vocabulary score\", title = \"d. Superimposed density plots\") +\n  theme_bw()\n\np.facet.hist + p.colour.boxplot + p.colour.hist + p.colour.density\n\n\nIn plot “a. Faceted histograms”, we use the code to construct a histogram but the difference is we use:\n\n\nfacet_wrap(~ age.group) to tell R to split the data by age.group then present the histograms indicating vocabulary score distributions separately for each group.\n\n\nIn plot “b. Boxplots”, we use the geom_boxplot() code to construct a boxplot to summarize the distributions of vocabulary scores – as you have seen previously – but the difference is we use:\n\n\naes(y = BPVSRS, colour = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\n\n\nIn plot “c. Superimposed histograms”, we use the code to construct a histogram but the difference is we use:\n\n\naes(x = BPVSRS, colour = age.group, fill = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\nNotice that the fill gives the colour inside the bars and colour gives the colour of the outline edges of the bars.\n\n\nIn plot “d. Superimposed density plots”, we use the code geom_density(...) to construct what is called a density plot.\n\n\nA density plot presents a smoothed histogram to show the distribution of variable values.\nWe add arguments in geom_density(alpha = .5, size = 1.5) to adjust the thickness of the line (size = 1.5) drawn to show the shape of the distribution and adjust the transparency of the colour fill inside the line alpha = .5).\nWe useaes(x = BPVSRS, colour = age.group, fill = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\nNotice that the fill gives the colour inside the density plots and colour gives the colour of the outline edges of the densities.\n\n\n\n\nDensity plots can be helpful when we wish to compare distributions. This is because we can superimpose distribution plots on top of each other, enabling us or our audience to directly compare the distributions: directly because the distributions are shown on the same scale, in the same image.\nWe can (roughly) understand a density plot as working like a smoothed version of the histogram. Imagine how the heights of the bars in the histogram represent how many observations we have of the values in a particular bin. If we draw a smooth curving line through the tops of the bars then we are representing the chances that an observation in our sample has a value (the value under the curve) at any specific location on the x-axis. You can see that in Figure 10.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nFigure 10: Distribution of childrens’ scores on the BPVS vocabulary measure. The figure shows the histogram versus density plot representation of the same data distribution\n\n\n\n\n\nYou can find the ggplot2 reference information on the geom_density() function, with further examples, here. You can find technical information on density functions here and here.\nWe can develop the density plot to enrich the information we can discover or communicate through the plot. Figure 11 shows the distribution of scores on both the BPVS and WASI vocabulary knowledge measures.\n\np.BPVSRS.density &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  geom_rug(alpha = .5) +\n  geom_vline(xintercept = 120, linetype = \"dashed\") +\n  geom_vline(xintercept = 140, linetype = \"dotted\") +\n  labs(x = \"BPVSRS vocabulary score\") +\n  theme_bw()\n\np.WASIvRS.density &lt;- ggplot(data = conc.orth.subjs, aes(x = WASIvRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  geom_rug(alpha = .5) +\n  labs(x = \"WASI vocabulary score\") +\n  theme_bw()\n\np.BPVSRS.density + p.WASIvRS.density + plot_layout(guides = 'collect')\n\n\n\n\n\n\n\nFigure 11: Distribution of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nHere is what the code does:\n\np.BPVRS.density &lt;- ggplot(...) creates a plot object called p.BPVRS.density.\ndata = conc.orth.subjs, ... says we use the conc.orth.subjs dataset to do this.\naes(x = BPVRS, colour = age.group, fill = age.group)) + says we want to map BPVRS scores to x-axis location, and age.group level coding (young, old) to both colour and fill.\ngeom_density(alpha = .5, size = 1.5) + draws a density plot; note that we said earlier what we want for colour and fill but here we also say that:\n\n\nalpha = .5 we want the fill to be transparent;\nsize = 1.5 we want the density curve line to be thicker than usual.\n\n\ngeom_rug(alpha = .5) + adds a one-dimensional plot, a series of tick marks, to show where we have observations of BPVRS scores for specific children. We ask R to make the tick marks semi-transparent.\ngeom_vline(xintercept = 120, linetype = \"dashed\") + draws a vertical dashed line where BPVRS = 120.\ngeom_vline(xintercept = 140, linetype = \"dotted\") + draws a vertical dotted line where BPVRS = 140.\nlabs(x = \"BPVS vocabulary score\") + makes the x-axis label something understandable to someone who does not know about the study.\ntheme_bw() changes the theme.\n\n\n\n\nAs we work with visualization, we should aim to develop skills in reading plots, so:\n\nWhat do we see?\n\nWhen we look at Figure 11, we can see that the younger and older children in the @ricketts2021 sample have broadly overlapping distributions of vocabulary scores. However, as we have noticed previously, the peak of the distribution is a bit lower for the younger children compared to the older children. This appears to be the case whether we are looking at the BPVS or at the WASI measures of vocabulary, suggesting that the observation does not depend on the particular vocabulary test. Is this observation unexpected? Probably not, as we should hope to see vocabulary knowledge increase as children get older. Is this observation a problem for our analysis? You need to read the paper to find out what we decided.\n\n\n\nIn the demonstration examples, I focused on comparing age groups on vocabulary, what about the other measures?\nI used superimposed density plots: are other plotting styles more effective, for you? Try using boxplots or superimposed or faceted histograms instead.\n\n\n\n\n\nSo far, we have looked at how and why we may examine the distributions of numeric variables. We have used histograms to visualize the distribution of variable values. We have explored the construction of grids of plots to enable the quick examination or concise communication of information about the distributions of multiple variables at the same time. And we have used histograms, boxplots and density plots to examine how the distributions of variables may differ between groups.\nThe comparison of the distributions of variable values in different groups (or, similarly, between different conditions) may be the kind of work we would need to do, in data visualization, as part of an analysis ending in, for example, a t-test comparison of mean values.\nWhile boxplots, density plots and histograms are typically used to examine how the values of a numeric variable vary, scatterplots are typically used when we wish to examine, to make sense of or communicate potential associations or relations between two (or more) numeric variables. We turn to scatterplots, next.\n\n\n\nMany of us start learning about scatterplots in high school math classes. Using the modern tools made available to us through the ggplot2 library (as part of tidyverse), we can produce effective, nice-looking, scatterplots for a range of discovery or communication scenarios.\nWe continue working with the @ricketts2021 dataset. In the context of the @ricketts2021 investigation, there is interest in how children vary in the reading, spelling and vocabulary abilities that may influence the capacity of children to learn new words. So, in this context, we can begin to progress our development in visualization skills by usefully considering the potential association between participant attributes in the Study 2 sample.\nLater on, we will look at more advanced plots that help us to communicate the impact of the experimental manipulations implemented by @ricketts2021, and also to discover the ways that these impacts may vary between children.\n\n\nWe can begin by asking a simple research question we can guess the answer to:\n\nDo vocabulary knowledge scores on two alternative measures, the BPVS and the WASI, relate to each other?\n\nIf two measurement instruments or tests are intended to measure individual differences in the same psychological attribute, here, vocabulary knowledge, then we would reasonably expect that scores on one test should covary with scores on the second test.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 12: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nWhat does the plot show us?\nAs a reminder of how scatterplots work, we can recall that they present integrated information. Each point, for the @ricketts2021 data, represents information about both the BPVS and the WASI score for each child.\n\nThe vertical height of a point tells us the BPVS score recorded for a child: higher points represent higher scores.\nThe left-to-right horizontal position of the same point tells us the WASI score for the same child: points located more on the right represent higher scores.\n\nFigure 12 is a scatterplot comparing variation in childrens’ scores on the BPVS and WASI vocabulary measures: variation in BPVS scores are shown on the y-axis and variation in WASI scores are shown on the x-axis. Critically, the scientific insight the plot gives us is this: higher WASI scores are associated with higher BPVS scores.\nHow does the code work? We have seen scatterplots before but, to ensure we are comfortable with the coding, we can go through them step by step.\n\nggplot(data = conc.orth.subjs...) + tells R we want to produce a plot using ggplot() with the conc.orth.subjs dataset.\naes(x = WASIvRS, y = BPVSRS) tells R that, in the plot, WASIvRS values are mapped to x-axis (horizontal) position and BPVSRS values are mapped to y-axis (vertical) position.\ngeom_point() + constructs a scatterplot, using these data and these position mappings.\nlabs(x = \"WASI vocabulary score\", ... fixes the x-axis label.\ny = \"BPVSRS vocabulary score\",... fixes the y-axis label.\ntitle = \"Are WASI and BPVS vocabulary scores associated?\") + fixes the title.\ntheme_bw() changes the theme.\n\n\n\n\nFor this pair of variables in this dataset, the potential association in the variation of scores is quite obvious. However, sometimes it is helpful to guide the audience by imposing a smoother. There are different ways to do this, for different objectives and in different contexts. Here, we look at two different approaches. In addition, as we go, we examine how to adjust the appearance of the plot to address different potential discovery or communication needs.\nWe begin by adding what is called a LOESS smoother.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 13: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nThe only coding difference between this plot Figure 13 and the previous plot Figure 12 appears at line 3:\n\ngeom_smooth()\n\nThe addition of this bit of code results in the addition of the curving line you see in Figure 13. The blue line is curving, and visually suggests that the relation between BPVS and WASI scores is different – sometimes more sometimes less steep – for different values of WASI vocabulary score.\nThis line is generated by the geom_smooth() code, by default, in an approach in which the dataset is effectively split into sub-sets, dividing the data up into sub-sets from the lowest to the highest WASI scores, and the predicted association between the y-axis variable (here, BPVS score) and the x-axis variable (here, WASI score) is calculated bit by bit, in a series of regression analyses, working in order through sub-sets of the data. This calculation of what is called the LOESS (locally estimated scatterplot smoothing) trend is done by ggplot for us. And this approach to visualizing the trend in a potential association between variables is often a helpful way to discover curved or non-linear relations.\nYou can find technical information on geom_smooth() here and an explanation of LOESS here.\nFor us, this default visualization is not helpful for two reasons:\n\nWe have not yet learned about linear models, so learning about LOESS comes a bit early in our development.\nIt is hard to look at Figure 13 and identify a convincing curvilinear relation between the two variables. A lot of the curve for low WASI scores appears to be linked to the presence of a small number of data points.\n\nAt this stage, it is more helpful to adjust the addition of the smoother. We can do that by adding an argument to the geom_smooth() function code.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 14: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nNotice the difference between Figure 13 and Figure 14:\n\ngeom_smooth(method = 'lm') tells R to draw a trend line, a smoother, using the lm method.\n\nThe lm method requires R to estimate the association between the two variables, here, BPVS and WASI, assuming a linear model. Of course, we are going to learn about linear models but, in short, right now, what we need to know is that we assume a “straight line” relationship between the variables. This assumption requires that for any interval of WASI scores – e.g., whether we are talking about WASI scores between 20-25 or about WASI scores between 30-35 – the relation between BPVS and WASI scores has the same shape: the direction and steepness of the slope of the line is the same.\n\n\n\n\nDeveloping skill in working with data visualizations is not just about developing coding skills, it is also about developing skills in reading, and critically evaluating, the information the plots we produce show us.\n\nStop and take a good look at the scatterplot in Figure 14. Use the visual representation of data to critically evaluate the potential association between the BPVS and WASI variables. What can you see?\nYou can train your critical evaluation by asking yourself questions like the following:\n\nHow does variation in the x-axis variable relate to variation in values of the y-axis variable?\n\n\nWe can see, here, that higher WASI scores are associated with higher BPVS scores.\n\n\nHow strong is the relation?\n\n\nThe strength of the relation can be indicated by the steepness of the trend indicated by the smoother, here, the blue line.\nIf you track the position of the line, you can see, for example, that going from a WASI score of 20 to a WASI score of 40 is associated with going from a BPVS score of a little over 110 to a BPVS score of about a 150.\nThat seems like a big difference.\n\n\nHow well does the trend we are looking at capture the data in our sample?\n\n\nHere, we are concerned with how close the points are to the trend line.\nIf the trend line represents a set of predictions about how the BPVS scores vary (in height) given variation in WASI scores, we can see that in places the prediction is not very good.\nTake a look at the points located at WASI 25. We can see that there there are points indicating that different children have the same WASI score of 25 but BPVS scores ranging from about 115 to 140.\n\n\n\n\nFigure 14 presents a satisfactory looking plot but it is worth checking what edits we can make to the appearance of the plot, to indicate some of the ways that you can exercise choice in determining what a plot looks like. This will be helpful to you when you are constructing plots for presentation and report and you want to ensure the plots are as effective as possible.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point(alpha = .5, size = 2) +\n  geom_smooth(method = 'lm', colour = \"red\", size = 1.5) +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  xlim(0, 40) + ylim(0, 160) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 15: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nIf you inspect the code, you can see that I have made three changes:\n\ngeom_point(alpha = .5, size = 2 changes the size of the points and their transparency (using alpha).\ngeom_smooth(method = 'lm', colour = \"red\", size = 1.5) change the colour of the smoother line, and the thickness (size) of the line.\nxlim(0, 40) + ylim(0, 160) changes the axis limits.\n\nThe last step — changing the axis limits — reveals how the sample data can be understood in the context of possible scores on these ability measures. Children could get BPVS scores of 0 or WASI scores of 0. By showing the start of the axes we get a more realistic sense of how our sample compares to the possible ranges of scores we could see in the wider population of children. This perhaps offers a more honest or realistic visualization of the potential association between BPVS and WASI vocabulary scores.\n\n\n\nAs we have seen previously, we can construct a series of plots and present them all at once in a grid or lattice. Figure 16 presents just such a grid: of scatterplots, indicating a series of potential associations.\nLet’s suppose that we are primarily interested in what factors influence the extent to which children in the @ricketts2021 word learning experiment are able to correctly spell the target words they were given to learn. As explained earlier, in Section 1.7.2, @ricketts2021 examined the spellings produced by participant children in response to target words, counting how many string edits (i.e., letter deletions etc.) separated the spelling each child produced from the target spelling they should have produced.\nWe can calculate the mean spelling accuracy score for each child, over all the target words we observed their response to. We can identify mean spelling score as the outcome variable. We can then examine whether the outcome spelling scores are or are not influenced by participant attributes like vocabulary knowledge.\nFigure 16 presents a grid of scatterplots indicating the potential association between mean spelling score and each of the variables we have in the conc.orth dataset, including the Castles and Coltheart (CC) and TOWRE measures of word or nonword reading skill, WASI and BPVS measures of vocabulary knowledge, and the WASI matrix measure of intelligence, as well as (our newly coded) age group factor.\nI hide an explanation of the coding behind the Notes tab, because we have seen how to produce grids of plots, but you can take a look if you want to learn how the plot is produced.\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 16: Grid of scatterplots showing the potential association between mean spelling score, for each child, and variation in the Castles and Coltheart (CC) and TOWRE measures of word or nonword reading skill, WASI and BPVS measures of vocabulary knowledge, the WASI matrix measure of intelligence, and age group factor\n\n\n\n\n\n\n\nThe code to produce the figure is set out as follows.\n\np.wordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                              y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Word reading\", \n       y = \"Spelling score\",\n       title = \"(a.)\") +\n  theme_bw()\n\np.nonwordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Nonword reading\", \n       y = \"Spelling score\",\n       title = \"(b.)\") +\n  theme_bw()\n\np.WASIvRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = WASIvRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"WASI vocabulary\", \n       y = \"Spelling score\",\n       title = \"(c.)\") +\n  theme_bw()\n\np.BPVSRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = BPVSRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"BPVS vocabulary score\", \n       y = \"Spelling score\",\n       title = \"(d.)\") +\n  theme_bw()\n\np.WASImRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = WASImRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"WASI matrix\", \n       y = \"Spelling score\",\n       title = \"(e.)\") +\n  theme_bw()\n\np.CC2regRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2regRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC regular words\", \n       y = \"Spelling score\",\n       title = \"(f.)\") +\n  theme_bw()\n\np.CC2irregRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2irregRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC irregular words\", \n       y = \"Spelling score\",\n       title = \"(g.)\") +\n  theme_bw()\n\np.CC2nwRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2nwRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC nonwords\", \n       y = \"Spelling score\",\n       title = \"(h.)\") +\n  theme_bw()\n\np.age.groupvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = age.group, \n                                  y = mean.score)) +\n  geom_boxplot() +\n  labs(x = \"Age group\", \n       y = \"Spelling score\",\n       title = \"(i.)\") +\n  theme_bw()\n\np.wordsvsmean.score + p.nonwordsvsmean.score + p.WASIvRSvsmean.score +\n  p.BPVSRSvsmean.score + p.WASImRSvsmean.score + p.CC2regRSvsmean.score +\n  p.CC2irregRSvsmean.score + p.CC2nwRSvsmean.score + p.age.groupvsmean.score\n\n\nTo produce the grid of plots, we first create a series of plot objects using code like that shown in the chunk.\n\n\np.wordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                              y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Word reading\", \n       y = \"Spelling score\",\n       title = \"(a.)\") +\n  theme_bw()\n\n\np.wordsvsmean.score &lt;- ggplot(...) creates the plot.\ndata = conc.orth.subjs tells R what data to work with.\naes(x = TOWREsweRS, y = mean.score) specifies the aesthetic data mappings.\ngeom_point(alpha = .5, size = 3) tells R to produce a scatterplot, specifying the size and transparency of the points.\ngeom_smooth(method = 'lm', size = 1.5) tells R to add a smoother, specifying the method and the thickness of the line.\nlabs(x = \"Word reading\", y = \"Spelling score\", title = \"(a.)\") fixes the labels.\ntheme_bw() adjusts the theme.\n\n\nWe then put the plots together, using the patchwork syntax where we list the plot objects by name, separating each name by a +.\n\n\np.BPVSRSvsmean.score + p.WASImRSvsmean.score + p.CC2regRSvsmean.score +\n  p.CC2irregRSvsmean.score + p.CC2nwRSvsmean.score + p.age.groupvsmean.score\n\n\n\n\nFigure 16 allows us to visually represent the potential association between an outcome measure, the average spelling score, and a series of other variables that may or may not have an influence on that outcome. Using a grid in this fashion allows us to compare the extent to which different variables appear to have an influence on the outcome. We can see, for example, that measures of variation in word reading skill appear to have stronger association (the trend lines are more steeply slowed) than measures of vocabulary knowledge or intelligence, or age group.\nUsing grids of plots like this allow us to compactly communicate these potential associations in a single figure.\n\n\n\n\n\n\nWarning\n\n\n\nLevenshtein distance scores are higher if a child makes more errors in producing the letters in a spelling response.\n\nThis means that if we want to see what factors help a child to learn a word, including its spelling, then we want to see that helpful factors are associated with lower Levenshtein scores.\n\n\n\n\n\n\n\nAs explained in Section 1.7.2, in the @ricketts2021 study, we taught children taught 16 novel words in a study with a 2 x 2 factorial design. The presence of orthography (orthography absent vs. orthography present) was manipulated within participants: for all children, eight of the words were taught with orthography (the word spelling) present and eight with orthography absent. Instructions (incidental vs. explicit) were manipulated between participants such that children in the explicit condition were alerted to the presence of orthography whereas children in the incidental condition were not. The @ricketts2021 investigation was primarily concerned with the effects on word learning of presenting words for learning with or without showing the words with their spellings, with or without instructing students explicitly that they would be helped by the presence of the spellings.\nWe can analyze the effects of orthography and instruction using a linear model.\n\nmodel &lt;- lm(Levenshtein.Score ~ Instructions*Orthography, data = conc.orth)\n\nThe model code estimates variation in spelling score (values of the Levenshtein.Score) variable, given variation in the levels of the Instructions and Orthography factors, and their interaction.\nThis model is a limited approximation of the analysis we would need to do with these data to estimate the effects of orthography and instruction; see @ricketts2021 for more information on what analysis is required (in our view). However, it is good enough as a basis for exploring the kind of data visualization work — in terms of both discovery and communication — that you can do when you are working with data from an experimental study.\nWe can get a summary of the model results which presents the estimated effect of each experimental factor. These estimates represent the predicted change in spelling score, given variation in Orthography (present, absent) or Instruction (explicit, incidental), and given the possibility that the effect of the presence of orthography is different for different levels of instruction.\nNotice that some of the p-values are incorrectly shown as 0.000. This is a result of using functions to automatically take a model summary and generate a table. I am going to leave this error with a warning because our focus is on visualization, next.\n\n\n\nModel summary\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.584\n0.072\n21.857\n0.000\n\n\nInstructionsincidental\n-0.041\n0.103\n-0.396\n0.692\n\n\nOrthographypresent\n-0.409\n0.103\n-3.987\n0.000\n\n\nInstructionsincidental:Orthographypresent\n0.060\n0.146\n0.409\n0.683\n\n\n\n\n\n\n\nVery often, when we complete a statistical analysis of outcome data, in which we estimate or test the effects on outcomes of variation in some variables or of variation in experimental conditions, then we present a table summary of the analysis results. However, these estimates are typically difficult to interpret (it gets easier with practice) and talk about. Take a look at the summary table. We are often to focus on whether effects are significant or not significant. But, really, what we should consider is how much the outcome changes given the different experimental conditions.\nHow do we get that information from the analysis results? We can communicate results — to ourselves or to an audience — by constructing plots from the model information. The ggeffects library extends ggplot2 to enable us to do this quite efficiently.\nWhen we write code to fit a linear model like:\n\nmodel &lt;- lm(Levenshtein.Score ~ Instructions*Orthography, data = conc.orth)\n\nWe record the results as an object called model because we specify model &lt;- lm(...). We can take these results and ask R to create a plot showing predicted change in outcome (spelling) given our model. We can then present the effects of the variables, as shown in Figure 17.\n\ndat &lt;- ggpredict(model, terms = c(\"Instructions\", \"Orthography\"))\nplot(dat, facet = TRUE) + ylim(0, 3)\n\n\n\n\n\n\n\nFigure 17: Dot and whisker plots showing the predicted effect on outcome spelling (Levenshtein) score, given different experimental conditions: Orthography (present, absent) x Instruction (explicit, incidental).\n\n\n\n\n\nThe code works as follows:\n\ndat &lt;- ggpredict(model, terms = c(\"Instructions\", \"Orthography\")) tells R to calculate predicted outcomes, given our model information, for the factors \"Instructions\", \"Orthography\".\nplot(dat, facet = TRUE) plot the effects, given the predictions, showing the effect of different instruction conditions in different plot facets (the left and right panels).\nylim(0, 3) fix the y-axis to show a more honest indication of the effect on outcomes, given the potential range of spelling scores can start at 0.\n\nIn Figure 17, the dots represent the linear model estimates of outcome spelling, predicted under different conditions. The plots indicate that spelling scores are predicted to be lower when orthography is present. There appears to be little or no effect associated with different kinds of instruction.\nThe vertical lines (often termed “whiskers”) indicate the 95% confidence interval about these estimates. Confidence intervals (CIs) are often mis-interpreted so I will give the quick definition outlined by @Hoekstra2014 here:\n\nA CI is a numerical interval constructed around the estimate of a parameter [i.e. the model estimate of the effect]. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95 % of the cases.\n\nIn short, the interval shows us the range of values within which we can expect to capture the effects of interest, in the long run, if we were to run our experiment over and over again.\nGiven our data and our model, these intervals indicate where the outcome might be expected to vary, given different conditions, and that is quite useful information. If you look at Figure 17, you can see that the presence of orthography (present versus absent) appears to shift outcome spelling, on average, by about a quarter of a letter edit: from over 1.5 to about 1.25. This is about one quarter of the difference, on average, between getting a target spelling correct and getting it wrong by one letter (e.g., the response ‘epegram’ for the target ‘epigram’). This is a relatively small effect but we may consider how such small effects add up, over a child’s development, cumulatively, in making the difference between wrong or nearly right spellings to correct spellings.\nIn the @ricketts2021 paper, we conducted Bayesian analyses which allow us to plot the estimated effects of experimental conditions along with what are called credible intervals indicating our uncertainty about the estimates. In a Bayesian analysis, we can indicate the probable or plausible effect of conditions, or range of plausible effects, given our data and our model. (This intuitive sense of the probable location of effects is, sometimes, what researchers and students mis-interpret confidence intervals as showing; @Hoekstra2014.) Accounting for our uncertainty is a productive approach to considering how much we learn from the evidence we collect in experiments.\nBut this gets ahead of where we are now in our development of skills and understanding. There is another way to discover how uncertain we may be about the results of our analysis. This is an approach we have already experienced: plotting trends or estimates together with the observed data points. We present an example in Figure 18.\n\nplot(dat, add.data = TRUE)\n\n\n\n\n\n\n\nFigure 18: Dot and whisker plots showing the predicted effect on outcome spelling (Levenshtein) score, given different experimental conditions: Orthography (present, absent) x Instruction (explicit, incidental). The estimates are shown as dot-whisker points. In addition, the plot shows as points the spelling score observed for each child for each response recorded in the conc.orth dataset.\n\n\n\n\n\nFigure 18 reveals the usefulness of plotting model estimates of effects alongside the raw observed outcomes. We can make two critical observations.\n\nWe can see that the observed scores clearly cluster around outcome spelling values of 0, 1, 2, 3, 4, and 5.\n\n\nThis is not a surprise because @ricketts2021 scored each response in their test of spelling knowledge by counting the number of letter edits (letter deletions, additions etc.) separating a spelling response from a target response.\nBut the plot does suggest that the linear model is missing something about the outcome data because there is no recognition in the model or the results of this bunching or clustering around whole number values of the outcome variable. (This is why @ricketts2021 use a different analysis approach.)\n\n\nWe can also see that it is actually quite difficult to distinguish the effects of the experimental condition differences on the observed spelling responses. There is a lot of variation in the responses.\n\nHow can we make sense of this variation?\nAnother approach we can take to experimental data is to examine visually how the effects of experimental conditions vary between individual participants. Usually, in teaching, learning and doing foundation or introductory statistical analyses we think about the average impact on outcomes of the experimental conditions or some set of predictor variables. It often makes sense, also, or instead, to consider the ways that the impact on outcomes vary between individuals.\nHere, it might be worthwhile to look at the effect of the conditions for each child. We can do that in different ways. In the following, we will look at a couple of approaches that are often useful. We will focus on the effect of variation in the Orthography condition (present, absent)\nTo begin our work, we first calculate the average outcome (Levenshtein.Score) spelling score for each child in each of the experimental conditions (Orthography, present versus absent):\nWe do this in a series of steps.\n\nscore.by.subj &lt;- conc.orth %&gt;%\n  group_by(Participant, Orthography) %&gt;%\n  summarise(mean.score = mean(Levenshtein.Score))\n\n\nscore.by.subj &lt;- conc.orth %&gt;% create a new dataset score.by.subj by taking the original data conc.orth and piping it through a series of processing steps, to follow.\ngroup_by(Participant, Orthography) %&gt;% first group the rows of the original dataset and piped the grouped data to the next bit. We group the data by participant identity code and by Orthography condition\nsummarise(mean.score = mean(Levenshtein.Score)) then calculate the mean Levenshtein.Score for each participant, for their responses in the Orthography present and in the Orthography absent conditions.\n\nThis first step produces a summary version of the original dataset, with two mean outcome spelling scores for each child, for their responses in the Orthography present and in the Orthography absent conditions. This arranges the summary mean scores in rows, with two rows per child: one for the absent, one for the present condition. You can see what we get in the extract from the dataset, shown next.\n\n\n\n\n\nParticipant\nOrthography\nmean.score\n\n\n\n\nEOF001\nabsent\n1.750\n\n\nEOF001\npresent\n0.875\n\n\nEOF002\nabsent\n1.375\n\n\nEOF002\npresent\n2.125\n\n\nEOF004\nabsent\n1.625\n\n\nEOF004\npresent\n1.000\n\n\nEOF006\nabsent\n0.750\n\n\nEOF006\npresent\n0.500\n\n\nEOF007\nabsent\n1.500\n\n\nEOF007\npresent\n0.625\n\n\n\n\n\n\n\nIn the second step, we also calculate the difference between spelling scores in the different Orthography conditions. We do this because @ricketts2021 were interested in whether spelling responses were different in the different conditions.\n\nscore.by.subj.diff &lt;- score.by.subj %&gt;%\n  pivot_wider(names_from = Orthography, values_from = mean.score) %&gt;%\n  mutate(difference.score = absent - present) %&gt;%\n  pivot_longer(cols = c(absent, present), \n               names_to = 'Orthography',\n               values_to = 'mean.score') \n\n\nscore.by.subj.diff &lt;- score.by.subj %&gt;% creates a new version of the summary dataset from the dataset we just produced.\npivot_wider(names_from = Orthography, values_from = mean.score) %&gt;% re-arranges the dataset so that the absent, present mean scores are side-by-side, in different columns, for each child.\nmutate(difference.score = absent - present) %&gt;% calculates the difference between the absent, present mean scores, creating a new variable, difference.score.\npivot_longer(cols = c(absent, present) ...) re-arranges the data back again so that the dataset is in tidy format, with one column of mean spelling scores, with two rows for each participant for the absent, present mean scores.\n\nThis code arranges the summary mean scores in rows, with two rows per child: one for the absent, one for the present condition — plus a difference score.\n\n\n\n\n\nParticipant\ndifference.score\nOrthography\nmean.score\n\n\n\n\nEOF001\n0.875\nabsent\n1.750\n\n\nEOF001\n0.875\npresent\n0.875\n\n\nEOF002\n-0.750\nabsent\n1.375\n\n\nEOF002\n-0.750\npresent\n2.125\n\n\nEOF004\n0.625\nabsent\n1.625\n\n\nEOF004\n0.625\npresent\n1.000\n\n\nEOF006\n0.250\nabsent\n0.750\n\n\nEOF006\n0.250\npresent\n0.500\n\n\nEOF007\n0.875\nabsent\n1.500\n\n\nEOF007\n0.875\npresent\n0.625\n\n\n\n\n\n\n\nNow we can use these data to consider how the impact of the experimental condition (Orthography: present versus absent) varies between individual participants. We do this by showing the mean outcome spelling score, separately for each participant, in each condition.\nFigure 19 shows dot plots indicating the different outcome spelling (Levenshtein) scores, for each participant, in the different experimental conditions: Orthography (present, absent). Plots are ordered, from top left to bottom right, by the difference between mean spelling scores in the absent versus present conditions. The plots indicate that some children show higher spelling scores in the present than in the absent condition (top left plots), some children show little difference between conditions (middle rows), while some children show higher spelling scores in the absent than in the present condition (bottom rows).\n\nggplot(data = score.by.subj.diff, \n       aes(x = Orthography, y = mean.score,\n           colour = Orthography)) +\n  geom_point() +\n  facet_wrap(~ reorder(Participant, difference.score)) +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\nFigure 19: Dot plots showing the different outcome spelling (Levenshtein) scores, for each participant, in the different experimental conditions: Orthography (present, absent). Plots are ordered, from top left to bottom right, by the difference between mean spelling scores in the absent versus present conditions.\n\n\n\n\n\nOnce we have done the data processing in preparation, the code to produce the plot is fairly compact.\n\nggplot(data = score.by.subj.diff ... tells R to produce a plot, using ggplot() and the newly created score.by.subj.diff dataset.\naes(x = Orthography, y = mean.score,... specifies the aesthetic mappings: we tell R to locate mean.score on the y-axis and Orthography condition on the x-axis/\naes(...colour = Orthography)) + specifies a further aesthetic mapping: we tell R to map different Orthography conditions to different colours.\ngeom_point() + tells R to take the data and produce a scatterplot, given our mapping specifications.\nfacet_wrap(...) + tells to split the dataset into sub-sets (facets).\nfacet_wrap(~ reorder(Participant, difference.score)) tells R that we want the sub-sets to be organized by Participant, and we want the facets to be ordered by the difference.score calculated for each participant.\ntheme(axis.text.x = element_blank()) removes the x-axis labels because it is too crowded with the axis labels left in, and the information is already present in the colour guide legend shown on the right of the plot.\n\n\n\n\nVisualizing associations between variables encompasses a wide range of the things we have to do, in terms of both discovery and communication, when we work with data from psychological experiments.\nThe conventional method to visualize how the distribution of values in one variable covaries with the distribution of values in another variable is through using a scatterplot. However, the construction of a scatterplot can be elaborated in various ways to enrich the information we present or communicate to our audiences, or to ourselves.\n\nWe can add elements like smoothers to indicate trends.\nWe can add annotation, as with the histograms, to highlight specific thresholds.\nWe can facet the plots to indicate how trends may vary between sub-sets of the data.\n\nIn the final phases of our practical work, we started by presenting model-based predictions of the effects of experimental manipulations. However, you will have noticed that presenting plots of effects is not where we stop when we engage with a dataset. Further plotting indicates quite marked variation between participants in the effects of the conditions. This kind of insight is something we can and should seek to reveal through our visualization work.\n\n\n\n\nTo take your development further, take a look at the resources listed in Section 1.9.\nIn my experience, the most productive way to learn about visualization and about coding the production of plots, is by doing. And this work is most interesting if you have a dataset you care about: for your research report, or for your dissertation study.\nAs you have the alternate datasets described in Section 1.7.1.2.1, you can start with the data from the other task or the other study in @ricketts2021. @ricketts2021 recorded children’s responses in two different outcome tasks, the orthographic spelling task we have looked at, and a semantic or meaning-based task. It would be a fairly short step to adapt the code you see in the example code chunks to work with the semantic datasets.\nAlternatively, you can look at the data reported by @rodríguez-ferreiro2020. @rodríguez-ferreiro2020 present both measures of individual differences (on schizotypyal traits) and experimental manipulations (of semantic priming) so you can do similar things with those data as we have explored here.\n\n\n\n\n\n\nWe typically use the ggplot library (part of the tidyverse) to produce plots. Clear technical information, with useful examples you can copy and run, can be found in the reference webpages:\n\nhttps://ggplot2.tidyverse.org/reference/index.html\n\nA source of inspiration can be found here:\n\nhttps://r-graph-gallery.com\nIf you are trying to work out how to do things by searching for information online, you often find yourself at tutorial webpages. You will develop a sense of quality and usefulness with experience. Most often, what you are looking for is a tutorial that provides some explanation, and example code you can adapt for your own purposes. Here are some examples.\n\nCedric Scherer on producing raincloud plots:\n\nhttps://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-and-how-to-create-them-with-ggplot2/\n\nWinston Chang on colours and colour blind palettes:\n\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nThomas Lin Pedersen (and others) on putting together plots into a single presentation using the patchwork library functions:\n\nhttps://patchwork.data-imaginist.com/articles/patchwork.html\n\n\n\n\nThe book “R for Data Science” [@wickham2016] will guide you through the data analysis workflow, including data visualization, and the latest version can be accessed in an online free version here:\n\nhttps://r4ds.hadley.nz\n\nThe “ggplot2: Elegant Graphics for Data Analysis” book [@R-ggplot2] corresponding to the ggplot library was written by Hadley Wickham in its first edition, it is now in its third edition (as a work in progress, co-authored by Wickham, Danielle Navarro and Thomas Lin Pedersen) and this latest version can be accessed in an online free version here:\n\nhttps://ggplot2-book.org/index.html\n\nThe “R graphics cookbook” [@Chang2013a], and the latest version can be accessed in an online free version here:\n\nhttps://r-graphics.org\n\nThe book “Fundamentals of Data Visualization” [@wilke] is about different aspects of visualization, and can be accessed in an online free version here:\n\nhttps://clauswilke.com/dataviz/"
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-aims",
    "href": "PSYC411/part2/visualization.html#sec-vis-aims",
    "title": "Data visualization",
    "section": "",
    "text": "In writing this chapter, I have two aims.\n\nThe first aim for this chapter is to expose students to an outline summary of some key ideas and techniques for data visualization in psychological science.\n\nThere is an extensive experimental and theoretical literature concerning data visualization, what choices we can or should make, and how these choices have more or less impact, in different circumstances or for different audiences. Here, we can only give you a flavour of the on-going discussion. If you are interested, you can follow-up the references in the cited articles. But, using this chapter, I hope that you will gain a sense of the reasons how or why we may choose to do different things when we produce visualizations.\n\nThe second aim is to provide materials, and to show visualizations, to raise an awareness of what results come from making different choices. This is because we hope to encourage students to make choices based on reasons and it is hard to know what choices count without first seeing what the results might look like.\n\nIn my experience, knowing that there are choices is the first step. In proprietary software packages like Excel and SPSS there are plenty of choices but these are limited by the menu systems to certain combinations of elements. Here, in using R to produce visualizations, there is much more freedom, and much more capacity to control what a plot shows and how it looks, but knowing where to start has to begin with seeing examples of what some of the choices result in.\nAt the end of the chapter, I highlight some resources you can use in independent learning for further development, see Section 1.9.\nSo, we are aiming to (1.) start to build insight into the choices we make and (2.) provide resources to enable making those choices in data visualization."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-why-visualization-matters",
    "href": "PSYC411/part2/visualization.html#sec-why-visualization-matters",
    "title": "Data visualization",
    "section": "",
    "text": "Data visualization is important. Building skills in visualization matters to you because, even if you do not go on to professional work in which you produce visualizations you will certainly be working in fields in which you need to work with, or read or evaluate, visualizations.\nYou have already been doing this: our cultural or visual environment is awash in visualizations, from weather maps to charts on the television news. It will empower you if you know a bit about how or why these visualizations are produced in the ways that they are produced. That is a complex development trajectory but we can get started here.\nIn the context of the research report exercise, see ?@sec-pipeline, I mention data visualization in relation to stages of the data analysis pipeline or workflow. But the reality is that, most of the time, visualization is useful and used at every stage of data analysis workflow.\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nAnalyze\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow"
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-honesty",
    "href": "PSYC411/part2/visualization.html#sec-vis-honesty",
    "title": "Data visualization",
    "section": "",
    "text": "I write this chapter with three kinds of honesty in mind.\n\nI will expose some of the process involved in thinking about and preparing for the production of plots.\n\n\nI can assure you that when a professional data analysis worker produces plots in R they will be looking for information about what to do, and how to do it, online. I will provide links to the information I used, when I wrote this chapter, in order to figure out the coding to produce the plots.\nI won’t pretend that I got the plots “right first time” or that I know all the coding steps by memory. Neither is true for me and they would not be true for most professionals if they were to write a chapter like this. Looking things up online is something we all do so showing you where the information can be found will help you grow your skills.\n\n\nI will show how we often prepare for the production of plots by processing the data that we must use to inform the plots.\n\n\nWe almost always have to process the data we collected or gathered together from our exerimental work or our observations.\nIn this chapter, some of the coding steps I will outline are done in advance of producing a plot, to give the plotting code something to work with.\nKnowing about these processing steps will ensure you have more flexibility or power in getting your plots ready.\n\n\nI am going to expose variation, as often as I can, in observations.\n\n\nWe typically collect data about or from people, about their responses to things we may present (stimuli) or, given tasks, under different conditions, or concerning individual differences on an array of dimensions.\nSources of variation will be everywhere in our data, even though we often work with statistical analyses (like the t-test) that focus our attention on the average participant or the average response.\nModern analysis methods (like mixed-effects models) enable us to account for sources of variation systematically, so it is good to begin thinking about, say, how people vary in their response to different experimental conditions from early in your development."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-tidyverse",
    "href": "PSYC411/part2/visualization.html#sec-vis-tidyverse",
    "title": "Data visualization",
    "section": "",
    "text": "The approach we will take is to focus on step-by-step guides to coding. I will show plots and I will walk through the coding steps, explaining my reasons for the choices I make.\nWe will be working with plotting functions like ggplot() provided in libraries like ggplot2 [@R-ggplot2] which is part of the tidyverse [@R-tidyverse] collection of libraries.\nYou can access information about the tidyverse collection here.\n\n\nThe gg in ggplot stands for the “Grammar of Graphics”, and the ideas motivating the development of the ggplot2 library of functions are grounded in the ideas concerning the grammar of graphics, set out in the book of that name [@wilkinson2013].\nWhat is helpful to us, here, is the insight that the code elements (and how they result in visual elements) can be identified as building blocks, or layers, that we can add and adjust piece by piece when we are producing a visualization.\nA plot represents information and, critically, every time we write ggplot code we must specify somewhere the ways that our plot links data to something we see. In terms of ggplot, we specify aesthetic mappings using the aes() code to tell R what variables should be mapped e.g. to x-axis or y-axis location, to colour, or to group assignments. We then add elements to instruct R how to represent the aesthetic mappings as visual objects or attributes: geometric objects like a scatter of points geom_point() or a collection of bars geom_bar(); or visual features like colour, shape or size e.g. aes(colour = group). We can add visual elements in a series of layers, as shall see in the practical demonstrations of plot construction. We can adjust how scaling works. And we can add annotation, labels, and other elements to guide and inform the attention of the audience.\nYou can read more about mastering the grammar here.\n\n\n\nWe know that (some of) you want to see more use of pipes (represented as %&gt;% or |&gt;) in coding. There will be plenty of pipes in this chapter.\nIn using pipes in the code, I am structuring the code so that it works — and is presented — in a sequence of steps. There are different ways to write code but I find this way easier to work with and to read and I think you will too.\nLet’s take a small example:\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  summarise(average = mean(Reaction)) %&gt;%\n  ggplot(aes(x = average)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\nHere, we work through a series of steps:\n\nsleepstudy %&gt;% we first tell R we want to work with the dataset called sleepstudy and the %&gt;% pipe symbol at the end of the line tells R that we want it to pass that dataset on to the next step for what happens next.\ngroup_by(Subject) %&gt;% tells R that we want it to do something, here, group the rows of data according to the Subject (participant identity) coding variable, and pass the grouped data on to the next step for what happens following.\nsummarise(average = mean(Reaction)) %&gt;% tells R to take the grouped variable and calculate a summary, the mean Reaction score, for each group of observations for each participant. The %&gt;% pipe at the end of the line tells R to pass the summary dataset of mean Reaction scores on to the next process.\nggplot(aes(x = average)) + tells R that we want it to take these summary average Reaction scores and make a plot out of them.\ngeom_histogram() tells R that we want a histogram plot.\n\nWhat you can see is that each line ending in a %&gt; pipe passes something on to the next line. A following line takes the output of the process coded in the preceding line, and works with it.\nEach step is executed in turn, in strict sequence. This means that if I delete line 3 summarise(average = mean(Reaction)) %&gt;% then the following lines cannot work because the ggplot() function will be looking for a variable average that does not yet exist.\n\n\n\n\n\n\nWarning\n\n\n\n\nYou can see that in the data processing part of the code, successive steps in data processing end in a pipe %&gt;%.\nIn contrast, successive steps of the plotting code add ggplot elements line by line with each line (except the last) ending in a +.\n\n\n\nNotice that none of the processing steps actually changes the dataset called sleepstudy. The results of the process exist and can be used only within the sequence of steps that I have coded. If you want to keep the results of processing steps, you need to assign an object name to hold them, and I show how to do this, in the following.\nYou can read a clear explanation of pipes here.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the code you see:\n\nEach chunk of code is highlighted in the chapter.\nIf you hover a cursor over the highlighted code a little clipboard symbol appears in the top right of the code chunk.\nClick on the clipboard symbol to copy the code, paste it into your own R-Studio instance.\nThen experiment: try out things like removing or commmenting out lines, or changing lines, to see what effect that has.\nBreaking things, or changing things, helps to show what each bit of code does."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-ideas",
    "href": "PSYC411/part2/visualization.html#sec-vis-ideas",
    "title": "Data visualization",
    "section": "",
    "text": "Data visualization is not really about coding, as about thinking.\n\nWhat are our goals?\nWhy do we make some choices instead of others?\n\n\n\n@gelman2013 outline the goals we may contemplate when we produce or evaluate visual data displays. In general, they argue, we are doing one or both of two things.\n\nDiscovery\nCommunication\n\nIn practice, this may involve the following (I paraphrase them, here).\n\nDiscovery goals\n\n\nGetting a sense of what is in a dataset, checking assumptions, confirming expectations, and looking for distinct patterns.\nMaking sense of the scale and complexity of the dataset.\nExploring the data to reveal unexpected aspects. As we will see, using small multiples (grids of plots) can often help with this.\n\n\nCommunication goals\n\n\nWe communicate about our data to ourselves and to others. The process of constructing and evaluating a plot is often one way we speak to ourselves about own data, developing an understanding of what we have got. Once we have done this for ourselves, we can better figure out how to do it to benefit the understanding of an audience.\nWe often use a plot to tell a story: the story of our study, our data, or our insight and how we get to it.\nWe can use visualizations to attract attention and stimulate interest. Often, in presenting data to an audience through a talk or a report we need to use effective visualizations to ensure we get attention and that we locate the attention of our audience in the right places.\n\n\n\n\nYou will see a rich variety of data visualizations in media and in the research literature. You will know that some choices, in the production of those visualizations, appear to work better than others.\nSome of the reasons why some choices work better will relate to what we can understand in terms of the psychological science of how visual data communication works. A useful recent review of relevant research is presented by @franconeri2021.\n@franconeri2021 provide a reason for working on visualizations: they allow us humans to process an array of information at once, often faster than if we were reading about the information, bit by bit. Effective visualization, then, is about harnessing the power of the human visual system, or visual cognition, for quick, efficient, information processing. Critically for science, in addition, visualizations can be more effective for discovering or communicating the critical features of data than summary statistics, as we shall see.\nIn producing visualizations, we often work with a vocabulary or palette of objects or visual elements. @franconeri2021 discuss how visualizations rely on visual channels to transform numbers into images that we can process visually.\n\nDot plots and scatterplots represent values as position.\nBar graphs represent values as position (the heights of the tops of bars) but also as lengths.\nAngles are presented when we connect points to form a line, allowing us to encode the differences between points.\nIntensity can be presented through variation in luminance contrast or colour saturation.\n\nThese channels can be ordered by how precisely they have been found to communicate different numeric values to the viewer. Your audience may more accurately perceive the difference between two quantities if you communicate that difference through the difference in the location of two points than if you ask your audience to compare the angles of two lines or the intensity of two colour spots.\nIn constructing data visualizations, we often work with conventions, established through common practice in a research tradition. For example, if you are producing a scatterplot, then most of the time your audience will expect to see the outcome (or dependent variable) represented by the vertical height (on the y-axis) of points. And your audience will expect that higher points represent larger quantities of the y-axis variable.\nIn constructing visualizations, we need to be aware of the cognitive work that we require the audience to do. Comparisons are harder, requiring more processing and imposing more load on working memory. You can help your reader by guiding their attention, by grouping or ordering visual elements to identify the most important comparisons. We can vary colour and shape to group or distinguish visual elements. We can add annotation or elements like lines or arrows to guide attention.\nVisualizations are presented in context, whether in presentations or in reports. This context should be provided, by you the producer, with the intention to support the communication of your key messages. A visual representation, a plot, will be presented with a title, maybe a title note, maybe with annotation in the plot, and maybe with accompanying text. You should use these textual elements to lead your audience, to help them make sense of what they are looking at.\nThe diversity of audiences means that we should habitually add alt text for data visualizations to help those who use screen readers by providing a summary description of what images show. This chapter has been written using Quarto and rendered to .html with alt text included along with all images. Please do let me know if you are using a screen reader and the alt text description is or is not so helpful.\nYou can read a helpful explanation of alt text here.\nIf you use colour in images then we should use colour bind colour palettes.\nYou can read about using colour blind palettes here or here.\nIn the following practical exercises, we work with many of the insights in our construction of visualizations."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-quick-start",
    "href": "PSYC411/part2/visualization.html#sec-vis-quick-start",
    "title": "Data visualization",
    "section": "",
    "text": "We can get started before we understand in depth the key ideas or the coding steps. This will help to show where we are going. We will work with the sleepstudy dataset.\nI will model the process, to give you an example workflow:\n\nthe data, where they come from — what we can find out;\nhow we approach the data — what we expect to see;\nhow we visualize the data — discovery, communication.\n\n\n\nWhen we work with R, we usually work with functions like ggplot() provided in libraries like ggplot2 [@R-ggplot2]. These libraries typically provide not only functions but also datasets that we can use for demonstration and learning.\nThe lme4 library [@R-lme4] provides the sleepstudy dataset and we will take a look at these data to offer a taste of what we can learn to do. Usually, information about the R libraries we use will be located on the Comprehensive R Archive Network (CRAN) web pages, and we can find the technical reference information for lme4 in the CRAN reference manual for the library, where we see that the sleepstudy data are from a study reported by [@belenky2003]. The manual says that the sleepstudy dataset comprises:\n\nA data frame with 180 observations on the following 3 variables. [1.] Reaction – Average reaction time (ms) [2.] Days – Number of days of sleep deprivation [3.] Subject – Subject number on which the observation was made.\n\nWe can take a look at the first few rows of the dataset.\n\nsleepstudy %&gt;%\n    head(n = 4)\n\n  Reaction Days Subject\n1 249.5600    0     308\n2 258.7047    1     308\n3 250.8006    2     308\n4 321.4398    3     308\n\n\nWhat we are looking at are:\n\nThe average reaction time per day (in milliseconds) for subjects in a sleep deprivation study. Days 0-1 were adaptation and training (T1/T2), day 2 was baseline (B); sleep deprivation started after day 2.\n\nThe abstract for @belenky2003 tells us that participants were deprived of sleep and the impact of relative deprivation was tested using a cognitive vigilance task for which the reaction times of responses were recorded.\nSo, we can expect to find:\n\nA set of rows corresponding to multiple observations for each participant (Subject)\nA reaction time value for each participant (Reaction)\nRecorded on each Day\n\n\n\n\nIn data analysis work, we often begin with the objective to understand the structure or the nature of the data we are working with.\nYou can call this the discovery phase:\n\nwhat have we got?\ndoes it match our expectations?\n\nIf these are reaction time data (collected in an cognitive experiment) do they look like cognitive reaction time data should look? We would expect to see a skewed distribution of observed reaction times distributed around an average located somewhere in the range 200-700ms.\nFigure 2 represents the distribution of reaction times in the sleepstudy dataset.\nI provide notes on the code steps that result in the plot. Click on the Notes tab to see them. Later, I will discuss some of these elements.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Reaction)) +\n  geom_histogram(binwidth = 15) +\n  geom_vline(xintercept = mean(sleepstudy$Reaction), \n             colour = \"red\", linetype = 'dashed', size = 1.5) +\n  annotate(\"text\", x = 370, y =20, \n                    colour = \"red\", \n                    label = \"Average value shown in red\") +\n  theme_bw()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nFigure 2: Figure showing a histogram of sleepstudy reaction time data\n\n\n\n\n\n\n\nThe plotting code pipes the data into the plotting code steps to produce the plot. You can see some elements that will be familiar to you and some new elements.\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Reaction)) +\n  geom_histogram(binwidth = 15) +\n  geom_vline(xintercept = mean(sleepstudy$Reaction), \n             colour = \"red\", linetype = 'dashed', size = 1.5) +\n  annotate(\"text\", x = 370, y =20, \n                    colour = \"red\", \n                    label = \"Average value shown in red\") +\n  theme_bw()\n\nLet’s go through the code step-by-step:\n\nsleepstudy %&gt;% asks R to take the sleepstudy dataset and %&gt;% pipe it to the next steps for processing.\nggplot(aes(x = Reaction)) + takes the sleepstudy data and asks R to use the ggplot() function to produce a plot.\naes(x = Reaction) tells R that in the plot we want it to map the Reaction variable values to locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = 15) + tells R to produce a histogram then add a step.\ngeom_vline(...) + tells R we want to draw vertical line.\nxintercept = mean(sleepstudy$Reaction), ... tells R to draw the vertical line at the mean value of the variable Reaction in the sleepstudy dataset.\ncolour = \"red\", linetype = 'dashed', size = 1.5 tells R we want the vertical line to be red, dashed and 1.5 times the usual size.\nannotate(\"text\", ...) tells R we want to add a text note.\nx = 370, y =20, ... tells R we want the note added at the x,y coordinates given.\ncolour = \"red\", ..; and we want the text in red.\n...label = \"Average value shown in red\") + tells R we want the text note to say that this is where the average is.\ntheme_bw() lastly, we change the theme.\n\n\n\n\nFigure 2 shows a distribution of reaction times, ranging from about 200ms to 500ms. The distribution has a peak around 300ms. The location of the mean is shown with a dashed red line. The distribution includes a long tail of longer times. This is pretty much what we would expect to see.\nWe may wish to communicate the information we gain through using this histogram, in a presentation or in a report.\n\n\n\nLet us imagine that it is our study. (Here, we shall not concern ourselves too much — with apologies — with understanding what the original study authors actually did.)\nIf we are looking at the impact of sleep deprivation on cognitive performance, we might predict that reaction times got longer (responses slowed) as the study progressed. Is that what we see?\nTo examine the association between two variables, we often use scatterplots. Figure 3 is a scatterplot indicating the possible association between reaction time and days in the sleepstudy data. Points are ordered on x-axis from 0 to 9 days, on y-axis from 200 to 500 ms reaction time.\nI provide notes on the code steps that result in the plot. Click on the Notes tab to see them. Later, I will discuss some of these elements.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point(size = 1.5, alpha = .5) + \n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 3: Figure showing a scatterplot of the relation between reaction time and days in the sleepstudy data\n\n\n\n\n\n\n\nNotice the numbered steps in producing this plot.\n\nsleepstudy %&gt;% \n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  theme_bw()\n\n\nName the dataset: the dataset is called sleepstudy in the lme4 library which makes it available therefore we use this name to specify it.\nsleepstudy %&gt;% uses the %&gt;% pipe operator to pass this dataset to ggplot() to work with, in creating the plot. Because ggplot() now knows about the sleepstudy data, we can next specify what aesthetic mappings we need to use.\nggplot(aes(x = Days, y = Reaction)) + tells R that we want to map Days information to x-axis position and Reaction (response time) information to y-axis position.\ngeom_point() + tells R that we want to locate points – creating a scatterplot – at the paired x-axis and y-xis coordinates.\nscale_x_continuous(breaks = c(0, 3, 6, 9)) + is new: we tell R that we want the x-axis tick labels – the numbers R shows as labels on the x-axis – at the values 0, 3, 6, 9 only.\ntheme_bw() requires R to make the plot background white and the foreground plot elements black.\n\nYou can find more information on scale_ functions in the ggplot2 reference information.\nhttps://ggplot2.tidyverse.org/reference/scale_continuous.html\n\n\n\nThe plot suggests that reaction time increases with increasing number of days.\nIn producing this plot, we are both (1.) engaged in discovery and, potentially, (2.) able to do communication.\n\nDiscovery: is the relation between variables what we should expect, given our assumptions?\nCommunication: to ourselves and others, what relation do we observe, given our sample?\n\nAt this time, we have used and discussed scatterplots before, why we use them, how we write code to produce them, and how we read them.\nWith two additional steps we can significantly increase the power of the visualization. Figure 4 is a grid of scatterplots indicating the possible association between reaction time and days separately for each participant.\nAgain, I hide an explanation of the coding steps in the Notes tab: the interested reader can click on the tab to view the step-by-step guide to what is happening.\n\nPlotNotes\n\n\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  mutate(average = mean(Reaction)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Subject = fct_reorder(Subject, average)) %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  geom_line() +\n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  facet_wrap(~ Subject) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 4: Figure showing a scatterplot of the relation between reaction time and days: here, we plot the data for each participant separately\n\n\n\n\n\n\n\nNotice the numbered steps in producing this plot.\n\nsleepstudy %&gt;%\n  group_by(Subject) %&gt;%\n  mutate(average = mean(Reaction)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Subject = fct_reorder(Subject, average)) %&gt;%\n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point() + \n  geom_line() +\n  scale_x_continuous(breaks = c(0, 3, 6, 9)) +\n  facet_wrap(~ Subject) +\n  theme_bw()\n\nYou can see that the block of code combines data processing and data plotting steps. Let’s look at the data processing steps then the plotting steps in order.\nFirst: why are we doing this? My aim is to produce a plot in which I show the association between Days and Reaction for each Subject individually. I suspect that the association between Days and Reaction may be stronger – so the trend will be steeper – for participants who are slower overall. I suspect this because, given experience, I know that slower, less accurate, participants tend to show larger effects.\nSo: in order to get a grid of plots, one plot for each Subject, in order of the average Reaction for each individual Subject, I need to first calculate the average Reaction then order the dataset rows by those averages. I do that in steps, using pipes to feed information from one step to the next step, as follows.\n\nsleepstudy %&gt;% tells R what data I want to use, and pipe it to the next step.\ngroup_by(Subject) tells R I want it to work with data (rows) grouped by Subject identity code, %&gt;% piping the grouped form of the data forward to the next step\nmutate(average = mean(Reaction)) uses mutate() to create a new variable average which I calculate as the mean() of Reaction, piping the data with this additional variable %&gt;% forward to the next step.\nungroup() %&gt;% tells R I want it to go back to working with the data in rows not grouped rows, and pipe the now ungrouped form of the data to the next step.\nmutate(Subject = fct_reorder(Subject, average)) tells R I want it to sort the rows of the whole sleepstudy dataset in order, moving groups of rows identified by Subject so that data for Subject codes associated with faster times are located near the top of the dataset.\n\nThese data, ordered by Subject by the average Reaction for each participant, are then %&gt;% piped to ggplot to create a plot.\n\nggplot(aes(x = Days, y = Reaction)) + specifies the aesthetic mappings, as before.\ngeom_point() + asks R to locate points at the x-axis, y-axis coordinates, creating a scatterplot, as before.\ngeom_line() + is new: I want R to connect the points, showing the trend in the association between Days and Reaction for each person.\nscale_x_continuous(breaks = c(0, 3, 6, 9)) + fixes the x-axis labels, as before.\nfacet_wrap(~ Subject) + is the big new step: I ask R to plot a separate scatterplot for the data for each individual Subject.\n\nYou can see more information about facetting here:\nhttps://ggplot2.tidyverse.org/reference/facet_wrap.html\nIn short, with the facet_wrap(~ .) function, we are asking R to subset the data by a grouping variable, specified (~ .) by replacing the dot with the name of the variable.\nNotice that I use %&gt;% pipes to move the data processing forward, step by step. But I use + to add plot elements, layer by layer.\n\n\n\nFigure Figure 4 is a grid or lattice of scatterplots revealing how the possible association between reaction time and days varies quite substantially between the participants in the sleepstudy data. Most plots indicate that reaction time increases with increasing number of days. However, different participants show this trend to differing extents.\nWhat are the two additions I made to the conventional scatterplot code?\n\nI calculated the average reaction time per participant, and I ordered the data by those averages.\nI facetted the plots, breaking them out into separate scatterplots per participant.\n\nWhy would you do this? Variation between people or groups, in effects or in average outcomes, are often to be found in psychological data [@vasishth2021]. The variation between people that we see in these data — in the average response reaction time, and in how days affects times — would motivate the use of linear mixed-effects models to analyze the way that sleep patterns affect responses in the sleep study [@Pinheiro2000a].\n\n\n\n\n\n\nTip\n\n\n\nThe data processing and plotting functions in the tidyverse collection of libraries enable us to discover and to communicate variation in behaviours that should strengthen our and others’ scientific understanding.\n\n\n\n\n\nWhat we have seen, so far, is that we can make dramatic changes to the appearance of visualizations (e.g., through faceting) and also that we can exert fine control over the details (e.g., adjusting scale labels). What we need to stop and consider are what we want to do (and why), in what order.\nWe have seen how we can feed a data process into a plot to first prepare then produce the plot in a sequence of steps. In processing the data, we can take some original data and extract or calculate information that we can use for our plotting e.g. calculating the mean of a distribution in order to then highlight where that mean is located.\nWe have also seen the use of plots, and the editing of their appearance, to represent information visually. We can verbalize the thought process behind the production of these plots through a series of questions.\n\nAre we looking at the distribution of one variable (if yes: consider a histogram) or are we comparing the distributions of two or more variables (if yes: consider a scatterplot)?\nIs there a salient feature of the plot we want to draw the attention of the audience to? We can add a visual element (like a line) and annotation text to guide the audience.\nAre we interested in variation between sub-sets of the data? We can facet the plot to examine variation between sub-sets (facets) enabling the comparison of trends."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-practical-visualization",
    "href": "PSYC411/part2/visualization.html#sec-vis-practical-visualization",
    "title": "Data visualization",
    "section": "",
    "text": "In this guide, we illustrate some of the ideas about visualization we discussed at the start, working with practical coding examples. We will be working with real data from a published research project. We are going to focus the practical coding examples on the data collected for the analysis reported by @ricketts2021.\n\nWe will focus on working with the data from one of the tasks, in one of the studies reported by @ricketts2021.\n\nThis means that you can consolidate your learning by applying the same code moves to data from the other task in the same study, or to data from the other study.\nIn applying code to other data, you will need to be aware of differences in, say, the way that some things like the outcome response variable are coded.\n\nYou can then further extend your development by trying out the coding moves for yourself using the data collected by @rodríguez-ferreiro2020.\n\nThese data are from a quite distinct kind of investigation, on a different research topic than the topic we will be exploring through our working examples.\nHowever, some aspects of the data structure are similar.\nCritically, the data are provided with comprehensive documentation.\n\n\n\n\nTo do our practical work, we will need functions and data. We get these at the start of our workflow.\n\n\nWe are going to need the lme4, patchwork, psych and tidyverse libraries of functions and data.\n\nlibrary(ggeffects)\nlibrary(patchwork)\nlibrary(psych)\nlibrary(tidyverse)\n\n\n\n\nYou can access the data we are going to use in two different ways.\n\n\nThe data associated with both [@ricketts2021] and [@rodríguez-ferreiro2020] are freely available through project repositories on the Open Science Framework web pages.\nYou can get the data from the @ricketts2021 paper through the repository located here.\nYou can get the data from the @rodríguez-ferreiro2020 paper through the repository located here.\nThese data are associated with full explanations of data collection methods, materials, data processing and data analysis code. You can review the papers and the repository material guides for further information.\nIn the following, I am going to abstract summary information about the @ricketts2021 study and data. I shall leave you to do the same for the @rodríguez-ferreiro2020 study.\n\n\n\nDownload the data.zip files folder and upload the files to RStudio Server.\nThe folder includes the @ricketts2021 data files:\n\nconcurrent.orth_2020-08-11.csv\nconcurrent.sem_2020-08-11.csv\nlong.orth_2020-08-11.csv\nlong.sem_2020-08-11.csv\n\nThe folder also includes the @rodríguez-ferreiro2020 data files:\n\nPrimDir-111019_English.csv\nPrimInd-111019_English.csv\n\n\n\n\n\n\n\nWarning\n\n\n\n\nThese data files are collected together in a folder for download, for your convenience, but the version of record for the data for each study comprise the files located on the OSF repositories associated with the original articles.\n\n\n\n\n\n\n\n\n@ricketts2021 conducted an investigation of word learning in school-aged children. They taught children 16 novel words in a study with a 2 x 2 factorial design. In this investigation, they tested whether word learning is helped by presenting targets for word learning with their spellings, and whether learning is helped by telling children that they would benefit from the presence of those spellings.\nThe presence of orthography (the word spelling) was manipulated within participants (orthography absent vs. orthography present): for all children, eight of the words were taught with orthography present and eight with orthography absent. Instructions (incidental vs. explicit) were manipulated between participants such that children in the explicit condition were alerted to the presence of orthography whereas children in the incidental condition were not.\nA pre-test was conducted to establish participants’ knowledge of the stimuli. Then, each child was seen for three 45-minute sessions to complete training (Sessions 1 and 2) and post-tests (Session 3). @ricketts2021 completed two studies: Study 1 and Study 2. All children, in both studies 1 and 2 completed the Session 3 post-tests.\nIn Study 1, longitudinal post-test data were collected because children were tested at two time points. Children were administered post-tests in Session 3, as noted: Time 1. Post-tests were then re-administered approximately eight months later at Time 2 (\\(M = 241.58\\) days from Session 3, \\(SD = 6.10\\)). In Study 2, the Study 1 sample was combined with an older sample of children. The additional Study 2 children were not tested at Time 2, and the analysis of Study 2 data did not incorporate test time as a factor.\nThe outcome data for both studies consisted of performance on post-tests.\nThe semantic post-test assessed knowledge for the meanings of newly trained words using a dynamic or sequential testing approach. I will not explain this approach in more detail, here, because the practical visualization exercises focus on the orthographic knowledge (spelling knowledge) post-test, explained next.\nThe orthographic post-test was included to ascertain the extent of orthographic knowledge after training. Children were asked to spell each word to dictation and spelling productions were transcribed for scoring. Responses were scored using a Levenshtein distance measure indexing the number of letter deletions, insertions and substitutions that distinguish between the target and child’s response. The maximum score is 0, with higher scores indicating less accurate responses.\nFor the Study 1 analysis, the files are:\n\nlong.orth_2020-08-11.csv\nlong.sem_2020-08-11.csv\n\nWhere long indicates the longitudinal nature of the data-set.\nFor the Study 2 analysis, the files are:\n\nconcurrent.orth_2020-08-11.csv\nconcurrent.sem_2020-08-11.csv\n\nWhere concurrent indicates the inclusion of concurrent (younger and older) child participant samples.\nEach column in each data-set corresponds to a variable and each row corresponds to an observation (i.e., the data are tidy). Because the design of the study involves the collection of repeated observations, the data can be understood to be in a long format.\nEach child was asked to respond to 16 words and, for each of the 16 words, we collected post-test responses from multiple children. All words were presented to all children.\nWe explain what you will find when you inspect the .csv files, next.\n\n\nThe variables included in .csv files are listed, following, with information about value coding or calculation.\n\nParticipant — Participant identity codes were used to anonymize participation. Children included in studies 1 and 2 – participants in the longitudinal data collection – were coded “EOF[number]”. Children included in Study 2 only (i.e., the older, additional, sample) were coded “ND[number]”.\nTime — Test time was coded 1 (time 1) or 2 (time 2). For the Study 1 longitudinal data, it can be seen that each participant identity code is associated with observations taken at test times 1 and 2.\nStudy — Observations taken for children included in studies 1 and 2 – participants in the longitudinal data collection – were coded “Study1&2”. Children included in Study 2 only (i.e., the older, additional, sample) were coded “Study2”.\nInstructions — Variable coding for whether participants undertook training in the explicit or incidental conditions.\nVersion — Experiment administration coding\nWord — Letter string values show the words presented as stimuli to children.\nConsistency_H — Calculated orthography-to-phonology consistency value for each word.\nOrthography — Variable coding for whether participants had seen a word in training in the orthography absent or present conditions.\nMeasure — Variable coding for the post-test measure: Sem_all if the semantic post-test; Orth_sp if the orthographic post-test.\nScore — Variable coding for response category.\n\nFor the semantic (sequential or dynamic) post-test, responses were scored as corresponding to:\n\n3 – correct response in the definition task\n2 – correct response in the cued definition task\n1 – correct response in the recognition task\n0 – if the item wasn’t correctly defined or recognised\n\nFor the orthographic post-test, responses were scored as:\n\n1 – correct, if the target spelling was produced in full\n0 – incorrect\n\nHowever, the analysis reported by @ricketts2021 focused on the more sensitive Levenshtein distance measure (see following).\n\nWASImRS — Raw score – Matrix Reasoning subtest of the Wechsler Abbreviated Scale of Intelligence\nTOWREsweRS — Raw score – Sight Word Efficiency (SWE) subtest of the Test of Word Reading Efficiency; number of words read correctly in 45 seconds\nTOWREpdeRS — Raw score – Phonemic Decoding Efficiency (PDE) subtest of the Test of Word Reading Efficiency; number of nonwords read correctly in 45 seconds\nCC2regRS — Raw score – Castles and Coltheart Test 2; number of regular words read correctly\nCC2irregRS — Raw score – Castles and Coltheart Test 2; number of irregular words read correctly\nCC2nwRS — Raw score – Castles and Coltheart Test 2; number of nonwords read correctly\nWASIvRS — Raw score – vocabulary knowledge indexed by the Vocabulary subtest of the WASI-II\nBPVSRS — Raw score – vocabulary knowledge indexed by the British Picture Vocabulary Scale – Third Edition\nSpelling.transcription — Transcription of the spelling response produced by children in the orthographic post-test\nLevenshtein.Score — Children were asked to spell each word to dictation and spelling productions were transcribed for scoring. Responses were scored using a Levenshtein distance measure indexing the number of letter deletions, insertions and substitutions that distinguish between the target and child’s response. For example, the response ‘epegram’ for target ‘epigram’ attracts a Levenshtein score of 1 (one substitution). Thus, this score gives credit for partially correct responses, as well as entirely correct responses. The maximum score is 0, with higher scores indicating less accurate responses.\n\n(Notice that, for the sake of brevity, I do not list the z_ variables but these are explained in the study OSF repository materials.)\n\n\n\n\n\n\nWarning\n\n\n\nLevenshtein distance scores are higher if a child makes more errors in producing the letters in a spelling response.\n\nThis means that if we want to see what factors help a child to learn a word, including its spelling, then we want to see that helpful factors are associated with lower Levenshtein scores.\n\n\n\nTo demonstrate some of the processes we can enact to process and visualize data, and some of the benefits of doing so, we are going to work with the concurrent.orth_2020-08-11.csv dataset. These are data corresponding to the @ricketts2021 Study 2. concurrent refers to the analysis (a concurrent comparison) of data from younger and older children.\n\n\n\n\nAssuming you have downloaded the data files, we first read the dataset into the R environment: concurrent.orth_2020-08-11.csv. We do the data read in a bit differently than you have seen it done before; we will come back to what is going on (in Section 1.7.4.1).\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\",\n\n                      col_types = cols(\n\n                        Participant = col_factor(),\n                        Time = col_factor(),\n                        Study = col_factor(),\n                        Instructions = col_factor(),\n                        Version = col_factor(),\n                        Word = col_factor(),\n                        Orthography = col_factor(),\n                        Measure = col_factor(),\n                        Spelling.transcription = col_factor()\n\n                      ))\n\nWe can inspect these data using summary().\n\nsummary(conc.orth)\n\n  Participant   Time          Study         Instructions Version\n EOF001 :  16   1:1167   Study1&2:655   explicit  :592   a:543  \n EOF002 :  16            Study2  :512   incidental:575   b:624  \n EOF004 :  16                                                   \n EOF006 :  16                                                   \n EOF007 :  16                                                   \n EOF008 :  16                                                   \n (Other):1071                                                   \n         Word     Consistency_H     Orthography     Measure    \n Accolade  : 73   Min.   :0.9048   absent :583   Orth_sp:1167  \n Cataclysm : 73   1st Qu.:1.5043   present:584                 \n Contrition: 73   Median :1.9142                               \n Debacle   : 73   Mean   :2.3253                               \n Dormancy  : 73   3rd Qu.:3.0436                               \n Epigram   : 73   Max.   :3.9681                               \n (Other)   :729                                                \n     Score           WASImRS     TOWREsweRS      TOWREpdeRS       CC2regRS    \n Min.   :0.0000   Min.   : 5   Min.   :51.00   Min.   :19.00   Min.   :28.00  \n 1st Qu.:0.0000   1st Qu.:13   1st Qu.:69.00   1st Qu.:35.00   1st Qu.:36.00  \n Median :0.0000   Median :17   Median :74.00   Median :41.00   Median :38.00  \n Mean   :0.2913   Mean   :16   Mean   :74.23   Mean   :41.59   Mean   :36.91  \n 3rd Qu.:1.0000   3rd Qu.:19   3rd Qu.:80.00   3rd Qu.:50.00   3rd Qu.:39.00  \n Max.   :1.0000   Max.   :25   Max.   :93.00   Max.   :59.00   Max.   :40.00  \n                                                                              \n   CC2irregRS       CC2nwRS         WASIvRS          BPVSRS     \n Min.   :17.00   Min.   :13.00   Min.   :16.00   Min.   :103.0  \n 1st Qu.:23.00   1st Qu.:29.00   1st Qu.:25.00   1st Qu.:119.0  \n Median :25.00   Median :33.00   Median :29.00   Median :133.0  \n Mean   :25.24   Mean   :32.01   Mean   :29.12   Mean   :130.9  \n 3rd Qu.:27.00   3rd Qu.:37.00   3rd Qu.:33.00   3rd Qu.:142.0  \n Max.   :35.00   Max.   :40.00   Max.   :39.00   Max.   :158.0  \n                                                                \n Spelling.transcription Levenshtein.Score  zTOWREsweRS        zTOWREpdeRS      \n Epigram   : 57         Min.   :0.000     Min.   :-2.67807   Min.   :-2.33900  \n Platitude : 43         1st Qu.:0.000     1st Qu.:-0.60283   1st Qu.:-0.68243  \n Contrition: 42         Median :1.000     Median :-0.02638   Median :-0.06122  \n fracar    : 39         Mean   :1.374     Mean   : 0.00000   Mean   : 0.00000  \n Nonentity : 39         3rd Qu.:2.000     3rd Qu.: 0.66537   3rd Qu.: 0.87061  \n raconter  : 35         Max.   :7.000     Max.   : 2.16415   Max.   : 1.80243  \n (Other)   :912                                                                \n   zCC2regRS        zCC2irregRS          zCC2nwRS          zWASIvRS       \n Min.   :-3.3636   Min.   :-2.22727   Min.   :-3.1053   Min.   :-2.63031  \n 1st Qu.:-0.3435   1st Qu.:-0.60461   1st Qu.:-0.4920   1st Qu.:-0.82633  \n Median : 0.4115   Median :-0.06373   Median : 0.1614   Median :-0.02456  \n Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.00000  \n 3rd Qu.: 0.7890   3rd Qu.: 0.47716   3rd Qu.: 0.8147   3rd Qu.: 0.77721  \n Max.   : 1.1665   Max.   : 2.64070   Max.   : 1.3047   Max.   : 1.97986  \n                                                                          \n    zBPVSRS         mean_z_vocab       mean_z_read       zConsistency_H   \n Min.   :-1.9946   Min.   :-2.06910   Min.   :-2.39045   Min.   :-1.4153  \n 1st Qu.:-0.8495   1st Qu.:-0.85941   1st Qu.:-0.43321   1st Qu.:-0.8181  \n Median : 0.1525   Median :-0.01483   Median : 0.08829   Median :-0.4096  \n Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.0000  \n 3rd Qu.: 0.7967   3rd Qu.: 0.72964   3rd Qu.: 0.68438   3rd Qu.: 0.7157  \n Max.   : 1.9418   Max.   : 1.96083   Max.   : 1.52690   Max.   : 1.6368  \n                                                                          \n\n\nYou should notice one key bit of information in the summary. Focus on the summary for what is in the Participant column. You can see that we have a number of participants in this dataset, listed by Participant identity code in the summary() view e.g. EOF001. For each participant, we have 16 rows of data.\nWhen we ask R for a summary of a nominal variable or factor it will show us the levels of each factor (i.e., each category or class of objects encoded by the categorical variable), and a count for the number of observations for each level.\nTake a look at the rows of data for EOF001.\n\n\n\n\n\nParticipant\nTime\nStudy\nInstructions\nVersion\nWord\nConsistency_H\nOrthography\nMeasure\nScore\nWASImRS\nTOWREsweRS\nTOWREpdeRS\nCC2regRS\nCC2irregRS\nCC2nwRS\nWASIvRS\nBPVSRS\nSpelling.transcription\nLevenshtein.Score\nzTOWREsweRS\nzTOWREpdeRS\nzCC2regRS\nzCC2irregRS\nzCC2nwRS\nzWASIvRS\nzBPVSRS\nmean_z_vocab\nmean_z_read\nzConsistency_H\n\n\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nAccolade\n1.9142393\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nacalade\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.4095955\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nCataclysm\n3.5060075\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nCataclysm\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.1763372\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nContrition\n1.7486898\nabsent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nContrition\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.5745381\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nDebacle\n2.9008386\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\ndibarcle\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.5733869\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nDormancy\n1.6263089\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\ndoormensy\n3\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.6964704\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nEpigram\n1.3822337\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nEpigram\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.9396508\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nFoible\n2.7051987\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nFoible\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.3784641\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nFracas\n3.1443345\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nfracar\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.8159901\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nLassitude\n0.9048202\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nlacitude\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.4153141\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nLuminary\n1.0985931\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nloomenery\n4\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.2222516\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nNonentity\n3.9681391\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nnonenterty\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.6367746\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nPlatitude\n0.9048202\npresent\nOrth_sp\n1\n15\n62\n33\n39\n27\n30\n26\n126\nPlatitude\n0\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-1.4153141\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nPropensity\n1.6861898\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\npropencity\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n-0.6368090\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nRaconteur\n3.8245334\nabsent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nraconter\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n1.4936954\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nSyncopation\n3.0436450\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nsincipation\n2\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.7156697\n\n\nEOF001\n1\nStudy1&2\nexplicit\na\nVeracity\n2.8693837\npresent\nOrth_sp\n0\n15\n62\n33\n39\n27\n30\n26\n126\nvaracity\n1\n-1.409869\n-0.8895032\n0.7889916\n0.4771563\n-0.3286222\n-0.6258886\n-0.3484719\n-0.4871803\n-0.2723693\n0.5420473\n\n\n\n\n\n\n\nYou can see that for EOF001, as for every participant, we have information on the conditions under which we observed their responses (Instructions, Orthography), as well as information about the stimuli that we asked participants to respond to (e.g., Word, Consistency_H), information about the responses or outcomes we recorded (Measure, Score, Spelling.transcription,  Levenshtein.Score), and information about the participants themselves (e.g., TOWREsweRS, TOWREpdeRS).\n\n\n\nWe almost always need to process data in order to render the information ready for discovery or communication data visualization.\n\n\nYou will have seen that data processing began when we first read the data in for use. Let’s go back and take a look at the code steps.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\",\n\n                      col_types = cols(\n\n                        Participant = col_factor(),\n                        Time = col_factor(),\n                        Study = col_factor(),\n                        Instructions = col_factor(),\n                        Version = col_factor(),\n                        Word = col_factor(),\n                        Orthography = col_factor(),\n                        Measure = col_factor(),\n                        Spelling.transcription = col_factor()\n\n                        )\n                      )\n\nThe chunk of code is doing two things: first, we tell R what .csv file we want to read into the environment, and what we want to call the dataset; and then we tell R how we want to classify the data variable columns.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\" first reads the named .csv file, creating an object I will call conc.orth: a dataset or tibble we can now work with in R.\n\n\nYou have been using the read.csv() function to read in data files.\nThe read_csv() function is the more modern tidyverse form of the function you were introduced to.\nBoth versions work in similar ways but read_csv() is a bit more efficient, and it allows us to do what we do next.\n\n\ncol_types = cols( ... ) tells R how to interpret some of the columns in the .csv.\n\n\nThe read_csv() function is excellent at working out what types of data are held in each column but sometimes we have to tell it what to do.\nHere, I am specifying with e.g. Participant = col_factor() that the Participant column should be treated as a categorical or nominal variable, a factor.\n\nUsing the col_types = cols( ... ) argument saves me from having to first read the data in then using code like the following to require, technically, coerce R into recognizing the nominal nature of variables like Participant with code like\n\nconc.orth$Participant &lt;- as.factor(conc.orth$Participant)\n\n\n\nI do not have to do step 2 of the read-in process, here. What happens if we use just read_csv()? Try it.\n\nconc.orth &lt;- read_csv(\"concurrent.orth_2020-08-11.csv\")\n\n\n\n\nYou can read more about read_csv() here\nYou can read more about col_types = cols() here\n\n\n\n\nThe @ricketts2021 dataset orth.conc is a moderately sized and rich dataset with several observations, on multiple variables, for each of many participants. Sometimes, we want to extract information from a more complex dataset because we want to understand or present a part of it, or a relatively simple account of it. We look at an example of how you might do that now.\nAs you saw when you looked at the summary of the orth.conc dataset, we have multiple rows of data for each participant. Recall the design of the study. For each participant, we recorded their response to a stimulus word, in a test of word learning, for 16 words.\nFor each participant, we have a separate row for each response the participant made to each word. But you will have noticed that information about the participant is repeated. So, for participant EOF001, we have data about their performance e.g. on the BPVSRS vocabulary test (they scored 126). Notice that that score is repeated: the same value is copied for each row, for this participant, in the BPVSRS column. The reason the data are structured like this are not relevant here 1 but it does require us to do some data processing, as I explain next.\nIt is a very common task to want to present a summary of the attributes of your participants or stimuli when you are reporting data in a report of a psychological research project. We could get a summary of the participant attributes using the psych library describe function as follows.\n\nconc.orth %&gt;%\n  select(WASImRS:BPVSRS) %&gt;%\n  describe(ranges = FALSE, skew = FALSE)\n\n           vars    n   mean    sd   se\nWASImRS       1 1167  16.00  4.30 0.13\nTOWREsweRS    2 1167  74.23  8.67 0.25\nTOWREpdeRS    3 1167  41.59  9.66 0.28\nCC2regRS      4 1167  36.91  2.65 0.08\nCC2irregRS    5 1167  25.24  3.70 0.11\nCC2nwRS       6 1167  32.01  6.12 0.18\nWASIvRS       7 1167  29.12  4.99 0.15\nBPVSRS        8 1167 130.87 13.97 0.41\n\n\nBut you can see that part of the information in the summary does not appear to make sense at first glance. We do not have 1167 participants in this dataset, as @ricketts2021 report.\nHow do we extract the participant attribute variable data for each unique participant code for the participants in our dataset?\n\nconc.orth.subjs &lt;- conc.orth %&gt;%\n  group_by(Participant) %&gt;%\n  mutate(mean.score = mean(Levenshtein.Score)) %&gt;%\n  ungroup() %&gt;%\n  distinct(Participant, .keep_all = TRUE) %&gt;%\n  select(WASImRS:BPVSRS, mean.score, Participant)\n\nWe create a new dataset conc.orth.subjs by taking conc.orth and piping it through a series of processing steps. As part of the process, we want to extract the data for each unique unique Participant identity code using distinct(). Along the way, we want to calculate the mean accuracy of response on the outcome measure (Score), that is, the average number of edits separating a child’s spelling of a target word from the correct spelling.\nThis is how we do it.\n\nconc.orth.subjs &lt;- ... tells R to create a new dataset conc.orth.subjs.\nconc.orth %&gt;% ... we do this by telling R to take conc.orth and pipe it through the following steps.\ngroup_by(Participant) %&gt;% first we group the data by Participant identity code.\nmutate(mean.score = mean(Score)) %&gt;% then we use mutate() to create the new variable mean.score by calculating the mean() of the Score variable values (i.e. the average score) for each participant. We then pipe to the next step.\nungroup() %&gt;% we tell R to ungroup the data because we want to work with all rows for what comes next, and we then pipe to the next step.\ndistinct(Participant, .keep_all = TRUE) %&gt;% requires R to extract from the full orth.conc dataset the set of (here, 16) data rows we have for each distinct (uniquely identified) Participant. We use the argument .keep_all = TRUE to tell R that we want to keep all columns. This requires the next step, so we tell R to pipe %&gt;% the data.\nselect(WASImRS:BPVSRS, mean.score, Participant) then tells R to select just the columns with information about participant attributes. (WASImRS:BPVSRS tells R to select every column between WASImRS and BPVSRS inclusive. mean.score, Participant tells R we also want those columns, specified by name, including the mean.score column of average response scores we calculated just earlier.\n\nWe can now get a sensible summary of the descriptive statistics for the participants in Study 2 of the @ricketts2021 investigation.\n\nconc.orth.subjs %&gt;%\n  select(-Participant) %&gt;%\n  describe(ranges = FALSE, skew = FALSE)\n\n           vars  n   mean    sd   se\nWASImRS       1 73  16.00  4.33 0.51\nTOWREsweRS    2 73  74.22  8.73 1.02\nTOWREpdeRS    3 73  41.58  9.73 1.14\nCC2regRS      4 73  36.90  2.67 0.31\nCC2irregRS    5 73  25.23  3.72 0.44\nCC2nwRS       6 73  32.00  6.17 0.72\nWASIvRS       7 73  29.12  5.02 0.59\nBPVSRS        8 73 130.88 14.06 1.65\nmean.score    9 73   1.38  0.62 0.07\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis is exactly the kind of tabled summary of descriptive statistics we would expect to produce in a report, in a presentation of the participant characteristics for a study sample (in e.g., the Methods section).\nNotice:\n\nThe table has not yet been formatted according to APA rules.\nWe would prefer to use real words for row name labels instead of dataset variable column labels, e.g, replace TOWREsweRS with: “TOWRE word reading score”.\n\n\n\n\n\nIn these bits of demonstration code, we extract information relating just to participants. However, in this study, we recorded the responses participants made to 16 stimulus words, and we include in the dataset information about the word properties Consistency_H.\n\nCan you adapt the code you see here in order to calculate a mean score for each word, and then extract the word-level information for each distinct stimulus word identity?\n\n\n\n\nYou can read more about the psych library, which is often useful, here. You can read more about the distinct() function here.\n\n\n\n\n\nIt has taken us a while but now we are ready to examine the data using visualizations. Remember, we are engaging in visualization to (1.) do discovery, to get a sense of our data, and maybe reveal unexpected aspects, and (2.) potentially to communicate to ourselves and others what we have observed or perhaps what insights we can gain.\nWe have been learning to use histograms, in other classes, so let’s start there.\n\n\n\nWe can use histograms to visualize the distribution of observed values for a numeric variable. Let’s start simple, and then explore how to elaborate the plotting code, in a series of edits, to polish the plot presentation.\n\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram()\n\n\n\n\n\n\n\nFigure 5: Distribution of WASImRS intelligence scores\n\n\n\n\n\nThis is how the code works.\n\nggplot(data = conc.orth.subjs, ... tells R what function to use ggplot() and what data to work with data = conc.orth.subjs.\naes(x = WASImRS) tells R what aesthetic mapping to use: we want to map values on the WASImRS variable (small to large) to locations on the x-axis (left to right).\ngeom_histogram() tells R to construct a histogram, presenting a statistical summary of the distribution of intelligence scores.\n\nWith histograms, we are visualizing the distribution of a single continuous variable by dividing the variable values into bins (i.e. subsets) and counting the number of observations in each bin. Histograms display the counts with bars.\nYou can see more information about geom_histogram here.\nFigure 5 shows how intelligence (WASImRS) scores vary in the Ricketts Study 2 dataset. Scores peak around 17, with a long tail of lower scores towards 5, and a maximum around 25.\n\nWhere I use the word “peak” I am talking about the tallest bar in the plot (or, later the highest point in a density curve). At this point, we have the most observations of the value under the bar. Here, we observed the score WASImRS \\(= 17\\) for the most children in this sample.\n\nA primary function of discovery visualization is to assess whether the distribution of scores on a variable is consistent with expectations, granted assumptions about a sample (e.g., that the children are typically developing). We would normally use research area knowledge to assess whether this distribution fits expectations for a sample of typically developing school-aged children in the UK. However, I shall leave that concern aside, here, so that we can focus on enriching the plot presentation, next.\nThere are two main problems with the plot:\n\nThe bars are “gappy” in the histogram, suggesting we have not grouped observed values in sufficiently wide subsets (bins). This is a problem because it weakens our ability to gain or communicate a visual sense of the distribution of scores.\nThe axis labeling uses the dataset variable name WASImRS but if we were to present the plot to others we could not expect them to know what that means.\n\nWe can fix both these problems, and polish the plot for presentation, through the following code steps.\n\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"Scores on the Wechsler Abbreviated Scale of Intelligence\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 6: Distribution of WASImRS intelligence scores\n\n\n\n\n\nFigure 6 shows the same data, and furnishes us with the same picture of the distribution of intelligence scores but it is a bit easier to read. We achieve this by making three edits.\n\ngeom_histogram(binwidth = 2) + we change the binwidth.\n\n\nThis is so that more different observed values of the data variable are included in bins (subsets corresponding to bars) so that the bars correspond to information about a wider range of values.\nThis makes the bars bigger, wider, and closes the gaps.\nAnd this means we can focus the eyes of the audience for our plot on the visual impression we wish to communicate: the skewed distribution of intelligence scores.\n\n\nlabs(x = \"Scores on the Wechsler Abbreviated Scale of Intelligence\") + changes the label to something that should be understandable by people, in our audience, who do not have access to variable information (as we do) about the dataset.\ntheme_bw() we change the overall appearance of the plot by changing the theme.\n\n\n\nWe could, if we wanted, add a line and annotation to indicate the mean value, as you saw in Figure 2.\n\nCan you add the necessary code to indicate the mean value of WASI scores, for this plot?\n\nWe can, of course, plot histograms to indicate the distributions of other variables.\n\nCan you apply the histogram code to plot histograms of other variables?\n\n\n\n\n\nWe may wish to discover or communicate how values vary on dataset variables in two different ways. Sometimes, we need to examine how values vary on different variables. And sometimes, we need to examine how values vary on the same variable but in different groups of participants (or stimuli) or under different conditions. We look at this next. We begin by looking at how you might compare how values vary on different variables.\n\n\nIt can be useful to compare the distributions of different variables. Why?\nConsider the @ricketts2021 investigation dataset. Like many developmental investigations (see also clinical investigations), we tested children and recorded their scores on a series of standardized measures, here, measures of ability on a range of dimensions. We did this, in part, to establish that the children in our sample are operating at about the level one might expect for typically developing children in cognitive ability dimensions of interest: dimensions like intelligence, reading ability or spelling ability. So, one of the aspects of the data we are considering is whether scores on these dimensions are higher or lower than typical threshold levels. But we also want to examine the distributions of scores because we want to find out:\n\nif participants are varied in ability (wide distribution) or if maybe they are all similar (narrow distribution) as would be the case if the ability measures are too easy (so all scores are at ceiling) or too hard (so all scores are at floor);\nif there are subgroups within the sample, maybe reflected by two or more peaks;\nif there are unusual scores, maybe reflected by small peaks at very low or very high scores.\n\nWe could look at each variable, one plot at a time. Instead, next, I will show you how to produce a set of histogram plots, and present them all as a single grid of plots.\n\n\n\n\n\n\nWarning\n\n\n\nI have to warn you that the way I write the code is not good practice. The code is written with repeats of the ggplot() block of code to produce each plot. This repetition is inefficient and leaves the coding vulnerable to errors because it is hard to spot a mistake in more code. What I should do is encapsulate the code as a function (see here). The reason I do not, here, is because I want to focus our attention on just the plotting.\n\n\nFigure 7 presents a grid of plots showing how scores vary for each ability test measure, for the children in the @ricketts2021 investigation dataset. We need to go through the code steps, next, and discuss what the plots show us (discovery and communication).\n\np.WASImRS &lt;- ggplot(data = conc.orth.subjs, aes(x = WASImRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"WASI matrix\") +\n  theme_bw()\n\np.TOWREsweRS &lt;- ggplot(data = conc.orth.subjs, aes(x = TOWREsweRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"TOWRE words\") +\n  theme_bw()\n\np.TOWREpdeRS &lt;- ggplot(data = conc.orth.subjs, aes(x = TOWREpdeRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"TOWRE phonemic\") +\n  theme_bw()\n\np.CC2regRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2regRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC regular words\") +\n  theme_bw()\n\np.CC2irregRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2irregRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC irregular words\") +\n  theme_bw()\n\np.CC2nwRS &lt;- ggplot(data = conc.orth.subjs, aes(x = CC2nwRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"CC nonwords\") +\n  theme_bw()\n\np.WASIvRS &lt;- ggplot(data = conc.orth.subjs, aes(x = WASIvRS)) +\n  geom_histogram(binwidth = 2) +\n  labs(x = \"WASI vocabulary\") +\n  theme_bw()\n\np.BPVSRS &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS)) +\n  geom_histogram(binwidth = 3) +\n  labs(x = \"BPVS vocabulary\") +\n  theme_bw()\n\np.mean.score &lt;- ggplot(data = conc.orth.subjs, aes(x = mean.score)) +\n  geom_histogram(binwidth = .25) +\n  labs(x = \"Mean orthographic test score\") +\n  theme_bw()\n\np.mean.score + p.BPVSRS + p.WASIvRS + p.WASImRS +\n  p.CC2nwRS + p.CC2irregRS + p.CC2regRS + \n  p.TOWREpdeRS + p.TOWREsweRS + plot_layout(ncol = 3)\n\n\n\n\n\n\n\nFigure 7: Distribution of childrens’ scores on ability measures\n\n\n\n\n\nThis is how the code works, step by step:\n\np.WASImRS &lt;- ggplot(...) first creates a plot object, which we call p.WASImRS.\nggplot(data = conc.orth.subjs, aes(x = WASImRS)) + tells R what data to use, and what aesthetic mapping to work with mapping the variable WASImRS here to the x-axis location.\ngeom_histogram(binwidth = 2) + tells R to sort the values of WASImRS scores into bins and create a histogram to show how many children in the sample present scores of different sizes.\nlabs(x = \"WASI matrix\") + changes the x-axis label to make it more informative.\ntheme_bw() changes the theme to make it a bit cleaner looking.\n\nWe do this bit of code separately for each variable. We change the plot object name, the x = variable specification, and the axis label text for each variable. We adjust the binwidth where it appears to be necessary.\nWe then use the following plot code to put all the plots together in a single grid.\n\np.mean.score + p.BPVSRS + p.WASIvRS + p.WASImRS +\n  p.CC2nwRS + p.CC2irregRS + p.CC2regRS + \n  p.TOWREpdeRS + p.TOWREsweRS + plot_layout(ncol = 3)\n\n\nIn the code, we add a series of plots together e.g. p.mean.score + p.BPVSRS + p.WASIvRS ...\nand then specify we want a grid of plots with a layout of three columns plot_layout(ncol = 3).\n\nThis syntax requires the library(patchwork) and more information about this very useful library can be found here.\nWhat do the plots show us?\nFigure 7 shows a grid of 9 histogram plots. Each plot presents the distribution of scores for the @ricketts2021 Study 2 participant sample on a separate ability measure, including scores on the BPVS vocabulary, WASI vocabulary, TOWRE words and TOWRE nonwords reading tests, as well as scores on the Castles and Coltheart regular words, irregular words and nonwords reading tests, and the mean Levenshtein distance (spelling score) outcome measure of performance for the experimental word learning post-test.\nTake a look, you may notice the following features.\n\nThe mean orthographic test score suggests that many children produced spellings to the words they learned in the @ricketts2021 study that, on average, were correct (0 edits) or were one or two edits (e.g., a letter deletion or replacement) away from the target word spelling. The children were learning the words, and most of the time, they learned the spellings of the words effectively. However, one or two children tended to produce spellings that were 2-3 edits distant from the target spelling.\n\n\nWe can see these features because we can see that the histogram peaks around 1 (at Levenshtein distance score \\(= 1\\)) but that there is a small bar of scores at around 3.\n\n\nWe can see that there are two peaks on the BPVS and WASI measures of vocabulary. What is going on there?\n\n\nIs it the case that we have two sub-groups of children within the overall sample? For example, on the BPVS test, maybe one sub-group of children has a distribution of vocabulary scores with a peak around 120 (the peak shows where most children have scores) while another sub-group of children has a distribution of vocabulary scores with a peak around 140.\n\n\nIf we look at the CC nonwords and CC regular words tests of reading ability, we may notice that while most children present relatively high scores on these tests (CC nonwords peak around 35, CC regular words peak around 37) there is a skewed distribution. Many of the children’s scores are piled up towards the maximum value in the data on the measures. But we can also see that, on both measures, there are long tails in the distributions because relatively small numbers of children have substantially lower scores.\n\n\nDevelopmental samples are often highly varied (just like clinical samples). Are all the children in the sample at the same developmental stage, or are they all typically developing?\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that in presenting a grid of plots like this, we offer a compact visual way to present the same summary information we might otherwise present using a table of descriptive statistics. In some ways, this grid of plots is more informative than the descriptive statistics because the mean and SD values do not tell you what you can see:\n\nthe characteristics of the variation in values, like the presence of two peaks;\nor the presence of unusually high or low scores (for this sample).\n\n\n\nGrids of plots like this can be helpful to inspect the distributions of variables in a concise approach. They are not really too useful for comparing the distributions because they require your eyes to move between plots, repeatedly, to do the comparison.\nHere is a more compact way to code the grid of histograms using the library(ggridges) function geom_density_ridges(). I do not discuss it in detail because I want to focus your attention on core tidyverse functions (I show you more information in the Notes tab).\nNotice that if you produce all the plots so that the are in line in the same column with a shared x-axis it becomes much easier to compare the distributions of scores. You lose some of the fine detail, discussed in relation to Figure 7, but this style allows you to gain an impression, quickly, of how for distributions of scores compare between measures. For example, we can see that within the Castles and Coltheart (CC) measures of reading ability, children do better on regular words than on nonwords, and on nonwords better than on irregular words.\n\nPlotNotes\n\n\n\nlibrary(ggridges)\nconc.orth.subjs %&gt;%\n  pivot_longer(names_to = \"task\", values_to = \"score\", cols = WASImRS:mean.score) %&gt;% \n  ggplot(aes(y = task, x = score)) +\n  geom_density_ridges(stat = \"binline\", bins = 20, scale = 0.95, draw_baseline = FALSE) +\n  theme_ridges()\n\n\n\n\n\n\n\nFigure 8: Distribution of childrens’ scores on ability measures\n\n\n\n\n\n\n\n\nlibrary(ggridges) get the library we need.\nconc.orth.subjs %&gt;% pipe the dataset for processing.\npivot_longer(names_to = \"task\", values_to = \"score\", cols = WASImRS:mean.score) %&gt;% pivot the data so all test scores are in the same column, “scores” wwith coding for “task” name, and pipe to the next step for plotting.\nggplot(aes(y = task, x = score)) + create a plot for the scores on each task.\ngeom_density_ridges(stat = \"binline\", bins = 20, scale = 0.95, draw_baseline = FALSE) + show the plots as histograms.\ntheme_ridges() change the theme to the specific theme suitable for showing a grid of ridges.\n\nYou can find more information on ggridges here.\n\n\n\n\n\n\nWe will often want to compare the distributions of variable values between groups or between conditions. This need may appear when, for example, we are conducting a between-groups manipulation of some condition and we want to check that the groups are approximately matched on dimensions that are potentially linked to outcomes (i.e., on potential confounds). The need may appear when, alternatively, we have recruited or selected participant (or stimulus) samples and we want to check that the sample sub-groups are approximately matched or detectably different on one or more dimensions of interest or of concern.\nAs a demonstration of the visualization work we can do in such contexts, let’s pick up on an observation we made earlier, that there are two peaks on the BPVS and WASI measures of vocabulary. I asked: Is it the case that we have two sub-groups of children within the overall sample? Actually, we know the answer to that question because @ricketts2021 state that they recruited one set of children for their Study 1 and then, for Study 2:\n\nThirty-three children from an additional three socially mixed schools in the South-East of England were added to the Study 1 sample (total N = 74). These additional children were older (\\(M_{age}\\) = 12.57, SD = 0.29, 17 female)\n\nDo the younger (Study 1) children differ in any way from the older (additional) children?\nWe can check this through data visualization. Our aim is to present the distributions of variables side-by-side or superimposed to ensure easy comparison. We can do this in different ways, so I will demonstrate one approach with an outline explanation of the actions, and offer suggestions for further approaches.\nI am going to process the data before I do the plotting. I will re-use the code I used before (see Section 1.7.4.2) with one additional change. I will add a line to create a group coding variable. This addition shows you how to do an action that is very often useful in the data processing part of your workflow.\n\n\nYou have seen that the @ricketts2021 report states that an additional group of children was recruited for the investigation’s second study. How do we know who they are? If you recall the summary view of the complete dataset, there is one variable we can use to code group identity.\n\nsummary(conc.orth$Study)\n\nStudy1&2   Study2 \n     655      512 \n\n\nThis summary tells us that we have 512 observations concerning the additional group of children recruited for Study 2, and 655 observations for the (younger) children whose data were analyzed for both Study 1 and Study 2 (i.e., coded as Study1&2 in the Study variable column). We can use this information to create a coding variable. (If we had age data, we could use that instead but we do not.) This is how we do that.\n\nconc.orth.subjs &lt;- conc.orth %&gt;%\n  group_by(Participant) %&gt;%\n  mutate(mean.score = mean(Levenshtein.Score)) %&gt;%\n  ungroup() %&gt;%\n  distinct(Participant, .keep_all = TRUE) %&gt;%\n  mutate(age.group = fct_recode(Study,\n    \n    \"young\" = \"Study1&2\",\n    \"old\" = \"Study2\"\n    \n  )) %&gt;%\n  select(WASImRS:BPVSRS, mean.score, Participant, age.group)\n\nThe code block is mostly the same as the code I used in Section Section 1.7.4.2 to extract the data for each participant, with two changes:\n\nFirst, mutate(age.group = fct_recode(...) tells R that I want to create a new variable age.group through the process of recoding, with fct_recode(...) the variable I specify next, in the way that I specify.\nfct_recode(Study, ...) tells R I want to recode the variable Study.\n\"young\" = \"Study1&2\", \"old\" = \"Study2\" specifies what I want recoded.\n\n\nI am telling R to look in the Study column and (a.) whenever it finds the value Study1&2 replace it with young whereas (b.) whenever it finds the value Study2 replace it with old.\nNotice that the syntax in recoding is fct_recode: “new name” = “old name”.\nHaving done that, I tell R to pipe the data, including the recoded variable, to the next step.\n\n\nselect(WASImRS:BPVSRS, mean.score, Participant, age.group) where I add the new recoded variable to the selection of variables I want to include in the new dataset conc.orth.subjs.\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that R handles categorical or nominal variables like Study (or, in other data, variables e.g. gender, education or ethnicity) as factors.\n\nWithin a classification scheme like education, we may have different classes or categories or groups e.g. “further, higher, school”. We can code these different classes with numbers (e.g. \\(school = 1\\)) or with words “further, higher, school”. Whatever we use, the different classes or groups are referred to as levels and each level has a name.\nIn factor recoding, we are changing level names while keeping the underlying data the same.\n\n\n\nThe tidyverse collection includes the forcats library of functions for working with categorical variables (forcats = factors). These functions are often very useful and you can read more about them here.\nChanging factors level coding by hand is, for many, a common task, and the fct_recode() function makes it easy. You can find the technical information on the function, with further examples, here.\n\n\n\nThere are different ways to examine the distributions of variables so that we can compare the distributions of the same variable between groups.\nFigure 9 presents some alternatives as a grid of 4 different kinds of plots designed to enable the same comparison. Each plot presents the distribution of scores for the @ricketts2021 Study 2 participant sample on the BPVS vocabulary measure so that we can compare the distribution of vocabulary scores between age groups.\nThe plots differ in method using:\n\nfacetted histograms showing the distribution of vocabulary scores, separately for each group, in side-by-side histograms for comparison;\nboxplots, showing the distribution of scores for each group, indicated by the y-axis locations of the edges of the boxes (25% and 75% quartiles) and the middle lines (medians);\nsuperimposed histograms, where the histograms for the separate groups are laid on top of each other but given different colours to allow comparison; and\nsuperimposed density plots where the densities for the separate groups are laid on top of each other but given different colours to allow comparison.\n\n\n\n\n\n\n\nTip\n\n\n\nThere is one thing you should notice about all these plots.\n\nIt looks like the BPVS vocabulary scores have their peak – most children show this value – at around 120 for the young group and at around 140 for the old group.\n\nWe return to this shortly.\n\n\n\nI am going to hide the coding and the explanation of the coding behind the Notes tab. Click on the tab to get a step-by-step explanation. Of these alternatives, I focus on one which I explain in more depth, following: d. Superimposed density plots.\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 9: Distribution of childrens’ scores on the BPVS vocabulary measure: distributions are compared between the younger and older age groups\n\n\n\n\n\n\n\n\np.facet.hist &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"BPVS vocabulary score\", title = \"a. Faceted histograms\") +\n  facet_wrap(~ age.group) +\n  theme_bw()\n\np.colour.boxplot &lt;- ggplot(data = conc.orth.subjs, aes(y = BPVSRS, colour = age.group)) +\n  geom_boxplot() +\n  labs(x = \"BPVS vocabulary score\", title = \"b. Boxplots\") +\n  theme_bw()\n\np.colour.hist &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"BPVS vocabulary score\", title = \"c. Superimposed histograms\") +\n  theme_bw()\n\np.colour.density &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  labs(x = \"BPVS vocabulary score\", title = \"d. Superimposed density plots\") +\n  theme_bw()\n\np.facet.hist + p.colour.boxplot + p.colour.hist + p.colour.density\n\n\nIn plot “a. Faceted histograms”, we use the code to construct a histogram but the difference is we use:\n\n\nfacet_wrap(~ age.group) to tell R to split the data by age.group then present the histograms indicating vocabulary score distributions separately for each group.\n\n\nIn plot “b. Boxplots”, we use the geom_boxplot() code to construct a boxplot to summarize the distributions of vocabulary scores – as you have seen previously – but the difference is we use:\n\n\naes(y = BPVSRS, colour = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\n\n\nIn plot “c. Superimposed histograms”, we use the code to construct a histogram but the difference is we use:\n\n\naes(x = BPVSRS, colour = age.group, fill = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\nNotice that the fill gives the colour inside the bars and colour gives the colour of the outline edges of the bars.\n\n\nIn plot “d. Superimposed density plots”, we use the code geom_density(...) to construct what is called a density plot.\n\n\nA density plot presents a smoothed histogram to show the distribution of variable values.\nWe add arguments in geom_density(alpha = .5, size = 1.5) to adjust the thickness of the line (size = 1.5) drawn to show the shape of the distribution and adjust the transparency of the colour fill inside the line alpha = .5).\nWe useaes(x = BPVSRS, colour = age.group, fill = age.group) to tell R to assign different colours to different levels of age.group to help distinguish the data from each group.\nNotice that the fill gives the colour inside the density plots and colour gives the colour of the outline edges of the densities.\n\n\n\n\nDensity plots can be helpful when we wish to compare distributions. This is because we can superimpose distribution plots on top of each other, enabling us or our audience to directly compare the distributions: directly because the distributions are shown on the same scale, in the same image.\nWe can (roughly) understand a density plot as working like a smoothed version of the histogram. Imagine how the heights of the bars in the histogram represent how many observations we have of the values in a particular bin. If we draw a smooth curving line through the tops of the bars then we are representing the chances that an observation in our sample has a value (the value under the curve) at any specific location on the x-axis. You can see that in Figure 10.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nFigure 10: Distribution of childrens’ scores on the BPVS vocabulary measure. The figure shows the histogram versus density plot representation of the same data distribution\n\n\n\n\n\nYou can find the ggplot2 reference information on the geom_density() function, with further examples, here. You can find technical information on density functions here and here.\nWe can develop the density plot to enrich the information we can discover or communicate through the plot. Figure 11 shows the distribution of scores on both the BPVS and WASI vocabulary knowledge measures.\n\np.BPVSRS.density &lt;- ggplot(data = conc.orth.subjs, aes(x = BPVSRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  geom_rug(alpha = .5) +\n  geom_vline(xintercept = 120, linetype = \"dashed\") +\n  geom_vline(xintercept = 140, linetype = \"dotted\") +\n  labs(x = \"BPVSRS vocabulary score\") +\n  theme_bw()\n\np.WASIvRS.density &lt;- ggplot(data = conc.orth.subjs, aes(x = WASIvRS, colour = age.group, fill = age.group)) +\n  geom_density(alpha = .5, size = 1.5) +\n  geom_rug(alpha = .5) +\n  labs(x = \"WASI vocabulary score\") +\n  theme_bw()\n\np.BPVSRS.density + p.WASIvRS.density + plot_layout(guides = 'collect')\n\n\n\n\n\n\n\nFigure 11: Distribution of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nHere is what the code does:\n\np.BPVRS.density &lt;- ggplot(...) creates a plot object called p.BPVRS.density.\ndata = conc.orth.subjs, ... says we use the conc.orth.subjs dataset to do this.\naes(x = BPVRS, colour = age.group, fill = age.group)) + says we want to map BPVRS scores to x-axis location, and age.group level coding (young, old) to both colour and fill.\ngeom_density(alpha = .5, size = 1.5) + draws a density plot; note that we said earlier what we want for colour and fill but here we also say that:\n\n\nalpha = .5 we want the fill to be transparent;\nsize = 1.5 we want the density curve line to be thicker than usual.\n\n\ngeom_rug(alpha = .5) + adds a one-dimensional plot, a series of tick marks, to show where we have observations of BPVRS scores for specific children. We ask R to make the tick marks semi-transparent.\ngeom_vline(xintercept = 120, linetype = \"dashed\") + draws a vertical dashed line where BPVRS = 120.\ngeom_vline(xintercept = 140, linetype = \"dotted\") + draws a vertical dotted line where BPVRS = 140.\nlabs(x = \"BPVS vocabulary score\") + makes the x-axis label something understandable to someone who does not know about the study.\ntheme_bw() changes the theme.\n\n\n\n\nAs we work with visualization, we should aim to develop skills in reading plots, so:\n\nWhat do we see?\n\nWhen we look at Figure 11, we can see that the younger and older children in the @ricketts2021 sample have broadly overlapping distributions of vocabulary scores. However, as we have noticed previously, the peak of the distribution is a bit lower for the younger children compared to the older children. This appears to be the case whether we are looking at the BPVS or at the WASI measures of vocabulary, suggesting that the observation does not depend on the particular vocabulary test. Is this observation unexpected? Probably not, as we should hope to see vocabulary knowledge increase as children get older. Is this observation a problem for our analysis? You need to read the paper to find out what we decided.\n\n\n\nIn the demonstration examples, I focused on comparing age groups on vocabulary, what about the other measures?\nI used superimposed density plots: are other plotting styles more effective, for you? Try using boxplots or superimposed or faceted histograms instead.\n\n\n\n\n\nSo far, we have looked at how and why we may examine the distributions of numeric variables. We have used histograms to visualize the distribution of variable values. We have explored the construction of grids of plots to enable the quick examination or concise communication of information about the distributions of multiple variables at the same time. And we have used histograms, boxplots and density plots to examine how the distributions of variables may differ between groups.\nThe comparison of the distributions of variable values in different groups (or, similarly, between different conditions) may be the kind of work we would need to do, in data visualization, as part of an analysis ending in, for example, a t-test comparison of mean values.\nWhile boxplots, density plots and histograms are typically used to examine how the values of a numeric variable vary, scatterplots are typically used when we wish to examine, to make sense of or communicate potential associations or relations between two (or more) numeric variables. We turn to scatterplots, next.\n\n\n\nMany of us start learning about scatterplots in high school math classes. Using the modern tools made available to us through the ggplot2 library (as part of tidyverse), we can produce effective, nice-looking, scatterplots for a range of discovery or communication scenarios.\nWe continue working with the @ricketts2021 dataset. In the context of the @ricketts2021 investigation, there is interest in how children vary in the reading, spelling and vocabulary abilities that may influence the capacity of children to learn new words. So, in this context, we can begin to progress our development in visualization skills by usefully considering the potential association between participant attributes in the Study 2 sample.\nLater on, we will look at more advanced plots that help us to communicate the impact of the experimental manipulations implemented by @ricketts2021, and also to discover the ways that these impacts may vary between children.\n\n\nWe can begin by asking a simple research question we can guess the answer to:\n\nDo vocabulary knowledge scores on two alternative measures, the BPVS and the WASI, relate to each other?\n\nIf two measurement instruments or tests are intended to measure individual differences in the same psychological attribute, here, vocabulary knowledge, then we would reasonably expect that scores on one test should covary with scores on the second test.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 12: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nWhat does the plot show us?\nAs a reminder of how scatterplots work, we can recall that they present integrated information. Each point, for the @ricketts2021 data, represents information about both the BPVS and the WASI score for each child.\n\nThe vertical height of a point tells us the BPVS score recorded for a child: higher points represent higher scores.\nThe left-to-right horizontal position of the same point tells us the WASI score for the same child: points located more on the right represent higher scores.\n\nFigure 12 is a scatterplot comparing variation in childrens’ scores on the BPVS and WASI vocabulary measures: variation in BPVS scores are shown on the y-axis and variation in WASI scores are shown on the x-axis. Critically, the scientific insight the plot gives us is this: higher WASI scores are associated with higher BPVS scores.\nHow does the code work? We have seen scatterplots before but, to ensure we are comfortable with the coding, we can go through them step by step.\n\nggplot(data = conc.orth.subjs...) + tells R we want to produce a plot using ggplot() with the conc.orth.subjs dataset.\naes(x = WASIvRS, y = BPVSRS) tells R that, in the plot, WASIvRS values are mapped to x-axis (horizontal) position and BPVSRS values are mapped to y-axis (vertical) position.\ngeom_point() + constructs a scatterplot, using these data and these position mappings.\nlabs(x = \"WASI vocabulary score\", ... fixes the x-axis label.\ny = \"BPVSRS vocabulary score\",... fixes the y-axis label.\ntitle = \"Are WASI and BPVS vocabulary scores associated?\") + fixes the title.\ntheme_bw() changes the theme.\n\n\n\n\nFor this pair of variables in this dataset, the potential association in the variation of scores is quite obvious. However, sometimes it is helpful to guide the audience by imposing a smoother. There are different ways to do this, for different objectives and in different contexts. Here, we look at two different approaches. In addition, as we go, we examine how to adjust the appearance of the plot to address different potential discovery or communication needs.\nWe begin by adding what is called a LOESS smoother.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 13: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nThe only coding difference between this plot Figure 13 and the previous plot Figure 12 appears at line 3:\n\ngeom_smooth()\n\nThe addition of this bit of code results in the addition of the curving line you see in Figure 13. The blue line is curving, and visually suggests that the relation between BPVS and WASI scores is different – sometimes more sometimes less steep – for different values of WASI vocabulary score.\nThis line is generated by the geom_smooth() code, by default, in an approach in which the dataset is effectively split into sub-sets, dividing the data up into sub-sets from the lowest to the highest WASI scores, and the predicted association between the y-axis variable (here, BPVS score) and the x-axis variable (here, WASI score) is calculated bit by bit, in a series of regression analyses, working in order through sub-sets of the data. This calculation of what is called the LOESS (locally estimated scatterplot smoothing) trend is done by ggplot for us. And this approach to visualizing the trend in a potential association between variables is often a helpful way to discover curved or non-linear relations.\nYou can find technical information on geom_smooth() here and an explanation of LOESS here.\nFor us, this default visualization is not helpful for two reasons:\n\nWe have not yet learned about linear models, so learning about LOESS comes a bit early in our development.\nIt is hard to look at Figure 13 and identify a convincing curvilinear relation between the two variables. A lot of the curve for low WASI scores appears to be linked to the presence of a small number of data points.\n\nAt this stage, it is more helpful to adjust the addition of the smoother. We can do that by adding an argument to the geom_smooth() function code.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 14: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nNotice the difference between Figure 13 and Figure 14:\n\ngeom_smooth(method = 'lm') tells R to draw a trend line, a smoother, using the lm method.\n\nThe lm method requires R to estimate the association between the two variables, here, BPVS and WASI, assuming a linear model. Of course, we are going to learn about linear models but, in short, right now, what we need to know is that we assume a “straight line” relationship between the variables. This assumption requires that for any interval of WASI scores – e.g., whether we are talking about WASI scores between 20-25 or about WASI scores between 30-35 – the relation between BPVS and WASI scores has the same shape: the direction and steepness of the slope of the line is the same.\n\n\n\n\nDeveloping skill in working with data visualizations is not just about developing coding skills, it is also about developing skills in reading, and critically evaluating, the information the plots we produce show us.\n\nStop and take a good look at the scatterplot in Figure 14. Use the visual representation of data to critically evaluate the potential association between the BPVS and WASI variables. What can you see?\nYou can train your critical evaluation by asking yourself questions like the following:\n\nHow does variation in the x-axis variable relate to variation in values of the y-axis variable?\n\n\nWe can see, here, that higher WASI scores are associated with higher BPVS scores.\n\n\nHow strong is the relation?\n\n\nThe strength of the relation can be indicated by the steepness of the trend indicated by the smoother, here, the blue line.\nIf you track the position of the line, you can see, for example, that going from a WASI score of 20 to a WASI score of 40 is associated with going from a BPVS score of a little over 110 to a BPVS score of about a 150.\nThat seems like a big difference.\n\n\nHow well does the trend we are looking at capture the data in our sample?\n\n\nHere, we are concerned with how close the points are to the trend line.\nIf the trend line represents a set of predictions about how the BPVS scores vary (in height) given variation in WASI scores, we can see that in places the prediction is not very good.\nTake a look at the points located at WASI 25. We can see that there there are points indicating that different children have the same WASI score of 25 but BPVS scores ranging from about 115 to 140.\n\n\n\n\nFigure 14 presents a satisfactory looking plot but it is worth checking what edits we can make to the appearance of the plot, to indicate some of the ways that you can exercise choice in determining what a plot looks like. This will be helpful to you when you are constructing plots for presentation and report and you want to ensure the plots are as effective as possible.\n\nggplot(data = conc.orth.subjs, aes(x = WASIvRS, y = BPVSRS)) +\n  geom_point(alpha = .5, size = 2) +\n  geom_smooth(method = 'lm', colour = \"red\", size = 1.5) +\n  labs(x = \"WASI vocabulary score\", \n       y = \"BPVSRS vocabulary score\",\n       title = \"Are WASI and BPVS vocabulary scores associated?\") +\n  xlim(0, 40) + ylim(0, 160) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 15: Scatterplot indicating the potential association of childrens’ scores on the BPVS and WASI vocabulary measures.\n\n\n\n\n\nIf you inspect the code, you can see that I have made three changes:\n\ngeom_point(alpha = .5, size = 2 changes the size of the points and their transparency (using alpha).\ngeom_smooth(method = 'lm', colour = \"red\", size = 1.5) change the colour of the smoother line, and the thickness (size) of the line.\nxlim(0, 40) + ylim(0, 160) changes the axis limits.\n\nThe last step — changing the axis limits — reveals how the sample data can be understood in the context of possible scores on these ability measures. Children could get BPVS scores of 0 or WASI scores of 0. By showing the start of the axes we get a more realistic sense of how our sample compares to the possible ranges of scores we could see in the wider population of children. This perhaps offers a more honest or realistic visualization of the potential association between BPVS and WASI vocabulary scores.\n\n\n\nAs we have seen previously, we can construct a series of plots and present them all at once in a grid or lattice. Figure 16 presents just such a grid: of scatterplots, indicating a series of potential associations.\nLet’s suppose that we are primarily interested in what factors influence the extent to which children in the @ricketts2021 word learning experiment are able to correctly spell the target words they were given to learn. As explained earlier, in Section 1.7.2, @ricketts2021 examined the spellings produced by participant children in response to target words, counting how many string edits (i.e., letter deletions etc.) separated the spelling each child produced from the target spelling they should have produced.\nWe can calculate the mean spelling accuracy score for each child, over all the target words we observed their response to. We can identify mean spelling score as the outcome variable. We can then examine whether the outcome spelling scores are or are not influenced by participant attributes like vocabulary knowledge.\nFigure 16 presents a grid of scatterplots indicating the potential association between mean spelling score and each of the variables we have in the conc.orth dataset, including the Castles and Coltheart (CC) and TOWRE measures of word or nonword reading skill, WASI and BPVS measures of vocabulary knowledge, and the WASI matrix measure of intelligence, as well as (our newly coded) age group factor.\nI hide an explanation of the coding behind the Notes tab, because we have seen how to produce grids of plots, but you can take a look if you want to learn how the plot is produced.\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 16: Grid of scatterplots showing the potential association between mean spelling score, for each child, and variation in the Castles and Coltheart (CC) and TOWRE measures of word or nonword reading skill, WASI and BPVS measures of vocabulary knowledge, the WASI matrix measure of intelligence, and age group factor\n\n\n\n\n\n\n\nThe code to produce the figure is set out as follows.\n\np.wordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                              y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Word reading\", \n       y = \"Spelling score\",\n       title = \"(a.)\") +\n  theme_bw()\n\np.nonwordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Nonword reading\", \n       y = \"Spelling score\",\n       title = \"(b.)\") +\n  theme_bw()\n\np.WASIvRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = WASIvRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"WASI vocabulary\", \n       y = \"Spelling score\",\n       title = \"(c.)\") +\n  theme_bw()\n\np.BPVSRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = BPVSRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"BPVS vocabulary score\", \n       y = \"Spelling score\",\n       title = \"(d.)\") +\n  theme_bw()\n\np.WASImRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = WASImRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"WASI matrix\", \n       y = \"Spelling score\",\n       title = \"(e.)\") +\n  theme_bw()\n\np.CC2regRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2regRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC regular words\", \n       y = \"Spelling score\",\n       title = \"(f.)\") +\n  theme_bw()\n\np.CC2irregRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2irregRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC irregular words\", \n       y = \"Spelling score\",\n       title = \"(g.)\") +\n  theme_bw()\n\np.CC2nwRSvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = CC2nwRS, \n                                  y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"CC nonwords\", \n       y = \"Spelling score\",\n       title = \"(h.)\") +\n  theme_bw()\n\np.age.groupvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = age.group, \n                                  y = mean.score)) +\n  geom_boxplot() +\n  labs(x = \"Age group\", \n       y = \"Spelling score\",\n       title = \"(i.)\") +\n  theme_bw()\n\np.wordsvsmean.score + p.nonwordsvsmean.score + p.WASIvRSvsmean.score +\n  p.BPVSRSvsmean.score + p.WASImRSvsmean.score + p.CC2regRSvsmean.score +\n  p.CC2irregRSvsmean.score + p.CC2nwRSvsmean.score + p.age.groupvsmean.score\n\n\nTo produce the grid of plots, we first create a series of plot objects using code like that shown in the chunk.\n\n\np.wordsvsmean.score &lt;- ggplot(data = conc.orth.subjs, \n                              aes(x = TOWREsweRS, \n                              y = mean.score)) +\n  geom_point(alpha = .5, size = 3) +\n  geom_smooth(method = 'lm', size = 1.5) +\n  labs(x = \"Word reading\", \n       y = \"Spelling score\",\n       title = \"(a.)\") +\n  theme_bw()\n\n\np.wordsvsmean.score &lt;- ggplot(...) creates the plot.\ndata = conc.orth.subjs tells R what data to work with.\naes(x = TOWREsweRS, y = mean.score) specifies the aesthetic data mappings.\ngeom_point(alpha = .5, size = 3) tells R to produce a scatterplot, specifying the size and transparency of the points.\ngeom_smooth(method = 'lm', size = 1.5) tells R to add a smoother, specifying the method and the thickness of the line.\nlabs(x = \"Word reading\", y = \"Spelling score\", title = \"(a.)\") fixes the labels.\ntheme_bw() adjusts the theme.\n\n\nWe then put the plots together, using the patchwork syntax where we list the plot objects by name, separating each name by a +.\n\n\np.BPVSRSvsmean.score + p.WASImRSvsmean.score + p.CC2regRSvsmean.score +\n  p.CC2irregRSvsmean.score + p.CC2nwRSvsmean.score + p.age.groupvsmean.score\n\n\n\n\nFigure 16 allows us to visually represent the potential association between an outcome measure, the average spelling score, and a series of other variables that may or may not have an influence on that outcome. Using a grid in this fashion allows us to compare the extent to which different variables appear to have an influence on the outcome. We can see, for example, that measures of variation in word reading skill appear to have stronger association (the trend lines are more steeply slowed) than measures of vocabulary knowledge or intelligence, or age group.\nUsing grids of plots like this allow us to compactly communicate these potential associations in a single figure.\n\n\n\n\n\n\nWarning\n\n\n\nLevenshtein distance scores are higher if a child makes more errors in producing the letters in a spelling response.\n\nThis means that if we want to see what factors help a child to learn a word, including its spelling, then we want to see that helpful factors are associated with lower Levenshtein scores.\n\n\n\n\n\n\n\nAs explained in Section 1.7.2, in the @ricketts2021 study, we taught children taught 16 novel words in a study with a 2 x 2 factorial design. The presence of orthography (orthography absent vs. orthography present) was manipulated within participants: for all children, eight of the words were taught with orthography (the word spelling) present and eight with orthography absent. Instructions (incidental vs. explicit) were manipulated between participants such that children in the explicit condition were alerted to the presence of orthography whereas children in the incidental condition were not. The @ricketts2021 investigation was primarily concerned with the effects on word learning of presenting words for learning with or without showing the words with their spellings, with or without instructing students explicitly that they would be helped by the presence of the spellings.\nWe can analyze the effects of orthography and instruction using a linear model.\n\nmodel &lt;- lm(Levenshtein.Score ~ Instructions*Orthography, data = conc.orth)\n\nThe model code estimates variation in spelling score (values of the Levenshtein.Score) variable, given variation in the levels of the Instructions and Orthography factors, and their interaction.\nThis model is a limited approximation of the analysis we would need to do with these data to estimate the effects of orthography and instruction; see @ricketts2021 for more information on what analysis is required (in our view). However, it is good enough as a basis for exploring the kind of data visualization work — in terms of both discovery and communication — that you can do when you are working with data from an experimental study.\nWe can get a summary of the model results which presents the estimated effect of each experimental factor. These estimates represent the predicted change in spelling score, given variation in Orthography (present, absent) or Instruction (explicit, incidental), and given the possibility that the effect of the presence of orthography is different for different levels of instruction.\nNotice that some of the p-values are incorrectly shown as 0.000. This is a result of using functions to automatically take a model summary and generate a table. I am going to leave this error with a warning because our focus is on visualization, next.\n\n\n\nModel summary\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.584\n0.072\n21.857\n0.000\n\n\nInstructionsincidental\n-0.041\n0.103\n-0.396\n0.692\n\n\nOrthographypresent\n-0.409\n0.103\n-3.987\n0.000\n\n\nInstructionsincidental:Orthographypresent\n0.060\n0.146\n0.409\n0.683\n\n\n\n\n\n\n\nVery often, when we complete a statistical analysis of outcome data, in which we estimate or test the effects on outcomes of variation in some variables or of variation in experimental conditions, then we present a table summary of the analysis results. However, these estimates are typically difficult to interpret (it gets easier with practice) and talk about. Take a look at the summary table. We are often to focus on whether effects are significant or not significant. But, really, what we should consider is how much the outcome changes given the different experimental conditions.\nHow do we get that information from the analysis results? We can communicate results — to ourselves or to an audience — by constructing plots from the model information. The ggeffects library extends ggplot2 to enable us to do this quite efficiently.\nWhen we write code to fit a linear model like:\n\nmodel &lt;- lm(Levenshtein.Score ~ Instructions*Orthography, data = conc.orth)\n\nWe record the results as an object called model because we specify model &lt;- lm(...). We can take these results and ask R to create a plot showing predicted change in outcome (spelling) given our model. We can then present the effects of the variables, as shown in Figure 17.\n\ndat &lt;- ggpredict(model, terms = c(\"Instructions\", \"Orthography\"))\nplot(dat, facet = TRUE) + ylim(0, 3)\n\n\n\n\n\n\n\nFigure 17: Dot and whisker plots showing the predicted effect on outcome spelling (Levenshtein) score, given different experimental conditions: Orthography (present, absent) x Instruction (explicit, incidental).\n\n\n\n\n\nThe code works as follows:\n\ndat &lt;- ggpredict(model, terms = c(\"Instructions\", \"Orthography\")) tells R to calculate predicted outcomes, given our model information, for the factors \"Instructions\", \"Orthography\".\nplot(dat, facet = TRUE) plot the effects, given the predictions, showing the effect of different instruction conditions in different plot facets (the left and right panels).\nylim(0, 3) fix the y-axis to show a more honest indication of the effect on outcomes, given the potential range of spelling scores can start at 0.\n\nIn Figure 17, the dots represent the linear model estimates of outcome spelling, predicted under different conditions. The plots indicate that spelling scores are predicted to be lower when orthography is present. There appears to be little or no effect associated with different kinds of instruction.\nThe vertical lines (often termed “whiskers”) indicate the 95% confidence interval about these estimates. Confidence intervals (CIs) are often mis-interpreted so I will give the quick definition outlined by @Hoekstra2014 here:\n\nA CI is a numerical interval constructed around the estimate of a parameter [i.e. the model estimate of the effect]. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95 % of the cases.\n\nIn short, the interval shows us the range of values within which we can expect to capture the effects of interest, in the long run, if we were to run our experiment over and over again.\nGiven our data and our model, these intervals indicate where the outcome might be expected to vary, given different conditions, and that is quite useful information. If you look at Figure 17, you can see that the presence of orthography (present versus absent) appears to shift outcome spelling, on average, by about a quarter of a letter edit: from over 1.5 to about 1.25. This is about one quarter of the difference, on average, between getting a target spelling correct and getting it wrong by one letter (e.g., the response ‘epegram’ for the target ‘epigram’). This is a relatively small effect but we may consider how such small effects add up, over a child’s development, cumulatively, in making the difference between wrong or nearly right spellings to correct spellings.\nIn the @ricketts2021 paper, we conducted Bayesian analyses which allow us to plot the estimated effects of experimental conditions along with what are called credible intervals indicating our uncertainty about the estimates. In a Bayesian analysis, we can indicate the probable or plausible effect of conditions, or range of plausible effects, given our data and our model. (This intuitive sense of the probable location of effects is, sometimes, what researchers and students mis-interpret confidence intervals as showing; @Hoekstra2014.) Accounting for our uncertainty is a productive approach to considering how much we learn from the evidence we collect in experiments.\nBut this gets ahead of where we are now in our development of skills and understanding. There is another way to discover how uncertain we may be about the results of our analysis. This is an approach we have already experienced: plotting trends or estimates together with the observed data points. We present an example in Figure 18.\n\nplot(dat, add.data = TRUE)\n\n\n\n\n\n\n\nFigure 18: Dot and whisker plots showing the predicted effect on outcome spelling (Levenshtein) score, given different experimental conditions: Orthography (present, absent) x Instruction (explicit, incidental). The estimates are shown as dot-whisker points. In addition, the plot shows as points the spelling score observed for each child for each response recorded in the conc.orth dataset.\n\n\n\n\n\nFigure 18 reveals the usefulness of plotting model estimates of effects alongside the raw observed outcomes. We can make two critical observations.\n\nWe can see that the observed scores clearly cluster around outcome spelling values of 0, 1, 2, 3, 4, and 5.\n\n\nThis is not a surprise because @ricketts2021 scored each response in their test of spelling knowledge by counting the number of letter edits (letter deletions, additions etc.) separating a spelling response from a target response.\nBut the plot does suggest that the linear model is missing something about the outcome data because there is no recognition in the model or the results of this bunching or clustering around whole number values of the outcome variable. (This is why @ricketts2021 use a different analysis approach.)\n\n\nWe can also see that it is actually quite difficult to distinguish the effects of the experimental condition differences on the observed spelling responses. There is a lot of variation in the responses.\n\nHow can we make sense of this variation?\nAnother approach we can take to experimental data is to examine visually how the effects of experimental conditions vary between individual participants. Usually, in teaching, learning and doing foundation or introductory statistical analyses we think about the average impact on outcomes of the experimental conditions or some set of predictor variables. It often makes sense, also, or instead, to consider the ways that the impact on outcomes vary between individuals.\nHere, it might be worthwhile to look at the effect of the conditions for each child. We can do that in different ways. In the following, we will look at a couple of approaches that are often useful. We will focus on the effect of variation in the Orthography condition (present, absent)\nTo begin our work, we first calculate the average outcome (Levenshtein.Score) spelling score for each child in each of the experimental conditions (Orthography, present versus absent):\nWe do this in a series of steps.\n\nscore.by.subj &lt;- conc.orth %&gt;%\n  group_by(Participant, Orthography) %&gt;%\n  summarise(mean.score = mean(Levenshtein.Score))\n\n\nscore.by.subj &lt;- conc.orth %&gt;% create a new dataset score.by.subj by taking the original data conc.orth and piping it through a series of processing steps, to follow.\ngroup_by(Participant, Orthography) %&gt;% first group the rows of the original dataset and piped the grouped data to the next bit. We group the data by participant identity code and by Orthography condition\nsummarise(mean.score = mean(Levenshtein.Score)) then calculate the mean Levenshtein.Score for each participant, for their responses in the Orthography present and in the Orthography absent conditions.\n\nThis first step produces a summary version of the original dataset, with two mean outcome spelling scores for each child, for their responses in the Orthography present and in the Orthography absent conditions. This arranges the summary mean scores in rows, with two rows per child: one for the absent, one for the present condition. You can see what we get in the extract from the dataset, shown next.\n\n\n\n\n\nParticipant\nOrthography\nmean.score\n\n\n\n\nEOF001\nabsent\n1.750\n\n\nEOF001\npresent\n0.875\n\n\nEOF002\nabsent\n1.375\n\n\nEOF002\npresent\n2.125\n\n\nEOF004\nabsent\n1.625\n\n\nEOF004\npresent\n1.000\n\n\nEOF006\nabsent\n0.750\n\n\nEOF006\npresent\n0.500\n\n\nEOF007\nabsent\n1.500\n\n\nEOF007\npresent\n0.625\n\n\n\n\n\n\n\nIn the second step, we also calculate the difference between spelling scores in the different Orthography conditions. We do this because @ricketts2021 were interested in whether spelling responses were different in the different conditions.\n\nscore.by.subj.diff &lt;- score.by.subj %&gt;%\n  pivot_wider(names_from = Orthography, values_from = mean.score) %&gt;%\n  mutate(difference.score = absent - present) %&gt;%\n  pivot_longer(cols = c(absent, present), \n               names_to = 'Orthography',\n               values_to = 'mean.score') \n\n\nscore.by.subj.diff &lt;- score.by.subj %&gt;% creates a new version of the summary dataset from the dataset we just produced.\npivot_wider(names_from = Orthography, values_from = mean.score) %&gt;% re-arranges the dataset so that the absent, present mean scores are side-by-side, in different columns, for each child.\nmutate(difference.score = absent - present) %&gt;% calculates the difference between the absent, present mean scores, creating a new variable, difference.score.\npivot_longer(cols = c(absent, present) ...) re-arranges the data back again so that the dataset is in tidy format, with one column of mean spelling scores, with two rows for each participant for the absent, present mean scores.\n\nThis code arranges the summary mean scores in rows, with two rows per child: one for the absent, one for the present condition — plus a difference score.\n\n\n\n\n\nParticipant\ndifference.score\nOrthography\nmean.score\n\n\n\n\nEOF001\n0.875\nabsent\n1.750\n\n\nEOF001\n0.875\npresent\n0.875\n\n\nEOF002\n-0.750\nabsent\n1.375\n\n\nEOF002\n-0.750\npresent\n2.125\n\n\nEOF004\n0.625\nabsent\n1.625\n\n\nEOF004\n0.625\npresent\n1.000\n\n\nEOF006\n0.250\nabsent\n0.750\n\n\nEOF006\n0.250\npresent\n0.500\n\n\nEOF007\n0.875\nabsent\n1.500\n\n\nEOF007\n0.875\npresent\n0.625\n\n\n\n\n\n\n\nNow we can use these data to consider how the impact of the experimental condition (Orthography: present versus absent) varies between individual participants. We do this by showing the mean outcome spelling score, separately for each participant, in each condition.\nFigure 19 shows dot plots indicating the different outcome spelling (Levenshtein) scores, for each participant, in the different experimental conditions: Orthography (present, absent). Plots are ordered, from top left to bottom right, by the difference between mean spelling scores in the absent versus present conditions. The plots indicate that some children show higher spelling scores in the present than in the absent condition (top left plots), some children show little difference between conditions (middle rows), while some children show higher spelling scores in the absent than in the present condition (bottom rows).\n\nggplot(data = score.by.subj.diff, \n       aes(x = Orthography, y = mean.score,\n           colour = Orthography)) +\n  geom_point() +\n  facet_wrap(~ reorder(Participant, difference.score)) +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\nFigure 19: Dot plots showing the different outcome spelling (Levenshtein) scores, for each participant, in the different experimental conditions: Orthography (present, absent). Plots are ordered, from top left to bottom right, by the difference between mean spelling scores in the absent versus present conditions.\n\n\n\n\n\nOnce we have done the data processing in preparation, the code to produce the plot is fairly compact.\n\nggplot(data = score.by.subj.diff ... tells R to produce a plot, using ggplot() and the newly created score.by.subj.diff dataset.\naes(x = Orthography, y = mean.score,... specifies the aesthetic mappings: we tell R to locate mean.score on the y-axis and Orthography condition on the x-axis/\naes(...colour = Orthography)) + specifies a further aesthetic mapping: we tell R to map different Orthography conditions to different colours.\ngeom_point() + tells R to take the data and produce a scatterplot, given our mapping specifications.\nfacet_wrap(...) + tells to split the dataset into sub-sets (facets).\nfacet_wrap(~ reorder(Participant, difference.score)) tells R that we want the sub-sets to be organized by Participant, and we want the facets to be ordered by the difference.score calculated for each participant.\ntheme(axis.text.x = element_blank()) removes the x-axis labels because it is too crowded with the axis labels left in, and the information is already present in the colour guide legend shown on the right of the plot.\n\n\n\n\nVisualizing associations between variables encompasses a wide range of the things we have to do, in terms of both discovery and communication, when we work with data from psychological experiments.\nThe conventional method to visualize how the distribution of values in one variable covaries with the distribution of values in another variable is through using a scatterplot. However, the construction of a scatterplot can be elaborated in various ways to enrich the information we present or communicate to our audiences, or to ourselves.\n\nWe can add elements like smoothers to indicate trends.\nWe can add annotation, as with the histograms, to highlight specific thresholds.\nWe can facet the plots to indicate how trends may vary between sub-sets of the data.\n\nIn the final phases of our practical work, we started by presenting model-based predictions of the effects of experimental manipulations. However, you will have noticed that presenting plots of effects is not where we stop when we engage with a dataset. Further plotting indicates quite marked variation between participants in the effects of the conditions. This kind of insight is something we can and should seek to reveal through our visualization work."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-next-steps",
    "href": "PSYC411/part2/visualization.html#sec-vis-next-steps",
    "title": "Data visualization",
    "section": "",
    "text": "To take your development further, take a look at the resources listed in Section 1.9.\nIn my experience, the most productive way to learn about visualization and about coding the production of plots, is by doing. And this work is most interesting if you have a dataset you care about: for your research report, or for your dissertation study.\nAs you have the alternate datasets described in Section 1.7.1.2.1, you can start with the data from the other task or the other study in @ricketts2021. @ricketts2021 recorded children’s responses in two different outcome tasks, the orthographic spelling task we have looked at, and a semantic or meaning-based task. It would be a fairly short step to adapt the code you see in the example code chunks to work with the semantic datasets.\nAlternatively, you can look at the data reported by @rodríguez-ferreiro2020. @rodríguez-ferreiro2020 present both measures of individual differences (on schizotypyal traits) and experimental manipulations (of semantic priming) so you can do similar things with those data as we have explored here."
  },
  {
    "objectID": "PSYC411/part2/visualization.html#sec-vis-resources",
    "href": "PSYC411/part2/visualization.html#sec-vis-resources",
    "title": "Data visualization",
    "section": "",
    "text": "We typically use the ggplot library (part of the tidyverse) to produce plots. Clear technical information, with useful examples you can copy and run, can be found in the reference webpages:\n\nhttps://ggplot2.tidyverse.org/reference/index.html\n\nA source of inspiration can be found here:\n\nhttps://r-graph-gallery.com\nIf you are trying to work out how to do things by searching for information online, you often find yourself at tutorial webpages. You will develop a sense of quality and usefulness with experience. Most often, what you are looking for is a tutorial that provides some explanation, and example code you can adapt for your own purposes. Here are some examples.\n\nCedric Scherer on producing raincloud plots:\n\nhttps://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-and-how-to-create-them-with-ggplot2/\n\nWinston Chang on colours and colour blind palettes:\n\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\n\nThomas Lin Pedersen (and others) on putting together plots into a single presentation using the patchwork library functions:\n\nhttps://patchwork.data-imaginist.com/articles/patchwork.html\n\n\n\n\nThe book “R for Data Science” [@wickham2016] will guide you through the data analysis workflow, including data visualization, and the latest version can be accessed in an online free version here:\n\nhttps://r4ds.hadley.nz\n\nThe “ggplot2: Elegant Graphics for Data Analysis” book [@R-ggplot2] corresponding to the ggplot library was written by Hadley Wickham in its first edition, it is now in its third edition (as a work in progress, co-authored by Wickham, Danielle Navarro and Thomas Lin Pedersen) and this latest version can be accessed in an online free version here:\n\nhttps://ggplot2-book.org/index.html\n\nThe “R graphics cookbook” [@Chang2013a], and the latest version can be accessed in an online free version here:\n\nhttps://r-graphics.org\n\nThe book “Fundamentals of Data Visualization” [@wilke] is about different aspects of visualization, and can be accessed in an online free version here:\n\nhttps://clauswilke.com/dataviz/"
  },
  {
    "objectID": "PSYC411/part2/visualization.html#footnotes",
    "href": "PSYC411/part2/visualization.html#footnotes",
    "title": "Data visualization",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs you can see if you read the @ricketts2021 paper, and the associated guide to the data and analysis on the OSF repository, we analysed the word learning data using Generalized Linear Mixed-effects Models (GLMM). GLMMs are used when we are analyzing data with a multilevel structure. These structures are very common and can be identified whenever we have groups or clusters observations: here, we have multiple observations of the test response, for each participant and for each stimulus word. When we fit GLMMs, the functions we use to do the analysis require the data to be structured in this tidy fashion, with different rows for each response or outcome observation, and repeated information for each participant or stimulus (if present).↩︎"
  },
  {
    "objectID": "PSYC411/part2/summary.html",
    "href": "PSYC411/part2/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nTo complete when book is completed.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC411/part2/lm-dev.html",
    "href": "PSYC411/part2/lm-dev.html",
    "title": "Developing the linear model",
    "section": "",
    "text": "Welcome to our overview of the materials for our class on developing the linear model in PSYC401 Week 10.\nWe will continue to locate our learning in the context of the Clearly understood project. We present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data (as we explain in ?@sec-preface).\nIn this chapter, we focus on extending your understanding and skills so that you can apply the linear model analysis approach to a wider range of research questions.\nIn the context of the Clearly understood project, we frame our analysis concerns and methods in relation to two example research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nIt will be seen that to answer these research questions, we need to think about how we analyze data when multiple different predictor variables could be included in our model of outcome data, and when these variables may consist of different kinds of observations.\nYou can read a bit more about the project and the project data in ?@sec-associations.\n\n\n\nThis week, we build on what we have learnt so far about how we can analyze data to predict data about people (e.g., our attributes) or about the things we make or do. To do this, we will learn to think about and work with linear models.\nOur learning objectives: — what are we learning about?\n\n\n\nWe will learn how to:\n\n\nExtend our capacity to code models so that we can incorporate multiple predictors\nDevelop the thought processes required to make decisions about what predictors to include\nDevelop the skills required to critically evaluate results\n\nEspecially considering potential variation across samples\n\nWe will revise how to:\n\n\nIdentify and interpret model statistics\nCritically evaluate the results\nCommunicate the results\n\n\nWe will learn how to: explore extensions or generalisations of the linear model\n\n\n\n\n\nYou will see in the next section links to the lectures we created both to explain the concepts we want to help you to learn about, and to explain the practical data analysis skills we want to help you to develop (Section 1.3.1). We then share links to information about the practical materials we have provided to help you to practise those skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 10 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points.\n\n\n\n\n\n\nTip\n\n\n\nLinked resources include:\n\nIn ?@sec-associations, we present an overview of our materials in relation to thinking about associations, and working with correlation-based analyses of associations.\nIn ?@sec-lm-intro-intro, we introduce you to the main ideas and practical steps involved in conducting linear model analyses.\n\n\n\n\n\nThe lecture material for this week is presented in four short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 4\nPart 2 of 4\nPart 3 of 4\nPart 4 of 4\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data file:\n\n2022-12-08_all-studies-subject-scores.csv\n\nand .R code files:\n\n401-lm-dev-how-to.R\n401-lm-dev-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-lm-dev-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-lm-dev-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\n2022-12-08_all-studies-subject-scores.csv.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures.\nThis is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-lm-dev-workbook.R\n\nyou will work with the data file\n\n2022-12-08_all-studies-subject-scores.csv\n\nWe split .R scripts into parts, tasks and questions.\nFor this class on developing the linear model, our practical materials have two aims:\n\nHelping you to consolidate your learning on how to use linear models to estimate and to visualize the hypothetical association between outcome and predictor variables.\n\n\nYou will work to code linear models, to identify key statistical information in model outputs, and to interpret and report the results of the models.\nWe refresh your learning by working with a data-set you have not encountered before\nWe extend your skills by using a new function to generate predictions from fitted models.\n\n\nHelping you to learn how to extend your capacity to work with data to answer research questions by developing linear models that include multiple predictor variables.\n\n\nWe extend your skills by looking at how you work with categorical predictor variables: factors.\nBecause factors are so important to research in Psychology, we examine how to code or recode factor levels, and how to visualize the effects on outcomes of differences between factor levels.\n\nTo meet these aims, we progress through a series of parts:\n\nPart 2 shows you how you can read in data and at the same time ensure that different kinds of variables (e.g., factors versus numeric variables) are handled differently by R.\nPart 3 consolidates your learning on how to work with linear models when there is one outcome variable and just one predictor variable. Learning to work with linear models involves not just coding models but also being able to identify and interpret the results of the models you fit.\nPart 5 extends your capacities by helping you to learn how to code linear models that include multiple predictor variables.\nPart 6 builds your understanding of what linear models do, and what model estimates mean, by demonstrating a key point: linear models are coded to fit sample outcome data. When you look at model results, your interpretation is based on how the outcome is predicted to change, on average, given differences in values of one or more predictor variables.\nPart 7 builds your skills by helping you to learn how to code, visualize and interpret the impact on outcomes of the differences between factor levels.\n\nThroughout, we help you to develop skills in calculating and presenting model predictions.\n\nParts optional are designed to help you to examine the ways in which the association between variables may, itself, differ between different samples, and to help you to consolidate skills on exporting plots for use in reports.\n\nThe activity 401-lm-dev-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-lm-dev-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\n\n\n\nThe data file we will work with has a similar structure to the structure you have seen before.\nHere are what the first few rows in the data file 2022-12-08_all-studies-subject-scores.csv looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResponseId\nmean.acc\nmean.self\nAGE\nGENDER\nEDUCATION\nETHNICITY\nSHIPLEY\nHLVA\nFACTOR3\nNATIVE.LANGUAGE\nstudy\n\n\n\n\nR_1lcaBAGJNNI2kju\n1.00\n7.6\n18\nFemale\nFurther\nWhite\n31\n10\n48\nEnglish\nPSYC122\n\n\nR_AG4jiTm8oxmuOOZ\n0.90\n7.6\n18\nFemale\nFurther\nWhite\n35\n10\n40\nEnglish\nPSYC122\n\n\nR_2Ckb6YXLPGwYSvg\n0.95\n7.2\n18\nMale\nFurther\nAsian\n35\n9\n47\nOther\nPSYC122\n\n\nR_27JY5xHHcMs7jGi\n0.90\n6.8\n18\nFemale\nFurther\nWhite\n35\n8\n52\nEnglish\nPSYC122\n\n\nR_1DtJ4mrOXmxre01\n0.85\n6.4\n19\nFemale\nFurther\nWhite\n33\n9\n41\nEnglish\nPSYC122\n\n\nR_PRFQFInzSS6T8e5\n0.90\n6.2\n19\nFemale\nFurther\nMixed\n36\n5\n52\nEnglish\nPSYC122\n\n\n\n\n\nThere are two new columns:\n\nNATIVE.LANGUAGE self reported language status, whether the participant reports whether they are or are not a native speaker of English\nstudy codes for which study participant data were collected in\n\nYou can also see the columns you have seen before:\n\nResponseId participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\nSHIPLEY vocabulary knowledge test score\nHLVA health literacy test score\nFACTOR3 reading strategy survey score\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful.\n\n\n\n\nSome people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nAnalyze\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow: we focus on the linear model\n\n\n\n\n\n\n\n\n\nWe will learn how to:\n\n\nExtend our capacity to code models so that we can incorporate multiple predictors\nDevelop the thought processes required to make decisions about what predictors to include\nDevelop the skills required to critically evaluate results\n\n\nEspecially considering potential variation across samples\n\n\n\n\n\nWe will revise how to:\n\n\nIdentify and interpret model statistics\nCritically evaluate the results\nCommunicate the results\n\n\nWe will learn how to: explore extensions of the linear model\n\n\n\n\n\nBecause public health impacts depend on giving people information they can understand\nWe want to know: What makes it easy or difficult to understand written health information?\n\n\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\n\n\n\n\n\n\nWe want to know: What makes it easy or difficult to understand written health information?\nSo our research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\nWe need only a limited change to R code\nTo specify a model with multiple predictors\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY,\n            data = all.studies.subjects)\nsummary(model)\n\n\nSpecify the lm function and the model mean.acc ~ ...\nSpecify what data we use data = all.studies.subjects\nGet the results summary(model)\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE,\n            data = all.studies.subjects)\nsummary(model)\n\n\nSpecify the lm function and the model:\n\n\nmean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE\n\n\n\n\nTake a good look:\n\nlm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, ...)\n\nYou will see this sentence structure in coding for many different analysis types\n\nmethod(outcome ~ predictors)\npredictors could be SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE ...\n\n\n\n\n\nWe assume that the outcome prediction errors residuals are normally distributed\nWe do not assume that the distributions of predictor variables are normal\n\n\n\n\n\nDifferences between observed and predicted outcomes are shown by the vertical lines – outcome prediction errors: residuals\nBetter models should show smaller differences between observed and predicted outcome values\n\n\n\n\n\n\n\n\n\nFigure 2: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\nSome outcome prediction errors – residuals – are positive\nSome residuals are negative\nThe average of the residuals will be zero overall\n\n\n\n\n\n\n\n\n\nFigure 3: Plot showing the distribution of prediction errors – residuals – for the linear model of comprehension accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Scatterplot showing the potential association between accuracy of comprehension and variation on each of a series of potential predictor variables. Data from 8 studies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Grid of plots showing the distribution of potential predictor variables. Data from 8 studies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can try to model anything using linear models: that is the real challenge we face\n\nAny analysis you have learned can instead be done using a linear model: ANOVA, t-test, correlation, \\(\\chi^2\\) test, …\nWe can work with any kind of dependent or independent variable you can think of\n\nThis is why we need to be careful\n\n\n\n\n\nClosing the loop: The health comprehension project questions\n\nWe want to know: What makes it easy or difficult to understand written health information?\nSo our research questions include:\n\n\nWhat person attributes predict success in understanding?\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 6: Understanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n(1.) experience (HLVA, SHIPLEY) and (2.) reasoning ability (reading strategy)\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 7: Understanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n\nWhich variables should be included in an analysis?\nAll of them; some of them; why?\nWill others disagree with reason?\n\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nA\n\n\n\nB1\n\nB1\n\n\n\nA-&gt;B1\n\n\n\n\n\nB2\n\nB2\n\n\n\nA-&gt;B2\n\n\n\n\n\nC1\n\nC1\n\n\n\nB1-&gt;C1\n\n\n\n\n\nC2\n\nC2\n\n\n\nB1-&gt;C2\n\n\n\n\n\nC3\n\nC3\n\n\n\nB1-&gt;C3\n\n\n\n\n\nC4\n\nC4\n\n\n\nB2-&gt;C4\n\n\n\n\n\nC5\n\nC5\n\n\n\nB2-&gt;C5\n\n\n\n\n\nC6\n\nC6\n\n\n\nB2-&gt;C6\n\n\n\n\n\n\n\n\nFigure 8: Forking paths in data analysis\n\n\n\n\n\n\n\n\nThis is why we care about open science\n\nTheory- and evidence-based selection of critical variables for analysis \\(\\rightarrow\\) literature review\nShare usable data and analysis code in open repositories \\(\\rightarrow\\) research report exercise, PSYC403 data archiving\n\n\n\n\n\nlm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, ...)\n\n\n\n\n\nlm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, ...)\n\n\nThe code represents a linear model with multiple predictors:\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\epsilon\\)\n\n\n\n\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\epsilon\\)\nOutcome \\(y\\) is calculated as the sum of:\n\nThe intercept \\(\\beta_0\\) plus\nThe product of the coefficient of the effect of e.g. AGE \\(\\beta_1\\) multiplied by \\(x_1\\) a person’s age +\n+ any number of other variables +\nThe error \\(\\epsilon\\): mismatches between observed and predicted outcomes\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nThe summary() of the linear model shows:\nEstimates of the coefficients of the effects of the predictors we included, with null hypothesis significance tests of those estimates\nModel fit statistics including R-squared and F-statistic estimates\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe Coefficient Estimate: 0.0242787 for the slope of the effect of variation in HLVA scores\nThe Std. Error (standard error) 0.0031769 for the estimate\nThe t value of 7.642 and associated Pr(&gt;|t|) p-value 9.44e-14 for the null hypothesis test of the coefficient\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nPay attention to sign and the size of coefficient estimate:\nIs the coefficient (e.g., HLVA 0.0242787) a positive or a negative number? is it relatively large or small?\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nRevision: Pay attention to R-squared\nR-squared indicates how much outcome variation we can predict, given our model\nRevision: we report Adjusted R-squared because it tends to be more accurate\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe model summary gives us the F-statistic:\nRevision: the F-test of the null hypothesis that the model does not predict the outcome\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: A grid of plots showing model predictions, for outcome accuracy, given variation in (a.) age, (b.) vocabulary, (c.) health literacy, (d) reading strategy and (e.) native language. Data from eight studies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoefficients estimates in the summary match what we see\nPositive coefficients show upward slopes\nLarger coefficients show steeper slopes\n\n\n\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and, as predictors: vocabulary knowledge (Shipley), health literacy (HLVA), reading strategy (FACTOR3), age (years) and native language status. Our analysis indicated significant effects of all predictor variables. The model is significant overall, with \\(F(5, 555) = 81.09, p &lt; .001\\), and explains 42% of variance (\\(\\text{adjusted } R^2 = 0.42\\)). The model estimates showed that the accuracy of comprehension increased with higher levels of participant vocabulary knowledge (\\(\\beta = .007, t = 6.64, p &lt;.001\\)), health literacy (\\(\\beta = .024, t = 7.64, p &lt;.001\\)), and reading strategy (\\(\\beta = .005, t = 5.98, p = &lt; .001\\)). Younger participants (\\(\\beta = -0.003, t = -5.39, p &lt;.001\\)) and native speakers of English as another language (\\(\\beta = -.090, t = -6.37, p &lt;.001\\)) tended to show lower levels of accuracy.\n\n\n\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and, as predictors: vocabulary knowledge (Shipley), health literacy (HLVA), reading strategy (FACTOR3), age (years) and native language status. Our analysis indicated significant effects of all predictor variables. The model is significant overall, with \\(F(5, 555) = 81.09, p &lt; .001\\), and explains 42% of variance (\\(\\text{adjusted } R^2 = 0.42\\)). The model estimates showed that the accuracy of comprehension increased with higher levels of participant vocabulary knowledge (\\(\\beta = .007, t = 6.64, p &lt;.001\\)), health literacy (\\(\\beta = .024, t = 7.64, p &lt;.001\\)), and reading strategy (\\(\\beta = .005, t = 5.98, p = &lt; .001\\)). Younger participants (\\(\\beta = -0.003, t = -5.39, p &lt;.001\\)) and native speakers of English as another language (\\(\\beta = -.090, t = -6.37, p &lt;.001\\)) tended to show lower levels of accuracy.\n\n\nExplain: the method (linear model); the outcome (accuracy) and the predictors\nReport the model fit statistics overall (\\(F, R^2\\))\nReport the significant effects (\\(\\beta, t, p\\)) and describe the nature of the effects\n\n\n\n\nThere are three levels of uncertainty when we look at sample data [@mcelreath2020] – uncertainty over:\n\nThe nature of the expected change in outcome\nThe ways that expected changes might vary between individual participants or between groups of participants\nThe random ways that specific responses can be produced\n\n\n\n\n\nThese uncertainties require us to carefully qualify the conclusions we draw from data analyses\nThis does not mean we should avoid causal language when we think that psychological processes cause the behaviours we examine [@Grosz2020]\nBut it does mean we can be careful to identify the limits in the evidence we analyse\n\n\n\n\n\nvalidity: that differences in knowledge or ability cause differences in test scores\nmeasurement: that this is equally true across the different kinds of people we tested\ngeneralizability: that the sample of people we recruited resembles the population\n\n\n\n\n\nvalidity\n\n\nWe want to work with valid measures but validity requires explaining [@borsboom2004]:\n\n\nDoes the thing exist in the world?\nIs variation in that thing be reflected in variation in our measurement?\n\n\nWhat you can do: literature review \\(\\rightarrow\\) to identify your reasoning in answer to these questions\n\n\n\n\n\nmeasurement\ngeneralizability\n\n\nIt is most helpful to assume from the start that effects estimates will vary [@Gelman2015; @vasishth2021]\nSo then we ask ourselves: will this test work in the same way in different groups?\nAnd we ask: how will these effects estimates vary across different groups\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Scatterplot showing the potential association between accuracy of comprehension and vocabulary scores: Data from eight studies. Effects will vary between different samples so: expect the variation [@Gelman2015; @vasishth2021] &gt;&gt;&gt; important to evaluating claims in the literature, and to evaluation of your own results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Effects will vary between samples so expect the variation [@Gelman2015; @vasishth2021] &gt;&gt;&gt; ask what variation may result from systematic differences between groups\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: Grid of plots showing the distribution of potential predictor variables\n\n\n\n\n\n\n\n\n\nWe test who we can – convenience sampling – and who we can test has an impact on the quality of evidence [@bornstein2013]\nIf age, ethnicity or gender are not balanced \\(\\rightarrow\\) does this matter to your research question?\nIf samples are limited in size \\(\\rightarrow\\) how does that affect our uncertainty over effects estimates?\n\n\n\n\n\nMost introductory statistics classes teach each statistical test as if they are independent\n\n\n\n\n\n\n\nTip\n\n\n\nMost common statistical tests are special cases of linear models, or are close approximations\n\n\n\n\n\n\\(y_i = \\beta_0 + \\beta_1X\\)\n\nIf you have two groups, with a variable X coding for group membership\nThen the mean outcome for one group \\(= \\beta_0\\)\nThe estimate of the slope \\(\\beta_1\\) tells about the average difference between groups\nAnd we can code the model like this: lm(y ~ group)\n\n\n\n\n\\(y_i = \\beta_0 + \\beta_1X + \\beta_2Z + \\beta_3XZ\\)\n\nIf you have a 2 x 2 factorial design, with two factors factor.1, factor.2, and a dataset with variables X, Z coding for group membership\nThen the mean outcome for baseline conditions \\(= \\beta_0\\)\nThe estimates of the slopes \\(\\beta_1, \\beta_2\\) tells about the average difference between groups\nThe estimate of the slope \\(\\beta_3\\) tells us about the interaction\nAnd we can code the model like this: lm(y ~ factor.1*factor.2)\nOr this Anova(aov(y ~ factor.1*factor.2, data), type='II')\n\n\n\n\n\nIn general, the psychological literature is full of ANOVA\nBut the field is moving away from ANOVA towards mixed-effects models\n\n\n\n\n\n\n\nTip\n\n\n\nWe have to make choices in teaching and, here, we are choosing to focus on a powerful, flexible, and generally applicable method we can explain in depth: linear models\n\nOur aim is for students to better understand how to use a general approach\n\n\n\n\n\n\n\\(outcome ~ predictors + error\\)\n\noutcome can generalize to analyse data that are not metric, do not come from normal distributions\npredictors can be curvilinear, categorical, involve interactions\nerror can be independent; can be non-independent\n\n\n\n\n\nWhat if the outcome measurement data cannot be understood to be metric or to come from a normal probability distribution?\n\n\n\n\n\nBinary outcomes are very common in Psychology: yes or no; correct or incorrect; left or right visual field etc.\nThe change in coding is e.g. glm(ratings ~ predictors, family = \"binomial\")\n\n\n\n\n\nLikert scale or ratings data are best analysed using ordinal models [@liddell2018]\nThe change in coding [@christensen] is e.g. clm(ratings ~ predictors)\n\n\n\n\n\nMuch – maybe most – psychological data are collected in ways that guarantee the non-independence of observations\n\n\nWe test children in classes, patients in clinics, individuals in regions\nWe test participants in multiple trials in an experiment, recording responses to multiple stimuli\n\n\nThese data should be analysed using linear mixed-effects models [@meteyard2020]\n\n\n\n\nAn old saying goes:\n\nAll models are wrong but some are useful\n\n(attributed to George Box).\n\n\n\n\n\n\nTip\n\n\n\n\nSometimes, it can be useful to adopt a simpler approach as a way to approximate get closer to better methods\nBox also advises “Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.”\nHere, we focus on validity, measurement, generalizability and critical thinking\n\n\n\n\n\n\n\nLinear models\n\n\nLinear models are a very general, flexible, and powerful analysis method\nWe can use assuming that prediction outcomes (residuals) are normally distributed\nWith potentially multiple predictor variables\n\n\nThinking about linear models\n\n\nClosing the loop: when we plan an analysis we should try to use contextual information – theory and measurement understanding – to specify our model\nClosing the loop: when we critically evaluate our or others’ findings, we should consider validity, measurement, and generalizability\n\n\nReporting linear models\n\n\nWhen we report an analysis, we should report:\n\n\nExplain what I did, specifying the method (linear model), the outcome variable (accuracy) and the predictor variables (health literacy, reading strategy, reading skill and vocabulary)\nReport the model fit statistics overall (\\(F, R^2\\))\nReport the significant effects (\\(\\beta, t, p\\)) and describe the nature of the effects (does the outcome increase or decrease?)"
  },
  {
    "objectID": "PSYC411/part2/lm-dev.html#sec-lm-dev-overview",
    "href": "PSYC411/part2/lm-dev.html#sec-lm-dev-overview",
    "title": "Developing the linear model",
    "section": "",
    "text": "Welcome to our overview of the materials for our class on developing the linear model in PSYC401 Week 10.\nWe will continue to locate our learning in the context of the Clearly understood project. We present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data (as we explain in ?@sec-preface).\nIn this chapter, we focus on extending your understanding and skills so that you can apply the linear model analysis approach to a wider range of research questions.\nIn the context of the Clearly understood project, we frame our analysis concerns and methods in relation to two example research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nIt will be seen that to answer these research questions, we need to think about how we analyze data when multiple different predictor variables could be included in our model of outcome data, and when these variables may consist of different kinds of observations.\nYou can read a bit more about the project and the project data in ?@sec-associations."
  },
  {
    "objectID": "PSYC411/part2/lm-dev.html#sec-lm-dev-goals",
    "href": "PSYC411/part2/lm-dev.html#sec-lm-dev-goals",
    "title": "Developing the linear model",
    "section": "",
    "text": "This week, we build on what we have learnt so far about how we can analyze data to predict data about people (e.g., our attributes) or about the things we make or do. To do this, we will learn to think about and work with linear models.\nOur learning objectives: — what are we learning about?\n\n\n\nWe will learn how to:\n\n\nExtend our capacity to code models so that we can incorporate multiple predictors\nDevelop the thought processes required to make decisions about what predictors to include\nDevelop the skills required to critically evaluate results\n\nEspecially considering potential variation across samples\n\nWe will revise how to:\n\n\nIdentify and interpret model statistics\nCritically evaluate the results\nCommunicate the results\n\n\nWe will learn how to: explore extensions or generalisations of the linear model"
  },
  {
    "objectID": "PSYC411/part2/lm-dev.html#sec-lm-dev-resources",
    "href": "PSYC411/part2/lm-dev.html#sec-lm-dev-resources",
    "title": "Developing the linear model",
    "section": "",
    "text": "You will see in the next section links to the lectures we created both to explain the concepts we want to help you to learn about, and to explain the practical data analysis skills we want to help you to develop (Section 1.3.1). We then share links to information about the practical materials we have provided to help you to practise those skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 10 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points.\n\n\n\n\n\n\nTip\n\n\n\nLinked resources include:\n\nIn ?@sec-associations, we present an overview of our materials in relation to thinking about associations, and working with correlation-based analyses of associations.\nIn ?@sec-lm-intro-intro, we introduce you to the main ideas and practical steps involved in conducting linear model analyses.\n\n\n\n\n\nThe lecture material for this week is presented in four short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 4\nPart 2 of 4\nPart 3 of 4\nPart 4 of 4\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data file:\n\n2022-12-08_all-studies-subject-scores.csv\n\nand .R code files:\n\n401-lm-dev-how-to.R\n401-lm-dev-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-lm-dev-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-lm-dev-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\n2022-12-08_all-studies-subject-scores.csv.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures.\nThis is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-lm-dev-workbook.R\n\nyou will work with the data file\n\n2022-12-08_all-studies-subject-scores.csv\n\nWe split .R scripts into parts, tasks and questions.\nFor this class on developing the linear model, our practical materials have two aims:\n\nHelping you to consolidate your learning on how to use linear models to estimate and to visualize the hypothetical association between outcome and predictor variables.\n\n\nYou will work to code linear models, to identify key statistical information in model outputs, and to interpret and report the results of the models.\nWe refresh your learning by working with a data-set you have not encountered before\nWe extend your skills by using a new function to generate predictions from fitted models.\n\n\nHelping you to learn how to extend your capacity to work with data to answer research questions by developing linear models that include multiple predictor variables.\n\n\nWe extend your skills by looking at how you work with categorical predictor variables: factors.\nBecause factors are so important to research in Psychology, we examine how to code or recode factor levels, and how to visualize the effects on outcomes of differences between factor levels.\n\nTo meet these aims, we progress through a series of parts:\n\nPart 2 shows you how you can read in data and at the same time ensure that different kinds of variables (e.g., factors versus numeric variables) are handled differently by R.\nPart 3 consolidates your learning on how to work with linear models when there is one outcome variable and just one predictor variable. Learning to work with linear models involves not just coding models but also being able to identify and interpret the results of the models you fit.\nPart 5 extends your capacities by helping you to learn how to code linear models that include multiple predictor variables.\nPart 6 builds your understanding of what linear models do, and what model estimates mean, by demonstrating a key point: linear models are coded to fit sample outcome data. When you look at model results, your interpretation is based on how the outcome is predicted to change, on average, given differences in values of one or more predictor variables.\nPart 7 builds your skills by helping you to learn how to code, visualize and interpret the impact on outcomes of the differences between factor levels.\n\nThroughout, we help you to develop skills in calculating and presenting model predictions.\n\nParts optional are designed to help you to examine the ways in which the association between variables may, itself, differ between different samples, and to help you to consolidate skills on exporting plots for use in reports.\n\nThe activity 401-lm-dev-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-lm-dev-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\n\n\n\nThe data file we will work with has a similar structure to the structure you have seen before.\nHere are what the first few rows in the data file 2022-12-08_all-studies-subject-scores.csv looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResponseId\nmean.acc\nmean.self\nAGE\nGENDER\nEDUCATION\nETHNICITY\nSHIPLEY\nHLVA\nFACTOR3\nNATIVE.LANGUAGE\nstudy\n\n\n\n\nR_1lcaBAGJNNI2kju\n1.00\n7.6\n18\nFemale\nFurther\nWhite\n31\n10\n48\nEnglish\nPSYC122\n\n\nR_AG4jiTm8oxmuOOZ\n0.90\n7.6\n18\nFemale\nFurther\nWhite\n35\n10\n40\nEnglish\nPSYC122\n\n\nR_2Ckb6YXLPGwYSvg\n0.95\n7.2\n18\nMale\nFurther\nAsian\n35\n9\n47\nOther\nPSYC122\n\n\nR_27JY5xHHcMs7jGi\n0.90\n6.8\n18\nFemale\nFurther\nWhite\n35\n8\n52\nEnglish\nPSYC122\n\n\nR_1DtJ4mrOXmxre01\n0.85\n6.4\n19\nFemale\nFurther\nWhite\n33\n9\n41\nEnglish\nPSYC122\n\n\nR_PRFQFInzSS6T8e5\n0.90\n6.2\n19\nFemale\nFurther\nMixed\n36\n5\n52\nEnglish\nPSYC122\n\n\n\n\n\nThere are two new columns:\n\nNATIVE.LANGUAGE self reported language status, whether the participant reports whether they are or are not a native speaker of English\nstudy codes for which study participant data were collected in\n\nYou can also see the columns you have seen before:\n\nResponseId participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\nSHIPLEY vocabulary knowledge test score\nHLVA health literacy test score\nFACTOR3 reading strategy survey score\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful."
  },
  {
    "objectID": "PSYC411/part2/lm-dev.html#sec-lm-dev-notes",
    "href": "PSYC411/part2/lm-dev.html#sec-lm-dev-notes",
    "title": "Developing the linear model",
    "section": "",
    "text": "Some people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nAnalyze\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow: we focus on the linear model\n\n\n\n\n\n\n\n\n\nWe will learn how to:\n\n\nExtend our capacity to code models so that we can incorporate multiple predictors\nDevelop the thought processes required to make decisions about what predictors to include\nDevelop the skills required to critically evaluate results\n\n\nEspecially considering potential variation across samples\n\n\n\n\n\nWe will revise how to:\n\n\nIdentify and interpret model statistics\nCritically evaluate the results\nCommunicate the results\n\n\nWe will learn how to: explore extensions of the linear model\n\n\n\n\n\nBecause public health impacts depend on giving people information they can understand\nWe want to know: What makes it easy or difficult to understand written health information?\n\n\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\n\n\n\n\n\n\nWe want to know: What makes it easy or difficult to understand written health information?\nSo our research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\n\n\n\nWe need only a limited change to R code\nTo specify a model with multiple predictors\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY,\n            data = all.studies.subjects)\nsummary(model)\n\n\nSpecify the lm function and the model mean.acc ~ ...\nSpecify what data we use data = all.studies.subjects\nGet the results summary(model)\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE,\n            data = all.studies.subjects)\nsummary(model)\n\n\nSpecify the lm function and the model:\n\n\nmean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE\n\n\n\n\nTake a good look:\n\nlm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, ...)\n\nYou will see this sentence structure in coding for many different analysis types\n\nmethod(outcome ~ predictors)\npredictors could be SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE ...\n\n\n\n\n\nWe assume that the outcome prediction errors residuals are normally distributed\nWe do not assume that the distributions of predictor variables are normal\n\n\n\n\n\nDifferences between observed and predicted outcomes are shown by the vertical lines – outcome prediction errors: residuals\nBetter models should show smaller differences between observed and predicted outcome values\n\n\n\n\n\n\n\n\n\nFigure 2: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\nSome outcome prediction errors – residuals – are positive\nSome residuals are negative\nThe average of the residuals will be zero overall\n\n\n\n\n\n\n\n\n\nFigure 3: Plot showing the distribution of prediction errors – residuals – for the linear model of comprehension accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Scatterplot showing the potential association between accuracy of comprehension and variation on each of a series of potential predictor variables. Data from 8 studies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Grid of plots showing the distribution of potential predictor variables. Data from 8 studies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can try to model anything using linear models: that is the real challenge we face\n\nAny analysis you have learned can instead be done using a linear model: ANOVA, t-test, correlation, \\(\\chi^2\\) test, …\nWe can work with any kind of dependent or independent variable you can think of\n\nThis is why we need to be careful\n\n\n\n\n\nClosing the loop: The health comprehension project questions\n\nWe want to know: What makes it easy or difficult to understand written health information?\nSo our research questions include:\n\n\nWhat person attributes predict success in understanding?\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 6: Understanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n(1.) experience (HLVA, SHIPLEY) and (2.) reasoning ability (reading strategy)\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 7: Understanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n\nWhich variables should be included in an analysis?\nAll of them; some of them; why?\nWill others disagree with reason?\n\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nA\n\n\n\nB1\n\nB1\n\n\n\nA-&gt;B1\n\n\n\n\n\nB2\n\nB2\n\n\n\nA-&gt;B2\n\n\n\n\n\nC1\n\nC1\n\n\n\nB1-&gt;C1\n\n\n\n\n\nC2\n\nC2\n\n\n\nB1-&gt;C2\n\n\n\n\n\nC3\n\nC3\n\n\n\nB1-&gt;C3\n\n\n\n\n\nC4\n\nC4\n\n\n\nB2-&gt;C4\n\n\n\n\n\nC5\n\nC5\n\n\n\nB2-&gt;C5\n\n\n\n\n\nC6\n\nC6\n\n\n\nB2-&gt;C6\n\n\n\n\n\n\n\n\nFigure 8: Forking paths in data analysis\n\n\n\n\n\n\n\n\nThis is why we care about open science\n\nTheory- and evidence-based selection of critical variables for analysis \\(\\rightarrow\\) literature review\nShare usable data and analysis code in open repositories \\(\\rightarrow\\) research report exercise, PSYC403 data archiving\n\n\n\n\n\nlm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, ...)\n\n\n\n\n\nlm(mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, ...)\n\n\nThe code represents a linear model with multiple predictors:\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\epsilon\\)\n\n\n\n\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\epsilon\\)\nOutcome \\(y\\) is calculated as the sum of:\n\nThe intercept \\(\\beta_0\\) plus\nThe product of the coefficient of the effect of e.g. AGE \\(\\beta_1\\) multiplied by \\(x_1\\) a person’s age +\n+ any number of other variables +\nThe error \\(\\epsilon\\): mismatches between observed and predicted outcomes\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nThe summary() of the linear model shows:\nEstimates of the coefficients of the effects of the predictors we included, with null hypothesis significance tests of those estimates\nModel fit statistics including R-squared and F-statistic estimates\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe Coefficient Estimate: 0.0242787 for the slope of the effect of variation in HLVA scores\nThe Std. Error (standard error) 0.0031769 for the estimate\nThe t value of 7.642 and associated Pr(&gt;|t|) p-value 9.44e-14 for the null hypothesis test of the coefficient\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nPay attention to sign and the size of coefficient estimate:\nIs the coefficient (e.g., HLVA 0.0242787) a positive or a negative number? is it relatively large or small?\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nRevision: Pay attention to R-squared\nR-squared indicates how much outcome variation we can predict, given our model\nRevision: we report Adjusted R-squared because it tends to be more accurate\n\n\n\n\n\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY + HLVA + FACTOR3 + AGE + NATIVE.LANGUAGE, \n    data = all.studies.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55939 -0.08115  0.02056  0.10633  0.41598 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.1873086  0.0472991   3.960 8.47e-05 ***\nSHIPLEY               0.0073947  0.0011144   6.635 7.70e-11 ***\nHLVA                  0.0242787  0.0031769   7.642 9.44e-14 ***\nFACTOR3               0.0053455  0.0008947   5.975 4.12e-09 ***\nAGE                  -0.0026434  0.0004905  -5.390 1.05e-07 ***\nNATIVE.LANGUAGEOther -0.0900035  0.0141356  -6.367 4.04e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1612 on 555 degrees of freedom\n  (54 observations deleted due to missingness)\nMultiple R-squared:  0.4221,    Adjusted R-squared:  0.4169 \nF-statistic: 81.09 on 5 and 555 DF,  p-value: &lt; 2.2e-16\n\n\n\nThe model summary gives us the F-statistic:\nRevision: the F-test of the null hypothesis that the model does not predict the outcome\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: A grid of plots showing model predictions, for outcome accuracy, given variation in (a.) age, (b.) vocabulary, (c.) health literacy, (d) reading strategy and (e.) native language. Data from eight studies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoefficients estimates in the summary match what we see\nPositive coefficients show upward slopes\nLarger coefficients show steeper slopes\n\n\n\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and, as predictors: vocabulary knowledge (Shipley), health literacy (HLVA), reading strategy (FACTOR3), age (years) and native language status. Our analysis indicated significant effects of all predictor variables. The model is significant overall, with \\(F(5, 555) = 81.09, p &lt; .001\\), and explains 42% of variance (\\(\\text{adjusted } R^2 = 0.42\\)). The model estimates showed that the accuracy of comprehension increased with higher levels of participant vocabulary knowledge (\\(\\beta = .007, t = 6.64, p &lt;.001\\)), health literacy (\\(\\beta = .024, t = 7.64, p &lt;.001\\)), and reading strategy (\\(\\beta = .005, t = 5.98, p = &lt; .001\\)). Younger participants (\\(\\beta = -0.003, t = -5.39, p &lt;.001\\)) and native speakers of English as another language (\\(\\beta = -.090, t = -6.37, p &lt;.001\\)) tended to show lower levels of accuracy.\n\n\n\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and, as predictors: vocabulary knowledge (Shipley), health literacy (HLVA), reading strategy (FACTOR3), age (years) and native language status. Our analysis indicated significant effects of all predictor variables. The model is significant overall, with \\(F(5, 555) = 81.09, p &lt; .001\\), and explains 42% of variance (\\(\\text{adjusted } R^2 = 0.42\\)). The model estimates showed that the accuracy of comprehension increased with higher levels of participant vocabulary knowledge (\\(\\beta = .007, t = 6.64, p &lt;.001\\)), health literacy (\\(\\beta = .024, t = 7.64, p &lt;.001\\)), and reading strategy (\\(\\beta = .005, t = 5.98, p = &lt; .001\\)). Younger participants (\\(\\beta = -0.003, t = -5.39, p &lt;.001\\)) and native speakers of English as another language (\\(\\beta = -.090, t = -6.37, p &lt;.001\\)) tended to show lower levels of accuracy.\n\n\nExplain: the method (linear model); the outcome (accuracy) and the predictors\nReport the model fit statistics overall (\\(F, R^2\\))\nReport the significant effects (\\(\\beta, t, p\\)) and describe the nature of the effects\n\n\n\n\nThere are three levels of uncertainty when we look at sample data [@mcelreath2020] – uncertainty over:\n\nThe nature of the expected change in outcome\nThe ways that expected changes might vary between individual participants or between groups of participants\nThe random ways that specific responses can be produced\n\n\n\n\n\nThese uncertainties require us to carefully qualify the conclusions we draw from data analyses\nThis does not mean we should avoid causal language when we think that psychological processes cause the behaviours we examine [@Grosz2020]\nBut it does mean we can be careful to identify the limits in the evidence we analyse\n\n\n\n\n\nvalidity: that differences in knowledge or ability cause differences in test scores\nmeasurement: that this is equally true across the different kinds of people we tested\ngeneralizability: that the sample of people we recruited resembles the population\n\n\n\n\n\nvalidity\n\n\nWe want to work with valid measures but validity requires explaining [@borsboom2004]:\n\n\nDoes the thing exist in the world?\nIs variation in that thing be reflected in variation in our measurement?\n\n\nWhat you can do: literature review \\(\\rightarrow\\) to identify your reasoning in answer to these questions\n\n\n\n\n\nmeasurement\ngeneralizability\n\n\nIt is most helpful to assume from the start that effects estimates will vary [@Gelman2015; @vasishth2021]\nSo then we ask ourselves: will this test work in the same way in different groups?\nAnd we ask: how will these effects estimates vary across different groups\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Scatterplot showing the potential association between accuracy of comprehension and vocabulary scores: Data from eight studies. Effects will vary between different samples so: expect the variation [@Gelman2015; @vasishth2021] &gt;&gt;&gt; important to evaluating claims in the literature, and to evaluation of your own results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Effects will vary between samples so expect the variation [@Gelman2015; @vasishth2021] &gt;&gt;&gt; ask what variation may result from systematic differences between groups\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: Grid of plots showing the distribution of potential predictor variables\n\n\n\n\n\n\n\n\n\nWe test who we can – convenience sampling – and who we can test has an impact on the quality of evidence [@bornstein2013]\nIf age, ethnicity or gender are not balanced \\(\\rightarrow\\) does this matter to your research question?\nIf samples are limited in size \\(\\rightarrow\\) how does that affect our uncertainty over effects estimates?\n\n\n\n\n\nMost introductory statistics classes teach each statistical test as if they are independent\n\n\n\n\n\n\n\nTip\n\n\n\nMost common statistical tests are special cases of linear models, or are close approximations\n\n\n\n\n\n\\(y_i = \\beta_0 + \\beta_1X\\)\n\nIf you have two groups, with a variable X coding for group membership\nThen the mean outcome for one group \\(= \\beta_0\\)\nThe estimate of the slope \\(\\beta_1\\) tells about the average difference between groups\nAnd we can code the model like this: lm(y ~ group)\n\n\n\n\n\\(y_i = \\beta_0 + \\beta_1X + \\beta_2Z + \\beta_3XZ\\)\n\nIf you have a 2 x 2 factorial design, with two factors factor.1, factor.2, and a dataset with variables X, Z coding for group membership\nThen the mean outcome for baseline conditions \\(= \\beta_0\\)\nThe estimates of the slopes \\(\\beta_1, \\beta_2\\) tells about the average difference between groups\nThe estimate of the slope \\(\\beta_3\\) tells us about the interaction\nAnd we can code the model like this: lm(y ~ factor.1*factor.2)\nOr this Anova(aov(y ~ factor.1*factor.2, data), type='II')\n\n\n\n\n\nIn general, the psychological literature is full of ANOVA\nBut the field is moving away from ANOVA towards mixed-effects models\n\n\n\n\n\n\n\nTip\n\n\n\nWe have to make choices in teaching and, here, we are choosing to focus on a powerful, flexible, and generally applicable method we can explain in depth: linear models\n\nOur aim is for students to better understand how to use a general approach\n\n\n\n\n\n\n\\(outcome ~ predictors + error\\)\n\noutcome can generalize to analyse data that are not metric, do not come from normal distributions\npredictors can be curvilinear, categorical, involve interactions\nerror can be independent; can be non-independent\n\n\n\n\n\nWhat if the outcome measurement data cannot be understood to be metric or to come from a normal probability distribution?\n\n\n\n\n\nBinary outcomes are very common in Psychology: yes or no; correct or incorrect; left or right visual field etc.\nThe change in coding is e.g. glm(ratings ~ predictors, family = \"binomial\")\n\n\n\n\n\nLikert scale or ratings data are best analysed using ordinal models [@liddell2018]\nThe change in coding [@christensen] is e.g. clm(ratings ~ predictors)\n\n\n\n\n\nMuch – maybe most – psychological data are collected in ways that guarantee the non-independence of observations\n\n\nWe test children in classes, patients in clinics, individuals in regions\nWe test participants in multiple trials in an experiment, recording responses to multiple stimuli\n\n\nThese data should be analysed using linear mixed-effects models [@meteyard2020]\n\n\n\n\nAn old saying goes:\n\nAll models are wrong but some are useful\n\n(attributed to George Box).\n\n\n\n\n\n\nTip\n\n\n\n\nSometimes, it can be useful to adopt a simpler approach as a way to approximate get closer to better methods\nBox also advises “Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.”\nHere, we focus on validity, measurement, generalizability and critical thinking\n\n\n\n\n\n\n\nLinear models\n\n\nLinear models are a very general, flexible, and powerful analysis method\nWe can use assuming that prediction outcomes (residuals) are normally distributed\nWith potentially multiple predictor variables\n\n\nThinking about linear models\n\n\nClosing the loop: when we plan an analysis we should try to use contextual information – theory and measurement understanding – to specify our model\nClosing the loop: when we critically evaluate our or others’ findings, we should consider validity, measurement, and generalizability\n\n\nReporting linear models\n\n\nWhen we report an analysis, we should report:\n\n\nExplain what I did, specifying the method (linear model), the outcome variable (accuracy) and the predictor variables (health literacy, reading strategy, reading skill and vocabulary)\nReport the model fit statistics overall (\\(F, R^2\\))\nReport the significant effects (\\(\\beta, t, p\\)) and describe the nature of the effects (does the outcome increase or decrease?)"
  },
  {
    "objectID": "PSYC411/part2/intro.html",
    "href": "PSYC411/part2/intro.html",
    "title": "Reasons why we do the research report assignment: What you will learn",
    "section": "",
    "text": "The research report assignment requires students to locate, access, analyse and report previously collected data. This introduction is intended to answer the first question anybody might ask.\n\nWhy: what will you learn about, what is our motivation?\n\nIn following chapters, I will answer the questions.\n\nWhat do we expect students to do?\nHow can the assignment be done?\n\nI hope you will agree that the discussion that follows is worth your time in reading it. It will help you to understand why we are asking you to do the assignment, and why we are looking for what we are looking for. It will help you to understand how this work will aid your development.\nYou may not be interested in the discussion in this chapter. If you are not, go ahead to the information on what we expect students to do ?@sec-what and on how the work can be done ?@sec-how.\n\n\nThere are two ideas motivating our approach. It will be helpful to you if I sketch them out early, here. We can demonstrate the usefulness of these ideas as we progress through our work.\nThe first key idea is expressed clearly in sociological discussions of science. This is that there is a difference between science “…being done, science in the making, and science already done, a finished product …” [@bourdieu2004; p.2]. The awareness we want to develop is that there are two things: there is the story that may be presented in a textbook or in a lecture about scientific work or scientific claims; and there is the work we do in practice, as we develop graduate skills, and as we exercise those skills professionally in the workplace.\nThe second key idea connects to the first. This idea is that reported analyses are not necessary or sufficient to the data or the question. What does this mean? It means that the same data can reasonably be analysed in different ways. There is no necessary way to analyse some data though there may be conventions or normal practices [@kuhn1970]. It means that it is unlikely that any one analysis will do all the work that could be done (a sufficiency) to get you from your data to useful or reasonable answers to your questions.\nThese ideas may be unsettling but they are realistic. Stating them will better prepare you for professional work. In the workplace, the accuracy of these ideas will emerge when you see how a team in any sector (health, marketing …) gets from its data to its product. If we talk about the ideas now, we can get you ready for dealing with the practical and the ethical concerns you will confront when that happens.\nWe will begin by discussing psychological research, and research about psychological research, to answer the question: Why: what is the motivation for the assignment? We will then move to answering the What question ?@sec-what and the How question ?@sec-how.\n\n\n\n\n\nWe are here because we are interested in humans and human behaviour, and because we are interested in scientific methods of making sense of these things. Some of us are aware that science (including psychological science) has undergone a rolling series of crises: the replicability or replication crisis [@Pashler2012a; @Pashler2012b]; the statistical crisis [@gelman2014a]; and the generalizability crisis [@yarkoni2022]. And that science is undergoing a response to these crises, evidenced in the advocacy of pre-registration [@nosek2018; @nosek2019prereg], and of registered reports [@nosek2014], the use of open science badges (e.g., for the journal Psychological Science), the completion of large-scale replication studies [@aarts2015], and the identification of open science principles [@munafò2017]. We may usefully refer, collectively, to the crises and the responses, as the credibility revolution [@vazire2018]\nWe could teach a course on this (in Lancaster, we do) but, here, I invite you to follow the references if you are interested. Before going on, I want to call your attention to the fact that important elements of the hard work in trying to make science work better has been led by PhD students and by junior researchers [e.g., @herndon2014]. Graduate students may, at first, assume that the fact that a research article has been published in a journal means the findings that are reported must be true. Most of the time, some educated skepticism is more appropriate. An important driver of the realization that there are problems evident in the literature, and that there are changes we can make to improve practice, comes from independent post-publication review work exposing the problems in published work (see, e.g., this account by Andrew Gelman)\n\n\n\n\n\n\nTip\n\n\n\n\nAllow yourself to feel skeptical about the reports you read then work with the motivation this feeling provides.\n\n\n\nIn brief, then, most practicing scientists now understand or should understand that many of the claims we encounter in the published scientific literature are unlikely to be supported by the evidence [@Ioannidis2005], whether we are looking at the evidence of the results in the reports themselves, or evidence in later attempts to find the same results [e.g., @aarts2015]. We suspect that this may result from a number of causes. We understand that researchers may engage in questionable research practices [@john2012]. We understand that researchers may exploit the potential for flexibility in doing and reporting analyses [@Simmons2011a]. We understand that there are problems in how psychologists use or talk about the measurement of psychological constructs [@flake2020]. We understand that there are problems in how psychologists sample people for their studies, both in where we recruit [@bornstein2013; @wild2022; @Henrich2010], and in how many we recruit [@button2013; @cohen1962; @sedlmeier1989; @vankov2014]. We understand that there are problems in how psychologists specify or think about their hypotheses or predictions [@meehl1967; @scheel2022]. And we understand that there are problems in how scientists do, or rather do not, comply with good practice recommendations designed to fix these problems (discussed further in the following).\nThis discussion could (again) be unsettling. This list of problems could make you angry or sad. I, like others, think it is exciting. It is exciting because these problems have probably existed for a long time [e.g., @cohen1962; @meehl1967] but now, having identified the problems, we can hope to do something about it. It is exciting because if you care about people, the study of people, or the applications in clinical, education and other domains of the results of the study of people, then you might hope to see better, more useful, science in the future [@vazire2018].\nAs someone who teaches graduate and undergraduate students, I want to help you to be the change you want to see in the world 1. We cannot solve every problem but we can try to do better those things that are within our reach. I am going to end this introduction with a brief discussion of some ideas we can use to guide our better practices.\n\n\n\nIn this course, for this assignment, we are going to focus on:\n\nmultiverse analyses\nkinds of reproducibility\nthe current state of the match between open science ideas and practices\n\nIn the classes on the linear model, we will discuss:\n\nthe links between theory, prediction and analysis\npsychological measurement\nsamples\nvariation in results\n\n\n\n\n\n\nI am going to link this discussion to a metaphor (see Figure Figure 1) or a description you will find useful: the data analysis pipeline or workflow.\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nanalyse\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow\n\n\n\n\n\nThis metaphor or way of thinking is very common (take a look at the diagram in Wickham and Grolemund’s 2017 book “R for Data Science) and you may see the words “data pipeline” used in job descriptions, or you may benefit from saying, in a job application, something like: I am skilled in designing and implementing each stage of the quantitative data analysis pipeline, from data tidying to results presentation. I say this because scientists I have mentored got their jobs because they can do these things – and successfully explained that they can do these things – in sectors like educational testing, behavioural analysis, or public policy research.\nThe reason this metaphor is useful is that it helps us to organize our thinking, and to manage what we do when we do data analysis, we:\n\nget some data;\nprocess or tidy the data;\nexplore, visualize, and analyse the data;\npresent or report our findings.\n\nWe introduce the idea that your analysis work will flow through the stages of a pipeline from getting the data to presenting your findings because, next, we will examine how pipelines can multiply.\n\n\n\n\n\n\nTip\n\n\n\n\nAs you practice your data analysis work, try to identify the elements and the order of your work, as the parts of a workflow.\n\n\n\n\n\n\nWhat researchers have come to realize: because we started looking … The open secret that has been well kept [@bourdieu2004]: because everybody who does science knows about it, yet we may not teach it; and because we do not write textbooks revealing it … Is that at each stage in the analysis workflow, we can and do make choices where multiple alternative choices are possible. @gelman2014 capture this insight as the “garden of forking paths”2 (see Figure 2).\nThe general idea is that it is possible to have multiple potential different paths from the data to the results. The results will vary, depending on the path we take. In an analysis, we could take multiple different paths simply because at point A we decide to do B1, B2 or B3, maybe we choose B1, and then at point B1, we may decide to do C1, C2 or C3. Here, maybe we have our raw data at point A. Maybe we could do one of two different things when we tidy the data: action B1 or B2. Then, when we have our tidy data, maybe we can choose to do our analysis in one of six ways. Where we are at each step depends on the choices we made at the previous steps.\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nA\n\n\n\nB1\n\nB1\n\n\n\nA-&gt;B1\n\n\n\n\n\nB2\n\nB2\n\n\n\nA-&gt;B2\n\n\n\n\n\nC1\n\nC1\n\n\n\nB1-&gt;C1\n\n\n\n\n\nC2\n\nC2\n\n\n\nB1-&gt;C2\n\n\n\n\n\nC3\n\nC3\n\n\n\nB1-&gt;C3\n\n\n\n\n\nC4\n\nC4\n\n\n\nB2-&gt;C4\n\n\n\n\n\nC5\n\nC5\n\n\n\nB2-&gt;C5\n\n\n\n\n\nC6\n\nC6\n\n\n\nB2-&gt;C6\n\n\n\n\n\n\n\n\nFigure 2: Forking paths in data analysis\n\n\n\n\n\nIn the end, it may appear to us that we took one path or that only one path was possible. When we report our analysis, in a dissertation or in a published journal article, we may report the analysis as if only one analysis path had been considered. But, critically, our findings may depend on the choices we made and this variation in results may be hidden from view.\nI am talking about forking paths because the multiplicity of paths has consequences, and we discuss these next.\n\n\n\n\n\n\nTip\n\n\n\n\nIt is about here, I hope, that you can start to see why it would makes sense to access data from a published study and to examine if you can get the same results as the study authors.\n\n\n\n\n\n\n\nI am going to discuss, now, what are commonly called multiverse analyses. Psychologists use this term, having been introduced to it in an influential paper by @steegen2016, but it comes from theoretical physics (take a look at wikipedia).\nI explain this because I do not want you to worry. The ideas themselves are within your grasp whatever your background in psychology or elsewhere. It is the implications for our data analysis practices that are challenging. They are challenging because what we discuss should increase your skepticism about the results you encounter in published papers. And they are challenging because they reveal your freedom to question whether published authors could have done their analysis in a different way.\nWe are going to look at:\n\ndata-set construction\nanalysis choices\n\n\n\nIn first discussing the wider context (of crisis and revolution), then discussing the specific context (of multiverses and, in the following, of reproducibility), I should be clear about the link between the two things. The finding that some results may not be supported by the evidence is probably due to a mix of causes. But one of those causes will be the combination of uncertainty over data processing or the uncertainty over analysis methods revealed in multiverse analyses, as we see next, combined with the limitations of data and code sharing, and the incompleteness of results reporting (as we see later).\n\n\n\nWhen you collect or access data for a research study, the complete raw data-set you receive is almost never the complete data-set you analyse or whose analysis you report. This is not a story about deliberately cheating. It is a story about the normal practice of science [@kuhn1970].\nPicture some common scenarios. You did a survey, you got responses from a 100 participants on 10 questions, and you asked people to report their education, ethnicity and gender. You did an experimental study, you tested two groups of 50 people each in 100 trials (imagine a common task like the Stroop test), and you observed the accuracy and the timing of their responses. You tested 100 children, 20 children in each of five different schools, on a range of educational ability measures.\nIn these scenarios, the psychologist or the analyst of behavioural data must process their data. In doing so, you will ask yourself a series of questions like:\n\nhow do we code for gender, ethnicity, education?\nwhat do we about reaction times that are very short, e.g., \\(RT &lt; 200ms\\) or very long, e.g., \\(RT &gt; 1500ms\\))?\nif we present multiple questions measuring broadly the same thing (e.g. how confident are you that you understand what you have read? how easy did you find what you read?) how do we summarize the scores on those questions? do we combine scores?\nwhat do we do about people who may not appear to have understood the task instructions?\n\nTypically, the answers to these questions will be given to you by your supervisor, a colleague or a textbook example. For example, we might say:\n\n“We excluded all reaction times greater than 1500ms before analysis.”\n\nTypically, the explanation for these answers are rarely explained. We might say:\n\n“Consistent with common practice in this field, we excluded all reaction times greater than 1500ms before analysis.”\n\nBut the reader of a journal article typically will not see an explanation for why, as in the example, we exclude reaction times greater than 1500ms and not 2000ms or 3000ms, etc. We typically do not see an explanation for why we exclude all reaction times greater than 1500ms but other researchers exclude all reaction times greater than 2000ms. (I do not pick this example at random: there are serious concerns about the impact on analyses of exclusions like this [@Ulrich1994a].)\nWhat @steegen2016 showed is that a data-set can be processed for analysis in multiple different ways, with a number of reasonable alternate choices that can be applied, for each choice point: construction choices about classifying people or about excluding participants given their responses. If a different data-set is constructed for each combination of alternatives then many different data-sets can be produced, all starting from the same raw data. (For their example study, @steegen2016 found they could construct 120 or 210 different data-sets, based on the choice combinations.) Critically, for us, @steegen2016 showed that if we apply the same analysis method to the different data-sets then our results will vary.\nLet me spell this out, bit by bit:\n\nwe approach our study with the same research question, and the same verbal prediction;\nwe begin with the exact same data;\nwe then construct different data-sets depending on different but equally reasonable processing choices;\nwe then apply the same analysis analysis, to test the same prediction, using each different data-set;\nwe will see different results for the analyses of the different data-sets.\n\nAlternate constructions of the same data may cause variation in the results of statistical tests. Some kinds of data processing choices may be more influential on results than others. It seems unlikely that we can identify, in advance, which choices matter more.\n@steegen2016 suggest that we can deflate (shrink) the multiverse in different ways. I want to state their suggestions, here, because we will come back to these ideas in the classes on the linear model.\n\nDevelop better theories and improved measurement of the constructs of interest.\nDevelop more complete and precise theory for why some processing options are better than others.\n\nBut you will be asking yourself: What do I need to think about, for the research report assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you read a psychological research report, identify where the researchers talk about how they process their data: classification, coding, exclusion, transformation, etc.\nIf you can access the raw data, ask yourself: could different choices change the results of the same analysis?\n\n\n\n\n\n\nEven if we begin with the same research question and, critically, the same data-set, the results of a series of studies show that different researchers will often (reasonably) make different choices about the analysis they do to answer the research question. We often call these studies (analysis or model) multiverse studies. In these studies, we see variation in analysis and this variation is also associated with variation in results.\nAn influential example, in psychology, is reported by Silberzahn and colleagues [@silberzahn2015; @silberzahn2017] who asked 29 teams of researchers to answer the same question (“Are (soccer) referees more likely to give red cards to players with dark skin than to players with light skin?”) with the same data-set (data about referee decisions in football league games). The teams made their own decisions about how to answer the question in doing the analysis. The teams shared their plans, and commented on each others’ ideas. The discussion did not lead to a consensus about what analysis approach is best. In the end, the different teams did different analyses and, critically, the different analyses had different results. The results varied in whether the test of the effect of players skin colour (on whether red cards were given) was significant or not, and on the strength of the estimated association between the darkness of skin colour (lighter to darker) and the chances (low to high) of getting a red card.\nThere have now been a series of multiverse or multi-analyst studies which demonstrate that, under certain conditions, different researchers may adopt different analysis approaches – which will have different results – in answering the same research question with the same data. This demonstration has been repeated in studies in health, medicine, psychology, neuoscience, and sociology, among other research fields (e.g., @parsons; @breznau2022; @klau; @klau2021; @wessel2020multiverse; @poline2006; @maier-hein2017; @starns2019; @fillard2011; @dutilh2019; @salganik2020; @bastiaansen2020; @botvinik-nezer2020; @schweinsberg2021; @patel2015; see, for reviews, and some helpful guidance, @aczel2021; @delgiudice2021; @hoffmann; @wagenmakers2022).\nIn these studies, we typically see variation in how psychological constructs are operationalized (e.g., how do we measure or code for social status?), how data are processed or data-sets constructed (as in @steegen2016a), plus variation in what statistical techniques are used, and in how those techniques are used. This variation can be understood to reflect kinds of uncertainty [@klau; @klau2021]: uncertainty about how to process data, and uncertainty about the model or methods we should use to test or estimate effects. Further research makes it clear that we should be aware, if we are not already, of the variation in results that can be expected because different researchers may choose to design studies, and construct stimulus materials, in different ways given the same research hypothesis information [@landy2020a].\nBut you will be asking yourself: What do I need to think about, for the research report assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you read a psychological research report, identify where the researchers talk about how they analyse their data: the hypothesis or prediction they test; the method; their assumptions; the variables they include; the checks or the alternate analyses they did or did not do.\nIf you can access the data and analysis code, ask yourself: could different methods change the results of the same analysis?\n\n\n\n\n\n\nThis is a good place to look at what we have discussed, and present an evaluation of the story so far.\nThis is not a story where everybody or nobody is right or where everything or nothing is true 3. Instead, we can be guided by the advice [@meehl1967; @scheel2022; @steegen2016] that we should:\n\nseek better and more complete theorizing about the constructs of interest and how we measure them, and\nseek more complete and more precise theory so that some options are theoretically superior than others, and should be preferred, when constructing data-sets or specifying analysis methods.\n\nNot all research questions and not all hypothesis information will allow an equally wide variety of potential reasonable approaches to the analysis. As Paul Meehl argued a long time ago [@meehl1967; @meehl1978], and researchers like Anne Scheel [@scheel2021; @scheel2022] argued more recently, the complexity of the thing we study – people, and what they do – and the still early development of our understanding of this thing, mean that what we want but what we do not see, in psychology, are scientifically productive tests of falsifiable theories. (See, consistent with this perspective, discussions by @auspurg2021 and by @delgiudice2021 about the range of analysis possibilities that may or may not be allowed, in multiverse analyses, by more or less clear research questions or well-developed causal theories.) Our concern should not so much be with being able to do statistical analysis, or with finding significant or not significant results. It would be more useful to do analyses to test concrete, inflexible, precise predictions that can be wrong.\nNor is this a story, I think, about the potential for cheating. While we may refer to subjective choices or to researcher flexibility, the differences that we see do not resemble the researcher degrees of freedom [@Simmons2011] some may exploit, consciously or unconsciously, to change results to suit their aims. Instead, the multiverse results show us the impact of the reasonable differences in approach that different researchers may sensibly choose to take when they try to answer a research question with data.\nNot all alternates, at a given point of choosing, in the data analysis workflow, will have equal impact. Work by Young [@young2017; @young2018] indicates that if we deliberately examine the impact of method or model uncertainty, over different sets of possible choices — about what variables or what observations we include in an analysis, for example — we may find that some results are robust to an array of different options, while other results are highly susceptible to different choices. This work suggests another way in which uncertainty about methods or variation in results can be turned into progress in understanding the phenomena that interest us: through systematic, informed, interrogation of the ways that results can vary.\nIn general, in science, the acceptance of research findings must always be negotiated [@bourdieu2004]. Here, we see that the grounds of negotiation should often include an analysis of the impact on the value of evidence of the different analysis approaches that researchers can or do apply to the data that underlie that evidence.\nBut you will be asking yourself: what do I need to think about, for the assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nThe results of multiverse analyses show us that if we see one analysis reported in a paper, or one workflow, that does not mean that only one analysis can reasonably be applied.\nIf you read the methods or results section of a paper, you should reflect: what other analysis methods could be used here? How could variation in analysis method — in what or how you do the analysis — influence the results?\n\n\n\nMaking you aware of the potential for analysis choices is useful because developing researchers, including graduate students, are often not aware of the room for choice in the data analysis workflow. Developing researchers — you — may be instructed that “this is how we do things” or “you should follow what researchers did previously”. Following convention is not necessarily a bad thing: it is a feature of the normal practice of science [@kuhn1970]. However, you can now see, perhaps, that there likely will be alternative ways to process or to analyse data than the approach a supervisor, lab or field normally adopts.\nThis understanding or awareness has three implications for practice, it means:\n\nWhen we talk about the analysis we do, we should explain our choices.\nWe should check, or enable others to check, what impact making different choices would have on our results.\nMost importantly: we can allow ourselves the freedom to critically evaluate the choices researchers make, even the choices researchers make in published articles.\n\n\n\n\n\nMultiverse analyses and post-publication analyses, in general, show that we can and should question or critically evaluate the analyses we encounter in the literature. This work can usefully detect problems in original published analyses [e.g., @Gelman2009c; @herndon2014; @Wagenmakers2011]. It can demonstrate where original published claims are or are not robust to variation of analysis method or approach.\nGiven these lessons, and the implications we have identified, we should expect or hope to see open science practices [@munafò2017; @nosek2022]:\n\nshare data and code;\npublish research reports in ways that enable others to check or query analyses.\n\nAs we discuss, following, these practices are now common but the quality of practice can sometimes be questioned. This matters for you because it makes it more challenging – in specific identifiable locations – to locate, access, analyse and report previously collected data.\nThe discussion of current practices identifies where or how the assignment may be more challenging, but also identifies some of the exact places where the assignment provides a real opportunity to do original research work.\nFirst, I am going to introduce some ideas that will help you to think about what you are doing when you do this work. We focus on the concept of reproducibility.\n@gilmore2017 [following @goodman2016] present three kinds of reproducibility:\n\nmethods reproducibility\nresults reproducibility\ninferential reproducibility\n\nIn looking at reproducibility, here, we are considering how much, or in what ways, the results or the claims that are made in a published study can be found or repeated by someone else.\n\n\nAs @gilmore2017 discuss, methods reproducibility means that another researcher should be able to get the same results if they use the same tools and analysis methods to analyse the same data-set [some researchers also refer to analytic reproducibility or computational reproducibility; see e.g. @crüwell; @hardwicke2018; @hardwicke; @laurinavichyute2022; @minocher].\nIn neuroimaging, the multiplicity of possible implementations of the data analysis pipeline [@carp2012plurality], and the fact that important elements or information about the pipeline deployed by researchers may be missing from published reports [@carp2012secret], can make it challenging to identify how results can be reproduced.\nIn psychological science, in evaluating reports of results from analyses of behavioural data collected through survey or experimental work, in principle, we should expect to be able to access the data collected by the study authors, follow the description of their analysis method, and reproduce the results they report.\n\n\n\n\n\n\nTip\n\n\n\n\nFor an assignment in which we ask students to locate, access, analyse and report previously collected data, we are directly concerned with methods reproducibility.\n\n\n\n\n\n\nResults reproducibility means that if another researcher completes a new study with new data they are able to get the same results as the results reported following an original study: this often referred to as replication. The replication studies that have been reported [e.g., @aarts2015], and continue to be reported (see, for example, the studies discussed by @nosek2022), in the last several years, present attempts to examine the results reproducibility of published findings.\nIn the classes on the linear model, we will examine if similar or different results are observed in a series of studies using the same procedure and the same materials. We shall discuss, in those classes, in more depth, what results reproducibility (or study replication) can or cannot tell us about the behaviours that interest us.\n\n\n\nInferential reproducibility means that if a researcher repeats a study (aiming for results reproducibility) or re-analyses an original data-set (aiming for methods reproducibility) then they can come to the same or similar conclusions as the authors of the report of an original study.\nHow is inferential reproducibility not methods or results reproducibility? @goodman2016 explain that researchers can make the same conclusions from different sets of results and can reach different conclusions from the same set of results.\nHow is it possible to reach different conclusions from the same results? We can imagine two scenarios.\nFirst, we have to think about the wider research field, the research context, within which we consider a set of results. It may be that two different researchers will come to look at the same results with different expectations about what the results could tell us (in Bayesian terms, with different prior expectations). Given different expectations, it is easy to imagine different researchers looking at the same results and, for example, one researcher being more skeptical than another about what conclusion can be taken from those results. (In the class on graduate writing skills, I discuss in some depth the importance of reviewing a research literature in order to get an understanding of the assumptions, conventions or expectations that may be shared by the researchers working in the field.)\nSecond, imagine two different researchers looking at the same results — picture the original authors of a published study, and someone doing a post-publication re-analysis of their data — you can expect that the re-analysis or the reproducibility analysis could identify reasons to value the evidence differently, or to reach more skeptical conclusions, through critical evaluation of:\n\ndata processing choices;\nthe choice of the method used to do analysis;\nchoices in how the analysis method is used.\n\n… where that critical evaluation involves an analysis of the choices the original researchers made, perhaps involving an analysis of other choices they could have made, perhaps reflecting on how effectively the analyses address a given research question or test a given prediction.\n\n\n\n\n\n\nTip\n\n\n\n\nWe can think about the work we do, when we analyse previously reported data, in terms of the need to identify the reproducibility of results, methods and inferences.\nIn psychological science, determining that someone can get the same results, by analysing the same data, or will reach the same conclusions from the same results, are important – potentially, original – research contributions.\n\n\n\n\n\n\n\nI have said that we should expect or hope to see open science practices [@munafò2017; @nosek2022] where researchers:\n\nshare data and code;\npublish research reports in ways that enable others to check or query analyses.\n\nThis raises an important question: What exactly do we see, when we look at current practices? The question is important because answering it helps to identify where the challenges are located when you complete your work to locate, access, analyse and report previously collected data.\nI break the discussion of what we see into two parts. Firstly, I look at the results of audits of data and code sharing (see Section 1.2.6.2): are data shared and can we access the data? Secondly, I discuss analyses of methods reproducibility, and shared data and code usability (see Section 1.2.6.3): can others reproduce the results reported in published articles, given shared data? can others access and run shared analysis code? can others use the shared code to reproduce the reported results? Again, I need to be brief but reference sources that you can follow-up.\n\n\nI should be clear, before we go on, about the link between the credibility revolution in science, and the effort to examine reproducibility of results. Many elements of the credibility revolution emerged out of the observation that it has often been difficult to repeat the results of published studies when we conduct new studies (replication studies or results reproducibility; e.g., @aarts2015). However, it is clearly difficult to know what to replicate or reproduce if we cannot reproduce the results presented in a study report (methods reproducibility), given the study data [@artner2021; @laurinavichyute2022; @minocher].\n\n\n\nResearch on data and code sharing practices suggest that practices have improved, from earlier low levels.\nIn an important early report, @wicherts2006 observed that it was very difficult to obtain data reported in psychological research articles from the authors of the articles. They asked for data from the lead authors of 141 articles published in four leading psychology journals, for about 25% of the studies. This low response rate was found despite the fact that authors in these journals must agree to the principle that data can be shared with others wishing to verify claims.\nPractice has changed: how?\nOne change to practice has involved the use of open science badges. In journals like Psychological Science authors of articles may be awarded badges — Open Data, Open Materials, Preregistration badges — by the editorial team. Authors can apply for and earn the badges by providing information about open practices, and journal articles are published with the badges displayed near the front of the articles.\nIn theory, initiatives like encouraging authors to earn open science badges should mean that data sharing practices improve, enabling access to data and code for those, like you, who would like to re-analyse previously published data. In theory, all you should need to do — to locate and access data — is just search articles in the journal Psychological Science for studies with open data badges, and follow links from the published articles to then access study data at an open repository like the Open Science Framework (OSF) What do we see in practice?\nAnalyses reported by @kidwell2016 as well as analyses reviewed by @nosek2022 indicate that more articles have claimed to make data available in the time since badges were introduced. When they did their analysis, @kidwell2016 found that a substantial proportion, but not all, of the articles in Psychological Science can be found to actually provide access to shared data. However, critically, many but not all the articles with open data badges provide access to data available through an open repository, data that are correct, complete and usable [@kidwell2016]. In their later report, the analyses reviewed by @nosek2022 suggest that the use of repositories like OSF for data sharing may be accelerating but that, over the last few years, the rate at which open science practices like sharing data, overall, appears to be substantial but not yet reported or observed in a majority of the work of researchers.\nMany journals now require the authors of articles to include a Data Availability Statement to locate their data. Analyses by @federer2022 indicate that Data Availability Statements for articles published in the open access 4 journal PLOS ONE often, helpfully, include Digital Object Identifiers (DOIs) or Universal resource locators (URLs) enabling direct access to shared data (i.e., without having to contact authors). Of those DOIs or URLs, most appeared to be associated with resources that could successfully be retrieved. In contrast, analyses reported by @gabelica2022 indicate that where article authors state that “data sets are available on reasonable request” (the most common availability statement), most of the time, the authors did not respond or declined to share the data [see similar findings, across fields, by @tedersoo2021]. Clearly, in the analyses of open science practices we have seen so far, data sharing is more effective where sharing does not have to work through authors.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you are looking for a study in order to get data that you can then re-analyse, it makes sense to look, first, for studies focusing on research questions that interest you.\nWhen you are looking for published reports where the authors share data, look for articles with open science badges or where you can see a Data Availability Statement.\nChoose articles where the authors provide a direct link to their data, where the data are located on an open repository like the Open Science Framework (there are other repositories).\n\n\n\n\n\n\nResearch on data and code sharing practices suggest that practices have improved but that there are concerns about the quality of the sharing. Here, the critical concern relates to the word enable in the objective: that we should publish research reports in ways that enable others to check or query analyses.\nJohn Towse and colleagues [@towse2021] at Lancaster University examined the quality of open data-sets to assess their quality in terms of their completeness and reusability [see also @roche2015].\n\ncompleteness: are all the data and the data descriptors supporting a study’s findings publicly available?\nreusability: how readily can the data be accessed and understood by others?\n\nFor a sample of data-sets, they found that about half were incomplete, and about two-thirds were shared in a way that made them difficult to use. Practices tended to be slightly better in more recent publications. (Broadly similar results are reported by [@hardwicke2018].)\nWhere data were found to be incomplete, this appeared to be, in part, because participants were excluded in the processing of the data for analysis but this information was not in the report, or because data were shared without a guide or “readme” file or data dictionary (or codebook) explaining the structure, coding or composition of the shared data.\nPotentially important for future open science practices, [@towse2021; also @roche2015] found that sharing data as Supplementary materials may appear to carry risks that, in the long term, mean that data may become inaccessible.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you locate open data you can access, look for a guide, “readme” file, codebook or data dictionary explaining the data: you need to be able to understand what the variables are, what the observations relate to (observations per person, per trial?) and how variables are coded.\nLocate and examine carefully the parts of the published report, or the data guide, where the authors explain how they processed their data.\n\n\n\nA number of studies have been conducted to examine whether shared data and analysis code can be reused by others to reproduce the results reported in papers [e.g., @artner2021; @crüwell; @hardwicke2018; @hardwicke; @laurinavichyute2022; @minocher; @obels2020; see @artner2021 for a review of reproducibility studies]. In critical respects, the researchers doing this work are doing work similar to the work we are helping students to do, locating, accessing, and analysing previously collected data. In these studies, typically, the researchers progressed through a series of steps.\n\nSearched the articles published in a journal (e.g., Cognition, the Journal of Memory and Language, Psychological Science), published in a topic area across multiple journals (e.g., social learning, psychological research), or associated with a specific practice (e.g., registered reports.\nSelected a subset of articles where it was identified that data could be accessed.\nIdentify a target result or outcome to reproduce, for each article. In their analyses, Hardwicke and colleagues [@hardwicke2018; @hardwicke] focused on attempting to reproduce primary or straightforward and substantive outcomes: substantive – if emphasized in the abstract, or presented in a table or figure; straightforward – if the outcome could be calculated using the kind of test one would learn in an introductory psychology course (e.g., t-test, correlation).\nAttempted to reproduce the results reported in the article, using the description of the data analysis presented in the article, and the analysis code (if provided), in some cases asking for information from the original study authors, in other cases working independently of original authors.\n\nWhat the reproducibility studies appear to show is that, for many published reports, if data are shared and if the shared data are accessible and reusable then, most of the time, the researchers could reproduce the results presented by the original study authors [@hardwicke2018; @hardwicke; @laurinavichyute2022; @minocher; @obels2020; but see @crüwell]. This is great. But what is interesting, for us, is where the reproducibility researchers encountered challenges. You may encounter the same or similar challenges.\nI list some challenges that the researchers describe, following. Before you look at the list, I want to assure you: you will not find all these challenges present for any one article you look at. Most likely, you will find one or two challenges. Obviously, some challenges will be more difficult than others.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you find a study you are interested in, with open data and maybe open analysis code, your main challenge will often be to identify exactly what analysis the original study authors did to answer their research question.\nLocate and examine carefully the parts of the published report where the authors explain how they did the analysis that gave them their key result. Usually that key result should be identified in the abstract or in the conclusion.\n\n\n\n\n\n\nData Availability Statements or open science badges indicate data are shared but data are not directly accessible through a link to an open repository.\nThe data are shared and accessible but there is missing or incorrect information about the data. The documentation, codebook or data dictionary is missing or incomplete. There is unclear or missing information about the variables or the observations, or about the coding of variable values, responses.\nOriginal study authors may share raw and processed data or just processed or just raw data. It may not be clear how raw data were processed to construct the data analysed for the report. It may not be clear how variables were transformed or calculated or processed.\nThere may be mismatches between the variables referred to in the report and the variables named in the data file. It may be unclear how a data file corresponds to a study described in a report, where there are multiple studies and multiple data files.\n\n\n\n\n\nThe original report includes a description of the analysis but the description of the analysis procedure is incomplete or ambiguous.\nThere may be a mismatch, in the report, between a hypothesis, and the analysis specified to test the hypothesis (maybe in the Methods section), compared to a long sequence of results reported in the Results section. This makes it difficult to identify the key analysis.\nIt is easier to reproduce results if both data and code are shared because the presentation of the analysis code usually (not always) makes clear what analysis was done to get the results presented in the report.\nSometimes, analysis code is shared but it is difficult to use because it requires proprietary software (e.g., SPSS) or because it requires function libraries that are no longer publicly available.\nSometimes, there are errors in the analysis. Sometimes, there are errors in the presentation of the results, where results have been incorrectly copied into reports from analysis outputs.\n\n\n\n\n\n\n\nThe research report assignment requires students to locate, access, analyse and report previously collected data. At the start of the introduction, I said I would explain the answer to the question:\n\nWhy: what is the motivation for the assignment?\n\nI summarize, following, the main points of the answer I have given. When you review these points, I want you to think about two things, returning to the ideas of @bourdieu2004 and @kuhn1970 I sketched at the start.\nOften what we do in science is guided by convention, the assumptions and habits of normal practice [@kuhn1970]. These conventions can work in our minds so that if we encounter an anomaly or discrepancy between what we expect and what we find, in our work, we may usually blame ourselves: it was something wrong that we did or failed to do. It can cause us anxiety if we do not reproduce a result we think we should be able to reproduce [@lubega]. But I want you to understand, from the start, that sometimes, if you think you have found an error or a problem in a published analysis or a shared data-set, you may be right.\nIf there is anything we have learned, through the findings of replication studies, multiverse analyses, and reproducibility audits it is that people make mistakes, different choices are often reasonable, and we always need to check the evidence.\n\n\n\nWe are in the middle of a credibility revolution. The lessons we have learned so far oblige us to think about and to teach good open science practices that safeguard the value of evidence in psychology.\nThis matters, even if we do not care about scientific methods, because if we care about the translation into policy or practice – in clinical psychology, in education, health, marketing and other fields – what we do will depend on the value of the research evidence that informs policy ideas or practice guides.\nFocusing on data analysis, it is useful to think about the whole data pipeline in analysis, the workflow that takes us from data collection to raw data to data processing to analysis to the presentation of results.\nAt every stage of the data pipeline, there are choices about what to do. There are not always reasons why we make one choice instead of another. Sometimes, we are guided by convention, example or instruction.\nThe existence of choices means the path we take, when we do data analysis, can be one path among multiple different forking paths.\nFor some parts of the pipeline – data-set construction, data analysis choices – reasonable people might make different decisions to sensibly answer the same research question, given the same data. This variation between pathways can be more or less important in influencing the results we see.\nIf results tend to stay similar across different ways of doing analysis, we might conclude that the results are reasonably robust across contexts, choices, or other variation in methods.\nTo enable others to see what we did (versus what we could have done), to see how we got to our results from our data, it is important to share our data and code.\nEveryone makes mistakes and we should make it easy for others, and ourselves, to find those mistakes by sharing our data and code in accessible, clear, usable ways.\nWe need to teach and learn how to share effectively the data and the code that we used to answer our research questions.\n\nIn constructing the assignment – in asking and supporting students to locate, access, analyse and report previously collected data – we are presenting an opportunity to really investigate and evaluate existing practices.\nYou may find that this work is challenging, in some of the places that reproducibility research has identified there can be challenges. Where the challenges cannot be fixed – if you have found an interesting study but the study data are inaccessible or unusable – we will advise you to move on to another study. Where the challenges can be fixed – if data require processing, or if analysis information requires clarification – we will provide you with help or enabling information so that you fix the problems yourself.\n\n\n\n\n\n\nTip\n\n\n\n\nMaybe the main lesson from this exercise is a reminder of the Golden rule: treat others as you would like to be treated.\nIf it is frustrating when it is difficult to understand information about an analysis or about data, or when it is difficult to access and reuse shared data and code.\nWhen it is your turn — do better — reflecting on what frustrated you.\n\n\n\nOne last question: why not just do less demanding or challenging tasks? Because this is part of what makes graduate degree valuable, what will make you more skilled in the workplace. Most of the time, we work in teams, we inherit problems or data analysis tasks, or are given results with partial information. The lessons you learn here will help you to effectively navigate those situations."
  },
  {
    "objectID": "PSYC411/part2/intro.html#sec-why-key-ideas",
    "href": "PSYC411/part2/intro.html#sec-why-key-ideas",
    "title": "Reasons why we do the research report assignment: What you will learn",
    "section": "",
    "text": "There are two ideas motivating our approach. It will be helpful to you if I sketch them out early, here. We can demonstrate the usefulness of these ideas as we progress through our work.\nThe first key idea is expressed clearly in sociological discussions of science. This is that there is a difference between science “…being done, science in the making, and science already done, a finished product …” [@bourdieu2004; p.2]. The awareness we want to develop is that there are two things: there is the story that may be presented in a textbook or in a lecture about scientific work or scientific claims; and there is the work we do in practice, as we develop graduate skills, and as we exercise those skills professionally in the workplace.\nThe second key idea connects to the first. This idea is that reported analyses are not necessary or sufficient to the data or the question. What does this mean? It means that the same data can reasonably be analysed in different ways. There is no necessary way to analyse some data though there may be conventions or normal practices [@kuhn1970]. It means that it is unlikely that any one analysis will do all the work that could be done (a sufficiency) to get you from your data to useful or reasonable answers to your questions.\nThese ideas may be unsettling but they are realistic. Stating them will better prepare you for professional work. In the workplace, the accuracy of these ideas will emerge when you see how a team in any sector (health, marketing …) gets from its data to its product. If we talk about the ideas now, we can get you ready for dealing with the practical and the ethical concerns you will confront when that happens.\nWe will begin by discussing psychological research, and research about psychological research, to answer the question: Why: what is the motivation for the assignment? We will then move to answering the What question ?@sec-what and the How question ?@sec-how."
  },
  {
    "objectID": "PSYC411/part2/intro.html#sec-motivation-for-assignment",
    "href": "PSYC411/part2/intro.html#sec-motivation-for-assignment",
    "title": "Reasons why we do the research report assignment: What you will learn",
    "section": "",
    "text": "We are here because we are interested in humans and human behaviour, and because we are interested in scientific methods of making sense of these things. Some of us are aware that science (including psychological science) has undergone a rolling series of crises: the replicability or replication crisis [@Pashler2012a; @Pashler2012b]; the statistical crisis [@gelman2014a]; and the generalizability crisis [@yarkoni2022]. And that science is undergoing a response to these crises, evidenced in the advocacy of pre-registration [@nosek2018; @nosek2019prereg], and of registered reports [@nosek2014], the use of open science badges (e.g., for the journal Psychological Science), the completion of large-scale replication studies [@aarts2015], and the identification of open science principles [@munafò2017]. We may usefully refer, collectively, to the crises and the responses, as the credibility revolution [@vazire2018]\nWe could teach a course on this (in Lancaster, we do) but, here, I invite you to follow the references if you are interested. Before going on, I want to call your attention to the fact that important elements of the hard work in trying to make science work better has been led by PhD students and by junior researchers [e.g., @herndon2014]. Graduate students may, at first, assume that the fact that a research article has been published in a journal means the findings that are reported must be true. Most of the time, some educated skepticism is more appropriate. An important driver of the realization that there are problems evident in the literature, and that there are changes we can make to improve practice, comes from independent post-publication review work exposing the problems in published work (see, e.g., this account by Andrew Gelman)\n\n\n\n\n\n\nTip\n\n\n\n\nAllow yourself to feel skeptical about the reports you read then work with the motivation this feeling provides.\n\n\n\nIn brief, then, most practicing scientists now understand or should understand that many of the claims we encounter in the published scientific literature are unlikely to be supported by the evidence [@Ioannidis2005], whether we are looking at the evidence of the results in the reports themselves, or evidence in later attempts to find the same results [e.g., @aarts2015]. We suspect that this may result from a number of causes. We understand that researchers may engage in questionable research practices [@john2012]. We understand that researchers may exploit the potential for flexibility in doing and reporting analyses [@Simmons2011a]. We understand that there are problems in how psychologists use or talk about the measurement of psychological constructs [@flake2020]. We understand that there are problems in how psychologists sample people for their studies, both in where we recruit [@bornstein2013; @wild2022; @Henrich2010], and in how many we recruit [@button2013; @cohen1962; @sedlmeier1989; @vankov2014]. We understand that there are problems in how psychologists specify or think about their hypotheses or predictions [@meehl1967; @scheel2022]. And we understand that there are problems in how scientists do, or rather do not, comply with good practice recommendations designed to fix these problems (discussed further in the following).\nThis discussion could (again) be unsettling. This list of problems could make you angry or sad. I, like others, think it is exciting. It is exciting because these problems have probably existed for a long time [e.g., @cohen1962; @meehl1967] but now, having identified the problems, we can hope to do something about it. It is exciting because if you care about people, the study of people, or the applications in clinical, education and other domains of the results of the study of people, then you might hope to see better, more useful, science in the future [@vazire2018].\nAs someone who teaches graduate and undergraduate students, I want to help you to be the change you want to see in the world 1. We cannot solve every problem but we can try to do better those things that are within our reach. I am going to end this introduction with a brief discussion of some ideas we can use to guide our better practices.\n\n\n\nIn this course, for this assignment, we are going to focus on:\n\nmultiverse analyses\nkinds of reproducibility\nthe current state of the match between open science ideas and practices\n\nIn the classes on the linear model, we will discuss:\n\nthe links between theory, prediction and analysis\npsychological measurement\nsamples\nvariation in results\n\n\n\n\n\n\nI am going to link this discussion to a metaphor (see Figure Figure 1) or a description you will find useful: the data analysis pipeline or workflow.\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nanalyse\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow\n\n\n\n\n\nThis metaphor or way of thinking is very common (take a look at the diagram in Wickham and Grolemund’s 2017 book “R for Data Science) and you may see the words “data pipeline” used in job descriptions, or you may benefit from saying, in a job application, something like: I am skilled in designing and implementing each stage of the quantitative data analysis pipeline, from data tidying to results presentation. I say this because scientists I have mentored got their jobs because they can do these things – and successfully explained that they can do these things – in sectors like educational testing, behavioural analysis, or public policy research.\nThe reason this metaphor is useful is that it helps us to organize our thinking, and to manage what we do when we do data analysis, we:\n\nget some data;\nprocess or tidy the data;\nexplore, visualize, and analyse the data;\npresent or report our findings.\n\nWe introduce the idea that your analysis work will flow through the stages of a pipeline from getting the data to presenting your findings because, next, we will examine how pipelines can multiply.\n\n\n\n\n\n\nTip\n\n\n\n\nAs you practice your data analysis work, try to identify the elements and the order of your work, as the parts of a workflow.\n\n\n\n\n\n\nWhat researchers have come to realize: because we started looking … The open secret that has been well kept [@bourdieu2004]: because everybody who does science knows about it, yet we may not teach it; and because we do not write textbooks revealing it … Is that at each stage in the analysis workflow, we can and do make choices where multiple alternative choices are possible. @gelman2014 capture this insight as the “garden of forking paths”2 (see Figure 2).\nThe general idea is that it is possible to have multiple potential different paths from the data to the results. The results will vary, depending on the path we take. In an analysis, we could take multiple different paths simply because at point A we decide to do B1, B2 or B3, maybe we choose B1, and then at point B1, we may decide to do C1, C2 or C3. Here, maybe we have our raw data at point A. Maybe we could do one of two different things when we tidy the data: action B1 or B2. Then, when we have our tidy data, maybe we can choose to do our analysis in one of six ways. Where we are at each step depends on the choices we made at the previous steps.\n\n\n\n\n\n\n\n\nD\n\n\n\nA\n\nA\n\n\n\nB1\n\nB1\n\n\n\nA-&gt;B1\n\n\n\n\n\nB2\n\nB2\n\n\n\nA-&gt;B2\n\n\n\n\n\nC1\n\nC1\n\n\n\nB1-&gt;C1\n\n\n\n\n\nC2\n\nC2\n\n\n\nB1-&gt;C2\n\n\n\n\n\nC3\n\nC3\n\n\n\nB1-&gt;C3\n\n\n\n\n\nC4\n\nC4\n\n\n\nB2-&gt;C4\n\n\n\n\n\nC5\n\nC5\n\n\n\nB2-&gt;C5\n\n\n\n\n\nC6\n\nC6\n\n\n\nB2-&gt;C6\n\n\n\n\n\n\n\n\nFigure 2: Forking paths in data analysis\n\n\n\n\n\nIn the end, it may appear to us that we took one path or that only one path was possible. When we report our analysis, in a dissertation or in a published journal article, we may report the analysis as if only one analysis path had been considered. But, critically, our findings may depend on the choices we made and this variation in results may be hidden from view.\nI am talking about forking paths because the multiplicity of paths has consequences, and we discuss these next.\n\n\n\n\n\n\nTip\n\n\n\n\nIt is about here, I hope, that you can start to see why it would makes sense to access data from a published study and to examine if you can get the same results as the study authors.\n\n\n\n\n\n\n\nI am going to discuss, now, what are commonly called multiverse analyses. Psychologists use this term, having been introduced to it in an influential paper by @steegen2016, but it comes from theoretical physics (take a look at wikipedia).\nI explain this because I do not want you to worry. The ideas themselves are within your grasp whatever your background in psychology or elsewhere. It is the implications for our data analysis practices that are challenging. They are challenging because what we discuss should increase your skepticism about the results you encounter in published papers. And they are challenging because they reveal your freedom to question whether published authors could have done their analysis in a different way.\nWe are going to look at:\n\ndata-set construction\nanalysis choices\n\n\n\nIn first discussing the wider context (of crisis and revolution), then discussing the specific context (of multiverses and, in the following, of reproducibility), I should be clear about the link between the two things. The finding that some results may not be supported by the evidence is probably due to a mix of causes. But one of those causes will be the combination of uncertainty over data processing or the uncertainty over analysis methods revealed in multiverse analyses, as we see next, combined with the limitations of data and code sharing, and the incompleteness of results reporting (as we see later).\n\n\n\nWhen you collect or access data for a research study, the complete raw data-set you receive is almost never the complete data-set you analyse or whose analysis you report. This is not a story about deliberately cheating. It is a story about the normal practice of science [@kuhn1970].\nPicture some common scenarios. You did a survey, you got responses from a 100 participants on 10 questions, and you asked people to report their education, ethnicity and gender. You did an experimental study, you tested two groups of 50 people each in 100 trials (imagine a common task like the Stroop test), and you observed the accuracy and the timing of their responses. You tested 100 children, 20 children in each of five different schools, on a range of educational ability measures.\nIn these scenarios, the psychologist or the analyst of behavioural data must process their data. In doing so, you will ask yourself a series of questions like:\n\nhow do we code for gender, ethnicity, education?\nwhat do we about reaction times that are very short, e.g., \\(RT &lt; 200ms\\) or very long, e.g., \\(RT &gt; 1500ms\\))?\nif we present multiple questions measuring broadly the same thing (e.g. how confident are you that you understand what you have read? how easy did you find what you read?) how do we summarize the scores on those questions? do we combine scores?\nwhat do we do about people who may not appear to have understood the task instructions?\n\nTypically, the answers to these questions will be given to you by your supervisor, a colleague or a textbook example. For example, we might say:\n\n“We excluded all reaction times greater than 1500ms before analysis.”\n\nTypically, the explanation for these answers are rarely explained. We might say:\n\n“Consistent with common practice in this field, we excluded all reaction times greater than 1500ms before analysis.”\n\nBut the reader of a journal article typically will not see an explanation for why, as in the example, we exclude reaction times greater than 1500ms and not 2000ms or 3000ms, etc. We typically do not see an explanation for why we exclude all reaction times greater than 1500ms but other researchers exclude all reaction times greater than 2000ms. (I do not pick this example at random: there are serious concerns about the impact on analyses of exclusions like this [@Ulrich1994a].)\nWhat @steegen2016 showed is that a data-set can be processed for analysis in multiple different ways, with a number of reasonable alternate choices that can be applied, for each choice point: construction choices about classifying people or about excluding participants given their responses. If a different data-set is constructed for each combination of alternatives then many different data-sets can be produced, all starting from the same raw data. (For their example study, @steegen2016 found they could construct 120 or 210 different data-sets, based on the choice combinations.) Critically, for us, @steegen2016 showed that if we apply the same analysis method to the different data-sets then our results will vary.\nLet me spell this out, bit by bit:\n\nwe approach our study with the same research question, and the same verbal prediction;\nwe begin with the exact same data;\nwe then construct different data-sets depending on different but equally reasonable processing choices;\nwe then apply the same analysis analysis, to test the same prediction, using each different data-set;\nwe will see different results for the analyses of the different data-sets.\n\nAlternate constructions of the same data may cause variation in the results of statistical tests. Some kinds of data processing choices may be more influential on results than others. It seems unlikely that we can identify, in advance, which choices matter more.\n@steegen2016 suggest that we can deflate (shrink) the multiverse in different ways. I want to state their suggestions, here, because we will come back to these ideas in the classes on the linear model.\n\nDevelop better theories and improved measurement of the constructs of interest.\nDevelop more complete and precise theory for why some processing options are better than others.\n\nBut you will be asking yourself: What do I need to think about, for the research report assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you read a psychological research report, identify where the researchers talk about how they process their data: classification, coding, exclusion, transformation, etc.\nIf you can access the raw data, ask yourself: could different choices change the results of the same analysis?\n\n\n\n\n\n\nEven if we begin with the same research question and, critically, the same data-set, the results of a series of studies show that different researchers will often (reasonably) make different choices about the analysis they do to answer the research question. We often call these studies (analysis or model) multiverse studies. In these studies, we see variation in analysis and this variation is also associated with variation in results.\nAn influential example, in psychology, is reported by Silberzahn and colleagues [@silberzahn2015; @silberzahn2017] who asked 29 teams of researchers to answer the same question (“Are (soccer) referees more likely to give red cards to players with dark skin than to players with light skin?”) with the same data-set (data about referee decisions in football league games). The teams made their own decisions about how to answer the question in doing the analysis. The teams shared their plans, and commented on each others’ ideas. The discussion did not lead to a consensus about what analysis approach is best. In the end, the different teams did different analyses and, critically, the different analyses had different results. The results varied in whether the test of the effect of players skin colour (on whether red cards were given) was significant or not, and on the strength of the estimated association between the darkness of skin colour (lighter to darker) and the chances (low to high) of getting a red card.\nThere have now been a series of multiverse or multi-analyst studies which demonstrate that, under certain conditions, different researchers may adopt different analysis approaches – which will have different results – in answering the same research question with the same data. This demonstration has been repeated in studies in health, medicine, psychology, neuoscience, and sociology, among other research fields (e.g., @parsons; @breznau2022; @klau; @klau2021; @wessel2020multiverse; @poline2006; @maier-hein2017; @starns2019; @fillard2011; @dutilh2019; @salganik2020; @bastiaansen2020; @botvinik-nezer2020; @schweinsberg2021; @patel2015; see, for reviews, and some helpful guidance, @aczel2021; @delgiudice2021; @hoffmann; @wagenmakers2022).\nIn these studies, we typically see variation in how psychological constructs are operationalized (e.g., how do we measure or code for social status?), how data are processed or data-sets constructed (as in @steegen2016a), plus variation in what statistical techniques are used, and in how those techniques are used. This variation can be understood to reflect kinds of uncertainty [@klau; @klau2021]: uncertainty about how to process data, and uncertainty about the model or methods we should use to test or estimate effects. Further research makes it clear that we should be aware, if we are not already, of the variation in results that can be expected because different researchers may choose to design studies, and construct stimulus materials, in different ways given the same research hypothesis information [@landy2020a].\nBut you will be asking yourself: What do I need to think about, for the research report assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you read a psychological research report, identify where the researchers talk about how they analyse their data: the hypothesis or prediction they test; the method; their assumptions; the variables they include; the checks or the alternate analyses they did or did not do.\nIf you can access the data and analysis code, ask yourself: could different methods change the results of the same analysis?\n\n\n\n\n\n\nThis is a good place to look at what we have discussed, and present an evaluation of the story so far.\nThis is not a story where everybody or nobody is right or where everything or nothing is true 3. Instead, we can be guided by the advice [@meehl1967; @scheel2022; @steegen2016] that we should:\n\nseek better and more complete theorizing about the constructs of interest and how we measure them, and\nseek more complete and more precise theory so that some options are theoretically superior than others, and should be preferred, when constructing data-sets or specifying analysis methods.\n\nNot all research questions and not all hypothesis information will allow an equally wide variety of potential reasonable approaches to the analysis. As Paul Meehl argued a long time ago [@meehl1967; @meehl1978], and researchers like Anne Scheel [@scheel2021; @scheel2022] argued more recently, the complexity of the thing we study – people, and what they do – and the still early development of our understanding of this thing, mean that what we want but what we do not see, in psychology, are scientifically productive tests of falsifiable theories. (See, consistent with this perspective, discussions by @auspurg2021 and by @delgiudice2021 about the range of analysis possibilities that may or may not be allowed, in multiverse analyses, by more or less clear research questions or well-developed causal theories.) Our concern should not so much be with being able to do statistical analysis, or with finding significant or not significant results. It would be more useful to do analyses to test concrete, inflexible, precise predictions that can be wrong.\nNor is this a story, I think, about the potential for cheating. While we may refer to subjective choices or to researcher flexibility, the differences that we see do not resemble the researcher degrees of freedom [@Simmons2011] some may exploit, consciously or unconsciously, to change results to suit their aims. Instead, the multiverse results show us the impact of the reasonable differences in approach that different researchers may sensibly choose to take when they try to answer a research question with data.\nNot all alternates, at a given point of choosing, in the data analysis workflow, will have equal impact. Work by Young [@young2017; @young2018] indicates that if we deliberately examine the impact of method or model uncertainty, over different sets of possible choices — about what variables or what observations we include in an analysis, for example — we may find that some results are robust to an array of different options, while other results are highly susceptible to different choices. This work suggests another way in which uncertainty about methods or variation in results can be turned into progress in understanding the phenomena that interest us: through systematic, informed, interrogation of the ways that results can vary.\nIn general, in science, the acceptance of research findings must always be negotiated [@bourdieu2004]. Here, we see that the grounds of negotiation should often include an analysis of the impact on the value of evidence of the different analysis approaches that researchers can or do apply to the data that underlie that evidence.\nBut you will be asking yourself: what do I need to think about, for the assignment?\n\n\n\n\n\n\nTip\n\n\n\n\nThe results of multiverse analyses show us that if we see one analysis reported in a paper, or one workflow, that does not mean that only one analysis can reasonably be applied.\nIf you read the methods or results section of a paper, you should reflect: what other analysis methods could be used here? How could variation in analysis method — in what or how you do the analysis — influence the results?\n\n\n\nMaking you aware of the potential for analysis choices is useful because developing researchers, including graduate students, are often not aware of the room for choice in the data analysis workflow. Developing researchers — you — may be instructed that “this is how we do things” or “you should follow what researchers did previously”. Following convention is not necessarily a bad thing: it is a feature of the normal practice of science [@kuhn1970]. However, you can now see, perhaps, that there likely will be alternative ways to process or to analyse data than the approach a supervisor, lab or field normally adopts.\nThis understanding or awareness has three implications for practice, it means:\n\nWhen we talk about the analysis we do, we should explain our choices.\nWe should check, or enable others to check, what impact making different choices would have on our results.\nMost importantly: we can allow ourselves the freedom to critically evaluate the choices researchers make, even the choices researchers make in published articles.\n\n\n\n\n\nMultiverse analyses and post-publication analyses, in general, show that we can and should question or critically evaluate the analyses we encounter in the literature. This work can usefully detect problems in original published analyses [e.g., @Gelman2009c; @herndon2014; @Wagenmakers2011]. It can demonstrate where original published claims are or are not robust to variation of analysis method or approach.\nGiven these lessons, and the implications we have identified, we should expect or hope to see open science practices [@munafò2017; @nosek2022]:\n\nshare data and code;\npublish research reports in ways that enable others to check or query analyses.\n\nAs we discuss, following, these practices are now common but the quality of practice can sometimes be questioned. This matters for you because it makes it more challenging – in specific identifiable locations – to locate, access, analyse and report previously collected data.\nThe discussion of current practices identifies where or how the assignment may be more challenging, but also identifies some of the exact places where the assignment provides a real opportunity to do original research work.\nFirst, I am going to introduce some ideas that will help you to think about what you are doing when you do this work. We focus on the concept of reproducibility.\n@gilmore2017 [following @goodman2016] present three kinds of reproducibility:\n\nmethods reproducibility\nresults reproducibility\ninferential reproducibility\n\nIn looking at reproducibility, here, we are considering how much, or in what ways, the results or the claims that are made in a published study can be found or repeated by someone else.\n\n\nAs @gilmore2017 discuss, methods reproducibility means that another researcher should be able to get the same results if they use the same tools and analysis methods to analyse the same data-set [some researchers also refer to analytic reproducibility or computational reproducibility; see e.g. @crüwell; @hardwicke2018; @hardwicke; @laurinavichyute2022; @minocher].\nIn neuroimaging, the multiplicity of possible implementations of the data analysis pipeline [@carp2012plurality], and the fact that important elements or information about the pipeline deployed by researchers may be missing from published reports [@carp2012secret], can make it challenging to identify how results can be reproduced.\nIn psychological science, in evaluating reports of results from analyses of behavioural data collected through survey or experimental work, in principle, we should expect to be able to access the data collected by the study authors, follow the description of their analysis method, and reproduce the results they report.\n\n\n\n\n\n\nTip\n\n\n\n\nFor an assignment in which we ask students to locate, access, analyse and report previously collected data, we are directly concerned with methods reproducibility.\n\n\n\n\n\n\nResults reproducibility means that if another researcher completes a new study with new data they are able to get the same results as the results reported following an original study: this often referred to as replication. The replication studies that have been reported [e.g., @aarts2015], and continue to be reported (see, for example, the studies discussed by @nosek2022), in the last several years, present attempts to examine the results reproducibility of published findings.\nIn the classes on the linear model, we will examine if similar or different results are observed in a series of studies using the same procedure and the same materials. We shall discuss, in those classes, in more depth, what results reproducibility (or study replication) can or cannot tell us about the behaviours that interest us.\n\n\n\nInferential reproducibility means that if a researcher repeats a study (aiming for results reproducibility) or re-analyses an original data-set (aiming for methods reproducibility) then they can come to the same or similar conclusions as the authors of the report of an original study.\nHow is inferential reproducibility not methods or results reproducibility? @goodman2016 explain that researchers can make the same conclusions from different sets of results and can reach different conclusions from the same set of results.\nHow is it possible to reach different conclusions from the same results? We can imagine two scenarios.\nFirst, we have to think about the wider research field, the research context, within which we consider a set of results. It may be that two different researchers will come to look at the same results with different expectations about what the results could tell us (in Bayesian terms, with different prior expectations). Given different expectations, it is easy to imagine different researchers looking at the same results and, for example, one researcher being more skeptical than another about what conclusion can be taken from those results. (In the class on graduate writing skills, I discuss in some depth the importance of reviewing a research literature in order to get an understanding of the assumptions, conventions or expectations that may be shared by the researchers working in the field.)\nSecond, imagine two different researchers looking at the same results — picture the original authors of a published study, and someone doing a post-publication re-analysis of their data — you can expect that the re-analysis or the reproducibility analysis could identify reasons to value the evidence differently, or to reach more skeptical conclusions, through critical evaluation of:\n\ndata processing choices;\nthe choice of the method used to do analysis;\nchoices in how the analysis method is used.\n\n… where that critical evaluation involves an analysis of the choices the original researchers made, perhaps involving an analysis of other choices they could have made, perhaps reflecting on how effectively the analyses address a given research question or test a given prediction.\n\n\n\n\n\n\nTip\n\n\n\n\nWe can think about the work we do, when we analyse previously reported data, in terms of the need to identify the reproducibility of results, methods and inferences.\nIn psychological science, determining that someone can get the same results, by analysing the same data, or will reach the same conclusions from the same results, are important – potentially, original – research contributions.\n\n\n\n\n\n\n\nI have said that we should expect or hope to see open science practices [@munafò2017; @nosek2022] where researchers:\n\nshare data and code;\npublish research reports in ways that enable others to check or query analyses.\n\nThis raises an important question: What exactly do we see, when we look at current practices? The question is important because answering it helps to identify where the challenges are located when you complete your work to locate, access, analyse and report previously collected data.\nI break the discussion of what we see into two parts. Firstly, I look at the results of audits of data and code sharing (see Section 1.2.6.2): are data shared and can we access the data? Secondly, I discuss analyses of methods reproducibility, and shared data and code usability (see Section 1.2.6.3): can others reproduce the results reported in published articles, given shared data? can others access and run shared analysis code? can others use the shared code to reproduce the reported results? Again, I need to be brief but reference sources that you can follow-up.\n\n\nI should be clear, before we go on, about the link between the credibility revolution in science, and the effort to examine reproducibility of results. Many elements of the credibility revolution emerged out of the observation that it has often been difficult to repeat the results of published studies when we conduct new studies (replication studies or results reproducibility; e.g., @aarts2015). However, it is clearly difficult to know what to replicate or reproduce if we cannot reproduce the results presented in a study report (methods reproducibility), given the study data [@artner2021; @laurinavichyute2022; @minocher].\n\n\n\nResearch on data and code sharing practices suggest that practices have improved, from earlier low levels.\nIn an important early report, @wicherts2006 observed that it was very difficult to obtain data reported in psychological research articles from the authors of the articles. They asked for data from the lead authors of 141 articles published in four leading psychology journals, for about 25% of the studies. This low response rate was found despite the fact that authors in these journals must agree to the principle that data can be shared with others wishing to verify claims.\nPractice has changed: how?\nOne change to practice has involved the use of open science badges. In journals like Psychological Science authors of articles may be awarded badges — Open Data, Open Materials, Preregistration badges — by the editorial team. Authors can apply for and earn the badges by providing information about open practices, and journal articles are published with the badges displayed near the front of the articles.\nIn theory, initiatives like encouraging authors to earn open science badges should mean that data sharing practices improve, enabling access to data and code for those, like you, who would like to re-analyse previously published data. In theory, all you should need to do — to locate and access data — is just search articles in the journal Psychological Science for studies with open data badges, and follow links from the published articles to then access study data at an open repository like the Open Science Framework (OSF) What do we see in practice?\nAnalyses reported by @kidwell2016 as well as analyses reviewed by @nosek2022 indicate that more articles have claimed to make data available in the time since badges were introduced. When they did their analysis, @kidwell2016 found that a substantial proportion, but not all, of the articles in Psychological Science can be found to actually provide access to shared data. However, critically, many but not all the articles with open data badges provide access to data available through an open repository, data that are correct, complete and usable [@kidwell2016]. In their later report, the analyses reviewed by @nosek2022 suggest that the use of repositories like OSF for data sharing may be accelerating but that, over the last few years, the rate at which open science practices like sharing data, overall, appears to be substantial but not yet reported or observed in a majority of the work of researchers.\nMany journals now require the authors of articles to include a Data Availability Statement to locate their data. Analyses by @federer2022 indicate that Data Availability Statements for articles published in the open access 4 journal PLOS ONE often, helpfully, include Digital Object Identifiers (DOIs) or Universal resource locators (URLs) enabling direct access to shared data (i.e., without having to contact authors). Of those DOIs or URLs, most appeared to be associated with resources that could successfully be retrieved. In contrast, analyses reported by @gabelica2022 indicate that where article authors state that “data sets are available on reasonable request” (the most common availability statement), most of the time, the authors did not respond or declined to share the data [see similar findings, across fields, by @tedersoo2021]. Clearly, in the analyses of open science practices we have seen so far, data sharing is more effective where sharing does not have to work through authors.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you are looking for a study in order to get data that you can then re-analyse, it makes sense to look, first, for studies focusing on research questions that interest you.\nWhen you are looking for published reports where the authors share data, look for articles with open science badges or where you can see a Data Availability Statement.\nChoose articles where the authors provide a direct link to their data, where the data are located on an open repository like the Open Science Framework (there are other repositories).\n\n\n\n\n\n\nResearch on data and code sharing practices suggest that practices have improved but that there are concerns about the quality of the sharing. Here, the critical concern relates to the word enable in the objective: that we should publish research reports in ways that enable others to check or query analyses.\nJohn Towse and colleagues [@towse2021] at Lancaster University examined the quality of open data-sets to assess their quality in terms of their completeness and reusability [see also @roche2015].\n\ncompleteness: are all the data and the data descriptors supporting a study’s findings publicly available?\nreusability: how readily can the data be accessed and understood by others?\n\nFor a sample of data-sets, they found that about half were incomplete, and about two-thirds were shared in a way that made them difficult to use. Practices tended to be slightly better in more recent publications. (Broadly similar results are reported by [@hardwicke2018].)\nWhere data were found to be incomplete, this appeared to be, in part, because participants were excluded in the processing of the data for analysis but this information was not in the report, or because data were shared without a guide or “readme” file or data dictionary (or codebook) explaining the structure, coding or composition of the shared data.\nPotentially important for future open science practices, [@towse2021; also @roche2015] found that sharing data as Supplementary materials may appear to carry risks that, in the long term, mean that data may become inaccessible.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you locate open data you can access, look for a guide, “readme” file, codebook or data dictionary explaining the data: you need to be able to understand what the variables are, what the observations relate to (observations per person, per trial?) and how variables are coded.\nLocate and examine carefully the parts of the published report, or the data guide, where the authors explain how they processed their data.\n\n\n\nA number of studies have been conducted to examine whether shared data and analysis code can be reused by others to reproduce the results reported in papers [e.g., @artner2021; @crüwell; @hardwicke2018; @hardwicke; @laurinavichyute2022; @minocher; @obels2020; see @artner2021 for a review of reproducibility studies]. In critical respects, the researchers doing this work are doing work similar to the work we are helping students to do, locating, accessing, and analysing previously collected data. In these studies, typically, the researchers progressed through a series of steps.\n\nSearched the articles published in a journal (e.g., Cognition, the Journal of Memory and Language, Psychological Science), published in a topic area across multiple journals (e.g., social learning, psychological research), or associated with a specific practice (e.g., registered reports.\nSelected a subset of articles where it was identified that data could be accessed.\nIdentify a target result or outcome to reproduce, for each article. In their analyses, Hardwicke and colleagues [@hardwicke2018; @hardwicke] focused on attempting to reproduce primary or straightforward and substantive outcomes: substantive – if emphasized in the abstract, or presented in a table or figure; straightforward – if the outcome could be calculated using the kind of test one would learn in an introductory psychology course (e.g., t-test, correlation).\nAttempted to reproduce the results reported in the article, using the description of the data analysis presented in the article, and the analysis code (if provided), in some cases asking for information from the original study authors, in other cases working independently of original authors.\n\nWhat the reproducibility studies appear to show is that, for many published reports, if data are shared and if the shared data are accessible and reusable then, most of the time, the researchers could reproduce the results presented by the original study authors [@hardwicke2018; @hardwicke; @laurinavichyute2022; @minocher; @obels2020; but see @crüwell]. This is great. But what is interesting, for us, is where the reproducibility researchers encountered challenges. You may encounter the same or similar challenges.\nI list some challenges that the researchers describe, following. Before you look at the list, I want to assure you: you will not find all these challenges present for any one article you look at. Most likely, you will find one or two challenges. Obviously, some challenges will be more difficult than others.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you find a study you are interested in, with open data and maybe open analysis code, your main challenge will often be to identify exactly what analysis the original study authors did to answer their research question.\nLocate and examine carefully the parts of the published report where the authors explain how they did the analysis that gave them their key result. Usually that key result should be identified in the abstract or in the conclusion.\n\n\n\n\n\n\nData Availability Statements or open science badges indicate data are shared but data are not directly accessible through a link to an open repository.\nThe data are shared and accessible but there is missing or incorrect information about the data. The documentation, codebook or data dictionary is missing or incomplete. There is unclear or missing information about the variables or the observations, or about the coding of variable values, responses.\nOriginal study authors may share raw and processed data or just processed or just raw data. It may not be clear how raw data were processed to construct the data analysed for the report. It may not be clear how variables were transformed or calculated or processed.\nThere may be mismatches between the variables referred to in the report and the variables named in the data file. It may be unclear how a data file corresponds to a study described in a report, where there are multiple studies and multiple data files.\n\n\n\n\n\nThe original report includes a description of the analysis but the description of the analysis procedure is incomplete or ambiguous.\nThere may be a mismatch, in the report, between a hypothesis, and the analysis specified to test the hypothesis (maybe in the Methods section), compared to a long sequence of results reported in the Results section. This makes it difficult to identify the key analysis.\nIt is easier to reproduce results if both data and code are shared because the presentation of the analysis code usually (not always) makes clear what analysis was done to get the results presented in the report.\nSometimes, analysis code is shared but it is difficult to use because it requires proprietary software (e.g., SPSS) or because it requires function libraries that are no longer publicly available.\nSometimes, there are errors in the analysis. Sometimes, there are errors in the presentation of the results, where results have been incorrectly copied into reports from analysis outputs."
  },
  {
    "objectID": "PSYC411/part2/intro.html#this-is-why",
    "href": "PSYC411/part2/intro.html#this-is-why",
    "title": "Reasons why we do the research report assignment: What you will learn",
    "section": "",
    "text": "The research report assignment requires students to locate, access, analyse and report previously collected data. At the start of the introduction, I said I would explain the answer to the question:\n\nWhy: what is the motivation for the assignment?\n\nI summarize, following, the main points of the answer I have given. When you review these points, I want you to think about two things, returning to the ideas of @bourdieu2004 and @kuhn1970 I sketched at the start.\nOften what we do in science is guided by convention, the assumptions and habits of normal practice [@kuhn1970]. These conventions can work in our minds so that if we encounter an anomaly or discrepancy between what we expect and what we find, in our work, we may usually blame ourselves: it was something wrong that we did or failed to do. It can cause us anxiety if we do not reproduce a result we think we should be able to reproduce [@lubega]. But I want you to understand, from the start, that sometimes, if you think you have found an error or a problem in a published analysis or a shared data-set, you may be right.\nIf there is anything we have learned, through the findings of replication studies, multiverse analyses, and reproducibility audits it is that people make mistakes, different choices are often reasonable, and we always need to check the evidence.\n\n\n\nWe are in the middle of a credibility revolution. The lessons we have learned so far oblige us to think about and to teach good open science practices that safeguard the value of evidence in psychology.\nThis matters, even if we do not care about scientific methods, because if we care about the translation into policy or practice – in clinical psychology, in education, health, marketing and other fields – what we do will depend on the value of the research evidence that informs policy ideas or practice guides.\nFocusing on data analysis, it is useful to think about the whole data pipeline in analysis, the workflow that takes us from data collection to raw data to data processing to analysis to the presentation of results.\nAt every stage of the data pipeline, there are choices about what to do. There are not always reasons why we make one choice instead of another. Sometimes, we are guided by convention, example or instruction.\nThe existence of choices means the path we take, when we do data analysis, can be one path among multiple different forking paths.\nFor some parts of the pipeline – data-set construction, data analysis choices – reasonable people might make different decisions to sensibly answer the same research question, given the same data. This variation between pathways can be more or less important in influencing the results we see.\nIf results tend to stay similar across different ways of doing analysis, we might conclude that the results are reasonably robust across contexts, choices, or other variation in methods.\nTo enable others to see what we did (versus what we could have done), to see how we got to our results from our data, it is important to share our data and code.\nEveryone makes mistakes and we should make it easy for others, and ourselves, to find those mistakes by sharing our data and code in accessible, clear, usable ways.\nWe need to teach and learn how to share effectively the data and the code that we used to answer our research questions.\n\nIn constructing the assignment – in asking and supporting students to locate, access, analyse and report previously collected data – we are presenting an opportunity to really investigate and evaluate existing practices.\nYou may find that this work is challenging, in some of the places that reproducibility research has identified there can be challenges. Where the challenges cannot be fixed – if you have found an interesting study but the study data are inaccessible or unusable – we will advise you to move on to another study. Where the challenges can be fixed – if data require processing, or if analysis information requires clarification – we will provide you with help or enabling information so that you fix the problems yourself.\n\n\n\n\n\n\nTip\n\n\n\n\nMaybe the main lesson from this exercise is a reminder of the Golden rule: treat others as you would like to be treated.\nIf it is frustrating when it is difficult to understand information about an analysis or about data, or when it is difficult to access and reuse shared data and code.\nWhen it is your turn — do better — reflecting on what frustrated you.\n\n\n\nOne last question: why not just do less demanding or challenging tasks? Because this is part of what makes graduate degree valuable, what will make you more skilled in the workplace. Most of the time, we work in teams, we inherit problems or data analysis tasks, or are given results with partial information. The lessons you learn here will help you to effectively navigate those situations."
  },
  {
    "objectID": "PSYC411/part2/intro.html#footnotes",
    "href": "PSYC411/part2/intro.html#footnotes",
    "title": "Reasons why we do the research report assignment: What you will learn",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis encouragement is often attributed to Gandhi but is attributed ((here)) to a Brooklyn school teacher, Ms Arleen Lorrance, who led a transformative school project in the 1970s.↩︎\nThe term is taken from the name of a short story by Jorge Luis Borges, “El jardin de senderos que se bifurcan” (translated as ‘The garden of forking paths’).↩︎\nThere could be a story where the hero (us) ultimately learns to reject binary (present, absent; significant, non-significant) choices, and embrace variation, or embrace uncertainty [@Gelman2015; @vasishth2021].↩︎\nOpen access journals publish articles that are free to read or download.↩︎"
  },
  {
    "objectID": "PSYC411/part2/knowledge-ecosystem.html",
    "href": "PSYC411/part2/knowledge-ecosystem.html",
    "title": "The R knowledge ecosystem and how to help yourself",
    "section": "",
    "text": "The R knowledge ecosystem and how to help yourself\n\n\n\n\n\n\nWarning\n\n\n\nUnder construction\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC412/part1/Week14.html",
    "href": "PSYC412/part1/Week14.html",
    "title": "4. Logistic regression",
    "section": "",
    "text": "All of the models considered up to this point dealt with continuous response variables. Previously we looked at categorical predictors, but what if the response itself is categorical? For instance, whether the participant has made an accurate or inaccurate selection or whether a job candidate gets hired or not. Another common type of data is count data, where values are also discrete. Often with count data, the number of opportunities for something to occur is not well-defined. For instance, the number of speech error in a corpus, the number of turn shifts between speakers in a conversation or the number of visits to the doctor. Logistic regression allows us to model a categorical response variable."
  },
  {
    "objectID": "PSYC412/part1/Week14.html#sec-wk14-lectures",
    "href": "PSYC412/part1/Week14.html#sec-wk14-lectures",
    "title": "4. Logistic regression",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented below:\nLogistic regression (~38 min)\n\nSlides Transcript"
  },
  {
    "objectID": "PSYC412/part1/Week14.html#sec-wk14-reading",
    "href": "PSYC412/part1/Week14.html#sec-wk14-reading",
    "title": "4. Logistic regression",
    "section": "Reading",
    "text": "Reading\n\nBarr (2020)\nLink\nThis online textbook provides a useful overview of logistic regression. It does talk about modelling multi-level data and random effects. Don’t worry about that for now, those will be covered in the second half of 402. This week we’ll focus on ‘single-level’ data.\n\n\nWinter (2020)\nLink\nChapter 12 provides a comprehensive introduction to logistic regression and its implementation in R."
  },
  {
    "objectID": "PSYC412/part1/Week14.html#sec-wk14-pre-lab-activities",
    "href": "PSYC412/part1/Week14.html#sec-wk14-pre-lab-activities",
    "title": "4. Logistic regression",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Getting ready\n\nGet your files ready\nDownload the 402_week14_forStudents.zip file and upload it into a new folder in RStudio Server.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.\n\n\n\n\n\n\nPre-lab activity 2: Rainy days\nTry running the code mentioned in the online textbook by Barr. If you find it easier, use the rainy_days.R script (in the ‘402_week14_forStudents folder you were asked to download in ’Pre-lab activity 1’). It illustrates the point that for discrete data, the variance is often not independent from the mean. In addition, it introduces some very useful R functions: What do the rep() function, the c() function and the facet_wrap() function do? Remember, you can type ?function name() (e.g., ?rep()) in the Console to get more information about a function. Finally, can you add a graph for rainy days in Lancaster?\n\n\nPre-lab activity 3: Gesture perception\nPlease go through the example described in section 12.6 of the chapter on logistic regression in Bodo Winter’s book (link under ‘Reading’). Read the section and (simultaneously) work through the script (chapter12_6.R; in the ‘402_week14_forStudents folder you were asked to download in ’Pre-lab activity 1’). We’ll be working more with this dataset during the lab, so it is helpful if you get a feel for it now."
  },
  {
    "objectID": "PSYC412/part1/Week14.html#sec-wk14-lab-activities",
    "href": "PSYC412/part1/Week14.html#sec-wk14-lab-activities",
    "title": "4. Logistic regression",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply logistic regression to answer questions in psychological science\nconducting logistic regression in R\ninterpreting the R output of logistic regression\nreporting results for logistic regression following APA guidelines\n\nMore info will be uploaded soon.\n\nLab activity 1: More work on gesture perception\n\nBackground\nThe dataset we’ll be working with is described in section 12.6 of the chapter on logistic regression in Bodo Winter’s book (link under ‘Reading’). In the pre-lab activity, we explored the dataset and fitted a first logistic regression model assessing whether participants’ perception of a gesture (expressed as a categorical decision between a ‘shape’ vs. a ‘height’ interpretation of the gesture) was affected by the extent of ‘pinkie curl’. In this lab activity, we’ll be building on that analysis by: 1) Repeating the analysis with a centered pinkie curl variable, and 2) by adding a second predictor: index_curve.\nOur research question: Is gesture perception associated with different aspects of hand shape?\n\n\nStep 1: Set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week14/hassemer_winter_2016_gesture.csv?raw=true\", destfile = \"hassemer_winter_2016_gesture.csv\")\n\n\nTASK: Finally, read in the data file (hassemer_winter_2016_gesture.csv), and familiarise yourself with its structure.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function and the head() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nges &lt;- read_csv(\"hassemer_winter_2016_gesture.csv\")\nhead(ges)\n\n\n\n\n\nStep 2: Descriptive statistics and distributions\nAs part of the pre-lab activities, you’ve already familiarised yourself with the dataset by looking at:\n\nhow participants were distributed across the pinkie curl conditions;\nwhich response option was chosen more frequently in total and across pinkie curl conditions;\nproportions of response options across pinkie curl conditions\n\n\nTASK: Please remind yourself of these stages if necessary by revisiting the chaper12_6.R script.\n\n\n\nStep 3: Data wrangling\nFor logistic regression, the outcome variable needs to either be coded as 0 or 1, or it needs to be coded as a factor.\n\nTASK: Write the code to convert the outcome variable to a factor.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse mutate() and factor().\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges &lt;- mutate(ges, choice = factor(choice))\n\n\n\nAs with linear regression, centering your predictor makes it easier to interpret the output of a logistic regression.\n\nTASK: Write the code to center the pinkie curl predictor.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCentering involves subtracting the mean.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges &lt;- mutate(ges,\n    pinkie_c = pinkie_curl - mean(pinkie_curl))\n\n\n\n\n\nStep 5: Fit the regression model with the centered variable\nNow let’s re-fit choice (height vs. shape) as a function of pinkie curl, but using the centered variable.\n\nTASK: Write the code to fit the model and check the coefficients.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm() function and remember you need to specify the ‘family’ argument. To check the coefficients, you can use the tidy() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges_mdl_c &lt;- glm(choice ~ pinkie_c,\n               data = ges, family = 'binomial')\ntidy(ges_mdl_c)\n\n\n\nQUESTION 1: How does the coefficient table differ from the model fitted earlier where you used the pinkie curl predictor before you centered it?\nQUESTION 2: How should you now (using the model with the centered pinkie curl predictor) interpret the intercept?\nThe average pinkie curl is step 5 on the 9 step continuum. From our previous analysis (pre-lab activity), we know that the predicted log odds of ‘shape’ at that step was 0.38 and the probability was 0.59. So if we extract the intercept from the coefficient table of the model using the centered predictor, we should get those values. Use the code below to do so and compare the values to the ones from the pre-lab activity.\n\n# Extracting the estimate for the intercept and storing it in an object called intercept:\nintercept_logOdds &lt;- tidy(ges_mdl_c)$estimate[1]\n\n# Getting the predicted probability by applying the logistic:\nintercept_prob &lt;- plogis(intercept_logOdds)\n\nintercept_logOdds\nintercept_prob\n\nThe values are roughly the same!\n\n\nStep 6: Incorporating a second predictor\nIn addition to the ‘pinkie curl’, the extent to which the index finger is curved may also affect gesture perception. This is quantified in the ‘index_curve’ variable. Before we fit the model, we need to center both predictors.\n\nTASK: Write the code to center the second predictor.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCentering involves subtracting the mean.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges &lt;- mutate(ges,\n              index_c = index_curve - mean(index_curve))\n\n\n\n\nTASK: Write the code to fit model with both pinkie curl and index curve and check the coefficients.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm() function and remember you need to specify the ‘family’ argument. To check the coefficients, you can use the tidy() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nboth_mdl &lt;- glm(choice ~ pinkie_c + index_c,\n    data = ges, family = 'binomial')\ntidy(both_mdl)\nQUESTION 3: How does the index_curve predictor affect the proportion of shape responses?\nWe can see this more easily if we compare the descriptive proportions:\n\nindex_tab &lt;- with(ges, table(index_curve, choice))\nindex_tab\n\nprop.table(index_tab, 1)\n\nThe “1” in here stands for row-wise proportions.”2” would compute column-wise proportions.\n\nAnswers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk14_labAct1_withAnswers.R.\nQUESTION 1: How does the coefficient table differ from the model fitted earlier where you used the pinkie curl predictor before you centered it? # ANSWER: The intercept has changed from 1.065 to 0.397.\nQUESTION 2: How should you now (using the model with the centered pinkie curl predictor) interpret the intercept? # ANSWER: The intercept is now the predicted log odds of ‘shape’ for a gesture with # average pinkie curl.\nQUESTION 3: How does the index_curve predictor affect the proportion of shape responses? # ANSWER: The slope is positive, so more index-curved fingers results in more # shape responses."
  },
  {
    "objectID": "PSYC412/part1/Week14.html#sec-wk14-answers",
    "href": "PSYC412/part1/Week14.html#sec-wk14-answers",
    "title": "4. Logistic regression",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk14_labAct1_withAnswers.R.\nQUESTION 1: How does the coefficient table differ from the model fitted earlier where you used the pinkie curl predictor before you centered it? # ANSWER: The intercept has changed from 1.065 to 0.397.\nQUESTION 2: How should you now (using the model with the centered pinkie curl predictor) interpret the intercept? # ANSWER: The intercept is now the predicted log odds of ‘shape’ for a gesture with # average pinkie curl.\nQUESTION 3: How does the index_curve predictor affect the proportion of shape responses? # ANSWER: The slope is positive, so more index-curved fingers results in more # shape responses."
  },
  {
    "objectID": "PSYC412/part1/Week13.html",
    "href": "PSYC412/part1/Week13.html",
    "title": "3. More on interactions",
    "section": "",
    "text": "Interactions are ubiquitous in psychological science, which is why we’ll spend some more time building models that include interaction terms. Last week we modelled well-being as a function of screen-time (a continuous predictor) and biological sex (a categorical predictor) and their interaction. This week we’ll look at interactions between continuous predictors."
  },
  {
    "objectID": "PSYC412/part1/Week13.html#sec-wk13-lectures",
    "href": "PSYC412/part1/Week13.html#sec-wk13-lectures",
    "title": "3. More on interactions",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented below:\nMore on interactions (~18 min)\n\nSlides Transcript\nIf you need to remind yourself about the why’s and how’s of centering and standardising, please revisit this video. We’ll be using this in the lab activity.\nCentering and standardising (~5 min)\n\nSlides Transcript"
  },
  {
    "objectID": "PSYC412/part1/Week13.html#sec-wk13-reading",
    "href": "PSYC412/part1/Week13.html#sec-wk13-reading",
    "title": "3. More on interactions",
    "section": "Reading",
    "text": "Reading\n\nWinter (2020)\nLink\nChapter 8 explains what interactions are and how to model and interpret them."
  },
  {
    "objectID": "PSYC412/part1/Week13.html#sec-wk13-pre-lab-activities",
    "href": "PSYC412/part1/Week13.html#sec-wk13-pre-lab-activities",
    "title": "3. More on interactions",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Cheatsheets\nLast week, we had a look at some of the ‘recipes’ that Posit (the company behind RStudio) provides. If you need a reminder, an overview of all their ‘recipes’ can be found here.\nAnother great resource they provide are the ‘cheatsheets’: one-page overviews of the most important functions in a particular R package/library. There are many and some have been translated into differnt languages. You can access them online, or print them as a pdf to have on hand.\n\nTASK Explore the cheatsheets linked to below. The ones for RStudio IDE, dplyr, and ggplot2 are most relevant to the work we’ve been doing.\n\n\nOverview of all cheatsheets\nCheatsheet for RStudio IDE\nCheatsheet for dplyr\nCheatsheet for ggplot2\n\n\n\nPre-lab activity 2: Getting ready for the lab class\n\nGet your files ready\nDownload the 402_week13_forStudents.zip file and upload it into a new folder in RStudio Server.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below."
  },
  {
    "objectID": "PSYC412/part1/Week13.html#sec-wk13-lab-activities",
    "href": "PSYC412/part1/Week13.html#sec-wk13-lab-activities",
    "title": "3. More on interactions",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply multiple regression to answer questions in psychological science\nconducting multiple regression in R including interaction between continuous predictors\ninterpreting the R output of multiple linear regression (when including an interaction between continuous predictors)\nreporting results for multiple linear regression (when including an interaction between continuous predictors), following APA guidelines\n\n\nBackground\nToday, we’ll be working with a dataset from the following paper: Hamermesh, D. S. and Parker, A. (2005). Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity. Economics of Education Review, 24(4), 369 – 376.\nThe abstract of their paper is below or see here for the paper itself.\nAbstract: Adjusted for many other determinants, beauty affects earnings; but does it lead directly to the differences in productivity that we believe generate earnings differences? We take a large sample of student instructional ratings for a group of university teachers and acquire six independent measures of their beauty, and a number of other descriptors of them and their classes. Instructors who are viewed as better looking receive higher instructional ratings, with the impact of a move from the 10th to the 90th percentile of beauty being substantial. This impact exists within university departments and even within particular courses, and is larger for male than for female instructors. Disentangling whether this outcome represents productivity or discrimination is, as with the issue generally, probably impossible.\nOur research question: Do professors’ beauty score and age predict how students evaluate their teaching?\nTo complete this lab activity, you can use the R-script (402_wk13_labAct1_template.R) that you downloaded as part of the ‘Pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\nStep 1: Set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car, lsr and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(lsr)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week13/beauty.csv?raw=true\", destfile = \"beauty.csv\")\n\n\nTASK: Finally, read in the data file (beauty.csv), and familiarise yourself with its structure.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function and the head() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nbeauty &lt;- read_csv(\"beauty.csv\")    \nhead(beauty)\n\n\n\nQUESTION 1: Do you notice anything about the name of one of the variables and the name of the data table?\nThe table contains, amongst other things, the following characteristics of the professors\n\n‘beauty’ - beauty score per professor\n‘eval’ - teaching evaluation score per professor\n‘age’ - age of the professor\n\nQUESTION 2: Go back to the research question (see under ‘Background’ above), which of these three variables is the outcome variable? Which ones are the predictors?\n\n\nStep 2: Descriptive statistics and distributions\n\nTASK: Calculate some descriptive statistics for the variables of interest (eval, beauty and age).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use summarise() to calculate the mean, sd, min and max values.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\ndescriptives &lt;- beauty %&gt;% \n  summarise(mean_age = mean(age, na.rm = TRUE),\n            sd_age = sd(age, na.rm = TRUE),\n            min_age = min(age, na.rm = TRUE),\n            max_age = max(age, na.rm = TRUE),\n            mean_eval = mean(eval, na.rm = TRUE),\n            sd_eval = sd(eval, na.rm = TRUE),\n            min_eval = min(eval, na.rm = TRUE),\n            max_eval = max(eval, na.rm = TRUE),\n            mean_beauty = mean(beauty, na.rm = TRUE),\n            sd_beauty = sd(beauty, na.rm = TRUE),\n            min_beauty = min(beauty, na.rm = TRUE),\n            max_beauty = max(beauty, na.rm = TRUE))\n\n\n\nNow that we have the descriptive statistics, let’s get further information about the distribution of the variables by plotting histograms.\n\nTASK: Visualise the distributions of the variables of interest in histograms.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse ggplot() and geom_historgram()\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(data = beauty, aes(beauty)) +\n  geom_histogram()\n\nggplot(data = beauty, aes(eval)) +\n  geom_histogram()\n\nggplot(data = beauty, aes(age)) +\n  geom_histogram()\n\n\n\n\n\nStep 3: Center and standardise\nAs mentioned before, it will make it easier to interpret regression models with multiple predictors if we center and standardise our predictors. Before we go any further, we’ll do that.\n\nTASK: Center and standardise the predictor variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCentering involves subtracting the mean; standardising involves dividing by the standard deviation.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nbeauty_z &lt;- beauty %&gt;%\n  mutate(age_z = (age - mean(age, na.rm = TRUE)) / sd(age),\n         beauty_z = (beauty - mean(beauty, na.rm = TRUE)) / sd(beauty))\n\n\n\n\n\nStep 4: Scatterplots\nNow let’s have a look at the relationships between variables using scatterplots. To remind yourself of what centering and standardising does, do this for both the raw data and the centered and standardised data.\n\nTASK: Visualise the relationships between the variables of interest in scatterplots.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCreate six different scatterplots using ggplot() with geom_point() and geom_smooth().\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(beauty, aes(x = beauty, y = age)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty, aes(x = beauty, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty, aes(x = age, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty_z, aes(x = beauty_z, y = age_z)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty_z, aes(x = beauty_z, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty_z, aes(x = age_z, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\n\n\nQUESTION 3: Can you write an interpretation of the above plots in plain English?\nQUESTION 4: What is the difference between the scatterplots plotting the raw data and the ones plotting the centered and standardised data?\nIt is useful to have a quick look at the bivariate correlations between the variables of interest, before you run a regression model. We can easily generate a correlation matrix for these variables.\n\nTASK: Add the code below to your script and check you understand what each line does.\n\n\nbeauty_matrix &lt;- beauty_z %&gt;%\n  select(eval, age_z, beauty_z) %&gt;% # only keep relevant variables\n  as.data.frame() # tell R it is a specific type of data frame (needed for the correlate() function)\n\npairs(beauty_matrix) # make multiple scatterplots in one go\n\nintercor_results &lt;- correlate(x = beauty_matrix, # our data\n                              test = TRUE, # compute p-values\n                              corr.method = \"pearson\", # run a spearman test \n                              p.adjust.method = \"bonferroni\") # use the bonferroni correction\nintercor_results\n\nAfter you’ve run this code, look at the output in the console. It creates three tables, one with correlation coefficients, one with p-values for these coefficients and one with sample sizes.\n\n\nStep 5: The regression model\nWe’ve looked at descriptive statistics and distributions of variables and also at relations between variables. This has given us a good idea of what the data look like. Now we’ll construct the regression model to predict ‘evaluation score’ as a function of ‘age’ and ‘beauty score’. We’ll do this in two stages. First we’ll construct a model without an interaction term. Then we’ll construct a model that includes an interaction term betweeen the two predictor variables. Don’t forget to use the standardised data for all this.\n\nTASK: Construct a regression model without an interaction term.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the following formula, lm(y ~ x1 + x2, data); go back to the research question for your outcome and predictor variables.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod &lt;- lm(eval ~ age_z + beauty_z, data = beauty_z)\n\n\n\n\nTASK: Call and save the summary of your model; then have a look at it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the summary() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_int_summary &lt;- summary(mod_int)\nmod_int_summary\n\n\n\nQUESTION 5: Is the overall model significant?\nQUESTION 6: Are the predictors significant? What does this mean?\n\nTASK: Now create a model that includes an interaction term for the two predictors. Again, use the centered and standardised data.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the following formula, lm(y ~ x1 + x2 + x1:x2, data); go back to the research question for your outcome and predictor variables.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_int &lt;- lm(eval ~ age_z + beauty_z + age_z:beauty_z, data = beauty_z)\nmod_int_summary &lt;- summary(mod_int)\nmod_int_summary\n\n\n\nQUESTION 7: Is the overall model significant?\nQUESTION 8: Have a good look at the coefficients. Can you interpret each one of them in turn and then formulate an overall interpretation?\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that after centering and standardising, the meaning of 0 has changed for both predictor variables.\n\n\n\nInterpretation of coefficients in a multiple regression can be facilitated by ‘added variable’ plots.\n\nTASK: Use the function avPlots() to create ‘added variable’ plots.\n\nCreating a scatterplot with our outcome variable on the y-axis and the significant predictor on the x-axis and then plotting our third variable (age) using different colours gives some information. Do you see how high age scores (light blue + 2 SD) seem to be more frequent in the bottom left corner?\n\nTASK: Use the code below to create the plot.\n\n\nggplot(data = beauty_z, aes(x = beauty_z, y = eval, colour = age_z)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE, colour = 'black') +\n  theme_bw() +\n  labs(x = \"Beauty score\", y = \"Teaching evaluation score\")\n\nBut it might be more useful to plot different regression lines for different values of age. We can do this be transforming age into a categorical variable for plotting purposes. We want to create three categories, based on eye-balling the histogram for age:\n\nyoungest (40 and younger)\naverage (between 41 and 53)\noldest (54 and older).\n\nWe can do this by using the mutate() function, in combination with the cut() function. There is a ‘recipe’ for this on the Posit website:\n\ncut() - group continuous variable into categories - recipe\n\n\nTASK: Read through the recipe mentioned above. Working through the example will be particularly helpful. Write the code to create the categories mentioned above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFill in the relevant bits in the code template below:\n  mutate(NEW VARIABLE = cut(\n    CONTINUOUS VARIABLE,\n    breaks = c(DEFINE BREAK POINTS),\n    labels = c(ADD LABELS FOR BREAK POINTS)\n    )\n  )\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nbeauty_z_ageCat &lt;- beauty_z %&gt;%\n  mutate(ageCat = cut(\n    age,\n    breaks = c(0, 40, 54, Inf),\n    labels = c(\"youngest\",\"average\",\"oldest\")\n    )\n  )\n\n\n\nNow let’s create a single plot with three different lines, one for each of the age groups created above.\n\nTASK: Copy the code below to your script and make sure you understand what it does.\n\n\nggplot(data = beauty_z_ageCat, aes(x = beauty_z, y = eval, colour = ageCat)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  labs(x = \"Beauty score\", y = \"Teaching evaluation score\")\n\nThe line for the oldest participants seems much steeper than for the other two groups, suggesting that the interaction between age and beauty is mostly driven by older participants who have received more extreme beauty scores.\n\n\nStep 6: Checking assumptions\nNow that we’ve fitted a model, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity.\nLinearity Unlike when we did simple regression we can’t use crPlots() to test for linearity when there is an interaction, but we know from looking at the grouped scatterplot that this assumption has been met.\nNormality Normally we would test for normality with a qq-plot and a Shapiro-Wilk test. However, because this dataset is so large, the Shapiro-Wilk is not appropriate (if you try to run the test it will produce a warning telling you that the sample size must be between 3 and 5000). This is because with extremely large sample sizes the Shapiro-Wilk test will find that any deviation from normality is significant. Therefore we should judge normality based upon the qq-plot.\n\nTASK: Create a qq-plot to check the residuals are normally distributed.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the qqPlot() function; mind the capital P.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nqqPlot(mod_int$residuals)\n\n\n\nQUESTION 9: What do you conclude from the qq-plot?\nHomoscedasticity Here we have the same problem as with testing for normality: with such a large sample the ncvTest() will produce a significant result for any deviation from homoscedasticity. So we need to rely on plots again.\nTo check for homoscedasticity we can use plot() from Base R that will produce a bunch of helpful plots (more information [here] (https://www.r-bloggers.com/2016/01/how-to-detect-heteroscedasticity-and-rectify-it/).\n\nTASK: Copy the code below to your script and run it to create the plots\n\n\npar(mfrow=c(2,2))                 # 4 charts in 1 panel\nplot(mod_int)                     # this may take a few seconds to run\n\nQUESTION 10: What do you conclude from the residuals vs leverage plot?\nMulti-collinearity Now let’s check for multi-collinearity using the vif() function. Essentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. Thankfully, the vif() function is not affected by large samples like the other tests. There are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.\n\nTASK: Use the vif() function to test for multi-collinearity.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nvif(mod_int)   \n\n\n\nQUESTION 11: Do any of the predictors show evidence of multi-collinearity?\nFinally, we need to write up the results.\nQUESTION 12: Can you write up the results of the regression analysis following APA guidelines?\n\n\n\n\n\n\nHint\n\n\n\n\n\nDon’t forget to mention and interpret the interaction effect."
  },
  {
    "objectID": "PSYC412/part1/Week13.html#sec-wk13-answers",
    "href": "PSYC412/part1/Week13.html#sec-wk13-answers",
    "title": "3. More on interactions",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk13_labAct1_withAnswers.R.\n\nDo you notice anything about the name of one of the variables and the name of the data table? Both the data table and one of the variables are called ‘beauty’. Not a problem, as such as long as you don’t get confused.\nGo back to the research question (see under ‘Background’ above), which of these three variables is the outcome variable? Which ones are the predictors? The research question is ‘Do professors’ beauty score and age predict how students evaluate their teaching?’ From this we can deduct that the outcome variable is teaching evaluation score and that the predictors are age and beauty score.\nCan you write an interpretation of the above plots in plain English? A moderate negative association seems present between beauty score and age: with increasing age, beauty score decreases. A moderate positive association seems present between beauty score and teaching evaluation: professors with higher beauty scores also receive higher teaching evaluations. Not much of a association seems present between age and teaching evaluation (the line is pretty horizontal).\nWhat is the difference between the scatterplots plotting the raw data and the ones plotting the centered and standardised data? The units of the x-axis have changed from years (for age) and scores (for beauty) to standard units, with zero in the middle.\nIs the overall model significant? Yes, F(2, 460) = 8.53, p = .0002\nAre the predictors significant? What does this mean? The beauty score significantly predicts teaching evaluation score, but age does not. Professors with higher beauty scores, received better teaching evaluations.\nIs the overall model significant? Yes, F(3, 459) = 9.32, p = 5.451e-06\nHave a good look at the coefficients. Can you interpret each one of them in turn and then formulate an overall interpretation? HINT: Remember that after centering and standardising, the meaning of 0 has changed for both predictor variables. The intercept is predicted teaching evaluation score for a professor with average age and average beauty score. The slope of ‘age’ is positive; this means that for higher age, teaching evaluation scores were better. However the coefficient is not significant, therefore has little predictive power.The slope of ‘beauty’ is positive; this means that with higher beauty score, professors receive higher teaching evaluations. This predictor is significant. The slope for the interaction is also positive. This can be read as follows: When age and beauty both increase, teaching evaluation score also increases. The interaction is significant.\nWhat do you conclude from the qq-plot? The residuals are mostly normally distributed. At the top right (quantile + 3), there are some values that don’t quite look normally distributed, this is probably due to fewer data points being available in the highest age bracket. Have a look at a histogram for age. There are a few individuals well above the retirement age, but clearly a lot fewer than in younger age brackets. This basically means that the model does not do a particularly good job for predicting evaluation score at high values of age. As retirement age is quite a natural point to limit the data, you could run the model again, only including people below retirement age, this should give you better behaving residuals. Ideally, you’d pre-register a decision such as this. If you didn’t do this prior to data collection, you could still limit the age range included in the final model, but you would need to be transparent in your reporting.\nWhat do you conclude from the residuals vs leverage plot? The residuals vs leverage plot shows a flat red line so, whilst it isn’t perfect, we can assume that with regression is still an appropriate analysis.\nDo any of the predictors show evidence of multi-collinearity? No\nCan you write up the results of the regression analysis following APA guidelines? The results of the regression indicated that the model significantly predicted teaching evaluation scores (F(3, 459) = 9.316, p &lt; .001, adjusted R^2 = 0.05), accounting for 5% of the variance. A professor’s beauty score was a significant positive predictor of teaching evaluation score (\\(\\beta\\) = 0.12, p &lt; .001). This effect was moderated by a significant positive interaction between beauty score and age (\\(\\beta\\) = 0.08, p &lt; .001), suggesting that when age and beauty score both increased, teaching evaluation score also increased."
  },
  {
    "objectID": "PSYC412/index.html",
    "href": "PSYC412/index.html",
    "title": "Analysing and Interpreting Psychological Data II",
    "section": "",
    "text": "Welcome\nWelcome to PSYC402!\nThis module builds on the knowledge and skills acquired in Statistics for Psychologists 1 (PSYC401). You will continue to practise data handling, data processing and data visualisation, using R and R Studio. In addition, you will extend your knowledge of the general linear model and learn how to adapt it when working with different types of data. Of course you’ll also learn how to implement those methods in R and R Studio.\nThis page gives you access to all the materials that you will need. You will have timetabled lab classes during which you are expected to work through a series of exercises to practise that week’s material. Before you come to your lab session, you should watch the lectures for that week, read the relevant book chapter and complete the pre-lab activities.\n\n\nAsking for help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 11, Week 12, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our teaching staff is there to help you. There are no “stupid questions” in statistics, so just ask the GTA or the lecturer any question about what you’re doing.\nAsk on the Discussion Forum. On the PSYC402 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nMargriet Groen\nm.groen at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies1 at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html",
    "href": "PSYC412/part2/05-ordinal.html",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "Ordinal data are very common in psychological science. Often, we will encounter ordinal data recorded as responses to Likert-style items in which the participant is asked to indicate a response on an ordered scale ranging between two end points (Bürkner and Vuorre 2019; Liddell and Kruschke 2018). An example of a Likert question item might be: How well do you think you have understood this text? (Please check one response) where the participant must respond by checking an option, given 5 options ranging from 1 (not well at all) to 5 (very well). The critical characteristics of such responses are that:\n\nThe responses are ordered, as indicated by the number labels;\nResponse types are categorical or qualitative, not numeric.\n\nWe will be working with study data in which the outcome that is the target for our analyses comprise responses to questions designed to elicit ratings. Ordinal data may, however, also derive from situations in which ordered categorical responses do not derive from ratings items (we will look briefly at sequential responses, Bürkner and Vuorre 2019).\nThe challenge we face is that we will aim to develop skills in using ordinal models when, in contrast, most psychological research articles will report analyses of ordinal data using conventional methods like ANOVA or linear regression. We will work to understand why ordinal models are better. We will learn that applying conventional methods to ordinal data will, in principle, involve a poor account of the data and, in practice, will create the risk of producing misleading results. And we will learn how to work with and interpret the results from ordinal models with or without random effects.\nIn our work in this chapter, we will rely extensively on the ideas set out by Liddell and Kruschke (2018), see Section 1.13.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOrdinal responses are labelled with numbers but ordinal data are not numeric.\n\n\nOrdinal responses are coded with numeric labels. These number labels may indicate order but we do not know that the difference between e.g. response options 1 versus 2 is the same as the difference between 2 versus 3 or 3 versus 4. Ordinal data contrast with metric data (Liddell and Kruschke 2018) which are recorded on scales for which we assume both order and equal intervals. When researchers apply metric models to ordinal data, they incorrectly assume that the response options e.g. in ratings are separated by equal intervals. Yet, in a review of the 68 recently articles that mentioned the term “Likert” in a sample of highly ranked Psychology journals, Liddell and Kruschke (2018) found that ordinal data were treated as metric and the articles presented results from metric models.\nOne way to think about ordinal data is that often (but not always) ratings may be understood to come from psychological processes in which the participant, in response to the Likert question, divides some latent (unobserved) psychological continuum or scale into categories in order to select a response option.\nImagine, for example, that you have been asked the question “How well do you understand this text? (on a scale from 1-5)”. Presumably, to answer this question, you will have to choose a response based on where you think you are on your unobserved measure of your understanding. You may be able to evaluate the cohesion, or some other internal measure, of your understanding of the text. Simplifying a bit, we might assume that your internal measure of understanding is associated with a normal probability distribution so that it peaks over some value (e.g., 3) of the strength of understanding though other values are possible. As Figure 1 suggests, a participant in this common situation will have to map the internal measure (the latent scale, e.g., of understanding) to a number from the response options you are given (e.g., rating scale values ranging 1-5). But there is no reason to suppose that your internal measure of your understanding is divided into an ordered metric scale.\n\n\n\n\n\n\n\n\nFigure 1: A latent scale on the horizontal axis is divided into intervals or bins divided by thresholds marked by dotted lines. The cumulative normal probability in the intervals is the probability of the ordinal values.\n\n\n\n\n\nIn conducting analyses of ordinal data with ordinal models, we often fit models that describe the cumulative probability that a rating response is located at some value (typically, understood in terms of threshold) on an underlying latent continuum. In ordinal models, we do not assume that the ordinal responses map to equally spaced intervals on the latent scale: the values or thresholds at which the continuum are split are to be estimated.\nIn applying metric models to ordinal data, we do assume that intervals are equal though this assumption is unlikely to be true or, at least, is unlikely to be verifiable. This faulty assumption has consequences because the mis-application of metric models (e.g. ANOVA, linear models) to ordinal data is both commonplace and risky. As Liddell and Kruschke (2018) demonstrate, mis-applying metric models to ordinal data can result in false positives (detecting a difference when none is present), false negatives (missing a difference that is present) and inversions (swapping the difference so that it appears to be positive instead of negative or vice versa). These kinds of misrepresentions cannot be avoided and are not fixed by, for example, averaging ratings scales data together.\n\n\n\n\nUnderstand practically the reasons for using ordinal models when we analyze ordinal outcome variables, ?@sec-ordinal-practical-understanding.\nPractice running ordinal models with varying random effects structures.\nPractice reporting the results of ordinal models, including through the use of prediction plots.\n\n\n\n\nI have provided a collection of materials you can use. Here, I explain what they are and how I suggest you use them.\n1. Chapter: 05-ordinal\n1.1. I have written this chapter to discuss the main ideas and set out the practical steps you can follow to start to develop the skills required to work with ordered categorical outcomes i.e. ordinal data using ordinal models.\n1.2. The practical elements include data tidying, visualization and analysis steps.\n1.3. You can read the chapter and run the code to gain experience and encounter code you can adapt for your own purposes.\n\nRead in the example dataset.\nExperiment with the .R code used to work with the example data.\nRun ordinal models of demonstration data.\nRun ordinal models of alternate data sets (see links in Section 1.9).\nReview the recommended readings (Section 1.13).\n\n2. Practical materials\n2.1 In the following sections, I describe the practical steps, and associated resources, you can use for your learning. I set out the data tidying, analysis and visualization steps you can follow, working with the example dataset, described next.\n\n\n\nWe will be working, at first, with a sample of data collected as part of the Clearly understood: health comprehension project (Davies, Ratajczak, Gillings, Chadwick & Gold). These data are unpublished.\n\n\n\n\nOur interest, in conducting the project, lies in identifying what factors make it easy or difficult to understand written health information. In part, we are concerned about the processes that health providers or clinicians apply to assure the effectiveness of the text they produce to guide patients or carers, for example, in taking medication, in making treatment decisions, or in order to follow therapeutic programmes.\nIt is common, in the quality assurance process in the production of health information texts, that text producers ask participants in patient review panels to evaluate draft texts. In such reviews, a participant may be asked a question like “How well do you understand this text?” This kind of question presents a metacognitive task: we are asking a participant to think about their thinking. But it is unclear that people can do this well or, indeed, what factors determine the responses to such questions (Dunlosky and Lipko 2007).\nFor these reasons, we conducted studies in which we presented adult participants with sampled health information texts (taken from health service webpages) and, critically, asked them to respond to the question:\n\nHow well do you think you have understood this text? (Please check one response)\n\nFor each text, in response to this question, participants were asked to click on one option from an array of response options ranging from (1) Not well at all to (9) Extremely well. The data we collected in this element of our studies comprise, clearly, ordinal responses. Thus, we may use these data to address the following research question.\n\n\n\n\n\n\nNote\n\n\n\n\nWhat factors predict self-evaluated rated understanding of health information.\n\n\n\n\n\n\nWe will work with a sample of participant data drawn from a series of Lancaster University undergraduate dissertation studies connected to the Clearly understood project. In these studies, we collected data from 202 participants on a series of measures (Section 1.5.1.3) of vocabulary knowledge, health literacy, reading strategy, as well as responses to health information texts. The distributions of participants’ scores on each of a range of attribute variables\n\n\n\n\n\n\n\n\nFigure 2: Grid of plots showing the distribution of participant attributes. The grid includes histograms of the distributions of: self-rated accuracy; vocabulary (SHIPLEY); health literacy (HLVA); reading strategy (FACTOR3); and age (years). We also see dot plots presenting counts of numbers of participants of different self-reported gender, education, and ethnicity categories.\n\n\n\n\n\nThe plots indicate:\n\nmost self-rated accuracy scores are high (over 6);\nmany participants with vocabulary scores greater than 30, a few present lower scores;\nhealth literacy scores centered on 8 or some, with lower and higher scores;\na skewed distribution of reading strategy scores, with many around 20-40, and a tail of higher scores;\nmost participants are 20-40 years of age, some older;\nmany more female than male participants, very few non-binary reported;\nmany more participants with higher education than further, very few with secondary;\nand many White participants (Office of National Statistics categories), far fewer Asian or Mixed or Black ethnicity participants.\n\n\n\n\nWe collected data through an online survey administered through Qualtrics.\nWe used the Shipley vocabulary sub-test (Shipley et al. 2009) to estimate vocabulary knowledge.\nWe used the Health Literacy Vocabulary Assessment (HLVA, Ratajczak, 2020; adapted for online presentation, Chadwick, 2020) to estimate health literacy.\nWe used an instrument drawn from unpublished work by Calloway (2019) to assess the approach participants took to reading and understanding written information.\nWe presented participants with a sample of 20 health information texts. In the data collection process for this dataset, participants were recruited in multiple different studies. In each study, any one participant was presented with a randomly selected subset of the total of 20 texts.\nWe asked participants to rate their level of understanding of the health-related texts that we presented in the study. We used a nine-point judgment scales because they have been found to outperform alternative scales with fewer categories in terms of criterion validity, internal consistency, test-retest reliability, and discriminating power (Preston and Colman 2000).\nWe recorded participants’ demographic characteristics: gender (coded: Male, Female, non-binary, prefer not to say); education (coded: Secondary, Further, Higher); and ethnicity (coded: White, Black, Asian, Mixed, Other).\n\n\n\n\nYou can download the 2021-22_PSYC304-health-comprehension.csv file holding the data we analyse in this chapter by clicking on the link.\n\n\n\nI am going to assume you have downloaded the data file, and that you know where it is. We use read_csv to read the data file into R.\n\nhealth &lt;- read_csv(\"2021-22_PSYC304-health-comprehension.csv\", \n                                 na = \"-999\",\n                                 col_types = cols(\n                                   ResponseId = col_factor(),\n                                   rating = col_factor(),\n                                   GENDER = col_factor(),\n                                   EDUCATION = col_factor(),\n                                   ETHNICITY = col_factor(),\n                                   NATIVE.LANGUAGE = col_factor(),\n                                   OTHER.LANGUAGE = col_factor(),\n                                   text.id = col_factor(),\n                                   text.question.id = col_factor(),\n                                   study = col_factor()\n                                 )\n                               )\n\nNotice that we use col_types = cols(...) to require read_csv() to class some columns as factors.\nImportantly, we ask R to treat the rating variable as a factor with rating = col_factor().\n\n\n\n\n\n\nTip\n\n\n\nIn the practical work we do, we will be using functions from the {ordinal} library to model ordinal data.\n\nIn using these functions, we need ask R to treat the ordinal outcome variable as a factor.\n\n\n\n\n\n\nIt is always a good to inspect what you have got when you read a data file in to R. Here, what may most concern us is the distribution of observed responses on the rating scale (responses to the “How well do you understand?” question). Figure 3 is a dot plot showing the distribution of ratings responses. The Likert-style questions in the surveys asked participants to rate their level of understanding of the texts they saw on a scale from 1 (not well) to 9 (extremely well). The plot shows the number of responses recorded for each response option, over all participants and all texts.\n\nhealth &lt;- health %&gt;% mutate(rating = fct_relevel(rating, sort))\n\nhealth %&gt;%\n  group_by(rating) %&gt;%\n  summarise(count = n()) %&gt;%\n  ggplot(aes(x = rating, y = count, colour = rating)) + \n  geom_point(size = 3) +\n  scale_color_viridis(discrete=TRUE, option = \"mako\") + theme_bw() +\n  theme(\n    panel.grid.major.y = element_blank()  # No horizontal grid lines\n  ) +\n  coord_flip()\n\n\n\n\n\n\n\nFigure 3: Dot plot showing the distribution of ratings responses. The Likert-style questions in the surveys asked participants to rate their level of understanding of the texts they saw on a scale from 1 (not well) to 9 (extremely well). The plot shows the number of responses recorded for each response option, over all participants and all texts.\n\n\n\n\n\nThe plot indicates that most participants chose response options 5-9, while very few rated their understanding at the lowest levels (options 1-4). Interestingly, many ratings responses around 7-8 were recorded: many more than responses at 5-6.\nIn analyzing these data, we will seek to estimate what information available to us can be used to predict whether a participant’s rating of their understanding is more likely to be, say, 1 or 2, 2 or 3 … 7 or 8, 8 or 9.\n\nOne practical way to think about the estimation problem when working with ratings-style ordinal data is this:\n\nWhat factors move or how do influential factors move the probability that the ordinal response is a relatively low or relatively high order response option?\nIn doing this, we do not have to assume that rating scale points map to equal sized intervals on the underlying latent scale where the scale may be an unobserved psychological continuum (like understanding).\n\n\nHere, we mostly have information on participant attributes and some information on text properties to do our prediction analyses. In other studies, we may be using information about experimental conditions, or selected groups of participants to estimate effects on variation in ratings responses.\n\n\n\n\nThe Clearly understood health comprehension project dataset is tidy (?@sec-intro-mixed-data-tidy):\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.\n\nHowever, there are aspects of the data structure or properties of the dataset variables that will cause inefficiencies or problems in later data analysis if we do not fix them first.\nYou can see what we have if you look at the results we get from using summary() and str() to inspect the dataset.\n\nsummary(health)\n\n             ResponseId        AGE                     GENDER    \n R_sKW4OJnOlidPxrH:  20   Min.   :18.0   Female           :2900  \n R_27paPJzIutLoqk8:  20   1st Qu.:20.0   Male             :1120  \n R_1nW0lpFdfumlI1p:  20   Median :27.0   Prefer-not-to-say:  20  \n R_31ZqPQpNEEapoW8:  20   Mean   :34.3                           \n R_2whvE2IW90nj2P7:  20   3rd Qu.:50.0                           \n R_3CAxrri9clBT7sl:  20   Max.   :81.0                           \n (Other)          :3920                                          \n     EDUCATION    ETHNICITY    NATIVE.LANGUAGE    OTHER.LANGUAGE\n Further  :1780   Asian: 680   English:2720    NA        :2720  \n Higher   :1800   White:3260   Other  :1320    Polish    : 580  \n Secondary: 460   Other:  40                   Cantonese : 280  \n                  Mixed:  60                   Chinese   : 120  \n                                               Portuguese:  60  \n                                               polish    :  60  \n                                               (Other)   : 220  \n ENGLISH.PROFICIENCY    SHIPLEY           HLVA           FACTOR3     \n Length:4040         Min.   :15.00   Min.   : 3.000   Min.   :17.00  \n Class :character    1st Qu.:30.00   1st Qu.: 7.000   1st Qu.:45.00  \n Mode  :character    Median :34.00   Median : 9.000   Median :49.00  \n                     Mean   :32.97   Mean   : 8.564   Mean   :49.03  \n                     3rd Qu.:37.00   3rd Qu.:10.000   3rd Qu.:55.00  \n                     Max.   :40.00   Max.   :13.000   Max.   :63.00  \n                                                                     \n     rating        response          RDFKGL       study    \n 8      :1044   Min.   :0.0000   Min.   : 4.552   cs: 480  \n 7      : 916   1st Qu.:1.0000   1st Qu.: 6.358   jg:1120  \n 9      : 824   Median :1.0000   Median : 8.116   ml: 720  \n 6      : 500   Mean   :0.8064   Mean   : 7.930   rw:1720  \n 5      : 352   3rd Qu.:1.0000   3rd Qu.: 9.413            \n 4      : 176   Max.   :1.0000   Max.   :13.278            \n (Other): 228                                              \n             text.id                  text.question.id\n studyone.TEXT.37: 344   studyone.TEXT.37.CQ.1:  86   \n studyone.TEXT.39: 344   studyone.TEXT.37.CQ.2:  86   \n studyone.TEXT.72: 344   studyone.TEXT.37.CQ.3:  86   \n studyone.TEXT.14: 344   studyone.TEXT.37.CQ.4:  86   \n studyone.TEXT.50: 344   studyone.TEXT.39.CQ.1:  86   \n studyone.TEXT.10: 224   studyone.TEXT.39.CQ.2:  86   \n (Other)         :2096   (Other)              :3524   \n\n\nYou should be used to seeing the summary() of a dataset, showing summary statistics of numeric variables and counts of the numbers of observations of data coded at different levels for each categorical or nominal variable classed as a factor.\nUsing the str() function may be new to you and, as you can see, the output from the function call gives you a bit more information on how R interprets the data in the variable columns. You can see that each variable is listed alongside information about how the data in the column are interpreted (as Factor or num numeric). Where we have columns holding information on factors there we see information about the levels.\nRecall that for a categorical or nominal variable e.g. ETHNICITY, provided R interprets the variable as a factor, each data value in the column is coded as corresponding to one level i.e. group or class or category (e.g., we have ETHNICITY classes \"Asian\" etc.) Recall, also, that at the data read-in stage, we instructed R how we wanted it to interpret each column using col_types = cols().\n\nstr(health)\n\ntibble [4,040 × 17] (S3: tbl_df/tbl/data.frame)\n $ ResponseId         : Factor w/ 202 levels \"R_sKW4OJnOlidPxrH\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ AGE                : num [1:4040] 20 20 20 20 20 20 20 20 20 20 ...\n $ GENDER             : Factor w/ 3 levels \"Female\",\"Male\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ EDUCATION          : Factor w/ 3 levels \"Further\",\"Higher\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ ETHNICITY          : Factor w/ 4 levels \"Asian\",\"White\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ NATIVE.LANGUAGE    : Factor w/ 2 levels \"English\",\"Other\": 1 1 1 1 1 1 1 1 1 1 ...\n $ OTHER.LANGUAGE     : Factor w/ 17 levels \"NA\",\"Catonese\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ ENGLISH.PROFICIENCY: chr [1:4040] \"NA\" \"NA\" \"NA\" \"NA\" ...\n $ SHIPLEY            : num [1:4040] 26 26 26 26 26 26 26 26 26 26 ...\n $ HLVA               : num [1:4040] 8 8 8 8 8 8 8 8 8 8 ...\n $ FACTOR3            : num [1:4040] 59 59 59 59 59 59 59 59 59 59 ...\n $ rating             : Factor w/ 9 levels \"1\",\"2\",\"3\",\"4\",..: 8 8 8 8 7 7 7 7 7 7 ...\n $ response           : num [1:4040] 1 1 1 1 1 1 1 0 1 1 ...\n $ RDFKGL             : num [1:4040] 10.61 10.61 10.61 10.61 8.12 ...\n $ study              : Factor w/ 4 levels \"cs\",\"jg\",\"ml\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ text.id            : Factor w/ 20 levels \"studyone.TEXT.105\",..: 1 1 1 1 2 2 2 2 3 3 ...\n $ text.question.id   : Factor w/ 80 levels \"studyone.TEXT.105.CQ.1\",..: 1 2 3 4 5 6 7 8 9 10 ...\n\n\nOur specific concern, here, is that the rating response variable is treated as a factor because the {ordinal} library we are going to use to do the modeling must find the outcome variable is a factor.\nWe can focus str() on the rating variable. We see that it is being treated as a factor.\n\nstr(health$rating)\n\n Factor w/ 9 levels \"1\",\"2\",\"3\",\"4\",..: 8 8 8 8 7 7 7 7 7 7 ...\n\n\nHowever, we also need to make sure that the rating outcome variable is being treated as an ordered factor.\nWe can perform a check as follows. (I found how to do this here)\n\nis.ordered(factor(health$rating))\n\n[1] FALSE\n\n\nWe can see that the variable is not being treated as an ordered factor. We need to fix that.\nThe ordinal model estimates the locations (thresholds) for where to split the latent scale (the continuum underlying the ratings) corresponding to different ratings values. If we do not make sure that the outcome factor variable is split as it should be then there is no guarantee that {ordinal} functions will estimate the thresholds in the right order (i.e., 1,2,3 ... rather than 3,2,1...).\nWe can make sure that the confidence rating factor is ordered precisely as we wish using the ordered() function.\n\nhealth$rating &lt;- ordered(health$rating,\n                         levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"))\n\nWe can then do a check to see that we have got what we want. We do not wantrating to be treated as numeric, we do want it to be treated as an ordered factor.\n\nis.numeric(health$rating)\n\n[1] FALSE\n\nis.factor(health$rating)\n\n[1] TRUE\n\nstr(health$rating)\n\n Ord.factor w/ 9 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 8 8 8 8 7 7 7 7 7 7 ...\n\nis.ordered(health$rating)\n\n[1] TRUE\n\n\nIt is.\nNext, before doing any modelling, it will be sensible to standardize potential predictors\n\nhealth &lt;- health %&gt;% \n  mutate(across(c(AGE, SHIPLEY, HLVA, FACTOR3, RDFKGL), \n                scale, center = TRUE, scale = TRUE,\n                .names = \"z_{.col}\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(...)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nYou can see that in this chunk of code, we are doing a number of things:\n\nhealth &lt;- health %&gt;% recreates the health dataset from the following steps.\nmutate(...) do an operation which retains the existing variables in the dataset, to change the variables as further detailed.\nacross(...) work with the multple column variables that are named in the c(AGE, SHIPLEY, HLVA, FACTOR3, RDFKGL) set.\n...scale, center = TRUE, scale = TRUE... here is where we do the standardization work.\n\nWhat we are asking for is that R takes the variables we name and standardizes each of them.\n\n.names = \"z_{.col}\") creates the standardized variables under adapted names, adding z_ to the original column name so that we can distinguish between the standardized and original raw versions of the data columns.\n\nNote that the across() function is a useful function for applying a function across multiple column variables see information here There is a helpful discussion on how we can do this task here\nWe can then check that we have produced the standardized variables as required.\n\nsummary(health)\n\n             ResponseId        AGE                     GENDER    \n R_sKW4OJnOlidPxrH:  20   Min.   :18.0   Female           :2900  \n R_27paPJzIutLoqk8:  20   1st Qu.:20.0   Male             :1120  \n R_1nW0lpFdfumlI1p:  20   Median :27.0   Prefer-not-to-say:  20  \n R_31ZqPQpNEEapoW8:  20   Mean   :34.3                           \n R_2whvE2IW90nj2P7:  20   3rd Qu.:50.0                           \n R_3CAxrri9clBT7sl:  20   Max.   :81.0                           \n (Other)          :3920                                          \n     EDUCATION    ETHNICITY    NATIVE.LANGUAGE    OTHER.LANGUAGE\n Further  :1780   Asian: 680   English:2720    NA        :2720  \n Higher   :1800   White:3260   Other  :1320    Polish    : 580  \n Secondary: 460   Other:  40                   Cantonese : 280  \n                  Mixed:  60                   Chinese   : 120  \n                                               Portuguese:  60  \n                                               polish    :  60  \n                                               (Other)   : 220  \n ENGLISH.PROFICIENCY    SHIPLEY           HLVA           FACTOR3     \n Length:4040         Min.   :15.00   Min.   : 3.000   Min.   :17.00  \n Class :character    1st Qu.:30.00   1st Qu.: 7.000   1st Qu.:45.00  \n Mode  :character    Median :34.00   Median : 9.000   Median :49.00  \n                     Mean   :32.97   Mean   : 8.564   Mean   :49.03  \n                     3rd Qu.:37.00   3rd Qu.:10.000   3rd Qu.:55.00  \n                     Max.   :40.00   Max.   :13.000   Max.   :63.00  \n                                                                     \n     rating        response          RDFKGL       study    \n 8      :1044   Min.   :0.0000   Min.   : 4.552   cs: 480  \n 7      : 916   1st Qu.:1.0000   1st Qu.: 6.358   jg:1120  \n 9      : 824   Median :1.0000   Median : 8.116   ml: 720  \n 6      : 500   Mean   :0.8064   Mean   : 7.930   rw:1720  \n 5      : 352   3rd Qu.:1.0000   3rd Qu.: 9.413            \n 4      : 176   Max.   :1.0000   Max.   :13.278            \n (Other): 228                                              \n             text.id                  text.question.id       z_AGE.V1      \n studyone.TEXT.37: 344   studyone.TEXT.37.CQ.1:  86    Min.   :-0.9826247  \n studyone.TEXT.39: 344   studyone.TEXT.37.CQ.2:  86    1st Qu.:-0.8620352  \n studyone.TEXT.72: 344   studyone.TEXT.37.CQ.3:  86    Median :-0.4399723  \n studyone.TEXT.14: 344   studyone.TEXT.37.CQ.4:  86    Mean   : 0.0000000  \n studyone.TEXT.50: 344   studyone.TEXT.39.CQ.1:  86    3rd Qu.: 0.9468060  \n studyone.TEXT.10: 224   studyone.TEXT.39.CQ.2:  86    Max.   : 2.8159420  \n (Other)         :2096   (Other)              :3524                        \n    z_SHIPLEY.V1          z_HLVA.V1          z_FACTOR3.V1    \n Min.   :-3.294105   Min.   :-2.6074887   Min.   :-4.205936  \n 1st Qu.:-0.543723   1st Qu.:-0.7330662   1st Qu.:-0.529155  \n Median : 0.189713   Median : 0.2041450   Median :-0.003900  \n Mean   : 0.000000   Mean   : 0.0000000   Mean   : 0.000000  \n 3rd Qu.: 0.739789   3rd Qu.: 0.6727506   3rd Qu.: 0.783981  \n Max.   : 1.289866   Max.   : 2.0785675   Max.   : 1.834490  \n                                                             \n     z_RDFKGL.V1     \n Min.   :-1.4644660  \n 1st Qu.:-0.6814594  \n Median : 0.0807363  \n Mean   : 0.0000000  \n 3rd Qu.: 0.6430616  \n Max.   : 2.3187650  \n                     \n\n\n\n\n\nIn our first analysis, we can begin by assuming no random effects. We keep things simple at this point so that we can focus on the key changes in model coding.\nThe model is conducted to examine what shapes the variation in rating responses that we see in Figure 3.\n\n\n\n\n\n\nNote\n\n\n\n\nWhat factors predict self-evaluated rated understanding of health information.\n\n\n\nIn our analysis, the outcome variable is the ordinal response variable rating. The predictors consist of the variables we standardized earlier. We use the clm() function from the {ordinal} library to do the analysis. I will give information in outline here, the interested reader can see more detailed information in Rune Haubo Bojesen Christensen (2022) and R. H. B. Christensen (2015). You can also find the manual for the {ordinal} library functions here\nWe code the model as follows.\n\nhealth.clm &lt;- clm(rating ~\n                    \n                    z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL,\n                  \n                  Hess = TRUE, link = \"logit\",\n                  data = health)\n\nsummary(health.clm)\n\nThe code works as follows.\nFirst, we have a chunk of code mostly similar to what we have done before, but changing the function.\n\nclm() the function name changes because now we want a cumulative link model of the ordinal responses.\n\nThe model specification includes information about the fixed effects, the predictors: z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL.\nSecond, we have the bit that is specific to cumulative link models fitted using the clm() function.\n\nHess = TRUE is required if we want to get a summary of the model fit; the default is TRUE but it is worth being explicit about it.\nlink = \"logit\" specifies that we want to model the ordinal responses in terms of the log odds (hence, the probability) that a response is a low or a high rating value (compare ?@sec-glmm-practical-understanding).\n\n\n\nIf you run the model code, it may take a few seconds to run. Then you will get the results shown in the output.\n\n\nformula: rating ~ z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL\ndata:    health\n\n link  threshold nobs logLik   AIC      niter max.grad cond.H \n logit flexible  4040 -6880.78 13787.55 5(0)  9.26e-07 7.3e+01\n\nCoefficients:\n          Estimate Std. Error z value Pr(&gt;|z|)    \nz_AGE     -0.17719    0.02966  -5.975 2.30e-09 ***\nz_SHIPLEY  0.34384    0.03393  10.135  &lt; 2e-16 ***\nz_HLVA     0.16174    0.03265   4.954 7.28e-07 ***\nz_FACTOR3  0.74535    0.03145  23.699  &lt; 2e-16 ***\nz_RDFKGL  -0.27220    0.02892  -9.412  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -4.65066    0.12978 -35.836\n2|3 -4.13902    0.10395 -39.817\n3|4 -3.26845    0.07390 -44.228\n4|5 -2.56826    0.05804 -44.248\n5|6 -1.69333    0.04437 -38.160\n6|7 -0.87651    0.03671 -23.876\n7|8  0.24214    0.03402   7.117\n8|9  1.63049    0.04252  38.346\n\n\nThe summary() output for the model is similar to the outputs you have seen for other model types.\n\nWe first get formula: information about the model you have specified.\nR will tell us what data: we are working with.\nWe then get Coefficients: estimates.\n\nThe table summary of coefficients arranges information in ways that will be familiar you:\n\nFor each predictor variable, we see ’Estimate, Std. Error, z value, and Pr(&gt;|z|)` statistics.\nThe Pr(&gt;|z|) p-values are based on Wald tests of the null hypothesis that a predictor has null impact.\nThe coefficient estimates can be interpreted based on whether they are positive or negative.\n\nA positive coefficient estimate indicates that higher values of the predictor variable are associated with greater probability of higher rating values. A negative coefficient estimate indicates that higher values of the predictor variable are associated with greater probability of lower rating values.\n\nWe then get Threshold coefficients: indicating where the model fitted estimates the threshold locations: where the latent scale is cut, corresponding to different rating values.\n\n\n\n\n\n\n\nTip\n\n\n\nIn reporting ordinal (e.g., cumulative link) models, we typically focus on the coefficient estimates for the predictor variables.\n\n\n\n\n\n\nIn our analysis, we begn by assuming no random effects. However, this is unlikely to be appropriate given the data collection process deployed in the Clearly understood projects, where:\n\na sample of participants were asked to respond to a sample of texts;\nwe have multiple observations of responses for each participant;\nwe have multiple observations of responses for each stimulus text;\nparticipants were assigned to groups, and within a group all participants were asked to respond to the same stimulus texts.\n\nThese features ensure that the data have a multilevel structure and this structure requires us to fit a Cumulative Link Mixed-effects Model (CLMM).\nWe keep things simple at this point so that we can focus on the key changes in model coding. We can code a Cumulative Link Mixed-effects Model as follows.\n\nhealth.clmm &lt;- clmm(rating ~\n                      \n                      z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL +\n                      \n                      (1|ResponseId),\n                    \n                    Hess = TRUE, link = \"logit\",\n                    data = health)\n\nsummary(health.clmm)\n\nIf you inspect the code chunk, you can see that we have made two changes.\nFirst, we have changed the function.\n\nclmm() the function name changes because now we want a Cumulative Linear Mixed-effects Model.\n\nSecondly, the model specification includes information about fixed effects and now about random effects.\n\nWith (1 | Participant) we include random effects of participants on on intercepts.\n\n\n\nIf you run the model code, you will see that the model may take several seconds, possibly a minute or two to complete. We will then get the results shown in the output.\n\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL +  \n    (1 | ResponseId)\ndata:    health\n\n link  threshold nobs logLik   AIC     niter       max.grad cond.H \n logit flexible  4040 -4978.08 9984.16 1480(19002) 3.93e-03 3.5e+02\n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n ResponseId (Intercept) 9.825    3.134   \nNumber of groups:  ResponseId 202 \n\nCoefficients:\n          Estimate Std. Error z value Pr(&gt;|z|)    \nz_AGE     -0.44313    0.23483  -1.887  0.05916 .  \nz_SHIPLEY  0.77130    0.26514   2.909  0.00363 ** \nz_HLVA     0.20809    0.25617   0.812  0.41663    \nz_FACTOR3  1.68342    0.23836   7.063 1.63e-12 ***\nz_RDFKGL  -0.44345    0.03677 -12.059  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -9.3297     0.3453 -27.019\n2|3  -8.1413     0.2948 -27.618\n3|4  -6.5243     0.2632 -24.786\n4|5  -5.2159     0.2491 -20.938\n5|6  -3.4668     0.2371 -14.623\n6|7  -1.8481     0.2316  -7.981\n7|8   0.2965     0.2296   1.292\n8|9   3.0417     0.2347  12.959\n\n\nYou can see that the output summary presents the same structure. If you compare the output you see in Section 1.7.1, however, you will notice some similarities and some differences:\n\nIf you focus first on the estimates of the coefficients for the predictor variables, you will see that the estimates have the same sign (positive or negative) as they had before.\nHowever, you will see that the estimates have different magnitudes.\nYou will also see that the p-values are different.\n\nStudents often focus on p-values in reading model summaries. This is mistaken for multiple reasons. The p-values correspond to the probabilities associated with the null hypothesis significance test: the test of the hypothesis that the effect of the predictor is null (i.e. the predictor has no impact). This null assumption is made whichever model we are looking at. The p-values do not indicate whether an effect is more or less probable. But you do get such posterior probabilities in Bayesian analyses. So it does not really mean much, though it is common, to talk about effects being highly significant. Thus it should not worry us too much if the p-values are significant in one analysis but not significant in another.\nThat said, it is interesting, perhaps, that once we include random effects of participants on intercepts in our analysis then the effects of z_AGE and z_HLVA are no longer significant. I would be tempted to ask if the previously significant effects of these variables owed their impact to random differences between participants in their average or overall level of rating response.\n\n\n\nIt will be helpful for the interpretation of the estimates of the coefficients of these predictor variables if we visualize the predictions we can make, about how rating values vary, given differences in predictor variable values, given our model estimates. We can do this using functions from the {ggeffects} library. You can read more about the {ggeffects} library here where you will see a collection of articles explaining what you can do, and why, as well as technical information including some helpful tutorials.\nThe basic model prediction coding looks like this.\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\nplot(dat)\n\nFigure 4 shows you the marginal effect of variation in the reading strategy attribute, i.e., the effect of differences between individuals in how they score on the FACTOR3 measure of reading strategy. Note that the variable is listed as z_FACTOR3 because, as you will recall, we standardized numeric predictor variables before entering them in our model.\nThese kinds of plots are understood to present what are variously called conditional effects, or adjusted predictions or marginal effects. You can find a discussion of marginal effects in the context of working with the {ggeffects} library here and here. You can find an extensive, helpful (with examples) discussion of marginal effects by Andrew Heiss here.\nIn short, what we want to do is to take the model coefficient estimates, and generate predictions with these estimates, given different values of the predictor variable, while holding the other predictor variables at some constant or some level (or some series of values).\nIf you look at the code chunk, you can see that we first:\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\n\n\nIn this line, we use ggpredict() to work with some model information, assuming we previously fitted a model and gave it a name (here, health.clmm).\n\nNote that if you fit the model and call it health.clmm, as we did in Section 1.8, then an object of that name is created in the R workspace or environment. If you click on that object name in the environment window in R-Studio, you will see that there is a list of pieces of information about the model, including the coefficient estimates, the model formula etc. associated with that name.\n\nSo when we use ggpredict(), we ask R to take that model information and, for the term we specify, here, specify using terms=\"z_FACTOR3 [all]\", we ask R to generate some predictions.\ndat &lt;- ggpredict(...) asks R to put those predictions in an object called dat.\n\nIf you click on that object name in the environment window in R-Studio, you will see that it comprises a dataset. The dataset includes the columns:\n\nx giving different values of the predictor variable. ggpredict() will choose some ‘representative’ values for you but you can construct a set of values of the predictor for which you want predictions.\npredicted holds predicted values, given different predictor x values.\n\nIf you then run the line plot(dat) you can see what this gets us for these kinds of models. Figure 4 presents a grid of plots showing the model-predicted probabilities that a rating response will have one value for each of the 1-9 rating response values that are possible given the Likert rating scale used in data collection. In the grid, a different plot is shown for each possible response value, indicating how the probability varies that the rating response will take that value.\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\nplot(dat)\n\n\n\n\n\n\n\nFigure 4: A grid of plots showing marginal or conditional predicted probabilities that a rating response will have one value (among the 1-9 rating values possible), indicating how these predicted probabilities vary given variation in values of the standardized reading strategy (FACTOR3) variable.\n\n\n\n\n\nIf you examine Figure 4, you can recognize that we have one plot for each different value of the response options available for the Likert-scale rating items: 1-9. You can also see that in each plot we get a curve. In some cases – for rating response values 1-4 – the curve is flat or flattens very quickly, for higher levels of the z_FACTOR3 variable. In some cases – for rating response values 5-9 – the curve is more obvious, and resembles a normal distribution curve.\nIf you think about it, what these plots indicate are the ways in which the probability that a rating response is a low value (e.g., a rating of 1) or a high value (e.g., a rating of 9) rises or falls. Each possible rating response is associated with a probability distribution. For example, look at the plot labelled 6: that shows you the probability distribution indicating how the probability varies that a response will take the value 6. We can see that the distribution is normal in shape, a bell-shaped curve. We can see that the peak of the curve is over the z_FACTOR3 score (shown on the x-axis) of about 1.5. We can see that the probability represented by the height of the line showing the curve is lower for z_FACTOR3 scores lower than the score under the peak (e.g. scores less than z_FACTOR3 \\(=2\\)). The probability represented by the height of the line showing the curve is lower for z_FACTOR3 scores higher than the score under the peak (e.g. scores greater than z_FACTOR3 \\(=1\\)).\nWe can see that the peak of the normal curve, in the case of rating response values 5-9, is located at different places on the horizontal axis. Look at each of the plots labelled 5-9. Notice how the horizontal location of the curves shifts as z_FACTOR3 scores increase. If you go from left to right, i.e. from low to high values of z_FACTOR3, on each plot then you will see that the peak of the curve is located in different places: going from plot 5 to plot 9 the peak of the curve moves rightwards. These curves show how the probability that a rating response takes a high value (e.g. 9 instead of 8 or 8 instead of 7 etc.) is higher for higher values of z_FACTOR3. This idea might be a bit clearer if we draw the plot in a different way.\nFigure 5 shows the same model predictions but plots the predictions of the way that probability changes, for each rating response, by superimposing the plots for each response value, one on top of the other. I have drawn each probability curve in a different colour, and these colours match those used to present the counts of different response values shown in Figure 3.\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\nggplot(dat, aes(x, predicted, \n                colour = response.level)) + \n  geom_line(size = 1.5) +\n  scale_color_viridis(discrete=TRUE, option = \"mako\") + \n  labs(x = \"Reading strategy (z_FACTOR3)\", y = \"Predicted probability of a rating\") +\n  guides(colour = guide_legend(title = \"Rating\")) +\n  ylim(0, 1) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 5: A plot showing marginal or conditional predicted probabilities that a rating response will have one value (among the 1-9 rating values possible), indicating how these predicted probabilities vary given variation in values of the standardized reading strategy (FACTOR3) variable\n\n\n\n\n\nYou can read Figure 5 by observing that:\n\nFor low value ratings e.g. for rating responses from 1-4, there is not much predicted probability that a response with such a value will be made (flat lines) but if they are going to be made they are likely to be made by people with low scores on the z_FACTOR3.\n\nYou can see this because you can see how the curves peak around low values of z_FACTOR3. This should make sense: people with low scores on reading strategy are maybe not doing reading effectively, are maybe as a result not doing well in understanding the texts they are given to read, and thus are not confident about their understanding. (This is a speculative causal theory but it will suffice for now.)\nRecall, also, that as Figure 3 indicated, in the Clearly understood health comprehension dataset, we saw that few rating responses were recorded for low value ratings of understanding. Few people in our sample made rating responses by choosing ratings of 1 or 2 to indicate low levels of understanding.\nFigure 5 also suggests that:\n\nFor higher value rating responses – responses representing ratings from 5 to 9 – there is variation in the probability that responses with such values will be made.\nThat variation in probability is shown by the probability distribution curves.\nFor these data, and this model, we can see that the probability shifts suggesting that participants in our sample were more likely to choose a higher value rating if they were also presenting high scores on the z_FACTOR3 measure of reading strategy.\n\n\n\n\n\nAs the review reported by Liddell and Kruschke (2018) suggests, we may have many many studies in which ordinal outcome data are analysed but very few published research reports that present analyses of ordinal data using ordinal models.\nYou can see two examples in the papers published by Ricketts, Dawson, and Davies (2021) and by Rodríguez-Ferreiro, Aguilera, and Davies (2020). These papers are both published open accessible, so that they are freely available, and they are both associated with accessible data repositories.\n\nYou can find the repository for Ricketts, Dawson, and Davies (2021) here.\nYou can find the repository for Rodríguez-Ferreiro, Aguilera, and Davies (2020) here.\n\nThe Rodríguez-Ferreiro, Aguilera, and Davies (2020) shares a data .csv only.\nThe Ricketts, Dawson, and Davies (2021) repository shares data and analysis code as well as a fairly detailed guide to the analysis methods. Note that the core analysis approach taken in Ricketts, Dawson, and Davies (2021) is based on Bayesian methods but that we also conduct clmm() models using the {ordinal} library functions discussed here; these models are labelled frequentist models and can be found under sensitivity analyses.\nFor what it’s worth, the Ricketts, Dawson, and Davies (2021) is much more representative of the analysis approach I would recommend now.\nWhatever the specifics of your research question, dataset, analysis approach or model choices, I would recommend the following for your results report.\n\nExplain the model – the advice extended by Meteyard and Davies (2020) still apply: the reader will need to know:\n\n\nThe identity of the outcome and predictor variables;\nThe reason why you are using an ordinal approach, explaining the ordinal (ordered, categorical) nature of the outcome;\nThe structure of the fixed effects part of the model, i.e. the effects, in what form (main effects, interactions) you are seeking to estimate;\nAnd the structure of the random effects part of the model, i.e. what grouping variable (participants? items?), whether they encompass random intercepts or random slopes or covariances.\n\nYou can report or indicate some of this information by presenting a table summary of the effects estimated in your model (e.g., see Table 5, Rodríguez-Ferreiro, Aguilera, and Davies 2020; see tables 2 and 3, Ricketts, Dawson, and Davies 2021). Journal formatting restrictions or other conventions may limit what information you can present.\nNotice that I do not present information on threshold estimates.\n\nExplain the results – I prefer to show and tell.\n\n\nPresent conditional or marginal effects plots (see figures 2 and 3, Ricketts, Dawson, and Davies 2021) to indicate the predictions you can make given your model estimates.\nAnd explain what the estimates or what the prediction plots appear to show.\n\n\n\n\n\n\nAs I hint, when we discuss the concept that ordinal responses may map somehow to a latent unobserved underlying continuum (see Figure 1), there are other ways to think about ordinal data. Rather, there are other ways to think about the psychological mechanisms or the data generating mechanisms that give rise to the ordinal responses we analyse.\nIn Ricketts, Dawson, and Davies (2021), we explain:\n\nIn the semantic post-test, participants worked their way through three steps, only progressing from one step to the next step if they provided an incorrect response or no response. Given the sequential nature of this task, we analysed data using sequential ratio ordinal models (Bürkner & Vuorre, 2019). In sequential models, we account for variation in the probability that a response falls into one response category (out of k ordered categories), equal to the probability that it did not fall into one of the foregoing categories, given the linear sum of predictors. We estimate the k-1 thresholds and the coefficients of the predictors.\n\nWhat this explanation refers to is the fact that, in our study:\n\nThe semantic post-test assessed knowledge for the meanings of newly trained words. We took a dynamic assessment or cuing hierarchy approach (Hasson & Joffe, 2007), providing children with increasing support to capture partial knowledge and the incremental nature of acquiring such knowledge (Dale, 1965). Each word was taken one at a time and children were given the op- portunity to demonstrate knowledge in three steps: definition, cued definition, recognition.\n\nWe follow advice set out by Bürkner and Vuorre (2019) in modeling the ordered categorical (i.e. ordinal) responses using a sequential ratio approach.\n\n\n\n\nYou will have noticed that the mixed-effects model coded in Section 1.8 incorporates a relatively simple random effect: a term specified to estimate the variance associated with the random effect of differences between participants in intercepts.\nAs we we have seen, more complex random effects structures may be warranted Matuschek et al. (2017). When we attempt to fit models with more complex structures, as we have discussed, for example, in ?@sec-dev-mixed-convergence-problems and ?@sec-glmm-bad-signs, we may run into convergence problems. (Such convergence problems are one reason why I tend to favour Bayesian methods; see, for exampe, the discussions in Bürkner and Vuorre (2019) and Liddell and Kruschke (2018).) There are ways to resolve these problems by changing the control parameters of the {ordinal} functions (see e.g. this discussion or see the information here) or by simplfying the model.\n\n\n\nWe discussed ordinal data and the reasons why we are motivated to analyze ordinal data using ordinal models.\nWe examine the coding required to fit ordinal models.\nWe look at the results outputs from ordinal models, and visualizations representing the predictions that can be generated given ordinal model estimates.\nWe consider the kinds of information that results reports should include.\nWe examine possible extensions to ordinal models.\n\n\nWe used two functions from the {ordinal} library to fit and evaluate ordinal models.\n\nWe used clm() to fit an ordinal model without random effects.\nWe used clmm() to fit an ordinal mixed-effects model with fixed effects and random effects.\n\n\n\n\n\nThe published example studies referred to in this chapter are published in (Ricketts, Dawson, and Davies 2021; Rodríguez-Ferreiro, Aguilera, and Davies 2020).\nLiddell and Kruschke (2018) present a clear account of the problems associated with treating ordinal data as metric, and explain how we can better account for ordinal data.\nBürkner and Vuorre (2019) present a clear tutorial on cumulative and sequential ratio models.\nBoth Liddell and Kruschke (2018) and Bürkner and Vuorre (2019) work from a Bayesian perspective but the insights are generally applicable.\nGuides to the {ordinal} model functions clm() and clmm() are presented in (Rune Haubo Bojesen Christensen 2022; R. H. B. Christensen 2015)."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-motivations",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-motivations",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "Ordinal data are very common in psychological science. Often, we will encounter ordinal data recorded as responses to Likert-style items in which the participant is asked to indicate a response on an ordered scale ranging between two end points (Bürkner and Vuorre 2019; Liddell and Kruschke 2018). An example of a Likert question item might be: How well do you think you have understood this text? (Please check one response) where the participant must respond by checking an option, given 5 options ranging from 1 (not well at all) to 5 (very well). The critical characteristics of such responses are that:\n\nThe responses are ordered, as indicated by the number labels;\nResponse types are categorical or qualitative, not numeric.\n\nWe will be working with study data in which the outcome that is the target for our analyses comprise responses to questions designed to elicit ratings. Ordinal data may, however, also derive from situations in which ordered categorical responses do not derive from ratings items (we will look briefly at sequential responses, Bürkner and Vuorre 2019).\nThe challenge we face is that we will aim to develop skills in using ordinal models when, in contrast, most psychological research articles will report analyses of ordinal data using conventional methods like ANOVA or linear regression. We will work to understand why ordinal models are better. We will learn that applying conventional methods to ordinal data will, in principle, involve a poor account of the data and, in practice, will create the risk of producing misleading results. And we will learn how to work with and interpret the results from ordinal models with or without random effects.\nIn our work in this chapter, we will rely extensively on the ideas set out by Liddell and Kruschke (2018), see Section 1.13."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-ideas",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-ideas",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "Important\n\n\n\nOrdinal responses are labelled with numbers but ordinal data are not numeric.\n\n\nOrdinal responses are coded with numeric labels. These number labels may indicate order but we do not know that the difference between e.g. response options 1 versus 2 is the same as the difference between 2 versus 3 or 3 versus 4. Ordinal data contrast with metric data (Liddell and Kruschke 2018) which are recorded on scales for which we assume both order and equal intervals. When researchers apply metric models to ordinal data, they incorrectly assume that the response options e.g. in ratings are separated by equal intervals. Yet, in a review of the 68 recently articles that mentioned the term “Likert” in a sample of highly ranked Psychology journals, Liddell and Kruschke (2018) found that ordinal data were treated as metric and the articles presented results from metric models.\nOne way to think about ordinal data is that often (but not always) ratings may be understood to come from psychological processes in which the participant, in response to the Likert question, divides some latent (unobserved) psychological continuum or scale into categories in order to select a response option.\nImagine, for example, that you have been asked the question “How well do you understand this text? (on a scale from 1-5)”. Presumably, to answer this question, you will have to choose a response based on where you think you are on your unobserved measure of your understanding. You may be able to evaluate the cohesion, or some other internal measure, of your understanding of the text. Simplifying a bit, we might assume that your internal measure of understanding is associated with a normal probability distribution so that it peaks over some value (e.g., 3) of the strength of understanding though other values are possible. As Figure 1 suggests, a participant in this common situation will have to map the internal measure (the latent scale, e.g., of understanding) to a number from the response options you are given (e.g., rating scale values ranging 1-5). But there is no reason to suppose that your internal measure of your understanding is divided into an ordered metric scale.\n\n\n\n\n\n\n\n\nFigure 1: A latent scale on the horizontal axis is divided into intervals or bins divided by thresholds marked by dotted lines. The cumulative normal probability in the intervals is the probability of the ordinal values.\n\n\n\n\n\nIn conducting analyses of ordinal data with ordinal models, we often fit models that describe the cumulative probability that a rating response is located at some value (typically, understood in terms of threshold) on an underlying latent continuum. In ordinal models, we do not assume that the ordinal responses map to equally spaced intervals on the latent scale: the values or thresholds at which the continuum are split are to be estimated.\nIn applying metric models to ordinal data, we do assume that intervals are equal though this assumption is unlikely to be true or, at least, is unlikely to be verifiable. This faulty assumption has consequences because the mis-application of metric models (e.g. ANOVA, linear models) to ordinal data is both commonplace and risky. As Liddell and Kruschke (2018) demonstrate, mis-applying metric models to ordinal data can result in false positives (detecting a difference when none is present), false negatives (missing a difference that is present) and inversions (swapping the difference so that it appears to be positive instead of negative or vice versa). These kinds of misrepresentions cannot be avoided and are not fixed by, for example, averaging ratings scales data together."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-targets",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-targets",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "Understand practically the reasons for using ordinal models when we analyze ordinal outcome variables, ?@sec-ordinal-practical-understanding.\nPractice running ordinal models with varying random effects structures.\nPractice reporting the results of ordinal models, including through the use of prediction plots."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-study-guide",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-study-guide",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "I have provided a collection of materials you can use. Here, I explain what they are and how I suggest you use them.\n1. Chapter: 05-ordinal\n1.1. I have written this chapter to discuss the main ideas and set out the practical steps you can follow to start to develop the skills required to work with ordered categorical outcomes i.e. ordinal data using ordinal models.\n1.2. The practical elements include data tidying, visualization and analysis steps.\n1.3. You can read the chapter and run the code to gain experience and encounter code you can adapt for your own purposes.\n\nRead in the example dataset.\nExperiment with the .R code used to work with the example data.\nRun ordinal models of demonstration data.\nRun ordinal models of alternate data sets (see links in Section 1.9).\nReview the recommended readings (Section 1.13).\n\n2. Practical materials\n2.1 In the following sections, I describe the practical steps, and associated resources, you can use for your learning. I set out the data tidying, analysis and visualization steps you can follow, working with the example dataset, described next."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-data",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-data",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "We will be working, at first, with a sample of data collected as part of the Clearly understood: health comprehension project (Davies, Ratajczak, Gillings, Chadwick & Gold). These data are unpublished.\n\n\n\n\nOur interest, in conducting the project, lies in identifying what factors make it easy or difficult to understand written health information. In part, we are concerned about the processes that health providers or clinicians apply to assure the effectiveness of the text they produce to guide patients or carers, for example, in taking medication, in making treatment decisions, or in order to follow therapeutic programmes.\nIt is common, in the quality assurance process in the production of health information texts, that text producers ask participants in patient review panels to evaluate draft texts. In such reviews, a participant may be asked a question like “How well do you understand this text?” This kind of question presents a metacognitive task: we are asking a participant to think about their thinking. But it is unclear that people can do this well or, indeed, what factors determine the responses to such questions (Dunlosky and Lipko 2007).\nFor these reasons, we conducted studies in which we presented adult participants with sampled health information texts (taken from health service webpages) and, critically, asked them to respond to the question:\n\nHow well do you think you have understood this text? (Please check one response)\n\nFor each text, in response to this question, participants were asked to click on one option from an array of response options ranging from (1) Not well at all to (9) Extremely well. The data we collected in this element of our studies comprise, clearly, ordinal responses. Thus, we may use these data to address the following research question.\n\n\n\n\n\n\nNote\n\n\n\n\nWhat factors predict self-evaluated rated understanding of health information.\n\n\n\n\n\n\nWe will work with a sample of participant data drawn from a series of Lancaster University undergraduate dissertation studies connected to the Clearly understood project. In these studies, we collected data from 202 participants on a series of measures (Section 1.5.1.3) of vocabulary knowledge, health literacy, reading strategy, as well as responses to health information texts. The distributions of participants’ scores on each of a range of attribute variables\n\n\n\n\n\n\n\n\nFigure 2: Grid of plots showing the distribution of participant attributes. The grid includes histograms of the distributions of: self-rated accuracy; vocabulary (SHIPLEY); health literacy (HLVA); reading strategy (FACTOR3); and age (years). We also see dot plots presenting counts of numbers of participants of different self-reported gender, education, and ethnicity categories.\n\n\n\n\n\nThe plots indicate:\n\nmost self-rated accuracy scores are high (over 6);\nmany participants with vocabulary scores greater than 30, a few present lower scores;\nhealth literacy scores centered on 8 or some, with lower and higher scores;\na skewed distribution of reading strategy scores, with many around 20-40, and a tail of higher scores;\nmost participants are 20-40 years of age, some older;\nmany more female than male participants, very few non-binary reported;\nmany more participants with higher education than further, very few with secondary;\nand many White participants (Office of National Statistics categories), far fewer Asian or Mixed or Black ethnicity participants.\n\n\n\n\nWe collected data through an online survey administered through Qualtrics.\nWe used the Shipley vocabulary sub-test (Shipley et al. 2009) to estimate vocabulary knowledge.\nWe used the Health Literacy Vocabulary Assessment (HLVA, Ratajczak, 2020; adapted for online presentation, Chadwick, 2020) to estimate health literacy.\nWe used an instrument drawn from unpublished work by Calloway (2019) to assess the approach participants took to reading and understanding written information.\nWe presented participants with a sample of 20 health information texts. In the data collection process for this dataset, participants were recruited in multiple different studies. In each study, any one participant was presented with a randomly selected subset of the total of 20 texts.\nWe asked participants to rate their level of understanding of the health-related texts that we presented in the study. We used a nine-point judgment scales because they have been found to outperform alternative scales with fewer categories in terms of criterion validity, internal consistency, test-retest reliability, and discriminating power (Preston and Colman 2000).\nWe recorded participants’ demographic characteristics: gender (coded: Male, Female, non-binary, prefer not to say); education (coded: Secondary, Further, Higher); and ethnicity (coded: White, Black, Asian, Mixed, Other).\n\n\n\n\nYou can download the 2021-22_PSYC304-health-comprehension.csv file holding the data we analyse in this chapter by clicking on the link.\n\n\n\nI am going to assume you have downloaded the data file, and that you know where it is. We use read_csv to read the data file into R.\n\nhealth &lt;- read_csv(\"2021-22_PSYC304-health-comprehension.csv\", \n                                 na = \"-999\",\n                                 col_types = cols(\n                                   ResponseId = col_factor(),\n                                   rating = col_factor(),\n                                   GENDER = col_factor(),\n                                   EDUCATION = col_factor(),\n                                   ETHNICITY = col_factor(),\n                                   NATIVE.LANGUAGE = col_factor(),\n                                   OTHER.LANGUAGE = col_factor(),\n                                   text.id = col_factor(),\n                                   text.question.id = col_factor(),\n                                   study = col_factor()\n                                 )\n                               )\n\nNotice that we use col_types = cols(...) to require read_csv() to class some columns as factors.\nImportantly, we ask R to treat the rating variable as a factor with rating = col_factor().\n\n\n\n\n\n\nTip\n\n\n\nIn the practical work we do, we will be using functions from the {ordinal} library to model ordinal data.\n\nIn using these functions, we need ask R to treat the ordinal outcome variable as a factor.\n\n\n\n\n\n\nIt is always a good to inspect what you have got when you read a data file in to R. Here, what may most concern us is the distribution of observed responses on the rating scale (responses to the “How well do you understand?” question). Figure 3 is a dot plot showing the distribution of ratings responses. The Likert-style questions in the surveys asked participants to rate their level of understanding of the texts they saw on a scale from 1 (not well) to 9 (extremely well). The plot shows the number of responses recorded for each response option, over all participants and all texts.\n\nhealth &lt;- health %&gt;% mutate(rating = fct_relevel(rating, sort))\n\nhealth %&gt;%\n  group_by(rating) %&gt;%\n  summarise(count = n()) %&gt;%\n  ggplot(aes(x = rating, y = count, colour = rating)) + \n  geom_point(size = 3) +\n  scale_color_viridis(discrete=TRUE, option = \"mako\") + theme_bw() +\n  theme(\n    panel.grid.major.y = element_blank()  # No horizontal grid lines\n  ) +\n  coord_flip()\n\n\n\n\n\n\n\nFigure 3: Dot plot showing the distribution of ratings responses. The Likert-style questions in the surveys asked participants to rate their level of understanding of the texts they saw on a scale from 1 (not well) to 9 (extremely well). The plot shows the number of responses recorded for each response option, over all participants and all texts.\n\n\n\n\n\nThe plot indicates that most participants chose response options 5-9, while very few rated their understanding at the lowest levels (options 1-4). Interestingly, many ratings responses around 7-8 were recorded: many more than responses at 5-6.\nIn analyzing these data, we will seek to estimate what information available to us can be used to predict whether a participant’s rating of their understanding is more likely to be, say, 1 or 2, 2 or 3 … 7 or 8, 8 or 9.\n\nOne practical way to think about the estimation problem when working with ratings-style ordinal data is this:\n\nWhat factors move or how do influential factors move the probability that the ordinal response is a relatively low or relatively high order response option?\nIn doing this, we do not have to assume that rating scale points map to equal sized intervals on the underlying latent scale where the scale may be an unobserved psychological continuum (like understanding).\n\n\nHere, we mostly have information on participant attributes and some information on text properties to do our prediction analyses. In other studies, we may be using information about experimental conditions, or selected groups of participants to estimate effects on variation in ratings responses."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-data-tidy",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-data-tidy",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "The Clearly understood health comprehension project dataset is tidy (?@sec-intro-mixed-data-tidy):\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.\n\nHowever, there are aspects of the data structure or properties of the dataset variables that will cause inefficiencies or problems in later data analysis if we do not fix them first.\nYou can see what we have if you look at the results we get from using summary() and str() to inspect the dataset.\n\nsummary(health)\n\n             ResponseId        AGE                     GENDER    \n R_sKW4OJnOlidPxrH:  20   Min.   :18.0   Female           :2900  \n R_27paPJzIutLoqk8:  20   1st Qu.:20.0   Male             :1120  \n R_1nW0lpFdfumlI1p:  20   Median :27.0   Prefer-not-to-say:  20  \n R_31ZqPQpNEEapoW8:  20   Mean   :34.3                           \n R_2whvE2IW90nj2P7:  20   3rd Qu.:50.0                           \n R_3CAxrri9clBT7sl:  20   Max.   :81.0                           \n (Other)          :3920                                          \n     EDUCATION    ETHNICITY    NATIVE.LANGUAGE    OTHER.LANGUAGE\n Further  :1780   Asian: 680   English:2720    NA        :2720  \n Higher   :1800   White:3260   Other  :1320    Polish    : 580  \n Secondary: 460   Other:  40                   Cantonese : 280  \n                  Mixed:  60                   Chinese   : 120  \n                                               Portuguese:  60  \n                                               polish    :  60  \n                                               (Other)   : 220  \n ENGLISH.PROFICIENCY    SHIPLEY           HLVA           FACTOR3     \n Length:4040         Min.   :15.00   Min.   : 3.000   Min.   :17.00  \n Class :character    1st Qu.:30.00   1st Qu.: 7.000   1st Qu.:45.00  \n Mode  :character    Median :34.00   Median : 9.000   Median :49.00  \n                     Mean   :32.97   Mean   : 8.564   Mean   :49.03  \n                     3rd Qu.:37.00   3rd Qu.:10.000   3rd Qu.:55.00  \n                     Max.   :40.00   Max.   :13.000   Max.   :63.00  \n                                                                     \n     rating        response          RDFKGL       study    \n 8      :1044   Min.   :0.0000   Min.   : 4.552   cs: 480  \n 7      : 916   1st Qu.:1.0000   1st Qu.: 6.358   jg:1120  \n 9      : 824   Median :1.0000   Median : 8.116   ml: 720  \n 6      : 500   Mean   :0.8064   Mean   : 7.930   rw:1720  \n 5      : 352   3rd Qu.:1.0000   3rd Qu.: 9.413            \n 4      : 176   Max.   :1.0000   Max.   :13.278            \n (Other): 228                                              \n             text.id                  text.question.id\n studyone.TEXT.37: 344   studyone.TEXT.37.CQ.1:  86   \n studyone.TEXT.39: 344   studyone.TEXT.37.CQ.2:  86   \n studyone.TEXT.72: 344   studyone.TEXT.37.CQ.3:  86   \n studyone.TEXT.14: 344   studyone.TEXT.37.CQ.4:  86   \n studyone.TEXT.50: 344   studyone.TEXT.39.CQ.1:  86   \n studyone.TEXT.10: 224   studyone.TEXT.39.CQ.2:  86   \n (Other)         :2096   (Other)              :3524   \n\n\nYou should be used to seeing the summary() of a dataset, showing summary statistics of numeric variables and counts of the numbers of observations of data coded at different levels for each categorical or nominal variable classed as a factor.\nUsing the str() function may be new to you and, as you can see, the output from the function call gives you a bit more information on how R interprets the data in the variable columns. You can see that each variable is listed alongside information about how the data in the column are interpreted (as Factor or num numeric). Where we have columns holding information on factors there we see information about the levels.\nRecall that for a categorical or nominal variable e.g. ETHNICITY, provided R interprets the variable as a factor, each data value in the column is coded as corresponding to one level i.e. group or class or category (e.g., we have ETHNICITY classes \"Asian\" etc.) Recall, also, that at the data read-in stage, we instructed R how we wanted it to interpret each column using col_types = cols().\n\nstr(health)\n\ntibble [4,040 × 17] (S3: tbl_df/tbl/data.frame)\n $ ResponseId         : Factor w/ 202 levels \"R_sKW4OJnOlidPxrH\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ AGE                : num [1:4040] 20 20 20 20 20 20 20 20 20 20 ...\n $ GENDER             : Factor w/ 3 levels \"Female\",\"Male\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ EDUCATION          : Factor w/ 3 levels \"Further\",\"Higher\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ ETHNICITY          : Factor w/ 4 levels \"Asian\",\"White\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ NATIVE.LANGUAGE    : Factor w/ 2 levels \"English\",\"Other\": 1 1 1 1 1 1 1 1 1 1 ...\n $ OTHER.LANGUAGE     : Factor w/ 17 levels \"NA\",\"Catonese\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ ENGLISH.PROFICIENCY: chr [1:4040] \"NA\" \"NA\" \"NA\" \"NA\" ...\n $ SHIPLEY            : num [1:4040] 26 26 26 26 26 26 26 26 26 26 ...\n $ HLVA               : num [1:4040] 8 8 8 8 8 8 8 8 8 8 ...\n $ FACTOR3            : num [1:4040] 59 59 59 59 59 59 59 59 59 59 ...\n $ rating             : Factor w/ 9 levels \"1\",\"2\",\"3\",\"4\",..: 8 8 8 8 7 7 7 7 7 7 ...\n $ response           : num [1:4040] 1 1 1 1 1 1 1 0 1 1 ...\n $ RDFKGL             : num [1:4040] 10.61 10.61 10.61 10.61 8.12 ...\n $ study              : Factor w/ 4 levels \"cs\",\"jg\",\"ml\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ text.id            : Factor w/ 20 levels \"studyone.TEXT.105\",..: 1 1 1 1 2 2 2 2 3 3 ...\n $ text.question.id   : Factor w/ 80 levels \"studyone.TEXT.105.CQ.1\",..: 1 2 3 4 5 6 7 8 9 10 ...\n\n\nOur specific concern, here, is that the rating response variable is treated as a factor because the {ordinal} library we are going to use to do the modeling must find the outcome variable is a factor.\nWe can focus str() on the rating variable. We see that it is being treated as a factor.\n\nstr(health$rating)\n\n Factor w/ 9 levels \"1\",\"2\",\"3\",\"4\",..: 8 8 8 8 7 7 7 7 7 7 ...\n\n\nHowever, we also need to make sure that the rating outcome variable is being treated as an ordered factor.\nWe can perform a check as follows. (I found how to do this here)\n\nis.ordered(factor(health$rating))\n\n[1] FALSE\n\n\nWe can see that the variable is not being treated as an ordered factor. We need to fix that.\nThe ordinal model estimates the locations (thresholds) for where to split the latent scale (the continuum underlying the ratings) corresponding to different ratings values. If we do not make sure that the outcome factor variable is split as it should be then there is no guarantee that {ordinal} functions will estimate the thresholds in the right order (i.e., 1,2,3 ... rather than 3,2,1...).\nWe can make sure that the confidence rating factor is ordered precisely as we wish using the ordered() function.\n\nhealth$rating &lt;- ordered(health$rating,\n                         levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"))\n\nWe can then do a check to see that we have got what we want. We do not wantrating to be treated as numeric, we do want it to be treated as an ordered factor.\n\nis.numeric(health$rating)\n\n[1] FALSE\n\nis.factor(health$rating)\n\n[1] TRUE\n\nstr(health$rating)\n\n Ord.factor w/ 9 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 8 8 8 8 7 7 7 7 7 7 ...\n\nis.ordered(health$rating)\n\n[1] TRUE\n\n\nIt is.\nNext, before doing any modelling, it will be sensible to standardize potential predictors\n\nhealth &lt;- health %&gt;% \n  mutate(across(c(AGE, SHIPLEY, HLVA, FACTOR3, RDFKGL), \n                scale, center = TRUE, scale = TRUE,\n                .names = \"z_{.col}\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(...)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nYou can see that in this chunk of code, we are doing a number of things:\n\nhealth &lt;- health %&gt;% recreates the health dataset from the following steps.\nmutate(...) do an operation which retains the existing variables in the dataset, to change the variables as further detailed.\nacross(...) work with the multple column variables that are named in the c(AGE, SHIPLEY, HLVA, FACTOR3, RDFKGL) set.\n...scale, center = TRUE, scale = TRUE... here is where we do the standardization work.\n\nWhat we are asking for is that R takes the variables we name and standardizes each of them.\n\n.names = \"z_{.col}\") creates the standardized variables under adapted names, adding z_ to the original column name so that we can distinguish between the standardized and original raw versions of the data columns.\n\nNote that the across() function is a useful function for applying a function across multiple column variables see information here There is a helpful discussion on how we can do this task here\nWe can then check that we have produced the standardized variables as required.\n\nsummary(health)\n\n             ResponseId        AGE                     GENDER    \n R_sKW4OJnOlidPxrH:  20   Min.   :18.0   Female           :2900  \n R_27paPJzIutLoqk8:  20   1st Qu.:20.0   Male             :1120  \n R_1nW0lpFdfumlI1p:  20   Median :27.0   Prefer-not-to-say:  20  \n R_31ZqPQpNEEapoW8:  20   Mean   :34.3                           \n R_2whvE2IW90nj2P7:  20   3rd Qu.:50.0                           \n R_3CAxrri9clBT7sl:  20   Max.   :81.0                           \n (Other)          :3920                                          \n     EDUCATION    ETHNICITY    NATIVE.LANGUAGE    OTHER.LANGUAGE\n Further  :1780   Asian: 680   English:2720    NA        :2720  \n Higher   :1800   White:3260   Other  :1320    Polish    : 580  \n Secondary: 460   Other:  40                   Cantonese : 280  \n                  Mixed:  60                   Chinese   : 120  \n                                               Portuguese:  60  \n                                               polish    :  60  \n                                               (Other)   : 220  \n ENGLISH.PROFICIENCY    SHIPLEY           HLVA           FACTOR3     \n Length:4040         Min.   :15.00   Min.   : 3.000   Min.   :17.00  \n Class :character    1st Qu.:30.00   1st Qu.: 7.000   1st Qu.:45.00  \n Mode  :character    Median :34.00   Median : 9.000   Median :49.00  \n                     Mean   :32.97   Mean   : 8.564   Mean   :49.03  \n                     3rd Qu.:37.00   3rd Qu.:10.000   3rd Qu.:55.00  \n                     Max.   :40.00   Max.   :13.000   Max.   :63.00  \n                                                                     \n     rating        response          RDFKGL       study    \n 8      :1044   Min.   :0.0000   Min.   : 4.552   cs: 480  \n 7      : 916   1st Qu.:1.0000   1st Qu.: 6.358   jg:1120  \n 9      : 824   Median :1.0000   Median : 8.116   ml: 720  \n 6      : 500   Mean   :0.8064   Mean   : 7.930   rw:1720  \n 5      : 352   3rd Qu.:1.0000   3rd Qu.: 9.413            \n 4      : 176   Max.   :1.0000   Max.   :13.278            \n (Other): 228                                              \n             text.id                  text.question.id       z_AGE.V1      \n studyone.TEXT.37: 344   studyone.TEXT.37.CQ.1:  86    Min.   :-0.9826247  \n studyone.TEXT.39: 344   studyone.TEXT.37.CQ.2:  86    1st Qu.:-0.8620352  \n studyone.TEXT.72: 344   studyone.TEXT.37.CQ.3:  86    Median :-0.4399723  \n studyone.TEXT.14: 344   studyone.TEXT.37.CQ.4:  86    Mean   : 0.0000000  \n studyone.TEXT.50: 344   studyone.TEXT.39.CQ.1:  86    3rd Qu.: 0.9468060  \n studyone.TEXT.10: 224   studyone.TEXT.39.CQ.2:  86    Max.   : 2.8159420  \n (Other)         :2096   (Other)              :3524                        \n    z_SHIPLEY.V1          z_HLVA.V1          z_FACTOR3.V1    \n Min.   :-3.294105   Min.   :-2.6074887   Min.   :-4.205936  \n 1st Qu.:-0.543723   1st Qu.:-0.7330662   1st Qu.:-0.529155  \n Median : 0.189713   Median : 0.2041450   Median :-0.003900  \n Mean   : 0.000000   Mean   : 0.0000000   Mean   : 0.000000  \n 3rd Qu.: 0.739789   3rd Qu.: 0.6727506   3rd Qu.: 0.783981  \n Max.   : 1.289866   Max.   : 2.0785675   Max.   : 1.834490  \n                                                             \n     z_RDFKGL.V1     \n Min.   :-1.4644660  \n 1st Qu.:-0.6814594  \n Median : 0.0807363  \n Mean   : 0.0000000  \n 3rd Qu.: 0.6430616  \n Max.   : 2.3187650"
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-working-models-clm",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-working-models-clm",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "In our first analysis, we can begin by assuming no random effects. We keep things simple at this point so that we can focus on the key changes in model coding.\nThe model is conducted to examine what shapes the variation in rating responses that we see in Figure 3.\n\n\n\n\n\n\nNote\n\n\n\n\nWhat factors predict self-evaluated rated understanding of health information.\n\n\n\nIn our analysis, the outcome variable is the ordinal response variable rating. The predictors consist of the variables we standardized earlier. We use the clm() function from the {ordinal} library to do the analysis. I will give information in outline here, the interested reader can see more detailed information in Rune Haubo Bojesen Christensen (2022) and R. H. B. Christensen (2015). You can also find the manual for the {ordinal} library functions here\nWe code the model as follows.\n\nhealth.clm &lt;- clm(rating ~\n                    \n                    z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL,\n                  \n                  Hess = TRUE, link = \"logit\",\n                  data = health)\n\nsummary(health.clm)\n\nThe code works as follows.\nFirst, we have a chunk of code mostly similar to what we have done before, but changing the function.\n\nclm() the function name changes because now we want a cumulative link model of the ordinal responses.\n\nThe model specification includes information about the fixed effects, the predictors: z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL.\nSecond, we have the bit that is specific to cumulative link models fitted using the clm() function.\n\nHess = TRUE is required if we want to get a summary of the model fit; the default is TRUE but it is worth being explicit about it.\nlink = \"logit\" specifies that we want to model the ordinal responses in terms of the log odds (hence, the probability) that a response is a low or a high rating value (compare ?@sec-glmm-practical-understanding).\n\n\n\nIf you run the model code, it may take a few seconds to run. Then you will get the results shown in the output.\n\n\nformula: rating ~ z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL\ndata:    health\n\n link  threshold nobs logLik   AIC      niter max.grad cond.H \n logit flexible  4040 -6880.78 13787.55 5(0)  9.26e-07 7.3e+01\n\nCoefficients:\n          Estimate Std. Error z value Pr(&gt;|z|)    \nz_AGE     -0.17719    0.02966  -5.975 2.30e-09 ***\nz_SHIPLEY  0.34384    0.03393  10.135  &lt; 2e-16 ***\nz_HLVA     0.16174    0.03265   4.954 7.28e-07 ***\nz_FACTOR3  0.74535    0.03145  23.699  &lt; 2e-16 ***\nz_RDFKGL  -0.27220    0.02892  -9.412  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2 -4.65066    0.12978 -35.836\n2|3 -4.13902    0.10395 -39.817\n3|4 -3.26845    0.07390 -44.228\n4|5 -2.56826    0.05804 -44.248\n5|6 -1.69333    0.04437 -38.160\n6|7 -0.87651    0.03671 -23.876\n7|8  0.24214    0.03402   7.117\n8|9  1.63049    0.04252  38.346\n\n\nThe summary() output for the model is similar to the outputs you have seen for other model types.\n\nWe first get formula: information about the model you have specified.\nR will tell us what data: we are working with.\nWe then get Coefficients: estimates.\n\nThe table summary of coefficients arranges information in ways that will be familiar you:\n\nFor each predictor variable, we see ’Estimate, Std. Error, z value, and Pr(&gt;|z|)` statistics.\nThe Pr(&gt;|z|) p-values are based on Wald tests of the null hypothesis that a predictor has null impact.\nThe coefficient estimates can be interpreted based on whether they are positive or negative.\n\nA positive coefficient estimate indicates that higher values of the predictor variable are associated with greater probability of higher rating values. A negative coefficient estimate indicates that higher values of the predictor variable are associated with greater probability of lower rating values.\n\nWe then get Threshold coefficients: indicating where the model fitted estimates the threshold locations: where the latent scale is cut, corresponding to different rating values.\n\n\n\n\n\n\n\nTip\n\n\n\nIn reporting ordinal (e.g., cumulative link) models, we typically focus on the coefficient estimates for the predictor variables."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-working-models-clmm",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-working-models-clmm",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "In our analysis, we begn by assuming no random effects. However, this is unlikely to be appropriate given the data collection process deployed in the Clearly understood projects, where:\n\na sample of participants were asked to respond to a sample of texts;\nwe have multiple observations of responses for each participant;\nwe have multiple observations of responses for each stimulus text;\nparticipants were assigned to groups, and within a group all participants were asked to respond to the same stimulus texts.\n\nThese features ensure that the data have a multilevel structure and this structure requires us to fit a Cumulative Link Mixed-effects Model (CLMM).\nWe keep things simple at this point so that we can focus on the key changes in model coding. We can code a Cumulative Link Mixed-effects Model as follows.\n\nhealth.clmm &lt;- clmm(rating ~\n                      \n                      z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL +\n                      \n                      (1|ResponseId),\n                    \n                    Hess = TRUE, link = \"logit\",\n                    data = health)\n\nsummary(health.clmm)\n\nIf you inspect the code chunk, you can see that we have made two changes.\nFirst, we have changed the function.\n\nclmm() the function name changes because now we want a Cumulative Linear Mixed-effects Model.\n\nSecondly, the model specification includes information about fixed effects and now about random effects.\n\nWith (1 | Participant) we include random effects of participants on on intercepts.\n\n\n\nIf you run the model code, you will see that the model may take several seconds, possibly a minute or two to complete. We will then get the results shown in the output.\n\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ z_AGE + z_SHIPLEY + z_HLVA + z_FACTOR3 + z_RDFKGL +  \n    (1 | ResponseId)\ndata:    health\n\n link  threshold nobs logLik   AIC     niter       max.grad cond.H \n logit flexible  4040 -4978.08 9984.16 1480(19002) 3.93e-03 3.5e+02\n\nRandom effects:\n Groups     Name        Variance Std.Dev.\n ResponseId (Intercept) 9.825    3.134   \nNumber of groups:  ResponseId 202 \n\nCoefficients:\n          Estimate Std. Error z value Pr(&gt;|z|)    \nz_AGE     -0.44313    0.23483  -1.887  0.05916 .  \nz_SHIPLEY  0.77130    0.26514   2.909  0.00363 ** \nz_HLVA     0.20809    0.25617   0.812  0.41663    \nz_FACTOR3  1.68342    0.23836   7.063 1.63e-12 ***\nz_RDFKGL  -0.44345    0.03677 -12.059  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -9.3297     0.3453 -27.019\n2|3  -8.1413     0.2948 -27.618\n3|4  -6.5243     0.2632 -24.786\n4|5  -5.2159     0.2491 -20.938\n5|6  -3.4668     0.2371 -14.623\n6|7  -1.8481     0.2316  -7.981\n7|8   0.2965     0.2296   1.292\n8|9   3.0417     0.2347  12.959\n\n\nYou can see that the output summary presents the same structure. If you compare the output you see in Section 1.7.1, however, you will notice some similarities and some differences:\n\nIf you focus first on the estimates of the coefficients for the predictor variables, you will see that the estimates have the same sign (positive or negative) as they had before.\nHowever, you will see that the estimates have different magnitudes.\nYou will also see that the p-values are different.\n\nStudents often focus on p-values in reading model summaries. This is mistaken for multiple reasons. The p-values correspond to the probabilities associated with the null hypothesis significance test: the test of the hypothesis that the effect of the predictor is null (i.e. the predictor has no impact). This null assumption is made whichever model we are looking at. The p-values do not indicate whether an effect is more or less probable. But you do get such posterior probabilities in Bayesian analyses. So it does not really mean much, though it is common, to talk about effects being highly significant. Thus it should not worry us too much if the p-values are significant in one analysis but not significant in another.\nThat said, it is interesting, perhaps, that once we include random effects of participants on intercepts in our analysis then the effects of z_AGE and z_HLVA are no longer significant. I would be tempted to ask if the previously significant effects of these variables owed their impact to random differences between participants in their average or overall level of rating response.\n\n\n\nIt will be helpful for the interpretation of the estimates of the coefficients of these predictor variables if we visualize the predictions we can make, about how rating values vary, given differences in predictor variable values, given our model estimates. We can do this using functions from the {ggeffects} library. You can read more about the {ggeffects} library here where you will see a collection of articles explaining what you can do, and why, as well as technical information including some helpful tutorials.\nThe basic model prediction coding looks like this.\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\nplot(dat)\n\nFigure 4 shows you the marginal effect of variation in the reading strategy attribute, i.e., the effect of differences between individuals in how they score on the FACTOR3 measure of reading strategy. Note that the variable is listed as z_FACTOR3 because, as you will recall, we standardized numeric predictor variables before entering them in our model.\nThese kinds of plots are understood to present what are variously called conditional effects, or adjusted predictions or marginal effects. You can find a discussion of marginal effects in the context of working with the {ggeffects} library here and here. You can find an extensive, helpful (with examples) discussion of marginal effects by Andrew Heiss here.\nIn short, what we want to do is to take the model coefficient estimates, and generate predictions with these estimates, given different values of the predictor variable, while holding the other predictor variables at some constant or some level (or some series of values).\nIf you look at the code chunk, you can see that we first:\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\n\n\nIn this line, we use ggpredict() to work with some model information, assuming we previously fitted a model and gave it a name (here, health.clmm).\n\nNote that if you fit the model and call it health.clmm, as we did in Section 1.8, then an object of that name is created in the R workspace or environment. If you click on that object name in the environment window in R-Studio, you will see that there is a list of pieces of information about the model, including the coefficient estimates, the model formula etc. associated with that name.\n\nSo when we use ggpredict(), we ask R to take that model information and, for the term we specify, here, specify using terms=\"z_FACTOR3 [all]\", we ask R to generate some predictions.\ndat &lt;- ggpredict(...) asks R to put those predictions in an object called dat.\n\nIf you click on that object name in the environment window in R-Studio, you will see that it comprises a dataset. The dataset includes the columns:\n\nx giving different values of the predictor variable. ggpredict() will choose some ‘representative’ values for you but you can construct a set of values of the predictor for which you want predictions.\npredicted holds predicted values, given different predictor x values.\n\nIf you then run the line plot(dat) you can see what this gets us for these kinds of models. Figure 4 presents a grid of plots showing the model-predicted probabilities that a rating response will have one value for each of the 1-9 rating response values that are possible given the Likert rating scale used in data collection. In the grid, a different plot is shown for each possible response value, indicating how the probability varies that the rating response will take that value.\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\nplot(dat)\n\n\n\n\n\n\n\nFigure 4: A grid of plots showing marginal or conditional predicted probabilities that a rating response will have one value (among the 1-9 rating values possible), indicating how these predicted probabilities vary given variation in values of the standardized reading strategy (FACTOR3) variable.\n\n\n\n\n\nIf you examine Figure 4, you can recognize that we have one plot for each different value of the response options available for the Likert-scale rating items: 1-9. You can also see that in each plot we get a curve. In some cases – for rating response values 1-4 – the curve is flat or flattens very quickly, for higher levels of the z_FACTOR3 variable. In some cases – for rating response values 5-9 – the curve is more obvious, and resembles a normal distribution curve.\nIf you think about it, what these plots indicate are the ways in which the probability that a rating response is a low value (e.g., a rating of 1) or a high value (e.g., a rating of 9) rises or falls. Each possible rating response is associated with a probability distribution. For example, look at the plot labelled 6: that shows you the probability distribution indicating how the probability varies that a response will take the value 6. We can see that the distribution is normal in shape, a bell-shaped curve. We can see that the peak of the curve is over the z_FACTOR3 score (shown on the x-axis) of about 1.5. We can see that the probability represented by the height of the line showing the curve is lower for z_FACTOR3 scores lower than the score under the peak (e.g. scores less than z_FACTOR3 \\(=2\\)). The probability represented by the height of the line showing the curve is lower for z_FACTOR3 scores higher than the score under the peak (e.g. scores greater than z_FACTOR3 \\(=1\\)).\nWe can see that the peak of the normal curve, in the case of rating response values 5-9, is located at different places on the horizontal axis. Look at each of the plots labelled 5-9. Notice how the horizontal location of the curves shifts as z_FACTOR3 scores increase. If you go from left to right, i.e. from low to high values of z_FACTOR3, on each plot then you will see that the peak of the curve is located in different places: going from plot 5 to plot 9 the peak of the curve moves rightwards. These curves show how the probability that a rating response takes a high value (e.g. 9 instead of 8 or 8 instead of 7 etc.) is higher for higher values of z_FACTOR3. This idea might be a bit clearer if we draw the plot in a different way.\nFigure 5 shows the same model predictions but plots the predictions of the way that probability changes, for each rating response, by superimposing the plots for each response value, one on top of the other. I have drawn each probability curve in a different colour, and these colours match those used to present the counts of different response values shown in Figure 3.\n\ndat &lt;- ggpredict(health.clmm, terms=\"z_FACTOR3 [all]\")\nggplot(dat, aes(x, predicted, \n                colour = response.level)) + \n  geom_line(size = 1.5) +\n  scale_color_viridis(discrete=TRUE, option = \"mako\") + \n  labs(x = \"Reading strategy (z_FACTOR3)\", y = \"Predicted probability of a rating\") +\n  guides(colour = guide_legend(title = \"Rating\")) +\n  ylim(0, 1) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 5: A plot showing marginal or conditional predicted probabilities that a rating response will have one value (among the 1-9 rating values possible), indicating how these predicted probabilities vary given variation in values of the standardized reading strategy (FACTOR3) variable\n\n\n\n\n\nYou can read Figure 5 by observing that:\n\nFor low value ratings e.g. for rating responses from 1-4, there is not much predicted probability that a response with such a value will be made (flat lines) but if they are going to be made they are likely to be made by people with low scores on the z_FACTOR3.\n\nYou can see this because you can see how the curves peak around low values of z_FACTOR3. This should make sense: people with low scores on reading strategy are maybe not doing reading effectively, are maybe as a result not doing well in understanding the texts they are given to read, and thus are not confident about their understanding. (This is a speculative causal theory but it will suffice for now.)\nRecall, also, that as Figure 3 indicated, in the Clearly understood health comprehension dataset, we saw that few rating responses were recorded for low value ratings of understanding. Few people in our sample made rating responses by choosing ratings of 1 or 2 to indicate low levels of understanding.\nFigure 5 also suggests that:\n\nFor higher value rating responses – responses representing ratings from 5 to 9 – there is variation in the probability that responses with such values will be made.\nThat variation in probability is shown by the probability distribution curves.\nFor these data, and this model, we can see that the probability shifts suggesting that participants in our sample were more likely to choose a higher value rating if they were also presenting high scores on the z_FACTOR3 measure of reading strategy."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-reporting-results",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-reporting-results",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "As the review reported by Liddell and Kruschke (2018) suggests, we may have many many studies in which ordinal outcome data are analysed but very few published research reports that present analyses of ordinal data using ordinal models.\nYou can see two examples in the papers published by Ricketts, Dawson, and Davies (2021) and by Rodríguez-Ferreiro, Aguilera, and Davies (2020). These papers are both published open accessible, so that they are freely available, and they are both associated with accessible data repositories.\n\nYou can find the repository for Ricketts, Dawson, and Davies (2021) here.\nYou can find the repository for Rodríguez-Ferreiro, Aguilera, and Davies (2020) here.\n\nThe Rodríguez-Ferreiro, Aguilera, and Davies (2020) shares a data .csv only.\nThe Ricketts, Dawson, and Davies (2021) repository shares data and analysis code as well as a fairly detailed guide to the analysis methods. Note that the core analysis approach taken in Ricketts, Dawson, and Davies (2021) is based on Bayesian methods but that we also conduct clmm() models using the {ordinal} library functions discussed here; these models are labelled frequentist models and can be found under sensitivity analyses.\nFor what it’s worth, the Ricketts, Dawson, and Davies (2021) is much more representative of the analysis approach I would recommend now.\nWhatever the specifics of your research question, dataset, analysis approach or model choices, I would recommend the following for your results report.\n\nExplain the model – the advice extended by Meteyard and Davies (2020) still apply: the reader will need to know:\n\n\nThe identity of the outcome and predictor variables;\nThe reason why you are using an ordinal approach, explaining the ordinal (ordered, categorical) nature of the outcome;\nThe structure of the fixed effects part of the model, i.e. the effects, in what form (main effects, interactions) you are seeking to estimate;\nAnd the structure of the random effects part of the model, i.e. what grouping variable (participants? items?), whether they encompass random intercepts or random slopes or covariances.\n\nYou can report or indicate some of this information by presenting a table summary of the effects estimated in your model (e.g., see Table 5, Rodríguez-Ferreiro, Aguilera, and Davies 2020; see tables 2 and 3, Ricketts, Dawson, and Davies 2021). Journal formatting restrictions or other conventions may limit what information you can present.\nNotice that I do not present information on threshold estimates.\n\nExplain the results – I prefer to show and tell.\n\n\nPresent conditional or marginal effects plots (see figures 2 and 3, Ricketts, Dawson, and Davies 2021) to indicate the predictions you can make given your model estimates.\nAnd explain what the estimates or what the prediction plots appear to show."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-extensions",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-extensions",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "As I hint, when we discuss the concept that ordinal responses may map somehow to a latent unobserved underlying continuum (see Figure 1), there are other ways to think about ordinal data. Rather, there are other ways to think about the psychological mechanisms or the data generating mechanisms that give rise to the ordinal responses we analyse.\nIn Ricketts, Dawson, and Davies (2021), we explain:\n\nIn the semantic post-test, participants worked their way through three steps, only progressing from one step to the next step if they provided an incorrect response or no response. Given the sequential nature of this task, we analysed data using sequential ratio ordinal models (Bürkner & Vuorre, 2019). In sequential models, we account for variation in the probability that a response falls into one response category (out of k ordered categories), equal to the probability that it did not fall into one of the foregoing categories, given the linear sum of predictors. We estimate the k-1 thresholds and the coefficients of the predictors.\n\nWhat this explanation refers to is the fact that, in our study:\n\nThe semantic post-test assessed knowledge for the meanings of newly trained words. We took a dynamic assessment or cuing hierarchy approach (Hasson & Joffe, 2007), providing children with increasing support to capture partial knowledge and the incremental nature of acquiring such knowledge (Dale, 1965). Each word was taken one at a time and children were given the op- portunity to demonstrate knowledge in three steps: definition, cued definition, recognition.\n\nWe follow advice set out by Bürkner and Vuorre (2019) in modeling the ordered categorical (i.e. ordinal) responses using a sequential ratio approach."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#richly-parameterized-mixed-effects-models",
    "href": "PSYC412/part2/05-ordinal.html#richly-parameterized-mixed-effects-models",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "You will have noticed that the mixed-effects model coded in Section 1.8 incorporates a relatively simple random effect: a term specified to estimate the variance associated with the random effect of differences between participants in intercepts.\nAs we we have seen, more complex random effects structures may be warranted Matuschek et al. (2017). When we attempt to fit models with more complex structures, as we have discussed, for example, in ?@sec-dev-mixed-convergence-problems and ?@sec-glmm-bad-signs, we may run into convergence problems. (Such convergence problems are one reason why I tend to favour Bayesian methods; see, for exampe, the discussions in Bürkner and Vuorre (2019) and Liddell and Kruschke (2018).) There are ways to resolve these problems by changing the control parameters of the {ordinal} functions (see e.g. this discussion or see the information here) or by simplfying the model."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-summary",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-summary",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "We discussed ordinal data and the reasons why we are motivated to analyze ordinal data using ordinal models.\nWe examine the coding required to fit ordinal models.\nWe look at the results outputs from ordinal models, and visualizations representing the predictions that can be generated given ordinal model estimates.\nWe consider the kinds of information that results reports should include.\nWe examine possible extensions to ordinal models.\n\n\nWe used two functions from the {ordinal} library to fit and evaluate ordinal models.\n\nWe used clm() to fit an ordinal model without random effects.\nWe used clmm() to fit an ordinal mixed-effects model with fixed effects and random effects."
  },
  {
    "objectID": "PSYC412/part2/05-ordinal.html#sec-ordinal-recommended-reading",
    "href": "PSYC412/part2/05-ordinal.html#sec-ordinal-recommended-reading",
    "title": "Introduction to Ordinal Models",
    "section": "",
    "text": "The published example studies referred to in this chapter are published in (Ricketts, Dawson, and Davies 2021; Rodríguez-Ferreiro, Aguilera, and Davies 2020).\nLiddell and Kruschke (2018) present a clear account of the problems associated with treating ordinal data as metric, and explain how we can better account for ordinal data.\nBürkner and Vuorre (2019) present a clear tutorial on cumulative and sequential ratio models.\nBoth Liddell and Kruschke (2018) and Bürkner and Vuorre (2019) work from a Bayesian perspective but the insights are generally applicable.\nGuides to the {ordinal} model functions clm() and clmm() are presented in (Rune Haubo Bojesen Christensen 2022; R. H. B. Christensen 2015)."
  },
  {
    "objectID": "PSYC412/part2/references.html",
    "href": "PSYC412/part2/references.html",
    "title": "References",
    "section": "",
    "text": "References\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC412/part1/Week12.html",
    "href": "PSYC412/part1/Week12.html",
    "title": "2. Categorical predictors",
    "section": "",
    "text": "So far, all the predictors in the models we’ve looked at were continuous variables. What if you wanted to know whether a response differed between two or more discrete groups? Hang on, you might say, that sounds like doing an ANOVA. True, you might have used ANOVA to assess whether group means differed in previous stats courses. ANOVAs—to some degree—are just a special type of regression where you have categorical predictors. This week we’ll look at how to model responses as a function of categorical predictors and we’ll combine categorical predictors to model how a predictor might affect the outcome variable differently across two different groups. For example, we might be interested in whether the amount of time adolescents use digital devices (screen-time) predicts their well-being. Additionally, we might want to know whether well-being is different for adolescent boys and girls and whether the relationship between screen-time and well-being differs for these two groups. By fitting a regression model in which we combine a continuous (screen-time) and a categorical (sex) predictor, we can do exactly that. We’ll be working on that in the lab."
  },
  {
    "objectID": "PSYC412/part1/Week12.html#sec-wk12-lectures",
    "href": "PSYC412/part1/Week12.html#sec-wk12-lectures",
    "title": "2. Categorical predictors",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented in two parts. The videos have captions, in case you find that helpful. You can download the slides and the transcripts by clicking on the links below the videos.\n\nCategorical predictors (~17 min)\n\n\nSlides Transcript\n\nInteractions (~18 min)\n\n\nSlides Transcript\nIf you are (relatively) new to using R and RStudio and not yet confident in using various functions from the dplyr package, the video below will be useful:\n\nData wrangling with dplyr (~10 minutes) Watch this part before you complete the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript"
  },
  {
    "objectID": "PSYC412/part1/Week12.html#sec-wk12-reading",
    "href": "PSYC412/part1/Week12.html#sec-wk12-reading",
    "title": "2. Categorical predictors",
    "section": "Reading",
    "text": "Reading\n\nBlogpost by Professor Dorothy Bishop\nIn this very short blogpost Professor Dorothy Bishop explains the links between ANOVA and Regression.\n\n\nWinter (2020)\nLink\nChapter 7 provides an excellent overview of using categorical predictors in regression models and explains how this is implemented in R.\nChapter 8 explains what interactions are and how to model and interpret them."
  },
  {
    "objectID": "PSYC412/part1/Week12.html#sec-wk12-pre-labactivities",
    "href": "PSYC412/part1/Week12.html#sec-wk12-pre-labactivities",
    "title": "2. Categorical predictors",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Data-wrangling in R\nData comes in lots of different formats. One of the most common formats is that of a two-dimensional table (the two dimensions being rows and columns). Usually, each row stands for a separate observation (e.g. a participant), and each column stands for a different variable (e.g. a response, category, or group). A key benefit of tabular data is that it allows you to store different types of data-numerical measurements, alphanumeric labels, categorical descriptors-all in one place.\nIt may surprise you to learn that scientists actually spend far more of time cleaning and preparing their data than they spend actually analysing it. This means completing tasks such as cleaning up bad values, changing the structure of tables, merging information stored in separate tables, reducing the data down to a subset of observations, and producing data summaries. Some have estimated that up to 80% of time spent on data analysis involves such data preparation tasks (Dasu & Johnson, 2003)!\nMany people seem to operate under the assumption that the only option for data cleaning is the painstaking and time-consuming cutting and pasting of data within a spreadsheet program like Excel. We have witnessed students and colleagues waste days, weeks, and even months manually transforming their data in Excel, cutting, copying, and pasting data. Fixing up your data by hand is not only a terrible use of your time, but it is error-prone and not reproducible. Additionally, in this age where we can easily collect massive datasets online, you will not be able to organise, clean, and prepare these by hand.\nIn short, you will not thrive as a psychologist if you do not learn some key data wrangling skills. Although every dataset presents unique challenges, there are some systematic principles you should follow that will make your analyses easier, less error-prone, more efficient, and more reproducible.\nSome of the functions you’ll need in this week’s lab activity are listed below. You’ve used these functions before, but the following ‘recipes’ summarise what each one does and how to use it.\n\nTASK Have a look at each ‘recipe’ and read through it. Try to understand each step.\n\n\n\n\n\n\n\nRecipes - How to use them\n\n\n\nEach ‘recipe’ has the same structure.\n\nFirst, it summarises what it is that you want to achieve when using that specific function. In the case of select() it says “You want to extract specific columns from a data frame and return them as a new, smaller data frame.”\nThen, it outlines a number of steps that you need to carry out when using this function. For select() it outlines 2 steps: 1. Pass the dataframe to the function. 2. List the column(s) to return.\nFinally, there is an example talks you through using the function with some data. For select() it uses an example with data on the weather.\nAdditional information appears in extra boxes with a light-bulb icon. If you find those confusing, don’t worry about them at this stage.\n\n\n\nData wrangling:\n\nfilter() - extract observations (rows) - recipe\nmutate() - create a new variable (column) - recipe\ngroup_by() - organise the observations into groups - recipe\nsummarise() - compute summary statistics - recipe\n\nVisualisation:\n\ngeom_histogram() - draw a histogram - recipe\ngeom_line() - draw a line chart - recipe\n\nThe more you practise coding in R, the easier it will become.\n\n\n\n\n\n\nThe many ‘dialects’ of the R programming language\n\n\n\nPlease note that there are often different ways to do the same or similar things in R. This means you might encounter slightly different functions or styles of coding in different materials. This is not something to worry about. Just make sure you’re clear on what a bit of code achieves and choose the function/style that you feel most comfortable with.\n\n\n\n\nPre-lab activity 2: Getting ready for the lab class\n\nGet your files ready\nDownload the 402_week12_forStudents.zip file.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below."
  },
  {
    "objectID": "PSYC412/part1/Week12.html#sec-wk12-labactivities",
    "href": "PSYC412/part1/Week12.html#sec-wk12-labactivities",
    "title": "2. Categorical predictors",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply multiple regression to answer questions in psychological science\nconducting multiple regression in R when combining continuous and categorical predictors\ninterpreting the R output of multiple linear regression (when combining continuous and categorical predictors)\nreporting results for multiple linear regression (when combining continuous and categorical predictors), following APA guidelines\n\n\nLab activity 1: Combining a continuous and a categorical predictor in a regression model\n\nBackground: Smartphone screen-time and well-being\nThere is currently much debate (and hype) surrounding smartphones and their effects on well-being, especially with regard to children and teenagers. We’ll be looking at data from this recent study of English adolescents: Przybylski, A. & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis. Psychological Science, 28, 204–215.\nThis was a large-scale study that found support for the “Goldilocks” hypothesis among adolescents: that there is a “just right” amount of screen-time, such that any amount more or less than this amount is associated with lower well-being. This was a huge survey study with data containing responses from over 120,000 participants! Fortunately, the authors made the data from this study openly available, which allows us to dig deeper into their results. And the question we want to expand on in this lab is whether the relationship between screen-time and well-being depends on the partcipant’s (self-reported) sex. In other words, our research question is: Does screen-time have a bigger impact on boys or girls, or is it the same for both?\nThe dependent measure used in the study was the Warwick-Edinburgh Mental Well-Being Scale (WEMWBS). This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70.\nOn Przybylski & Weinstein’s page for this study on the Open Science Framework, you can find the participant survey, which asks a large number of additional questions (see page 14 for the WEMWBS questions and pages 4-5 for the questions about screen-time). Within the same page you can also find the raw data, which some of you might want to consider using for your research report.\nHowever, for the purpose of this lab, you will be using local pre-processed copies of the data (participant_info.csv, screen_time.csv and `wellbeing.csv, which you downloaded as part of the ‘Pre-lab activities’.\nPrzybylski and Weinstein looked at multiple measures of screen-time, but again for the interests of this lab we will be focusing on smartphone use, but do feel free to expand your skills after by looking at different definitions of screen-time. Overall, Przybylski and Weinstein suggested that decrements in well-being started to appear when respondents reported more than one hour of daily smartphone use. So, bringing it back to our additional variable of sex, our research question is now: Does the negative association between hours of smartphone use and well-being (beyond the one-hour point) differ for boys and girls?\nLet’s think about this in terms of the variables. We have:\n\na continuous outcome variable: well-being;\na continuous∗ predictor variable: screen-time;\na categorical predictor variable: sex.\n\nPlease note that well-being and screen-time are technically only quasi-continuous inasmuch as that only discrete values are possible. However, there are a sufficient number of discrete categories in our data that we can treat the data as effectively continuous.\nNow, in terms of analysis, what we are effectively trying to do is to estimate two slopes relating screen-time to well-being, one for adolescent girls and one for adolescent boys, and then statistically compare these slopes. Sort of like running a correlation for boys, a correlation for girls, and comparing the two. Or alternatively, where you would run a regression (to estimate the slopes) but also one where you would need a t-test (to compare two groups). But the expressive power of regression allows us to do this all within a single model. Again, as we have seen building up to this lab, an independent groups t-test is just a special case of ordinary regression with a single categorical predictor; ANOVA is just a special case of regression where all predictors are categorical. But remember, although we can express any ANOVA design using regression, the converse is not true: we cannot express every regression design in ANOVA. As such people like regression, and the general linear model, as it allows us to have any combination of continuous and categorical predictors in the model. The only inconvenience with running ANOVA models as regression models is that you have to take care in how you numerically code the categorical predictors. We will use an approach called deviation coding which we will look at today later in this lab.\nTo complete this lab activity, you can use the R-script (402_wk12_labAct1_template.R) that you downloaded as part of the ‘Pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\nStep 1: Background and set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/participant_info.csv?raw=true\", destfile = \"participant_info.csv\")\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/screen_time.csv?raw=true\", destfile = \"screen_time.csv\")\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/wellbeing.csv?raw=true\", destfile = \"wellbeing.csv\")\n\n\nTASK: Finally, read in the three data files; call the participant info pinfo; call the screen_time data screen and the well-being data wellbeing.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\npinfo &lt;- read_csv(\"participant_info.csv\")                                   \nscreen &lt;- read_csv(\"screen_time.csv\")\nwellbeing &lt;- read_csv(\"wellbeing.csv\")\n\n\n\n\n\nStep 2: Checking the formatting\nGiven our research question and the information you have about the scores, provided above under ‘Background’ and from the OSF-webpage, is the data ready for use?\n\nTASK: Add code to look at the first few lines of each data frame.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the head() function (or tail() function).\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nhead(pinfo)                                  # Look at the data frames\nhead(screen)\nhead(wellbeing)\n\n\n\n\nQUESTION 2a: In which table is the variable corresponding to sex located and what is this variable called?\n\nThe ‘source and analysis code.sps’ file in the ‘Data and Code’ section on the OSF-webpage tells us how they coded the sex variable: 0 = female indicator and 1 = male indicator. It is worth exploring the OSF-webpage, to get used to foraging other files for these kinds of information, as they are not always clearly explained in a codebook or README. file.\n\nTASK: For ease, lets recode the sex variable to reflect word labels of ‘female’ and ‘male’. This doesn’t change the order: R will still see female as 0, and male as 1 because female occurs before male in the alphabet. Add the code below to your script to do this. Don’t forget to run it as well.\n\n\npinfo$sex &lt;- ifelse(pinfo$sex == 1, \"male\", \"female\")\nhead(pinfo)\n\n\nQUESTION 2b: In what format is the well-being data (long or wide)? On how many participants does it include observations? And on how many items for each participant?\n\n\nQUESTION 2c: What is the name of the variable that identifies individual participants in this dataset? It is important to work this out as this variable will allow us to link information across the three data files.\n\n\n\nStep 3: Data preparation - Aggregating the total well-being scores\nWe need to sum the 14 items of the well-being scale for each participant to create one well-being score per participant.\n\nTASK: To create one well-being score per participant, add code to the script to do the following: first, transform the well-being data frame from wide to long (using pivot_longer()); then, use group_by() to get scores for each participant and finally use summarise() to calculate a total well-being score, calling the new variable tot_wellbeing. Save all of this to an object called wb_tot.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a code template. Make sure to add the relevant sections.\nwb_tot &lt;- DATA %&gt;%\n  pivot_longer(-Serial, names_to = \"\", values_to = \"\") %&gt;%\n  group_by(?) %&gt;%\n  summarise(tot_wellbeing = sum(?))\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nwb_tot &lt;- wellbeing %&gt;%\n  pivot_longer(-Serial, names_to = \"question\", values_to = \"score\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tot_wellbeing = sum(score))\n\n\n\nIt is useful to calculate some descriptive statistics for the new variable tot_wellbeing.\n\nTASK: Calculate some descriptive statistics for tot_wellbeing.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse summarise() to calculate the mean, standard deviation, minimum and maximum values.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nwb_tot %&gt;% summarise(mean = mean(tot_wellbeing),\n                     sd = sd(tot_wellbeing),\n                     min = min(tot_wellbeing), \n                     max = max(tot_wellbeing))\n\n\n\nFinally, let’s get an idea of the distribution of the new variable tot_wellbeing.\n\nTASK: Visualise the distribution in a histogram.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse ggplot() and geom_historgram().\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(wb_tot, aes(tot_wellbeing)) +\n  geom_histogram() \n\n\n\n\nQUESTION 3a: Is the distribution of well-being scores symmetrical, negatively skewed or positively skewed?\n\n\n\nStep 4: Data preparation - Transforming screen time data\nGreat, so we have the well-being scores sorted out, we now need to think about the screen-time usage data and whether it is being used on a weekday or a weekend. As always, to get an idea of the data, it is often very useful to visualise the variables before proceeding with the analysis.\nBefore we can do this, we’ll need to tidy these data up. Have another look at the screen data by using the head() function. You’ll see that we have Serial in the first column (this is good), but in the following eight columns, we have columns for each type of activity (Comph, Comp, Smart, Watch) and the part of the week it took place (we and wk) combined. Instead, to be able to work with the data, we need two columns: one for the type of activity (we’ll call it variable) and one for the part of the week (we’ll call it day).\nA second issue is that we need to alter the abbreviations Comph, Comp, Smart and Watch to reflect more descriptive text for each in plots.\nBelow are two chunks of code that represent these steps. In the next tasks you’ll practise with taking a set of piped commands apart. The purpose of this is to get you used to “parsing” the code at the right places so that when you see piped commands in other people’s code, you know how to break it down and find the relevant parts that you can use.\n\nTASK: In the code chunk below we use the separate() function to split the character strings already in the dataset. You know that with piped commands, there are chunks of code. Run the code first in its entirety and then pull each line apart to see how each function works on the data. Write a descriptive sentence for each function’s role in the command. Don’t forget to copy the chunk to your script and run it.\n\n\nscreen_long &lt;- screen %&gt;%\n  pivot_longer(-Serial, names_to = \"var\", values_to = \"hours\") %&gt;%\n  separate(var, c(\"variable\", \"day\"), \"_\")\n\n\nTASK: In the next code chunk we use the dplyr::recode() function with mutate() to relabel the separated names into understandable names that will be clear in plots. Again, run the code first in its entirety and then pull each line apart to see how each function works on the data. Write a descriptive sentence for each function’s role in the command. Don’t forget to copy the chunk to your script and run it.\n\n\nscreen2 &lt;- screen_long %&gt;%\n  mutate(variable = dplyr::recode(variable,\n                                  \"Watch\" = \"Watching TV\",\n                                  \"Comp\" = \"Playing Video Games\",\n                                  \"Comph\" = \"Using Computers\",\n                                  \"Smart\" = \"Using Smartphone\"),\n         day = dplyr::recode(day,\n                             \"wk\" = \"Weekday\",\n                             \"we\" = \"Weekend\"))\n\n\n\n\n\n\n\nTip\n\n\n\nThe code above has a new feature: the dplyr::recode part. This syntax – using the double colon – happens when there are many versions of a function with the same name. You can imagine that a function called ‘recode’ is immensely useful at the data wrangling stage of analysis. By using the name of the package, a double set of colons, followed by a function name, you are ensuring that R uses a particular version of the function, at that point only. This avoids having two or more packages loaded in your environment that sometimes do not play nicely together!\n\n\nTo be able to monitor that your code is performing as you want it to, you need to have in your mind an idea of how the data should look at the end of a code chunk. So stop a moment and be clear, discuss with your lab-mates if you feel like it and answer the following question.\n\nQUESTION 4a: What are the variables and the levels or conditions within each variable of screen2?\n\n\nTASK:Now join wb_tot and screen_2 by participant and then group by the variables ‘variable’, ‘day’ and ‘hours’ and then calculate a ‘mean_wellbeing’ variable for each of the grouped levels. Save it in an object called ‘dat_means’.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nWrite separate lines of code for each action and then, when you know each of them works, reformat them as a piped command. You’ll need inner_join(), group_by() and summarise().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow templates for separate lines of code for each action. You’ll need to replace the names of relevant data frames and variables.\njoined &lt;- inner_join(data1, data2, by=)\ngrouped &lt;- group_by(data, var1, var2, var3)\nmeans &lt;- summarise(data, mean = mean(variable))\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nBelow the code for a piped command.\ndat_means &lt;- inner_join(wb_tot, screen2, \"Serial\") %&gt;%\n  group_by(variable, day, hours) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\n\n\n\nTASK: Now check that you have an object that is 72 observations of 4 variables. You should have a mean wellbeing score for every level of the hours, over weekdays and weekends for each level of the four types of screen time (4 x 2 x 9)\n\nNext, it is a good idea to visualise the mean well-being data as function of hours of screen-time for the different days (weekday vs. weekend) and types of screen (playing video games, using computers, using smartphone and watching tv). This is quite a complex graph. We’ll go through creating it step-by-step, but let’s first look at the end result:\n\nOk, that’s what we are working towards.\n\nTASK: Below, a chunk of code is presented. It is your task to fill in the x and y variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nGo back to the research question - which variable is for the x axis and for the y axis?\n\n\n\n\nggplot(dat_means, aes(x = , y = )) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat_means, aes(x = hours, y = mean_wellbeing,)) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\nQUESTION 4b: What research question does this plot describe? Is it appropriate for the levels within the data?\n\nTASK: Now, let’s add a different linetype for each day (weekday vs. weekend). Fill in the blanks in the code below.\n\n\nggplot(dat_means, aes(x = , y = , linetype = )) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat_means, aes(x = hours, y = mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\nQUESTION 4c: What research question does this plot describe? Is it appropriate for the levels within the data?\nStill not quite there.\n\nTASK: Fill in the blanks (for x, y and linetype) as before. Now have a good look at the code below. What has changed? Copy the code to your script and run it. Then, for each line write a sentence as a comment to describe its effect on the plot.\n\n\nggplot(dat_means, aes(x = , y = , linetype = )) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~variable, nrow = 2) +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat_means, aes(hours, mean_wellbeing, linetype = day)) + # plot 'hours' on the x-axis, 'mean_wellbeing' on the y-axis and use a different type of line for the levels of 'day'\n  geom_line() + # add a line\n  geom_point() + # add point data\n  facet_wrap(~variable, nrow = 2) + # plot separate plots for each level of 'variable'\n  theme_bw() # use the 'black and white' theme\n\n\n\nWe add the facet_wrap() function here. You can check the ?facet_wrap() help page for more information.\nQUESTION 4d: c. What does the facet_wrap() function do? Is this plot appropriate for the levels in the data?\n\n\nStep 5: Calculating mean hours per day for smartphone use, for each participant\nAs mentioned at the beginning, in today’s lab we’ll focus on smartphone use. So looking at the bottom left of the figure we could suggest that smartphone use of more than 1 hour per day is associated with increasingly negative well-being the longer screen time people have. This looks to be a similar effect for Weekdays and Weekends, though perhaps overall well-being in Weekdays is marginally lower than in Weekends (the line for Weekday is lower on the y-axis than Weekends). This makes some sense as people tend to be happier on Weekends!\n\nTASK: Below is a set of comments that describe what the chunk of code that you need to write next does:\n\n\n\n#use ‘screen2’\n#and then filter out the observations for ‘Using Smartphone’,\n#and then group together each participant,\n#and then summarise the mean hours calling it ‘hours_per_day’,\n#save it in an object called ‘smarttot’\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code you need. Try to fill in the relevant bits:\nNEW_OBJECT &lt;- DATA %&gt;%\n  filter(variable == \"?\") %&gt;%\n  group_by(VARIABLE) %&gt;%\n  summarise(new_measure = mean(VARIABLE))\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nsmarttot &lt;- screen2 %&gt;% # use 'screen2'\n  filter(variable == \"Using Smartphone\") %&gt;% # filter out the observations for 'Using Smartphone'\n  group_by(Serial) %&gt;% # group together each participant\n  summarise(hours_per_day = mean(hours)) #summarise the mean hours calling it 'hours_per_day'\n\n\n\n\nTASK: Now let’s do it the other way around. Run the code below. Have a look at the structure of ‘smart_wb’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the str() function.\n\n\n\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(hours_per_day &gt; 1) %&gt;%\n  inner_join(wb_tot, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") %&gt;%\n  mutate(sex = as.factor(sex))\n\n\nQUESTION 5a: What does the code do? Write a short paragraph, using the phrase “and then” to represent the pipes.\n\n\n\nStep 6: More visualisation\nWe are now using only one small part of the data - smartphone use and its relationship with well-being over different durations of time. Before formally testing our research question, we can visualise the data and enquire about sex differences on the same plot - run each chunk of code below:\n\nTASK To further group the data, copy the code below to your script and run it. Look at the ‘smart_wb_gen’ dataframe. What has the code above done? Write a couple of sentences of description.\n\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  group_by(hours_per_day, sex) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\n\nTASK: Let’s visualise these data.\n\n\nggplot(smart_wb_gen, aes(hours_per_day, mean_wellbeing, color = sex)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_discrete(name = \"Sex\", labels = c(\"Girls\", \"Boys\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\") +\n  theme_bw()\n\n\nQUESTION 6a: Write an interpretation of the above plot in plain English.\n\n\n\nStep 7: The regression model\nIn the steps 2 to 6 we’ve covered some pretty heavy-lifting data-wrangling. As it is so often the case that something like this is needed when working with real data, ti is really important to practise this. However, to ensure you also spend time on fitting the regression model and interpreting the output, you can choose to use the data-file smart_wb.csv to get started with that. It contains the data in a format that is the result of all the data-wrangling we did in steps 2 to 6. So, download the smart_sb.csv data-file, put it in the folder that is your working directory and you’re all set for running the regression model.\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/smart_wb.csv?raw=true\", destfile = \"smart_wb.csv\")\n\n\nTASK: Let’s run the regression. Write code in your script in which you call your output ‘mod’, and use the data ‘smart_wb’ using the following formula, lm(y ~ x1 + x2 + x1:x2, data) to construct your regression model. Go back to the research question for your outcome and two predictor variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the following template:\nmod &lt;- lm(y ~ x1 + x2 + x1:x2, data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod &lt;- lm(tot_wellbeing ~ hours_per_day + sex + hours_per_day:sex, smart_wb)\n\n\n\n\nTASK: Call and save the summary of your model as ‘mod_summary’; then have a look at it.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_summary &lt;- summary(mod)\nmod_summary\n\n\n\nLet’s first look at the model as a whole:\n\nQUESTION 7a: What is the p-value for the overall model? Is it significant? What does this mean?\n\n\nQUESTION 7b: To two decimal places, what percentage of the variance in well-being scores does the overall model explain?\n\nNow, lets look at the coefficients of our predictors:\n\nQUESTION 7c: Are the main effects of smartphone use and sex significant?\n\n\nQUESTION 7d: Which variable indicates the interaction between smartphone use and sex?\n\n\nQUESTION 7e: And is the interaction significant?\n\n\nQUESTION 7f: What is the most reasonable interpretation of these results?\n\nThe above model uses treatment coding (sometimes called dummy coding), for the sex variable. In a categorical variable with only two levels this means that one level is coded as 0 and the other level is coded as 1. In categorical variables with more than two levels, it works slightly differently.\n\nTASK: We can check that the sex variable is treatment with the following code:\n\n\ncontrasts(smart_wb$sex)\n\nBecause we have not explicitly told R about the labels for the sex variable, it has used level 0 as the reference level, hidden within the intercept term and level sex1 describes the difference (or slope) between level 0 and 1 or in this dataset from female to male.\n\nQUESTION 7g: Is being Male better for a person’s well-being in the context of smartphone use than being Female?\n\nNow let’s look at deviation coding. There are other ways to code your categorical variables. One of them is deviation coding (also sometimes called sum coding). This effectively divides the difference of the values between your categorical levels by the number of levels so that each level can be compared to one intercept that is central to them all rather than comparing levels to one reference level. It is like centering for a categorical level.\n\nTASK Use the code chunk below to: 1) Add a variable to the smart_wb data that is a deviation coding of sex; 2) Set the deviation coding (we’ll label it ‘Sum’ here for easy variable naming); and 3) Look at the output for the sum-coded sex variable.\n\n\nsmart_wb &lt;- mutate(smart_wb, sexSum = sex) # add a variable to the smart_wb data that is a deviation coding of sex\ncontrasts(smart_wb$sexSum) &lt;- contr.sum(2) # wet the deviation coding\ncontrasts(smart_wb$sexSum) # look at the output for the sum coded sex variable\n\nNext, we’ll run the regression again, using the sum-coded sex variable and we’ll compare the outputs.\n\n# Run the regression model again, using the sumcoded sex model and compare outputs\nmod_S &lt;- lm(tot_wellbeing ~ hours_per_day + sexSum + hours_per_day:sexSum, smart_wb)\nmod_S_summary &lt;- summary(mod_S)\n\n# Compare the two model summary outputs\nmod_summary\nmod_S_summary\n\n‘sexSum1’ is now the coefficient for sex and represents the change from the intercept value which now lies between the values for being Female and Male. Note how this coefficient is negative.\nThe earlier model had a positive coefficient because the intercept described the reference group of the Girls, who on average begin at a lower well-being level than Boys (refer back to the scatterplot to verify this). Because the sum-coding has moved the intercept to a point that is the center of the difference between Boys and Girls, sexSum1 now describes the distance between the centre and a level of Sex.\nValues for well-being in Girls are thus: \\[ Intercept + sexSum*+1 = 49.74 + (-1.61)*(+1) \\]\nValues for well-being in Boys are thus: \\[Intercept + sexSum*-1 = 49.74 + (-1.61)*(-1)\\]\nwith the Boys being higher in well-being…(remember a negative number multiplied by a negative number produces a positive number and a negative number multiplied by a positive number produces a negative number).\nThe interpretation of both model effects is the same, and if you look at the summary statistics, they are identical. Deviation coding effectively centers your categorical variables and helps with interpretation of interaction terms.\n\n\nStep 8: Checking assumptions\nNow that we’ve fit a model, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity. With regression models, you do this after you’ve actually fit the model.\nLinearity Unlike when we did simple regression we can’t use crPlots() to test for linearity when there is an interaction, but we know from looking at the grouped scatterplot that this assumption has been met.\nNormality Normally we would test for normality with a QQ-plot and a Shapiro-Wilk test. However, because this dataset is so large, the Shapiro-Wilk is not appropriate (if you try to run the test it will produce a warning telling you that the sample size must be between 3 and 5000). This is because with extremely large sample sizes the Shapiro-Wilk test will find that any deviation from normality is significant. Therefore we should judge normality based upon the QQ-plot.\n\nTASK: Create a QQ-plot to check the residuals are normally distributed.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the qqPlot() function. The residuals are stored in the ‘mod’ object you created earlier.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nqqPlot(mod$residuals)\n\n\n\n\nQUESTION 8a: What do you conclude from the QQ-plot?\n\nHomoscedasticity Here we have the same problem as with testing for normality: with such a large sample the ncvTest() will produce a significant result for any deviation from homoscedasticity. So we need to rely on plots again. To check for homoscedasticity we can use plot() from Base R that will produce a bunch of helpful plots (more information here:.\n\nTASK: Copy the code chunk below to your script and run it.\n\n\npar(mfrow=c(2,2))             # 4 charts in 1 panel\nplot(mod)                     # this may take a few seconds to run\n\nThe residuals vs leverage plot shows a flat red line so, whilst it isn’t perfect, we can assume that with such a large sample size regression is still an appropriate analysis.\nMulti-collinearity Finally, lets check for multicollinearity using the vif() function. Essentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. Thankfully, vif is not affected by large samples like the other tests. There are various rules of thumb, but most converge on a VIF of above 2 to 2.5 for any one predictor being problematic.\n\nTASK: Copy the code chunk below to your script and run it.\n\n\nvif(mod)                      # Check for multi-collinearity\n\n\nQUESTION 8b: Do any of the predictors show evidence of multicollinearity?\n\n\n\nStep 9: Write up\n\nQUESTION 9a: How would you write up the results following APA guidance? You can choose whether you do so for the model using treatment coding or for the model using deviation coding."
  },
  {
    "objectID": "PSYC412/part1/Week12.html#sec-wk12-answers",
    "href": "PSYC412/part1/Week12.html#sec-wk12-answers",
    "title": "2. Categorical predictors",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk12_labAct1_withAnswers.R.\n\nLab activity 1: Combining a continuous and a categorical predictor in a regression model\n2a. In which table is the variable corresponding to sex located and what is this variable called? In pinfo; the variable is called sex.\n2b. In what format is the well-being data (long or wide)? On how many participants does it include observations? And on how many items for each participant? The well-being data are in ‘wide’ format. It contains observations on 102580 participants, on 14 items.\n2c. What is the name of the variable that identifies individual participants in this dataset? It is important to work this out as this variable will allow us to link information across the three data files. Serial\n3a. Is the distribution of well-being scores symmetrical, negatively skewed or positively skewed? Negatively skewed\n4a. What are the variables and the levels or conditions within each variable of screen2?\nParticipants plus: Levels: variables = 4: watching tv, playing video games, using computers, using smartphone day = 2 = weekdays, weekends hours = 9 = 0, 0.5, 1 - 7\n4b. What research question does this plot describe? Is it appropriate for the levels within the data? The plot describes how hours of use impact upon well-being? No, it is too broad a research question.\n4c. What research question would fit this visualisation?Is it appropriate for the levels in the data? The hours are now displayed by weekdays and weekends. How do hours of screen time impact on well-being on weekdays and at the weekend? No, it is still too broad.\n4d. What does the facet_wrap() function do? Is this plot appropriate for the levels in the data? The facet_wrap() function has split the types of screen time and shown how hours of use across weekdays and weekends impact upon well-being. This captures the levels of information within the dataset.\n5a. See the script\n6a. Write an interpretation of the above plot in plain English. Something along the lines of: Adolescent girls show lower overall well-being compared to adolescent boys. In addition, the slope for girls appears more negative than that for boys; the one for boys appears relatively flat. This suggests that the negative association between well-being and smartphone use is stronger for girls.\n7a. What is the p-value for the overall model? Is it significant? What does this mean? The p-value for the overall model fit is &lt; 2.2e-16. This significant. It means that together the predictors describe the variance in well-being better than a model without the predictors (the null model). So knowing something about smartphone use and sex of participants will allow us to predict their well-being to a degree.\n7b. To two decimal places, what percentage of the variance in well-being scores does the overall model explain? 9.38%\n7c. Are the main effects of smartphone use and sex significant? Yes.\n7d. Which variable indicates the interaction between smartphone use and sex? The interaction is indicated by the variable hours_per_day:sex.\n7e. And is the interaction significant? Yes.\n7f. What is the most reasonable interpretation of these results? Smartphone use was more negatively associated with well-being for girls than for boys.\n7g. Is being Male better for a person’s well-being in the context of smartphone use than being Female? Yes.\n8a. What do you conclude from the QQ-plot? The residuals are normally distributed.\n8b. Do any of the predictors show evidence of multicollinearity? Yes, Boys and the interaction do. We’ll talk about that more, later in the module.\n\nWrite up\n\nTreatment / dummy coded model Treatment coding was used for categorical predictors with the Girls level acting as the reference group. The results of the regression indicated that the model significantly predicted well-being (F(3, 71029) = 2450.89, p &lt; .001, Adjusted R2 = 0.09), accounting for 9% of the variance.Total hours of smart phone use was a significant negative predictor of well-being scores (β = -0.77, p &lt; .001, as was sex (β = 3.22, p &lt; .001), with girls having lower well-being scores than boys. Importantly, there was a significant interaction between screen time and sex (β = 0.45, p &lt; .001): smartphone use was more negatively associated with well-being for girls than for boys.\nDeviation / sum coded model Deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted well-being (F(3, 71029) = 2450.89, p &lt; .001, Adjusted R2 = 0.09), accounting for 9% of the variance. Total hours of smart phone use was a significant negative predictor of well-being scores (β = -0.55, p &lt; .001, as was sex (β = -1.61, p &lt; .001), with girls having lower well-being scores than boys. Importantly, there was a significant interaction between screen time and sex (β = -0.22, p &lt; .001), indicating that smartphone use was more negatively associated with well-being for girls than for boys."
  },
  {
    "objectID": "PSYC412/part1/Week11.html",
    "href": "PSYC412/part1/Week11.html",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "",
    "text": "Before we start covering new material, we want to spent some time on recapping the basic concepts of the linear model (correlation, simple regression, multiple regression). You all come from different educational backgrounds and therefore have vastly different knowledge of, and experience with statistics. Therefore, please follow your own judgement as to whether you feel you want to/need to revisit material outlining the theoretical background to and the practical implementation in R for these topics. Below we provide some guidance as to materials that are relevant. Just to be clear: We don’t expect you to watch and/or read and/or do everything, please have a look at what you feel you need and spend some time with those materials."
  },
  {
    "objectID": "PSYC412/part1/Week11.html#sec-wk11-lectures",
    "href": "PSYC412/part1/Week11.html#sec-wk11-lectures",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Lectures",
    "text": "Lectures\nThe linear model was discussed in weeks 6 to 9 of PSYC401, so that is a good place to start.\nAlternatively, if you don’t feel confident about the material, these recorded lectures might help.\n\nThe linear model: theory (~30 min) An introduction to the linear model and linear regression. I follow material as discussed in Chapter 4 of Bodo Winter’s book Statistics for Linguists: An Introduction using R (see below under ‘Reading’).\nHow to build a linear model in R (~14 min) In this video I demonstrate how to build a linear model in R by talking you through a simple linear regression script (you can download it by clicking on the link below the video). If you are unclear on what different parts of the lm() function do, or how to read the output, this video might help clarify that.\n\n\nSlides Transcript Example R-script\n\nMultiple regression: theory (~35 min) An introduction to multiple regression. I follow material as discussed in Chapter 5 of Bodo Winter’s book Statistics for Linguists: An Introduction using R (see below under ‘Reading’).\nCentering and standardising (~5 min) Brief explanation of what centering and standardising are."
  },
  {
    "objectID": "PSYC412/part1/Week11.html#sec-wk11-reading",
    "href": "PSYC412/part1/Week11.html#sec-wk11-reading",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Reading",
    "text": "Reading\n\nMiller & Haden (2013)\nLink\nChapter 10 gives you a brief overview of what correlation and regression are. Chapter 11 introduces correlation in more detail. Chapters 12 and 14 provide accessible overviews of simple and multiple regression, respectively. All these chapters are really short but provide a good basis to understanding. We consider this the minimum level of understanding you should acquire.\n\n\nWinter (2020)\nLink\nChapter 4 provides and excellent conceptual introduction to the linear model and also explains how this is implemented in R (highly recommended).\nChapter 5 takes a slightly different approach to the one taken in Miller & Haden (2013) to introducing correlation. If you already understand the basic theory behind correlation, this will be an interesting read. Chapter 5 also clearly explains what centering and standardizing are and why you need to bother with these linear transformations.\nChapter 6 provides an excellent overview of multiple regression and also explains how this is implemented in R."
  },
  {
    "objectID": "PSYC412/part1/Week11.html#sec-wk11-pre-labactvities",
    "href": "PSYC412/part1/Week11.html#sec-wk11-pre-labactvities",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualising the regression line\nHave a look at this visualisation of the regression line by Ryan Safner.\nIn this shiny app, you see a randomly-generated set of data points (within specific parameters, to keep the graph scaled properly). You can choose a slope and intercept for the regression line by using the sliders. The graph also displays the residuals as dashed red lines. Moving the slope or the intercept too much causes the generated line to create much larger residuals. The shiny app also calculates the sum of squared errors (SSE) and the standard error of the regression (SER), which calculates the average size of the error (the red numbers). These numbers reflect how well the regression line fits the data, but you don’t need to worry about those for now.\nIn the app he uses the equation Y = aX + b in which b is the intercept and a is the slope.\nThis is slightly different from the equation you saw during the lecture. There we talked about Y = b0 + b1*X + e. Same equation, just different letters. So b0 in the lecture is equivalent to b in the app and b1 in the lecture is equivalent to a in the app.\nPre-lab activity questions:\n\nChange the slider for the intercept. How does it change the regression line?\nChange the slider for the slope. How does it change the regression line?\nWhat happens to the residuals (the red dashed lines) when you change the slope and the intercept of the regression line?\n\n\n\nPre-lab activity 2: Data-wrangling in R\nIn PSYC401, you’ve already learned how to read in data, how to select variables and how to compute summary statistics, so re-visiting the PSYC401 materials is a good place to start.\nRStudio also provides some useful interactive tutorials that take you through the basics:\n\nThe Basics Start here to learn how to inspect, visualize, subset and transform your data, as well as how to run code.\nWork with Data Learn how to extract values form a table, subset tables, calculate summary statistics, and derive new variables.\nVisualize Data Learn how to use ggplot2 to make any type of plot with your data. The tutorials on Exploratory Data Analysis and Scatterplots are particularly relevant.\n\nPlease note that there are often different ways to do the same or similar things in R. This means you might encounter slightly different functions or styles of coding in different materials. This is not something to worry about. Just make sure you’re clear on what a bit of code achieves and choose the function/style that you feel most comfortable with.\n\n\nPre-lab activity 3: Getting ready for the lab class\n\nRemind yourself of how to access and work with the RStudio Server.\n\nRevisit PSYC401 to remind yourself of how to access the RStudio Server.\n\n\n\nGet your files ready\nDownload the 402_week11_forStudents.zip file and upload it into a new folder in RStudio Server."
  },
  {
    "objectID": "PSYC412/part1/Week11.html#sec-wk11-labactivities",
    "href": "PSYC412/part1/Week11.html#sec-wk11-labactivities",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply simple and multiple regression to answer questions in psychological science\nconducting multiple regression in R\ninterpreting the R output of simple and multiple linear regression\nreporting results for simple and multiple linear regression following APA guidelines\n\n\nLab activity 1: Interpreting and reporting results\nHave a look at the R output below.\nR Output 1\n\n\nWhat is the outcome or dependent variable?\nWhat is the predictor or independent variable?\nIs the overall model significant?\nHow much variance does the model account for?\n\nThinking about assumptions, what do you conlcude from the plots and output below?\n\nDoes the relationship appear linear?\nDo the residuals show normality and homoscedasticity?\n\nScatterplot\n\nQQ-plot\n\nR Output 2\n\n\n\nLab activity 2: Conducting simple and multiple regression\n\nBackground\nToday, to help get a practical understanding of regression, you will be working with real data and using regression to explore the question of whether there is a relationship between voice acoustics and ratings of perceived trustworthiness.\n\nThe Voice\nThe prominent theory of voice production is the source-filter theory (Fant, 1960) which suggests that vocalisation is a two-step process: air is pushed through the larynx (vocal chords) creating a vibration, i.e. the source, and this is then shaped and moulded into words and utterances as it passes through the neck, mouth and nose, and depending on the shape of those structures at any given time you produce different sounds, i.e. the filter. One common measure of the source is pitch (otherwise called Fundamental Frequency or F0 (F-zero)) (Titze, 1994), which is a measure of the vibration of the vocal chords, in Hertz (Hz); males have on average a lower pitch than females for example. Likewise, one measure of the filter is called formant dispersion (measured again in Hz), and is effectively a measure of the length of someone’s vocal tract (or neck). Height and neck length are suggested to be negatively correlated with formant dispersion, so tall people tend to have smaller formant dispersion. So all in, the sound of your voice is thought to give some indication of what you look like.\nMore recently, work has focussed on what the sound of your voice suggests about your personality. McAleer, Todorov and Belin (2014) suggested that vocal acoustics give a perception of your trustworthiness and dominance to others, regardless of whether or not it is accurate. One extension of this is that trust may be driven by malleable aspects of your voice (e.g. your pitch) but not so much by static aspects of your voice (e.g. your formant dispersion). Pitch is considered malleable because you can control the air being pushed through your vocal chords (though you have no conscious control of your vocal chords), whereas dispersion may be controlled by the structure of your throat which is much more rigid due to muscle, bone, and other things that keep your head attached. This idea of certain traits being driven by malleable features and others by static features was previously suggested by Oosterhof and Todorov (2008) and has been tested with some validation by Rezlescu, Penton, Walsh, Tsujimura, Scott and Banissy (2015).\nSo, the research question today is: Can vocal acoustics, namely pitch and formant dispersion, predict perceived trustworthiness from a person’s voice? We will only look at male voices today, but you have the data for female voices as well should you wish to practice (note that in the field, tendency is to analyse male and female voices separately as they are effectively sexually dimorphic). As such, we hypothesise that a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices. This is what we will analyse.\nTo complete this lab activity, you can use the R-script (402_wk11_labAct2.R) that you downloaded as part of the ‘pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\n\nStep 1: Background and set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. Use the code snippet below to clear the environment.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\n\n\nTip\n\n\n\nIf you hover your mouse over the box that includes the code snippet, a ‘copy to clipboard’ icon will appear in the top right corner of the box. Click that to copy the code. Now you can easily paste it into your script.\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car, pwr and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(pwr)\nlibrary(tidyverse)\n\n\n\nIn this lab, we are setting out to test whether a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices. We’ll be working with two data files:\n\nvoice_acoustics.csv - shows the VoiceID, the sex of the voice, and the pitch and dispersion values\nvoice_ratings.csv - shows the VoiceID and the ratings of each voice by 28 participants on a scale of 1 to 9 where 9 was extremely trustworthy and 1 was extremely untrustworthy.\n\n\nTASK: Read in both files, have a look at the layout of the data and familiarise yourself with it. The ratings data is rather messy and in a different layout to the acoustics but can you tell what is what?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nacoustics &lt;- read_csv(\"voice_acoustics.csv\")\nratings &lt;- read_csv(\"voice_ratings.csv\")\n\n\n\n\nQUESTION 1 How are the acoustics data and the ratings data organised (wide or long)? Are both data files ‘tidy’? If you need more info on what that means, have a look here.\n\n\n\nStep 2: Restructuring the ratings data\nWe are going to need to do some data-wrangling before we do any analysis! Specifically, we need the change the ratings data to the long format.\nHere we’ll use the pivot_longer() function (see here or type ?pivot_longer in the Console for more info) to restructure the ratings data from wide to long and store the resulting table as ‘ratings_tidy’.\n\nTASK: Use the code snippet below to restructure the data. Have a look at each line of code (and the comments in green) and check that you understand how it works.\n\n\nratings_tidy &lt;- pivot_longer(\n  data = ratings,    # the data you want to restructure\n  cols = P1:P28,     # columns you want to restructure\n  names_to = \"participant\", # variable name that captures whatever is across the columns\n  # (in this case P1 to P28 for the 28 different participants)\n  values_to = \"rating\") # variable name that captures whatever is in the cells\n  # (in this case numbers for ratings)\n\n\n\nStep 3: Calculate mean trustworthiness rating for each voice\nNow that we have the ratings data into a tidy format, the next step is to calculate the mean rating for each voice. Remember that each voice is identified by the ‘VoiceID’ variable.\n\nTASK: Calculate the mean rating for each voice and store the resulting table in a variable named ‘ratings_mean’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse group_by() and summarise(). Are you using the tidy data? Also, remember that if there are any missing values (NAs) then na.rm = TRUE would help.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nratings_mean &lt;- ratings_tidy %&gt;% \n  group_by(VoiceID) %&gt;% \n  summarise(mean_rating = mean(rating))\n\n\n\n\n\nStep 4: Join the data together\nOk, before we get ahead of ourselves, in order to perform the regression analysis we need to combine the data from ‘ratings_mean’ (the mean ratings) with ‘acoustics’ (the pitch and dispersion ratings). Also, as we said, we only want to analyse male voices today.\n\nTASK: Join the two tables and keep only the data for the male voices, call the resulting table ‘joined’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the inner_join() function (making use of the variable that is common across both tables) to join. See here or type ?inner_join in the Console for more info. Use the filter() function to only keep male voices. Remember that the Boolean operator for exactly equal is ==.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\njoined &lt;- ratings_mean %&gt;%\n  inner_join(acoustics, \"VoiceID\") %&gt;% \n  filter(sex == \"M\")\n\n\n\n\n\nStep 5: Spreading the data\nWe are starting to get an understanding of our data and we want to start thinking about the regression. However, the regression would be easier to work with if Pitch and Dispersion were in separate columns. This can be achieved using the pivot_wider() function (see here or type ?pivot_wider in the Console for more info). This is basically the inverse of pivot_longer(). It increases the number of columns and decreases the number of rows.\n\nTASK: Use the code snippet below to spread the data. Have a look at each line of code (and the comments in green) and check that you understand how it works.\n\n\njoined_wide &lt;- joined %&gt;%\n  pivot_wider(\n    names_from = measures, # name of the categorical column to spread\n    values_from = value) # name of the data to spread\n\n\nQUESTION 2 Why do we not need to specify within the pivot_wider() function which data to use?\n\n\n\nStep 6: Visualising the data\nAs always, it is a good idea to visualise your data.\n\nTASK: Now that we have all the variables in one place, make two scatterplots, one of mean trustworthiness rating with dispersion and one for mean trustworthiness rating and pitch.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nFor this you’ll need the ggplot() function together with geom_point() and geom_smooth(). Make sure to give your axes some sensible labels.\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nggplot(DATA, aes(x = variable X, y = variable Y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Label for variable Y\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(joined_wide, aes(x = Dispersion, y = mean_rating)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Mean Trustworthiness Rating\")\n\nggplot(joined_wide, aes(x = Pitch, y = mean_rating)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Mean Trustworthiness Rating\")\n\n\n\n\nQUESTION 3 According to the scatterplots, how would you describe the relationships between trustworthiness and dispersion and trustworthiness and pitch in terms of direction and strength? Which one of the two seems stronger?\n\n\n\nStep 7: Conducting and interpreting simple regression\nWith all the variables in place and having gained a better understanding of our data by inspecting the scatterplots, we’re ready now to start building two simple linear regression models:\n\nPredicting trustworthiness mean ratings from Pitch\nPredicting trustworthiness mean ratings from Dispersion\n\n\nTASK: Use the lm() function to run the following two regression models and use the summary() function to look at the output of each model. Store the first model in a table called ‘mod_pitch’ and store the second model in ‘mod_disp’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nlm(dv ~ iv, data = my_data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_disp &lt;- lm(mean_rating ~ Dispersion, joined_wide)\nmod_disp_sum &lt;- summary(mod_disp)\n\nmod_pitch &lt;- lm(mean_rating ~ Pitch, joined_wide)\nmod_pitch_sum &lt;- summary(mod_pitch)\n\n\n\n\nQUESTION 4 What do you conclude from the output of these models? Which model is significant? Which predictors are significant? How much variance does each model describe?\n\n\n\nStep 8: Conducting and interpreting multiple regression\nNow let’s look at both predictors in the same model. Before we do this, it is sensible to center and standardise the predictors.\nLook at the code below. Can you follow how the predictors are first centered (_c) and then standardised (_z)?\nHere I do this by hand because I think it makes it clearer, even though there are functions that do this in one step (scale()).\n\njoined_wide &lt;- mutate(joined_wide,\n                      Dispersion_c = Dispersion - mean(Dispersion),\n                      Dispersion_z = Dispersion_c / sd(Dispersion_c),\n                      Pitch_c = Pitch - mean(Pitch),\n                      Pitch_z = Pitch_c / sd(Pitch_c))\n\n\nTASK: Now use the centered and standardised data for the multiple regression. Use the lm() function to run a model for predicting trustworthiness mean ratings from Pitch and Dispersion, and store the model in ‘mod_pitchdisp_z’. Use the ‘summary()’ function to look at the output.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nlm(dv ~ iv1 + iv2, data = my_data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_pitchdisp_z &lt;- lm(mean_rating ~ Pitch_z + Dispersion_z, joined_wide)\nmod_pitchdisp_z_sum &lt;- summary(mod_pitchdisp_z)\n\n\n\n\nQUESTION 5 What do you conclude from the output of this model? Is the overall model significant? Which predictors are significant? How much variance does the model describe? Which model would you say is best for predicting ratings of trustworthiness, the Pitch only, the Dispersion only or the Pitch+Dispersion model?\n\n\n\nStep 9: Checking assumptions\nNow that we’ve established which model best fits the data, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity.\n\nTASK: Check the assumptions of linearity, normality and homoscedasticity.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the crPlots() and the qqPlot() functions to check linearity. The shapiro.test() can be used to check normality of the residuals and the residualPlot() and nvcTest() functions to check homoscedasticity of the residuals. These plots are from base R rather than using the ggplot() function. See [here] (https://r4ds.hadley.nz/base-r#plots) for a brief explanation of base R plots and why you might want to use them.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\ncrPlots(mod_pitch)\n\nqqPlot(mod_pitch$residuals) \nshapiro.test(mod_pitch$residuals)\n\nresidualPlot(mod_pitch)\nncvTest(mod_pitch)\n\n\n\n\nQUESTION 6 What do you conclude from the graphs and output? Should we also check for collinearity?\n\n\n\nStep 10: Writing up the results\n\nTASK: Write up the results following APA guidelines.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe Purdue writing lab website is helpful for guidance on punctuating statistics. The APA Style 7th Edition Numbers and Statistics Guide is also useful."
  },
  {
    "objectID": "PSYC412/part1/Week11.html#sec-wk11-answers",
    "href": "PSYC412/part1/Week11.html#sec-wk11-answers",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\n\nLab activity 1: Interpreting and reporting results\n\nWhat is the outcome or dependent variable? Word reading\nWhat is the predictor or independent variable? Non-word reading\nIs the overall model significant? Yes, F(1,50) = 69.03, p &lt; .001\nHow much variance does the model account for? 58%\nDoes the relationship appear linear? Yes. The dots and the pink line assemble quite closely on the dashed line.\nDo the residuals show normality and homoscedasticity? The qq-plot suggests that the residuals are normally distributed as the dots fall close to the solid blue line and within the range of the dashed blue lines. The Shapiro-Wilk test of normality confirms this (it is not significant). Similarly, the output of the non-constant variance score tests is not significant suggesting that the residuals are homoscedastic.\n\n\n\nLab activity 2: Conducting simple and multiple regression\nYou can download the R-script that includes the relevant code and answers to the questions here: 402_wk11_labAct2_withAnswers.R."
  },
  {
    "objectID": "PSYC412/part1/Week15.html",
    "href": "PSYC412/part1/Week15.html",
    "title": "5. Poisson regression",
    "section": "",
    "text": "Previously, we looked at logistic regression in the context of a binomial outcome variable, that is, a two-level variable such as correct vs. incorrect, or looking to the left vs. the right. Poisson regression is another type of generalized linear model that is particularly useful for count data."
  },
  {
    "objectID": "PSYC412/part1/Week15.html#lectures",
    "href": "PSYC412/part1/Week15.html#lectures",
    "title": "5. Poisson regression",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented below:\nPoisson regression (~28 min)\n\nSlides Transcript"
  },
  {
    "objectID": "PSYC412/part1/Week15.html#reading",
    "href": "PSYC412/part1/Week15.html#reading",
    "title": "5. Poisson regression",
    "section": "Reading",
    "text": "Reading\n\nWinter (2020)\nLink\nChapter 13 provides a clear introduction to Poisson regression and its implementation in R."
  },
  {
    "objectID": "PSYC412/part1/Week15.html#pre-lab-activities",
    "href": "PSYC412/part1/Week15.html#pre-lab-activities",
    "title": "5. Poisson regression",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Getting a feel for Poisson data\nTo get a feel for Poisson data, we’ll use the rpois() function to generate random data that is Poisson-distributed. rpois() needs two bits of information: lambda, and how many numbers you want to generate.\nAs usual, before we get stuck in we need to set up a few things.\n\nTASK: Add code to clear the environment. HINT: rm(list=ls())\n\nNext we need to tell R which libraries to use. For this pre-lab activity, we just need the tidyverse library.\n\nTASK: Add code to load relevant libraries. HINT: library()\n\nOk, now let’s play around with different lambdas to get a feel for the Poisson distribution.\n\nTASK: Copy the code below to your script and run it. Then change the value of lambda in the rpois() function and see how the distribution changes.\n\n\nlambda2 &lt;- rpois(n = 1000, lambda = 2)\n\nlambda2 &lt;- as.data.frame(lambda2)\n\nggplot(data = lambda2, mapping = aes(x = lambda2)) +\n  geom_bar()\n\nQUESTION: What do you notice about the Poisson distribution if you choose a high value for lambda?\n\n\nPre-lab activity 2: Getting ready\n\nGet your files ready\nDownload the 402_week15_forStudents.zip file and upload it into a new folder in RStudio Server.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below."
  },
  {
    "objectID": "PSYC412/part1/Week15.html#lab-activities",
    "href": "PSYC412/part1/Week15.html#lab-activities",
    "title": "5. Poisson regression",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply Poisson regression to answer questions in psychological science\nconducting Poisson regression in R\ninterpreting the R output of Poisson regression\nreporting results for Poisson regression following APA guidelines\n\n\nLab activity 1: Visual dominance\nWinter et al. (2018) showed that, on average, English words that were rated as strongly associated with the visual modality are more frequent than words more strongly associated with other sensory modalities. In this week’s lab activity we will retrace that analysis focusing on the subset of adjectives (the paper also included verbs and nouns). We’ll use sensory modality ratings as reported by Lynott and Connell (2009; see here for more info; data file: lynott_connell_2009_modality.csv) and word frequencies as reported by the English Lexicon Project (data file: ELP_full_length_frequency.csv). The research question is: Do English speakers use ‘visual’ adjectives more frequently than adjectives more strongly associated with other sensory modalities?\n\nStep 1: Set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 2: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, tidyverse, MASS and pscl.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(MASS)\nlibrary(pscl)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week15/402_week15_forStudents/ELP_full_length_frequency.csv?raw=true\", destfile = \"ELP_full_length_frequency.csv\")\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week15/402_week15_forStudents/lynott_connell_2009_modality.csv?raw=true\", destfile = \"lynott_connell_2009_modality.csv\")\n\n\nTASK: Finally, read in the two data files (lynott_connell_2009_modality.csv and ELP_full_length_frequency.csv) and have a look at them.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function and the head() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlyn &lt;- read_csv('lynott_connell_2009_modality.csv')\nELP &lt;- read_csv('ELP_full_length_frequency.csv')\nhead(lyn)\nhead(ELP)\n\n\n\nQUESTION 1: Which variables do you need to address the research question?\n\n\nStep 2: A bit of data wrangling\nWe need to combine the information in the data files to be able to do any analyses. We can use a ‘join’ to do this. Have a look at the online book by Hadley Wickam and Gareth Grolemund (here) to remind yourself what a ‘join’ is. In particular, have a look at the inner_join() and the left_join().\nQUESTION 2: Which ‘join’ is most appropriate, the inner_join() or the left_join()? Also, does it matter which data file you specify as x and which one as y? If so, why does it matter?\n\nTASK: Add code to join the two data files and store the resulting table in an object called both. Try out the different joins and use head() to inspect the result.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou should end up with a table that has 423 observations of at least 8 variables.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nboth &lt;- left_join(x = lyn, y = ELP, by = 'Word')\n\n\n\nNext, we want to select only the variables we need. We want to use the select() function from dplyr. Because the MASS library is also loaded and that library also contains a select() function, we need to tell R specifically to use the one from dplyr. You can do this by using dplyr::, like this:\n\nboth &lt;- both %&gt;%\n  dplyr::select(Word, DominantModality:Smell, Log10Freq)\n\n\nTASK: Add the code above to your script and run it.\n\nFinally, to apply Poisson regression, we need the frequency variable as positive integers.\n\nTASK: Use the code below to transform the frequency variable to raw values. Don’t forget to add it to your script and run it.\n\n\nboth &lt;- mutate(both, Freq = 10 ^ Log10Freq)\n\nQUESTION 3: What does this line of code do. Write a comment to summarise its function.\n\n\nStep 3: Visualise the data\nTo get a better feel for the data, let’s make some scatterplots.\n\nTASK: Add code to make scatterplots with Freq on the y axis and each of the sensory modality ratings on the respective x axis. To be able to see more easily what is going on, limit the y-axis to values between 0 and 20000.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake 5 different scatterplots using ggplot() withgeom_point() and geom_smooth(). You can use ylim() to limit the values on the y-axis.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(both, aes(x = Sight, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\nggplot(both, aes(x = Touch, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()  +\n  ylim(c(0, 20000))  \n\nggplot(both, aes(x = Sound, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\nggplot(both, aes(x = Taste, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\nggplot(both, aes(x = Smell, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\n\n\nQUESTION 4: What do you conclude from the scatterplots?\n\n\nStep 4: The regression model\nWe are going to fit a Poisson regression model with Taste, Smell, Touch, Sight and Sound as predictors (all of these are continuous rating scales).\n\nTASK: Fit a Poisson regression model for ‘Freq’ as a function of ‘Taste’, ‘Smell’, ‘Touch’, ‘Sight’ and ‘Sound’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm() function with family = poisson.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nfreqMod &lt;- glm(Freq ~ Sight + Taste + Smell + Sound + Touch,\n               data = both,\n               family = poisson)\n\nsummary(freqMod)\n\n\n\nQUESTION 5: How do you interpret the output of the Poisson regression?\n\n\nStep 5: Overdispersion\nIn the lecture we saw that it is possible that the variance is larger than theoretically expected for a given lambda. If this happens, we are dealing with what’s called ‘overdispersion’. You can compensate for this by using a variant of Poisson regression that is called ‘negative binomial regression’. In negative binomial regression the variance is uncouples from the mean.\n\nTASK: Fit a negative binomial regression model for ‘Freq’ as a function of ‘Taste’, ‘Smell’, ‘Touch’, ‘Sight’ and ‘Sound’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm.nb() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nfreqMod_nb &lt;- glm.nb(Freq ~ Sight + Taste + Smell + Sound + Touch,\n    data = both)\nsummary(freqMod_nb)\n\n\n\nNext, check whether there is significant overdispersion by performing a likelihood ratio test, comparing the likelihood of the negative binomial model against the likelihood of the corresponding Poisson model.\n\nTASK: Use the odTest() function to perform an ‘overdispersion’ test.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the odTest() function and pass object that identifies your model as the argument.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nodTest(freqMod_nb)\n\n\n\nQUESTION 6: What do you conclude from the results of the overdispersion test?\nQUESTION 7: How do you interpret the negative binomial regression output? Do English speakers use visual adjectives more frequently? What about smell adjectives in comparison?"
  },
  {
    "objectID": "PSYC412/part1/Week15.html#answers",
    "href": "PSYC412/part1/Week15.html#answers",
    "title": "5. Poisson regression",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\nThe answers to the questions and the script containing the code will be available after the lab session has taken place."
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html",
    "href": "PSYC411/part2/lm-intro.html",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "Welcome to our overview of the materials you will work with in our class introducing you to the linear model in PSYC401 Week 9.\nWe will return to locate our learning in the context of the Clearly understood project. We will present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data (as we explain in ?@sec-preface).\nRemember: it is unclear how to make health communication more effective. The problem is that we are not sure how health information should be communicated so that everyone can understand it. This is why we ask the research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills.\nYou can read a bit more about the project and the project data in ?@sec-associations.\n\n\n\nThis week, we focus on learning how to predict people: predicting observations about us (e.g., our attributes) or about the things we make or do. To do this, we will learn to think about and work with linear models.\nOur learning objectives: — what are we learning about?\n\n\n\nWe will learn how to:\n\n\ncode linear models\nidentify and interpret model statistics\ncritically evaluate the results\ncommunicate the results\n\n\nBecause we often want to know about relationships, asking questions like:\n\n\nDoes variation in X predict variation in Y?\nWhat are the factors that influence outcome Y?\nIs a theoretical model consistent with observed behaviour?\n\n\n\n\n\nYou will see in the next section links to the lectures we created both to explain the concepts we want to help you to learn about, and to explain the practical data analysis skills we want to help you to develop (Section 1.3.1). We then share links to information about the practical materials we have provided to help you to practise those skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 9 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points.\n\n\n\n\n\n\nTip\n\n\n\nLinked resources include:\n\nIn ?@sec-associations, we present an overview of the materials we have shared to support your development of critical thinking in relation to associations, and to support your learning about conducting correlation-based analyses of associations.\nIt may help you to revise these materials.\n\n\n\n\n\nThe lecture material for this week is presented in four short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 4\nPart 2 of 4\nPart 3 of 4\nPart 4 of 4\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-lm-intro-how-to.R\n401-lm-intro-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-lm-intro-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-lm-intro-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-lm-intro-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions.\nFor this class on linear models, our practical materials have two aims:\n\nHelping you to learn how to use linear models to address questions about associations, questions like “What person attributes predict success in understanding?”;\nHelping you to learn how to interpret linear model results, including how to work with data visualizations displaying distributions or associations.\n\nWe progress a series of parts, each designed to enable learning or developing concepts or skills:\n\nPart 3 refreshes your development of skills for working with histogram-based visualizations of data distributions. Here, we are aiming to advance your skills so that you can develop nicer looking histograms that present more accurate accounts of distributions (by showing the full range of potential values), and so that you can annotate histograms to direct the attention of your audience ?@sec-vis-intro-intro.\nPart 4 helps you to learn how you can present grids of histograms for easy comparison of variable distributions.\nPart 5 refreshes your development of skills for working with scatterplot-based visualizations of associations or of the relationships between two or more numeric variables. We look at how you can edit the appearance of the plots, element by element. And we look at how you can produce grids of scatterplots, again, to enable comparisons — here, of the potential relationships between one outcome and multiple other variables.\nPart 6 offers the opportunity to revise the calculation and interpretation of correlation analyses.\nPart 7 provides exercises designed to help you to learn how to conduct linear model analyses.\nPart 8 helps you to develop skills in calculating and presenting model predictions.\nPart 9 is optional and focuses on working with R-community information to find out how to annotate plots using geom_vline() or geom_hline().\n\nThe activity 401-lm-intro-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-lm-intro-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\n\n\n\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study-two-general-participants.csv looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful.\n\n\n\n\nSome people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nAnalyze\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow: we focus on the linear model\n\n\n\n\n\n\n\n\n\nUnderstand how to code: lm(mean.acc ~ SHIPLEY)\nTo answer questions like: Is comprehension success influenced by vocabulary knowledge?\n\n\n\n\n\n\n\n\n\nFigure 2: Scatterplot showing the potential association between accuracy of comprehension and vocabulary scores\n\n\n\n\n\n\n\n\n\nWe will learn how to:\n\n\ncode linear models\nidentify and interpret model statistics\ncritically evaluate the results\ncommunicate the results\n\n\n\n\nWe often want to know about relationships\n\nDoes variation in X predict variation in Y?\nWhat are the factors that influence outcome Y?\nIs a theoretical model consistent with observed behaviour?\n\n\n\n\n\nBecause public health impacts depend on giving people information they can understand\nWe want to know: What makes it easy or difficult to understand written health information?\n\n\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\n\n\n\n\n\n\nWe want to know: What makes it easy or difficult to understand written health information?\nSo our research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nThese kinds of research questions can be answered using methods like linear models\n\n\n\n\n\nUnderstanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 3: The potential drivers of comprehension success\n\n\n\n\n\n\n\n\n\n\nWe measure reading comprehension: asking people to read text and then answer multiple choice questions\nWe measure background knowledge: vocabulary knowledge (Shipley); health literacy (HLVA)\n\n\n\n\n\nAre multiple choice questions good ways to probe understanding? What alternatives are there?\nAre tests like the Shipley good measures of language knowledge? What do we miss?\n\n\n\n\n\nvalidity: that differences in knowledge or ability cause differences in test scores\nmeasurement: that this is equally true across the different kinds of people we tested\ngeneralizability: that the sample of people we recruited looks like the population\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1_l\n\nConcept formation\n\n\n\nnd_1_r\n\nCausal model\n\n\n\nnd_2_l\n\nMeasurement\n\n\n\nnd_1_l-&gt;nd_2_l\n\n\n\n\n\nnd_3\n\nStatistical predictions\n\n\n\nnd_2_l-&gt;nd_3\n\n\n\n\n\nnd_2_r\n\nAuxiliary assumptions\n\n\n\nnd_2_r-&gt;nd_3\n\n\n\n\n\nnd_4\n\nTesting hypotheses\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 4: The derivation chain\n\n\n\n\n\n\n\n\nLink: concepts, questions \\(\\rightarrow\\) assumptions \\(\\rightarrow\\) testable predictions\n\nconcepts, questions: Can people accurately understand health guidance? \\(\\rightarrow\\)\nassumptions: People who know more about language should also present more accurate understanding \\(\\rightarrow\\)\ntestable predictions: Higher levels of vocabulary should be associated with higher levels of comprehension accuracy: we expect to estimate a positive coefficient\n\n\n\n\n\nFor each value of the predictor vocabulary\nDoes the the value of the outcome accuracy\nIncrease or decrease?\n\n\n\n\n\n\n\n\n\nFigure 5: The association between comprehension accuracy and vocabulary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6 shows the distribution curve of mean (comprehension) accuracy scores observed at each value of vocabulary\nYou can see that the middle – the average – of each distribution increases\nas we go from left (low scores) to right (high scores) on vocabulary\n\n\n\n\n\n\n\n\n\nFigure 6: Association between accuracy and vocabulary\n\n\n\n\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY,\n            data = clearly.one.subjects)\nsummary(model)\n\n\nSpecify the lm function and the model mean.acc ~ SHIPLEY\nSpecify what data we use data = clearly.one.subjects\nGet the results summary(model)\n\n\n\n\nTake a good look:\n\nlm(mean.acc ~ SHIPLEY ...)\n\nYou will see this sentence structure in coding for many different analysis types\n\nmethod(outcome ~ predictors)\nmethod could be aov, brm, lm, glm, glmm, lmer, t.test, cor.test\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY,\n            data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\nA model summary gives us estimates of:\nThe coefficient \\(= 0.44914\\) for the intercept\nThe coefficient \\(= 0.01050\\) for the slope of the SHIPLEY ‘effect’\n\n\n\n\n\nThe line represents:\nour prediction for how the outcome varies on average\ngiven change in the predictor\n\n\n\n\n\n\nYou may remember from school that to draw a straight line you need four numbers:\n\n\\[y = a + bx\\]\n\nWe calculate the height \\(y\\) by adding\n\n\n\\(a\\) the intercept, the value of y when \\(x = 0\\)\nto the product of \\(b\\) the coefficient for the slope of the line\nmultiplied by \\(x\\) the value of the predictor variable\n\n\n\n\n\n\nLook at what we get if we draw the line using the linear model coefficients:\n\\(= 0.449\\) for the intercept, \\(a\\)\n\\(= 0.011\\) for the slope, \\(b\\)\nIn the formula: \\(y = 0.449 + 0.011x\\)\n(I round the numbers to three decimal places.)\n\n\n\n\n\n\n\n\n\nFigure 7: The predicted association between comprehension accuracy and vocabulary\n\n\n\n\n\n\n\n\n\n\nTo see how — we use the coefficients to predict just one potential outcome:\nthe expected accuracy for someone with a vocabulary score of 20\nWe do this using the formula:\n\n\\(\\text{predicted y} = 0.449 + \\text{0.011 } \\times \\text{ Shipley score of } 20\\)\n\n\n\n\n\n\n\n\nFigure 8: Predicted outcome in red\n\n\n\n\n\n\n\n\n\n\n\nLet’s expand our predictions\n\n\nPredict accuracy given a Shipley score of 20\n\n\n\\(y = 0.449 + 0.011 \\times 20\\)\n\n\nPredict accuracy given a Shipley score of 30\n\n\n\\(y = 0.449 + 0.011 \\times 30\\)\n\n\n\n\n\n\n\n\n\nFigure 9: Predicted outcome in red\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: The predicted change in mean comprehension accuracy, given variation in vocabulary scores\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe need to go back to the prediction model\n\nTo calculate a predicted outcome value, we calculated it as: \\(\\text{predicted y} = 0.449 + 0.011 \\times \\text{ Shipley score } 20\\)\nAssuming the linear model \\(\\text{predicted y} = intercept + \\text{slope } \\times \\text{ vocabulary}\\)\nBut we missed a bit: error\n\n\n\n\n\nMaybe you noticed that I talked about how the model allows us to predict\nhow the outcome varies on average given different values of the predictor\nWhen we use a linear model to estimate the intercept and slope – to build the predictions – we fit a model to the sample data\nAnd no model will fit sample data perfectly\n\n\n\n\n\n\nUsually, this means there are differences between the expected outcomes that the model predicts and the observed outcomes\n\nSo we often write the linear model like this: \\(y = a + bx + \\epsilon\\)\n\n\nThe observed outcome \\(y\\) equals\nthe intercept \\(a\\)\nplus the difference associated with a specific predictor value \\(bx\\)\nplus some amount of mismatch or error \\(\\epsilon\\), the difference between the observed outcome and the predicted outcome\n\n\n\n\n\nBut we won’t\nBecause the linear model calculations are done using matrix solution algorithms in R so we don’t have to \n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\nThe model expectation: higher vocabulary predicts higher mean comprehension accuracy\nThe predicted points are shown by the blue line\nThe prediction line increases in height for higher values of vocabulary\nLook at the differences in height between the observed points (in orange-red) and predicted points\n\n\n\n\n\n\n\n\n\nFigure 12: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\n\nIf the regression model were perfect then all the observed points would lie on the prediction line\nThey do not\n\n\n\n\n\n\n\n\n\nFigure 13: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\nDifferences between observed and predicted outcomes are shown by the vertical lines\nBetter models should show smaller differences between observed and predicted outcome values\nNotice: some participants had same vocabulary scores but different outcomes\n\n\n\n\n\n\n\n\n\nFigure 14: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\nSome are positive: observed outcome larger than predicted outcome\nSome are negative: observed outcome smaller than predicted outcome\nThe average of the residuals will be zero overall\n\n\n\n\n\n\n\n\n\nFigure 15: Plot showing the distribution of prediction errors – residuals – for the linear model of comprehension accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe summary() of the linear model shows …\nThe Estimate of the Coefficient of the effect of individual differences in vocabulary (SHIPLEY)\nhow much the outcome mean.acc value changes, given differences in SHIPLEY score\nAssociated t value and Pr(&gt; |t|) statistics for the coefficient t-test\nModel fit statistics: R-squared and F-statistic\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nThe coefficient for the slope of the effect of variation in vocabulary scores: 0.01050\nThe Std. Error (standard error) 0.00229 for that estimate\nThe tvalue 4.585 and associated Pr(&gt;|t|) p-value 8.85e-06 for the null hypothesis test of the coefficient\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nPay attention to the sign and the size of the coefficient estimate:\nIs the coefficient (e.g., SHIPLEY 0.01050) a positive or a negative number?\nIs it relatively large or small?\nWe come back to this, shortly, in the context of interpretation and reporting\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\n\n\n\\[t = \\frac{\\beta_j}{s_{\\beta_j}}\\]\n\n\nFor each coefficient, the t-test is used to evaluate if the coefficient \\(\\beta_j\\) is significantly different from zero\nWe assume the null hypothesis that the coefficient \\(\\beta_j\\) is zero\nWe do the test by comparing the estimated coefficient \\(\\beta_j\\) with the standard error of the estimate\n\n\n\n\n\n\n\n\\[t = \\frac{\\beta_j}{s_{\\beta_j}}\\]\n\nThe standard error \\(s_{\\beta_j}\\) indicates our uncertainty about the estimate\nLarger standard errors represent greater uncertainty\n\n\n\n\n\n\n\n\\[t = \\frac{\\beta_j}{s_{\\beta_j}}\\]\n\nStandard errors can be calculated using information about:\nError in the model — think of the distribution of residuals\nVariation of values in the predictor — how widely they range\nThe sample size\nStandard errors will be smaller for the coefficients of effects that appear to have bigger impacts, in models that describe outcomes better, in larger samples\n\n\n\n\n\nPay attention to R-squared:\nThe model summary gives us the Multiple R-squared and Adjusted R-squared\nThese numbers represent how much of the variation in the outcome can be predicted by the model\nWe usually report Adjusted R-squared because it tends to be more accurate\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nBetter models should show smaller differences between observed and predicted outcomes\nR-squared (\\(R^2\\)) gives the proportion of outcome variance\nwe can predict given information about differences in vocabulary\n\n\n\n\n\n\n\n\n\nFigure 16: The difference between predicted and observed outcomes, given variation in vocabulary\n\n\n\n\n\n\n\n\n\nTo understand what this means, look at the scatterplot\nOn average, values in outcome (accuracy) increase with increasing values in the predictor (vocabulary)\nBut different people got different outcomes even with same vocabulary scores\n\n\n\n\n\n\n\n\n\nFigure 17: The difference between predicted and observed outcomes, given variation in vocabulary\n\n\n\n\n\n\n\n\n\nSo: we have variation in the outcome that is related to variation in the predictor\nAnd: we have variation in the outcome that seems unrelated to the predictor\n\\(R^2\\) tells us how much variation in the outcome is explained by the model\n\\(R^2\\) gives us a proportion where \\(R^2 = \\frac{\\text{predicted outcome variation}}{\\text{total outcome variation}}\\)\n\n\n\n\n\n\n\n\n\nFigure 18: The difference between predicted and observed outcomes, given variation in vocabulary\n\n\n\n\n\n\n\n\n\nPay attention to F:\nThe model summary gives us the F-statistic:\nThis is the test statistic for the test of the null hypothesis that the model does not predict the outcome\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nYou will need to report three bits of information:\n\n\n\\(R^2\\) how much outcome variation is explained by the model\n\\(F\\) test for the null hypothesis that none of the predictors actually predict the outcome\nCoefficient estimates with the t-tests for the null hypothesis for each coefficient\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\nHere is an example of results reporting text that is conventional:\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and vocabulary (Shipley) as the predictor. Our analysis indicated a significant effect of vocabulary knowledge. The model is significant overall, with \\(F(1, 167) = 21.03, p &lt; .001\\), and explains 11% of variance (\\(\\text{adjusted } R^2 = 0.11\\)). The model estimates showed that the accuracy of comprehension increased with increasing levels of participant vocabulary knowledge (\\(\\beta = .011, t = 4.59, p &lt;.001\\)).\n\n\n\n\n\nExplain what I did, specifying the method (linear model), the outcome variable (accuracy) and the predictor variables (health literacy, reading strategy, reading skill and vocabulary)\nReport the model fit statistics overall (\\(F, R^2\\))\nReport the significant effects (\\(\\beta, t, p\\)) and describe the nature of the effects (does the outcome increase or decrease?)\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and vocabulary (Shipley) as the predictor. Our analysis indicated a significant effect of vocabulary knowledge. The model is significant overall, with \\(F(1, 167) = 21.03, p &lt; .001\\), and explains 11% of variance (\\(\\text{adjusted } R^2 = 0.11\\)). The model estimates showed that the accuracy of comprehension increased with increasing levels of participant vocabulary knowledge (\\(\\beta = .011, t = 4.59, p &lt;.001\\)).\n\n\n\n\n\n\nIn psychological science, we often ask questions like:\n\n\nDoes variation in X predict variation in Y?\nWhat are the factors that influence outcome Y?\nIs a theoretical model consistent with observed behaviour?\n\n\nWe can answer these questions using the linear model\nGiven sample data, we can predict the average difference in outcome values, for different levels of a predictor variable\nWe (or the math engine R uses) calculate the predictions so that they minimize the residuals, the errors of prediction or the mismatch between predicted and observed outcomes\nOur results report tells the reader about the model and the estimated effects"
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#sec-lm-intro-overview",
    "href": "PSYC411/part2/lm-intro.html#sec-lm-intro-overview",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "Welcome to our overview of the materials you will work with in our class introducing you to the linear model in PSYC401 Week 9.\nWe will return to locate our learning in the context of the Clearly understood project. We will present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data (as we explain in ?@sec-preface).\nRemember: it is unclear how to make health communication more effective. The problem is that we are not sure how health information should be communicated so that everyone can understand it. This is why we ask the research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills.\nYou can read a bit more about the project and the project data in ?@sec-associations."
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#sec-lm-intro-goals",
    "href": "PSYC411/part2/lm-intro.html#sec-lm-intro-goals",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "This week, we focus on learning how to predict people: predicting observations about us (e.g., our attributes) or about the things we make or do. To do this, we will learn to think about and work with linear models.\nOur learning objectives: — what are we learning about?\n\n\n\nWe will learn how to:\n\n\ncode linear models\nidentify and interpret model statistics\ncritically evaluate the results\ncommunicate the results\n\n\nBecause we often want to know about relationships, asking questions like:\n\n\nDoes variation in X predict variation in Y?\nWhat are the factors that influence outcome Y?\nIs a theoretical model consistent with observed behaviour?"
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#sec-lm-intro-resources",
    "href": "PSYC411/part2/lm-intro.html#sec-lm-intro-resources",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "You will see in the next section links to the lectures we created both to explain the concepts we want to help you to learn about, and to explain the practical data analysis skills we want to help you to develop (Section 1.3.1). We then share links to information about the practical materials we have provided to help you to practise those skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 9 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points.\n\n\n\n\n\n\nTip\n\n\n\nLinked resources include:\n\nIn ?@sec-associations, we present an overview of the materials we have shared to support your development of critical thinking in relation to associations, and to support your learning about conducting correlation-based analyses of associations.\nIt may help you to revise these materials.\n\n\n\n\n\nThe lecture material for this week is presented in four short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 4\nPart 2 of 4\nPart 3 of 4\nPart 4 of 4\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-lm-intro-how-to.R\n401-lm-intro-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-lm-intro-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-lm-intro-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-lm-intro-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions.\nFor this class on linear models, our practical materials have two aims:\n\nHelping you to learn how to use linear models to address questions about associations, questions like “What person attributes predict success in understanding?”;\nHelping you to learn how to interpret linear model results, including how to work with data visualizations displaying distributions or associations.\n\nWe progress a series of parts, each designed to enable learning or developing concepts or skills:\n\nPart 3 refreshes your development of skills for working with histogram-based visualizations of data distributions. Here, we are aiming to advance your skills so that you can develop nicer looking histograms that present more accurate accounts of distributions (by showing the full range of potential values), and so that you can annotate histograms to direct the attention of your audience ?@sec-vis-intro-intro.\nPart 4 helps you to learn how you can present grids of histograms for easy comparison of variable distributions.\nPart 5 refreshes your development of skills for working with scatterplot-based visualizations of associations or of the relationships between two or more numeric variables. We look at how you can edit the appearance of the plots, element by element. And we look at how you can produce grids of scatterplots, again, to enable comparisons — here, of the potential relationships between one outcome and multiple other variables.\nPart 6 offers the opportunity to revise the calculation and interpretation of correlation analyses.\nPart 7 provides exercises designed to help you to learn how to conduct linear model analyses.\nPart 8 helps you to develop skills in calculating and presenting model predictions.\nPart 9 is optional and focuses on working with R-community information to find out how to annotate plots using geom_vline() or geom_hline().\n\nThe activity 401-lm-intro-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-lm-intro-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\n\n\n\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study-two-general-participants.csv looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful."
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#sec-lm-intro-notes",
    "href": "PSYC411/part2/lm-intro.html#sec-lm-intro-notes",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "Some people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1\n\nGet raw data\n\n\n\nnd_2\n\nTidy data\n\n\n\nnd_1-&gt;nd_2\n\n\n\n\n\nnd_3_l\n\nVisualize\n\n\n\nnd_2-&gt;nd_3_l\n\n\n\n\n\nnd_3\n\nAnalyze\n\n\n\nnd_2-&gt;nd_3\n\n\n\n\n\nnd_3_r\n\nExplore\n\n\n\nnd_2-&gt;nd_3_r\n\n\n\n\n\nnd_3_a\n\nAssumptions\n\n\n\nnd_3_a-&gt;nd_3_l\n\n\n\n\n\nnd_3_a-&gt;nd_3\n\n\n\n\n\nnd_3_a-&gt;nd_3_r\n\n\n\n\n\nnd_3_l-&gt;nd_3\n\n\n\n\nnd_4\n\nPresent\n\n\n\nnd_3_l-&gt;nd_4\n\n\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The data analysis pipeline or workflow: we focus on the linear model\n\n\n\n\n\n\n\n\n\nUnderstand how to code: lm(mean.acc ~ SHIPLEY)\nTo answer questions like: Is comprehension success influenced by vocabulary knowledge?\n\n\n\n\n\n\n\n\n\nFigure 2: Scatterplot showing the potential association between accuracy of comprehension and vocabulary scores\n\n\n\n\n\n\n\n\n\nWe will learn how to:\n\n\ncode linear models\nidentify and interpret model statistics\ncritically evaluate the results\ncommunicate the results\n\n\n\n\nWe often want to know about relationships\n\nDoes variation in X predict variation in Y?\nWhat are the factors that influence outcome Y?\nIs a theoretical model consistent with observed behaviour?\n\n\n\n\n\nBecause public health impacts depend on giving people information they can understand\nWe want to know: What makes it easy or difficult to understand written health information?\n\n\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\n\n\n\n\n\n\nWe want to know: What makes it easy or difficult to understand written health information?\nSo our research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nThese kinds of research questions can be answered using methods like linear models\n\n\n\n\n\nUnderstanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 3: The potential drivers of comprehension success\n\n\n\n\n\n\n\n\n\n\nWe measure reading comprehension: asking people to read text and then answer multiple choice questions\nWe measure background knowledge: vocabulary knowledge (Shipley); health literacy (HLVA)\n\n\n\n\n\nAre multiple choice questions good ways to probe understanding? What alternatives are there?\nAre tests like the Shipley good measures of language knowledge? What do we miss?\n\n\n\n\n\nvalidity: that differences in knowledge or ability cause differences in test scores\nmeasurement: that this is equally true across the different kinds of people we tested\ngeneralizability: that the sample of people we recruited looks like the population\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1_l\n\nConcept formation\n\n\n\nnd_1_r\n\nCausal model\n\n\n\nnd_2_l\n\nMeasurement\n\n\n\nnd_1_l-&gt;nd_2_l\n\n\n\n\n\nnd_3\n\nStatistical predictions\n\n\n\nnd_2_l-&gt;nd_3\n\n\n\n\n\nnd_2_r\n\nAuxiliary assumptions\n\n\n\nnd_2_r-&gt;nd_3\n\n\n\n\n\nnd_4\n\nTesting hypotheses\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 4: The derivation chain\n\n\n\n\n\n\n\n\nLink: concepts, questions \\(\\rightarrow\\) assumptions \\(\\rightarrow\\) testable predictions\n\nconcepts, questions: Can people accurately understand health guidance? \\(\\rightarrow\\)\nassumptions: People who know more about language should also present more accurate understanding \\(\\rightarrow\\)\ntestable predictions: Higher levels of vocabulary should be associated with higher levels of comprehension accuracy: we expect to estimate a positive coefficient\n\n\n\n\n\nFor each value of the predictor vocabulary\nDoes the the value of the outcome accuracy\nIncrease or decrease?\n\n\n\n\n\n\n\n\n\nFigure 5: The association between comprehension accuracy and vocabulary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6 shows the distribution curve of mean (comprehension) accuracy scores observed at each value of vocabulary\nYou can see that the middle – the average – of each distribution increases\nas we go from left (low scores) to right (high scores) on vocabulary\n\n\n\n\n\n\n\n\n\nFigure 6: Association between accuracy and vocabulary\n\n\n\n\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY,\n            data = clearly.one.subjects)\nsummary(model)\n\n\nSpecify the lm function and the model mean.acc ~ SHIPLEY\nSpecify what data we use data = clearly.one.subjects\nGet the results summary(model)\n\n\n\n\nTake a good look:\n\nlm(mean.acc ~ SHIPLEY ...)\n\nYou will see this sentence structure in coding for many different analysis types\n\nmethod(outcome ~ predictors)\nmethod could be aov, brm, lm, glm, glmm, lmer, t.test, cor.test\n\n\n\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY,\n            data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\nA model summary gives us estimates of:\nThe coefficient \\(= 0.44914\\) for the intercept\nThe coefficient \\(= 0.01050\\) for the slope of the SHIPLEY ‘effect’\n\n\n\n\n\nThe line represents:\nour prediction for how the outcome varies on average\ngiven change in the predictor\n\n\n\n\n\n\nYou may remember from school that to draw a straight line you need four numbers:\n\n\\[y = a + bx\\]\n\nWe calculate the height \\(y\\) by adding\n\n\n\\(a\\) the intercept, the value of y when \\(x = 0\\)\nto the product of \\(b\\) the coefficient for the slope of the line\nmultiplied by \\(x\\) the value of the predictor variable\n\n\n\n\n\n\nLook at what we get if we draw the line using the linear model coefficients:\n\\(= 0.449\\) for the intercept, \\(a\\)\n\\(= 0.011\\) for the slope, \\(b\\)\nIn the formula: \\(y = 0.449 + 0.011x\\)\n(I round the numbers to three decimal places.)\n\n\n\n\n\n\n\n\n\nFigure 7: The predicted association between comprehension accuracy and vocabulary\n\n\n\n\n\n\n\n\n\n\nTo see how — we use the coefficients to predict just one potential outcome:\nthe expected accuracy for someone with a vocabulary score of 20\nWe do this using the formula:\n\n\\(\\text{predicted y} = 0.449 + \\text{0.011 } \\times \\text{ Shipley score of } 20\\)\n\n\n\n\n\n\n\n\nFigure 8: Predicted outcome in red"
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#we-can-understand-the-line-as-representing-a-set-of-predictions-1",
    "href": "PSYC411/part2/lm-intro.html#we-can-understand-the-line-as-representing-a-set-of-predictions-1",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "Let’s expand our predictions\n\n\nPredict accuracy given a Shipley score of 20\n\n\n\\(y = 0.449 + 0.011 \\times 20\\)\n\n\nPredict accuracy given a Shipley score of 30\n\n\n\\(y = 0.449 + 0.011 \\times 30\\)\n\n\n\n\n\n\n\n\n\nFigure 9: Predicted outcome in red\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: The predicted change in mean comprehension accuracy, given variation in vocabulary scores\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe need to go back to the prediction model\n\nTo calculate a predicted outcome value, we calculated it as: \\(\\text{predicted y} = 0.449 + 0.011 \\times \\text{ Shipley score } 20\\)\nAssuming the linear model \\(\\text{predicted y} = intercept + \\text{slope } \\times \\text{ vocabulary}\\)\nBut we missed a bit: error\n\n\n\n\n\nMaybe you noticed that I talked about how the model allows us to predict\nhow the outcome varies on average given different values of the predictor\nWhen we use a linear model to estimate the intercept and slope – to build the predictions – we fit a model to the sample data\nAnd no model will fit sample data perfectly\n\n\n\n\n\n\nUsually, this means there are differences between the expected outcomes that the model predicts and the observed outcomes\n\nSo we often write the linear model like this: \\(y = a + bx + \\epsilon\\)\n\n\nThe observed outcome \\(y\\) equals\nthe intercept \\(a\\)\nplus the difference associated with a specific predictor value \\(bx\\)\nplus some amount of mismatch or error \\(\\epsilon\\), the difference between the observed outcome and the predicted outcome\n\n\n\n\n\nBut we won’t\nBecause the linear model calculations are done using matrix solution algorithms in R so we don’t have to \n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\nThe model expectation: higher vocabulary predicts higher mean comprehension accuracy\nThe predicted points are shown by the blue line\nThe prediction line increases in height for higher values of vocabulary\nLook at the differences in height between the observed points (in orange-red) and predicted points\n\n\n\n\n\n\n\n\n\nFigure 12: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue"
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#what-the-prediction-errors-look-like-1",
    "href": "PSYC411/part2/lm-intro.html#what-the-prediction-errors-look-like-1",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "If the regression model were perfect then all the observed points would lie on the prediction line\nThey do not\n\n\n\n\n\n\n\n\n\nFigure 13: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\nDifferences between observed and predicted outcomes are shown by the vertical lines\nBetter models should show smaller differences between observed and predicted outcome values\nNotice: some participants had same vocabulary scores but different outcomes\n\n\n\n\n\n\n\n\n\nFigure 14: The predicted change in mean comprehension accuracy, given variation in vocabulary scores. Observed values are shown in orange-red. Predicted values are shown in blue\n\n\n\n\n\n\n\n\n\nSome are positive: observed outcome larger than predicted outcome\nSome are negative: observed outcome smaller than predicted outcome\nThe average of the residuals will be zero overall\n\n\n\n\n\n\n\n\n\nFigure 15: Plot showing the distribution of prediction errors – residuals – for the linear model of comprehension accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe summary() of the linear model shows …\nThe Estimate of the Coefficient of the effect of individual differences in vocabulary (SHIPLEY)\nhow much the outcome mean.acc value changes, given differences in SHIPLEY score\nAssociated t value and Pr(&gt; |t|) statistics for the coefficient t-test\nModel fit statistics: R-squared and F-statistic\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nThe coefficient for the slope of the effect of variation in vocabulary scores: 0.01050\nThe Std. Error (standard error) 0.00229 for that estimate\nThe tvalue 4.585 and associated Pr(&gt;|t|) p-value 8.85e-06 for the null hypothesis test of the coefficient\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nPay attention to the sign and the size of the coefficient estimate:\nIs the coefficient (e.g., SHIPLEY 0.01050) a positive or a negative number?\nIs it relatively large or small?\nWe come back to this, shortly, in the context of interpretation and reporting\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\n\n\n\\[t = \\frac{\\beta_j}{s_{\\beta_j}}\\]\n\n\nFor each coefficient, the t-test is used to evaluate if the coefficient \\(\\beta_j\\) is significantly different from zero\nWe assume the null hypothesis that the coefficient \\(\\beta_j\\) is zero\nWe do the test by comparing the estimated coefficient \\(\\beta_j\\) with the standard error of the estimate\n\n\n\n\n\n\n\n\\[t = \\frac{\\beta_j}{s_{\\beta_j}}\\]\n\nThe standard error \\(s_{\\beta_j}\\) indicates our uncertainty about the estimate\nLarger standard errors represent greater uncertainty\n\n\n\n\n\n\n\n\\[t = \\frac{\\beta_j}{s_{\\beta_j}}\\]\n\nStandard errors can be calculated using information about:\nError in the model — think of the distribution of residuals\nVariation of values in the predictor — how widely they range\nThe sample size\nStandard errors will be smaller for the coefficients of effects that appear to have bigger impacts, in models that describe outcomes better, in larger samples\n\n\n\n\n\nPay attention to R-squared:\nThe model summary gives us the Multiple R-squared and Adjusted R-squared\nThese numbers represent how much of the variation in the outcome can be predicted by the model\nWe usually report Adjusted R-squared because it tends to be more accurate\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nBetter models should show smaller differences between observed and predicted outcomes\nR-squared (\\(R^2\\)) gives the proportion of outcome variance\nwe can predict given information about differences in vocabulary\n\n\n\n\n\n\n\n\n\nFigure 16: The difference between predicted and observed outcomes, given variation in vocabulary\n\n\n\n\n\n\n\n\n\nTo understand what this means, look at the scatterplot\nOn average, values in outcome (accuracy) increase with increasing values in the predictor (vocabulary)\nBut different people got different outcomes even with same vocabulary scores\n\n\n\n\n\n\n\n\n\nFigure 17: The difference between predicted and observed outcomes, given variation in vocabulary\n\n\n\n\n\n\n\n\n\nSo: we have variation in the outcome that is related to variation in the predictor\nAnd: we have variation in the outcome that seems unrelated to the predictor\n\\(R^2\\) tells us how much variation in the outcome is explained by the model\n\\(R^2\\) gives us a proportion where \\(R^2 = \\frac{\\text{predicted outcome variation}}{\\text{total outcome variation}}\\)\n\n\n\n\n\n\n\n\n\nFigure 18: The difference between predicted and observed outcomes, given variation in vocabulary\n\n\n\n\n\n\n\n\n\nPay attention to F:\nThe model summary gives us the F-statistic:\nThis is the test statistic for the test of the null hypothesis that the model does not predict the outcome\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\n\nYou will need to report three bits of information:\n\n\n\\(R^2\\) how much outcome variation is explained by the model\n\\(F\\) test for the null hypothesis that none of the predictors actually predict the outcome\nCoefficient estimates with the t-tests for the null hypothesis for each coefficient\n\n\nmodel &lt;- lm(mean.acc ~ SHIPLEY, data = clearly.one.subjects)\nsummary(model)\n\n\nCall:\nlm(formula = mean.acc ~ SHIPLEY, data = clearly.one.subjects)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42871 -0.04921  0.02079  0.07480  0.18430 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.44914    0.08053   5.577 9.67e-08 ***\nSHIPLEY      0.01050    0.00229   4.585 8.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1115 on 167 degrees of freedom\nMultiple R-squared:  0.1118,    Adjusted R-squared:  0.1065 \nF-statistic: 21.03 on 1 and 167 DF,  p-value: 8.846e-06\n\n\n\n\n\nHere is an example of results reporting text that is conventional:\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and vocabulary (Shipley) as the predictor. Our analysis indicated a significant effect of vocabulary knowledge. The model is significant overall, with \\(F(1, 167) = 21.03, p &lt; .001\\), and explains 11% of variance (\\(\\text{adjusted } R^2 = 0.11\\)). The model estimates showed that the accuracy of comprehension increased with increasing levels of participant vocabulary knowledge (\\(\\beta = .011, t = 4.59, p &lt;.001\\)).\n\n\n\n\n\nExplain what I did, specifying the method (linear model), the outcome variable (accuracy) and the predictor variables (health literacy, reading strategy, reading skill and vocabulary)\nReport the model fit statistics overall (\\(F, R^2\\))\nReport the significant effects (\\(\\beta, t, p\\)) and describe the nature of the effects (does the outcome increase or decrease?)\n\n\nWe fitted a linear model with mean comprehension accuracy as the outcome and vocabulary (Shipley) as the predictor. Our analysis indicated a significant effect of vocabulary knowledge. The model is significant overall, with \\(F(1, 167) = 21.03, p &lt; .001\\), and explains 11% of variance (\\(\\text{adjusted } R^2 = 0.11\\)). The model estimates showed that the accuracy of comprehension increased with increasing levels of participant vocabulary knowledge (\\(\\beta = .011, t = 4.59, p &lt;.001\\))."
  },
  {
    "objectID": "PSYC411/part2/lm-intro.html#summary",
    "href": "PSYC411/part2/lm-intro.html#summary",
    "title": "Introduction to the linear model",
    "section": "",
    "text": "In psychological science, we often ask questions like:\n\n\nDoes variation in X predict variation in Y?\nWhat are the factors that influence outcome Y?\nIs a theoretical model consistent with observed behaviour?\n\n\nWe can answer these questions using the linear model\nGiven sample data, we can predict the average difference in outcome values, for different levels of a predictor variable\nWe (or the math engine R uses) calculate the predictions so that they minimize the residuals, the errors of prediction or the mismatch between predicted and observed outcomes\nOur results report tells the reader about the model and the estimated effects"
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html",
    "href": "PSYC411/part2/hypotheses-associations.html",
    "title": "Hypotheses and associations",
    "section": "",
    "text": "Welcome to our overview of the materials you will work with in our data analysis class in the PSYC401 module, Week 7.\nWe are completing five classes together in weeks 6-10. These classes are designed to help students to learn about some very common and powerful psychological data analysis methods. We will focus on methods that allow us to visualize and make sense of evidence for associations between variables. Our materials are designed to help you to think about what you are doing, to understand the aims of the practical steps.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly understood project. We will present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data, and to see why we ask you to practise the skills we are teaching.\nWe encounter written health information all the time: on medication labels, in letters from doctors, and online when we research things we are worried about. It is not always easy to understand this information.\nIt is unclear how to make health communication more effective. The problem is that we are not sure how health information should be communicated so that everyone can understand it. This is why we ask the research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills.\n\n\n\nThis week, we focus on both developing your critical thinking and strengthening your practical skills in data analysis.\n1. Critical thinking\n\nConcepts: begin with critical thinking\nSkills: developing hypotheses\n\n2. Practical skills\n\nConcepts – associations: correlations, estimates and hypothesis tests\nSkills – visualizing variation and covariation\nSkills – writing the code\nSkills – estimating correlations\nSkills – hypothesis tests for correlations\nSkills – interpreting and reporting correlations\n\n\n\n\nYou will see next links to the lectures we created to explain the concepts behind the critical thinking and analysis skills we want you to develop (Section 1.3.1), then information about the practical materials we have provided to help you to practise your skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 7 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points. We do this here because we can share the code we used to generate the plots we use in some of the slides 1\n\n\nThe lecture material for this week is presented in five short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 5\nPart 2 of 5\nPart 3 of 5\nPart 4 of 5\nPart 5 of 5\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-associations-how-to.R\n401-associations-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-associations-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-associations-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-associations-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions:\n\ndifferent parts for different phases of the analysis workflow;\ndifferent tasks for different steps in each phase;\ndifferent questions to examine different ideas or coding steps.\n\nIn the week 7 workbook, we are going to work through the following workflow steps:\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\nChange the type classification of a variable in the data – using as.factor()\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\nDraw scatterplots to examine the association between pairs of variables – using ggplot() and geom_point()\nEstimate and test the correlations between pairs of variables – using cor.test()\n\nThe activity 401-associations-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-associations-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\n\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study.two.gen looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful.\n\n\n\n\nSome people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\nTip\n\n\n\nIn these notes, I provide notes on the code steps that result in the plot.\n\nClick on the Notes tab to see them.\n\n\n\n\n\n\nPreviously – in week 6: I talked about improving science through open reproducible methods but we cannot make progress without better theory and data [@smaldino2019better]\nWe want open reproducible findings but we do not just want reproducibility\nWe want to make sense of people in useful ways\n\n\n\n\n\nNow: we need to think causally about predictions and about measurement\nWe discuss health comprehension project to demonstrate critical self-reflection\n\n\nFor useful hypotheses, we need better theory so we can build clear testable predictions from explicit assumptions\nAnd with better models, we need better measurement because if we cannot reliably measure something then it is hard to build a theory about it\n\n\n\n\n\nStudents and colleagues almost never have problems coding analyses in R\nThe challenges are almost always located in the critical reflection you must do in order to develop sensible analysis, and to interpret the analysis results\nSo we need to start by highlighting the work of critical reflection in data analysis\n\n\n\n\n\nAs you will know, it is often difficult to identify a claim in an article [@scheel2022]\nHere are some questions you can ask to decide if a claim you read or make is clear:\n\n\nIs the claim stated unambiguously: can the claim support or contradict (or is it uncertain about) a prediction?\nCan you understand how we get back from the claim to the data, given assumptions about measurement, sampling and procedure?\n\n\n\n\n\nThe response to crisis has been to teach and use better methods\nThis improvement reveals a core problem [@scheel2021]: we often work to test hypotheses but our hypotheses are often undeveloped\nWe train hypothesis testing but we also need to train hypothesising:\nhow to measure, operationalize, and how to decide if hypothesis is corroborated or not\n\n\n\n\n\n\n\nTip\n\n\n\nWe want to be capable of being wrong\n\n\n\n\n\n\nTraditionally, students learn statistical tests, and learn to identify if a test statistic is significance or not\nIf we do not also talk about what is actually observed, and whether or how – or why – it is or is not compatible with theory based predictions then we do ritual not science [@Gigerenzer2004]\nThis is a problem: the focus on anything-but-null allows us to build or accommodate vague theories that can never be wrong\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1_l\n\nConcept formation\n\n\n\nnd_1_r\n\nCausal model\n\n\n\nnd_2_l\n\nMeasurement\n\n\n\nnd_1_l-&gt;nd_2_l\n\n\n\n\n\nnd_3\n\nStatistical predictions\n\n\n\nnd_2_l-&gt;nd_3\n\n\n\n\n\nnd_2_r\n\nAuxiliary assumptions\n\n\n\nnd_2_r-&gt;nd_3\n\n\n\n\n\nnd_4\n\nTesting hypotheses\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The derivation chain\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe derivation chain [@meehl1990; @scheel2021]\n\nDevelop your theory: the concepts, and the assumptions about causality\nSpecify how psychological concepts will be measured\nIdentify auxiliary assumptions about how we get from theoretical concepts to observable data\nIdentify theoretical predictions\nLink theoretical predictions to specific statistical tests that may support or contradict them\n\n\n\n\n\nWe often teach and learn about different kinds of validity but the key idea is simple [@borsboom2004]\n\n\na test is valid for measuring an attribute if and only if (a) the attribute exists and (b) variations in the attribute causally produce variations in the outcomes of the measurement procedure\n\n\nWe want to work with valid measures but validity requires explaining: (Q.1) Does the thing exist in the world? (Q.2) Is variation in that thing be reflected in variation in our measurement?\n\n\n\n\n\nWhat is our (causal) theory?\nWhat measures are we using, why?\nWhat is our specific prediction, why?\nDoes the prediction relate to sign and to magnitude?\nWhat analysis can test this prediction, why?\nHow will our results affect our beliefs, why?\n\n\n\n\n\nBecause the important questions concern how psychologists ask and answer research questions\nWe will work in the context of a live research project: What makes it easy or difficult to understand written health information?\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\nWhy this? We don’t really know what makes it easy or difficult to understand advice about health\n\n\n\n\nWe are working to help improve communication\nWith partners at Vienna Business University, Kantar Public, and the London School of Economics\nOur work has implications for: business communication; understanding reading development; marketing communication\n\n\n\n\n\nOur research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nThese kinds of research questions can be answered using methods like correlation, linear models\n\n\n\n\n\nWe got funding to collect data online using online Qualtrics questionnaire surveys\nWe tested people on a range of dimensions using standardized ability and our own knowledge tests\nMany of you will go on to work with online surveys, and with data from standardized ability measures\n\n\n\n\n\nWe collected data in two studies in 2020: using the online Prolific platform to recruit participants\nWe did several replication studies in student-led projects: we analyze the data in class\n\n\n\n\n\nThe health project has strengths and limitations\nWe show how to identify and critically evaluate this project so you can do the same for your work\n\n\n\n\nExtract from Qualtrics survey\n\n\n\n\n\n\n\nWhen skilled adult readers read and try to understand written text [@kintsch1994]\nThey must recognize and access the meanings of words\nThen use knowledge and reasoning to build an interpretation of what is in the text\nBased on connecting the information in the text with what they already know\n\n\n\n\n\nSuccessfully understanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 2: Factors influencing comprehension success\n\n\n\n\n\n\n\n\n\n\nWe measure reading comprehension: asking people to read text and then answer multiple choice questions\nWe measure background knowledge: vocabulary knowledge (Shipley); health literacy (HLVA)\nWe ask people to rate their own understanding of each text\n\n\n\n\n\nAre multiple choice questions good ways to probe understanding? – What alternatives are there?\nAre tests like the Shipley good measures of language knowledge? – What do we miss?\nCan a person accurately evaluate their own understanding? – Can we rely on subjective judgments?\n\n\n\n\n\nEven very good students sometimes do not question the validity of measures:\nNot asking questions like this has a real impact on the value of the interpretation of results\nHere, we are looking ahead to the critical thinking you will need to do for your dissertations\n\n\n\n\n\nPsychologists and people who work in related fields often want to know about associations\nIs variation in observed values on one dimension (e.g., comprehension) related to variation in another dimension (e.g., vocabulary)?\nDo values on both dimensions vary together?\n\n\n\n\n\nOutcome \\(=\\) response \\(=\\) criterion \\(=\\) dependent variable\nPredictor \\(=\\) covariate \\(=\\) independent variable \\(=\\) factor\nLinear model \\(=\\) regression analysis \\(=\\) regression model \\(=\\) multiple regression\n\n\n\n\n\nFirst, we need to read the data into R\n\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")\n\n\nNext, we should take a look at the data: you can open the data-set in Excel or you can use the head command to show the first few rows in\nThe person in row 1 has ETHNICITY White, is AGE 34 years, scored 33 on Shipley vocabulary, scored 7 on HLVA health literacy and, on average, self-rated their understanding of health information as 7.96 (so 8/9, mean.self) while scoring 0.49 accuracy in tests of understanding (49% mean.acc)\n\n\nstudy.one.gen %&gt;%\n    select(mean.acc, mean.self, HLVA, SHIPLEY, AGE, ETHNICITY) %&gt;%\n    head(n = 4)\n\n# A tibble: 4 × 6\n  mean.acc mean.self  HLVA SHIPLEY   AGE ETHNICITY\n     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n1     0.49      7.96     7      33    34 White    \n2     0.85      7.28     7      33    25 White    \n3     0.82      7.36     8      40    43 White    \n4     0.94      7.88    11      33    46 White    \n\n\n\n\n\n\nCovariance\n\n\\[COV_{xy} = \\frac{\\sum(x - \\bar{x})(y - \\bar{y})}{n -1}\\]\n\nIf we want to estimate the correlation between two sets of numbers: \\(x\\) and \\(y\\)\nWe want to know if variation in \\(x\\) (given by \\(x - \\bar{x}\\))\nVaries together with variation in \\(y\\) (given by \\(y - \\bar{y}\\))\n\n\n\n\n\nCovariance divided by standard deviations\n\n\\[r = \\frac{COV_{xy}}{s_xs_y}\\]\n\nBecause the two sets of numbers can be on different scales: e.g., SHIPLEY out of 40; mean.acc (proportion, out of 1)\nAnd because covariance values depend on the scales\nTo correlations easier to compare, we need to remove scale by dividing by the variables standard deviations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch question: Can people accurately evaluate whether they correctly understand written health information?\nMeasurement: Someone with higher scores on tested accuracy of understanding will also present higher scores on their ratings of their own understanding\nStatistical prediction: We predict that mean.acc and mean.self scores will be associated\nTest: If the prediction is correct, mean.acc and mean.self scores will be correlated\n\n\n\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 3: Histograms showing the distribution of mean accuracy and mean self-rated accuracy scores in the ‘study.one.gen’ data-set: means calculated for each participant over all their responses\n\n\n\n\n\n\n\n\nlibrary(patchwork)\nlibrary(tidyverse)\n\np.acc &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.acc)) + \n           geom_histogram(binwidth = .1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.acc),\n                      size = 1.5, colour = \"red\") +\n           xlab(\"mean accuracy\") +\n           xlim(0, 1.1) +\n           theme_bw()\n\np.self &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.self)) + \n           geom_histogram(binwidth = 1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.self),\n                      size = 1.5, colour = \"red\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) +\n           theme_bw()\n\np.acc + p.self\n\nLet’s go through the code step-by-step.\n\n\n\n\n\n\nTip\n\n\n\n\nHere the code is broken down, line by line, and each line is numbered.\nThis presentation style is done to make it easier for you to see what each step is doing.\nNotice that when we use p.acc &lt;- study.one.gen we tell R to first create the plot (giving it the name p.acc) but to not show it yet.\n\n\n\n\nlibrary(patchwork) and library(tidyverse): We need to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid showing the plots next to each other. We use the library() function to get these libraries.\nWe construct two plots. We call the plots p.acc and p.self. Each plot is constructed in a similar way so we explain the main steps for one plot. The plots are constructed but not shown until the last line of code is run.\np.acc &lt;- ... creates a plot called p.acc, using the processes that are specified in the next lines of code that follow.\n... &lt;- study.one.gen tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is called the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(aes(x = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = .1) + tells R to produce a histogram then add a step, next.\ngeom_vline(...) + tells R we want to draw a vertical line.\nxintercept = mean(study.one.gen$mean.acc), ... tells R to draw the vertical line at the mean value of the variable mean.acc in the study.one.gen data-set.\nsize = 1.5, colour = \"red\" tells R we want the vertical line to be red, and 1.5 times the usual size.\nxlab(\"mean accuracy\") + tells R we want the x-axis label to say that the plot is of \"mean accuracy\".\nxlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy values shown in the plot.\ntheme_bw() lastly, we change the theme.\nThen we have code to construct the second plot p.self.\np.acc + p.self: tells R to put the two plots together so they appear side-by-side in a grid for easy comparison.\n\nIn using pipes in the code, I am structuring the code so that it works — and is presented — in a sequence of steps. There are different ways to write code but I find this way easier to work with and to read and I think you will too.\nWhat you can see is that each line ending in a %&gt; pipe passes something on to the next line. A following line takes the output of the process coded in the preceding line, and works with it.\nEach step is executed in turn, in strict sequence. This means that if I delete the line study.one.gen %&gt;% then the following lines cannot work because the ggplot() function will be looking for a variable average that does not yet exist.\n\n\n\n\n\n\nTip\n\n\n\n\nYou can see that in the data processing part of the code, successive steps in data processing end in a pipe %&gt;%.\nIn contrast, successive steps of the plotting code add ggplot elements line by line with each line (except the last) ending in a +.\n\n\n\nNotice that none of the processing steps actually changes the dataset called study.one.gen. The results of the process exist and can be used only within the sequence of steps coded to produce the plots.\n\nYou can read a clear explanation of pipes here.\nYou can read about the new geom_vline() here.\n\n\n\n\n\n\n\n\nWe have a sample of accuracy scores:\nMean accuracy scores vary between 0.0 and 1.0\nWe draw the plot by grouping together similar values in bins\nHeights of bars represent numbers of cases with similar values in same bin\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 4: Distribution of mean accuracy\n\n\n\n\n\n\n\n\nstudy.one.gen %&gt;%\n           ggplot(aes(x = mean.acc)) + \n           geom_histogram(binwidth = .1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.acc),\n                      size = 1.5, colour = \"red\") +\n           annotate(\"text\", x = 0.6, y = 60,\n                    colour = \"red\",\n                    label = \"average value\\nshown in red\") +\n           xlab(\"mean accuracy\") +\n           xlim(0, 1.1) +\n           theme_bw()\n\nWe go through the code line by line. It will be useful to identify some differences between this chunk of code and the previous chunk of code.\n\nWe are going to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid. I assume you have already run the library() function to get these libraries. We do not need to do it again in the same R session.\nWe construct one plot here. We do not give it a name. Run the code and R will show the plot in the plot window immediately.\nstudy.one.gen %&gt;% tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(aes(x = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = .1) + tells R to produce a histogram then add a step, next.\ngeom_vline(...) + tells R we want to draw a vertical line.\nxintercept = mean(study.one.gen$mean.acc), ... tells R to draw the vertical line at the mean value of the variable mean.acc in the study.one.gen data-set.\nsize = 1.5, colour = \"red\" tells R we want the vertical line to be red, and 1.5 times the usual size.\nannotate(\"text\", ...** tells R to write some text.\nx = 0.6, y = 60** tells R where to write the text.\ncolour = \"red\"** tells R what colour to write the text.\nlabel = \"average value\\nshown in red\"** tells R what text to write.\nxlab(\"mean accuracy\") + tells R we want the x-axis label to say that the plot is about \"mean accuracy\".\nxlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy values shown in the plot.\ntheme_bw() lastly, we change the theme.\n\n\nYou can read about the new annotate() function here.\n\n\n\n\n\n\n\n\nThe average of these mean accuracy scores is marked with a red line where \\(\\bar{x} =\\) 0.8\nThe accuracy score for the person in row 1 is located at \\(x = .49\\), marked in blue\n\n\n\n\n\n\n\n\n\nFigure 5: Distribution of mean accuracy\n\n\n\n\n\n\n\n\n\nIn comparison, the mean accuracy score for the person in row 4 is located at \\(x = .94\\), marked in blue\n\n\n\n\n\n\n\n\n\nFigure 6: Distribution of mean accuracy\n\n\n\n\n\n\n\n\n\nIf the person at row 1 has a mean.accuracy score of .49, lower than the average\nAnd the person at row 4 has a mean.accuracy score of .94, higher than the average\nWhat will their mean.self scores be: will they be higher or lower than the average mean.self score?\n\n\n\n\n\nIs variation in the mean accuracy of understanding (of health information) associated with variation in mean self-rated accuracy of understanding?\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 7: Scatterplots showing whether values on mean accuracy (mean.acc) vary together with values on mean self-rated accuracy (mean.self) for the participants in this sample\n\n\n\n\n\n\n\n\np.acc &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.self, y = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           ylab(\"mean accuracy\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) + ylim(0, 1.1) +\n           theme_bw()\n\np.self &lt;- study.one.gen %&gt;%\n           ggplot(aes(y = mean.self, x = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           xlab(\"mean accuracy\") +\n           ylab(\"mean self-rated accuracy\") +\n           ylim(0, 10) + xlim(0, 1.1) +\n           theme_bw()\n\np.acc + p.self\n\n\nWe are going to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid. I assume you have already run the library() function to get these libraries. We do not need to do it again in the same R session.\nWe construct two plots. We call the plots p.acc and p.self again. Each plot is constructed in a similar way so we explain the main steps for one plot. The plots are constructed but not shown until the last line of code is run.\np.acc &lt;- ... creates a plot called p.acc, using the processes that are specified in the next lines of code that follow.\n... &lt;- study.one.gen tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is called the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(...) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.self, ...) tells R that in the plot we want it to show the mean.self variable values as horizontal (left to right) locations on the x-axis: this is one aesthetic mapping.\naes(... , y = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as vertical (low to high) locations on the y-axis: this is the second aesthetic mapping.\naes(x = mean.self, y = mean.acc) thus encodes two aesthetic mappings, telling R the position of the things it will draw (it will draw points, next): the vertical height, and the horizontal left-to-right position.\ngeom_point(...) tells R to produce a scatterplot, representing data values as points.\nsize = 2, alpha = .5 tells R we want the points to be 2 times the usual size with size = 2, and half the usual level of opacity (i.e. how solid the colour is) with alpha = .5.\nylab(\"mean accuracy\") + tells R we want the y-axis label to say that the plot is of \"mean accuracy\".\nxlab(\"mean self-rated accuracy\") + tells R we want the y-axis label to say that the plot is of \"mean self-rated accuracy\".\nylim(0, 10) + xlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy and mean self-rated accuracy values shown in the plot.\ntheme_bw() changes the theme.\nThen we have code to construct the second plot p.self.\np.acc + p.self: tells R to put the two plots together so they appear side-by-side in a grid for easy comparison.\n\n\nYou can read about the geom_point() function here.\n\n\n\n\n\n\n\n\nMean accuracy scores vary between 0.0 and 1.0\n\n\nThe height of each point shows the observed value of accuracy on the y-axis\n\n\nSelf-rated accuracy scores vary between 1 and 9\n\n\nThe horizontal position of each point shows the observed value of self-rated accuracy on the x-axis\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 8: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\n\nstudy.one.gen %&gt;%\n           ggplot(aes(x = mean.self, y = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           ylab(\"mean accuracy\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) + ylim(0, 1.1) +\n           theme_bw()\n\nWe use mostly the same code to draw Figure 8, compared to the code we used to draw Figure 7, but there is one difference. I do not walk through every line of code, here, but highlight the difference.\n\nWe construct one plot here. We do not give it a name. Run the code and R will show the plot in the plot window immediately.\nstudy.one.gen %&gt;% tells R that we are working with the data-set study.one.gen that we read in earlier.\nggplot(aes(x = mean.self, y = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.self, y = mean.acc) thus encodes two aesthetic mappings, telling R the position of the things it will draw (it will draw points, next): the vertical height, and the horizontal left-to-right position.\n\n\n\n\nWe can focus in one point, showing the data for one person.\n\nWe have a sample of 170 people\nFor each person, we have a value for the mean accuracy and a paired value for the mean self-rated accuracy\nEach point shows the paired data values for a person\nIn red: someone scored 3.48 on mean self-rated accuracy, 0.57 on mean accuracy\n\n\n\n\n\n\n\n\n\nFigure 9: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\n\n\ncor.test(study.one.gen$mean.acc,\n         study.one.gen$mean.self,\n         method = \"pearson\")\n\n\nWe specify the cor.test function, and name one variable study.one.gen$mean.acc\nThen we name the second variable study.one.gen$mean.self\nLast we specify the correlation method = \"pearson\" because we have a choice (we can apply other methods to estimate the correlation, e.g., Spearmans)\n\n\n\n\n\nWe look at the value of the correlation (here, cor) and the p-value\nWe can see that the correlation statistic is positive cor = .4863771 which we round to \\(cor = .49\\)\nAnd p-value = 2.026e-11 indicating that the correlation is significant \\(p &lt; .001\\)\n\n\ncor.test(study.one.gen$mean.acc,\n         study.one.gen$mean.self,\n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one.gen$mean.acc and study.one.gen$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\n\n\n\nUsually, we report a correlation like this:\n\n\nMean accuracy and mean self-rated accuracy were significantly correlated (\\(r (167 \\text{ df}) = .49, p &lt; .001\\)). Higher mean accuracy scores are associated with higher mean self-rated accuracy scores.\n\n\n\n\n\nThe correlation statistic is positive in sign and moderate in size, about \\(r = .49\\)\nWe can see that higher mean accuracy (mean.acc) scores are associated with higher mean self-rated accuracy (mean.self) scores\n\n\n\n\n\n\n\n\n\nFigure 10: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\n\nWe can simulate data to demonstrate [what scatterplots look like if]: (left) the correlation is positive, \\(r = .5\\); (right) the correlation is negative, \\(r = -.5\\)\n\n\n\n\n\n\n\n\nFigure 11: Scatterplots showing how simulated data values on mean accuracy and mean self-rated accuracy could vary together given positive or negative correlations\n\n\n\n\n\n\n\n\n\nNotice how, as you compare the plots, going from left to right\nAs the correlation increases, the points cluster together more closely\n\n\n\n\n\n\n\n\n\nFigure 12: Scatterplots showing how simulated data values on mean accuracy and mean self-rated accuracy could vary together given positive correlations of increasing size\n\n\n\n\n\n\n\n\n\n\nWe are often interested in whether or how variation in the values of two variables are associated\nWe can visualize the distribution of values in any one variable using histograms\nWe visualize the association of values in two variables using scatterplots\nWe conduct correlation tests to examine the sign (positive or negative) and the strength of the association\nBut we always need to think about our research questions, about where our data come from and about whether our measures are any good\n\n\n\n\nEvery problem you ever have: someone has had it before, solved it, and written a blog (or tweet or toot) about it\n\n\n\n\n\nR is free open statistical software: everything you use is contributed, discussed and taught by a community of R users online, in open forums\nLearning to navigate this knowledge is an introduction to the future of knowledge sharing"
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html#sec-associations-overview",
    "href": "PSYC411/part2/hypotheses-associations.html#sec-associations-overview",
    "title": "Hypotheses and associations",
    "section": "",
    "text": "Welcome to our overview of the materials you will work with in our data analysis class in the PSYC401 module, Week 7.\nWe are completing five classes together in weeks 6-10. These classes are designed to help students to learn about some very common and powerful psychological data analysis methods. We will focus on methods that allow us to visualize and make sense of evidence for associations between variables. Our materials are designed to help you to think about what you are doing, to understand the aims of the practical steps.\nWe will do this in the context of a live research project with potential real world impacts: the Clearly understood project. We will present our PSYC401 lessons in the context of this research project because we think that this context will help you to make sense of the data, and to see why we ask you to practise the skills we are teaching.\nWe encounter written health information all the time: on medication labels, in letters from doctors, and online when we research things we are worried about. It is not always easy to understand this information.\nIt is unclear how to make health communication more effective. The problem is that we are not sure how health information should be communicated so that everyone can understand it. This is why we ask the research questions:\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills."
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html#sec-associations-goals",
    "href": "PSYC411/part2/hypotheses-associations.html#sec-associations-goals",
    "title": "Hypotheses and associations",
    "section": "",
    "text": "This week, we focus on both developing your critical thinking and strengthening your practical skills in data analysis.\n1. Critical thinking\n\nConcepts: begin with critical thinking\nSkills: developing hypotheses\n\n2. Practical skills\n\nConcepts – associations: correlations, estimates and hypothesis tests\nSkills – visualizing variation and covariation\nSkills – writing the code\nSkills – estimating correlations\nSkills – hypothesis tests for correlations\nSkills – interpreting and reporting correlations"
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html#sec-associations-resources",
    "href": "PSYC411/part2/hypotheses-associations.html#sec-associations-resources",
    "title": "Hypotheses and associations",
    "section": "",
    "text": "You will see next links to the lectures we created to explain the concepts behind the critical thinking and analysis skills we want you to develop (Section 1.3.1), then information about the practical materials we have provided to help you to practise your skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 7 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points. We do this here because we can share the code we used to generate the plots we use in some of the slides 1\n\n\nThe lecture material for this week is presented in five short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 5\nPart 2 of 5\nPart 3 of 5\nPart 4 of 5\nPart 5 of 5\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-associations-how-to.R\n401-associations-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-associations-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-associations-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-associations-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions:\n\ndifferent parts for different phases of the analysis workflow;\ndifferent tasks for different steps in each phase;\ndifferent questions to examine different ideas or coding steps.\n\nIn the week 7 workbook, we are going to work through the following workflow steps:\n\nEmpty the R environment – using rm(list=ls())\nLoad relevant libraries – using library()\nRead in the data file – using read_csv()\nInspect the data – using head() and summary()\nChange the type classification of a variable in the data – using as.factor()\nDraw histograms to examine the distributions of variables – using ggplot() and geom_histogram()\nDraw scatterplots to examine the association between pairs of variables – using ggplot() and geom_point()\nEstimate and test the correlations between pairs of variables – using cor.test()\n\nThe activity 401-associations-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-associations-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\n\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study.two.gen looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful."
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html#sec-associations-notes",
    "href": "PSYC411/part2/hypotheses-associations.html#sec-associations-notes",
    "title": "Hypotheses and associations",
    "section": "",
    "text": "Some people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\nTip\n\n\n\nIn these notes, I provide notes on the code steps that result in the plot.\n\nClick on the Notes tab to see them.\n\n\n\n\n\n\nPreviously – in week 6: I talked about improving science through open reproducible methods but we cannot make progress without better theory and data [@smaldino2019better]\nWe want open reproducible findings but we do not just want reproducibility\nWe want to make sense of people in useful ways\n\n\n\n\n\nNow: we need to think causally about predictions and about measurement\nWe discuss health comprehension project to demonstrate critical self-reflection\n\n\nFor useful hypotheses, we need better theory so we can build clear testable predictions from explicit assumptions\nAnd with better models, we need better measurement because if we cannot reliably measure something then it is hard to build a theory about it\n\n\n\n\n\nStudents and colleagues almost never have problems coding analyses in R\nThe challenges are almost always located in the critical reflection you must do in order to develop sensible analysis, and to interpret the analysis results\nSo we need to start by highlighting the work of critical reflection in data analysis\n\n\n\n\n\nAs you will know, it is often difficult to identify a claim in an article [@scheel2022]\nHere are some questions you can ask to decide if a claim you read or make is clear:\n\n\nIs the claim stated unambiguously: can the claim support or contradict (or is it uncertain about) a prediction?\nCan you understand how we get back from the claim to the data, given assumptions about measurement, sampling and procedure?\n\n\n\n\n\nThe response to crisis has been to teach and use better methods\nThis improvement reveals a core problem [@scheel2021]: we often work to test hypotheses but our hypotheses are often undeveloped\nWe train hypothesis testing but we also need to train hypothesising:\nhow to measure, operationalize, and how to decide if hypothesis is corroborated or not\n\n\n\n\n\n\n\nTip\n\n\n\nWe want to be capable of being wrong\n\n\n\n\n\n\nTraditionally, students learn statistical tests, and learn to identify if a test statistic is significance or not\nIf we do not also talk about what is actually observed, and whether or how – or why – it is or is not compatible with theory based predictions then we do ritual not science [@Gigerenzer2004]\nThis is a problem: the focus on anything-but-null allows us to build or accommodate vague theories that can never be wrong\n\n\n\n\n\n\n\n\n\n\n\n\nQ\n\n\ncluster_R\n\n\n\n\nnd_1_l\n\nConcept formation\n\n\n\nnd_1_r\n\nCausal model\n\n\n\nnd_2_l\n\nMeasurement\n\n\n\nnd_1_l-&gt;nd_2_l\n\n\n\n\n\nnd_3\n\nStatistical predictions\n\n\n\nnd_2_l-&gt;nd_3\n\n\n\n\n\nnd_2_r\n\nAuxiliary assumptions\n\n\n\nnd_2_r-&gt;nd_3\n\n\n\n\n\nnd_4\n\nTesting hypotheses\n\n\n\nnd_3-&gt;nd_4\n\n\n\n\n\n\n\n\nFigure 1: The derivation chain\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe derivation chain [@meehl1990; @scheel2021]\n\nDevelop your theory: the concepts, and the assumptions about causality\nSpecify how psychological concepts will be measured\nIdentify auxiliary assumptions about how we get from theoretical concepts to observable data\nIdentify theoretical predictions\nLink theoretical predictions to specific statistical tests that may support or contradict them\n\n\n\n\n\nWe often teach and learn about different kinds of validity but the key idea is simple [@borsboom2004]\n\n\na test is valid for measuring an attribute if and only if (a) the attribute exists and (b) variations in the attribute causally produce variations in the outcomes of the measurement procedure\n\n\nWe want to work with valid measures but validity requires explaining: (Q.1) Does the thing exist in the world? (Q.2) Is variation in that thing be reflected in variation in our measurement?\n\n\n\n\n\nWhat is our (causal) theory?\nWhat measures are we using, why?\nWhat is our specific prediction, why?\nDoes the prediction relate to sign and to magnitude?\nWhat analysis can test this prediction, why?\nHow will our results affect our beliefs, why?\n\n\n\n\n\nBecause the important questions concern how psychologists ask and answer research questions\nWe will work in the context of a live research project: What makes it easy or difficult to understand written health information?\n\n\n\n\nflickr: Sasin Tipchair ‘Senior woman in wheelchair talking to a nurse in a hospital’\n\n\nWhy this? We don’t really know what makes it easy or difficult to understand advice about health\n\n\n\n\nWe are working to help improve communication\nWith partners at Vienna Business University, Kantar Public, and the London School of Economics\nOur work has implications for: business communication; understanding reading development; marketing communication\n\n\n\n\n\nOur research questions are:\n\n\nWhat person attributes predict success in understanding?\nCan people accurately evaluate whether they correctly understand written health information?\n\n\nThese kinds of research questions can be answered using methods like correlation, linear models\n\n\n\n\n\nWe got funding to collect data online using online Qualtrics questionnaire surveys\nWe tested people on a range of dimensions using standardized ability and our own knowledge tests\nMany of you will go on to work with online surveys, and with data from standardized ability measures\n\n\n\n\n\nWe collected data in two studies in 2020: using the online Prolific platform to recruit participants\nWe did several replication studies in student-led projects: we analyze the data in class\n\n\n\n\n\nThe health project has strengths and limitations\nWe show how to identify and critically evaluate this project so you can do the same for your work\n\n\n\n\nExtract from Qualtrics survey\n\n\n\n\n\n\n\nWhen skilled adult readers read and try to understand written text [@kintsch1994]\nThey must recognize and access the meanings of words\nThen use knowledge and reasoning to build an interpretation of what is in the text\nBased on connecting the information in the text with what they already know\n\n\n\n\n\nSuccessfully understanding text depends on (1.) language experience and (2.) reasoning ability [@freed2017]\n\n\n\n\n\n\n\n\n\nQ\n\n\n\nnd_1_l\n\nLanguage experience\n\n\n\nnd_2\n\nComprehension outcome\n\n\n\nnd_1_l-&gt;nd_2\n\n\n\n\n\nnd_1_r\n\nReasoning capacity\n\n\n\nnd_1_r-&gt;nd_2\n\n\n\n\n\n\n\n\nFigure 2: Factors influencing comprehension success\n\n\n\n\n\n\n\n\n\n\nWe measure reading comprehension: asking people to read text and then answer multiple choice questions\nWe measure background knowledge: vocabulary knowledge (Shipley); health literacy (HLVA)\nWe ask people to rate their own understanding of each text\n\n\n\n\n\nAre multiple choice questions good ways to probe understanding? – What alternatives are there?\nAre tests like the Shipley good measures of language knowledge? – What do we miss?\nCan a person accurately evaluate their own understanding? – Can we rely on subjective judgments?\n\n\n\n\n\nEven very good students sometimes do not question the validity of measures:\nNot asking questions like this has a real impact on the value of the interpretation of results\nHere, we are looking ahead to the critical thinking you will need to do for your dissertations\n\n\n\n\n\nPsychologists and people who work in related fields often want to know about associations\nIs variation in observed values on one dimension (e.g., comprehension) related to variation in another dimension (e.g., vocabulary)?\nDo values on both dimensions vary together?\n\n\n\n\n\nOutcome \\(=\\) response \\(=\\) criterion \\(=\\) dependent variable\nPredictor \\(=\\) covariate \\(=\\) independent variable \\(=\\) factor\nLinear model \\(=\\) regression analysis \\(=\\) regression model \\(=\\) multiple regression\n\n\n\n\n\nFirst, we need to read the data into R\n\n\nstudy.one.gen &lt;- read_csv(\"study-one-general-participants.csv\")\n\n\nNext, we should take a look at the data: you can open the data-set in Excel or you can use the head command to show the first few rows in\nThe person in row 1 has ETHNICITY White, is AGE 34 years, scored 33 on Shipley vocabulary, scored 7 on HLVA health literacy and, on average, self-rated their understanding of health information as 7.96 (so 8/9, mean.self) while scoring 0.49 accuracy in tests of understanding (49% mean.acc)\n\n\nstudy.one.gen %&gt;%\n    select(mean.acc, mean.self, HLVA, SHIPLEY, AGE, ETHNICITY) %&gt;%\n    head(n = 4)\n\n# A tibble: 4 × 6\n  mean.acc mean.self  HLVA SHIPLEY   AGE ETHNICITY\n     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n1     0.49      7.96     7      33    34 White    \n2     0.85      7.28     7      33    25 White    \n3     0.82      7.36     8      40    43 White    \n4     0.94      7.88    11      33    46 White    \n\n\n\n\n\n\nCovariance\n\n\\[COV_{xy} = \\frac{\\sum(x - \\bar{x})(y - \\bar{y})}{n -1}\\]\n\nIf we want to estimate the correlation between two sets of numbers: \\(x\\) and \\(y\\)\nWe want to know if variation in \\(x\\) (given by \\(x - \\bar{x}\\))\nVaries together with variation in \\(y\\) (given by \\(y - \\bar{y}\\))\n\n\n\n\n\nCovariance divided by standard deviations\n\n\\[r = \\frac{COV_{xy}}{s_xs_y}\\]\n\nBecause the two sets of numbers can be on different scales: e.g., SHIPLEY out of 40; mean.acc (proportion, out of 1)\nAnd because covariance values depend on the scales\nTo correlations easier to compare, we need to remove scale by dividing by the variables standard deviations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch question: Can people accurately evaluate whether they correctly understand written health information?\nMeasurement: Someone with higher scores on tested accuracy of understanding will also present higher scores on their ratings of their own understanding\nStatistical prediction: We predict that mean.acc and mean.self scores will be associated\nTest: If the prediction is correct, mean.acc and mean.self scores will be correlated\n\n\n\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 3: Histograms showing the distribution of mean accuracy and mean self-rated accuracy scores in the ‘study.one.gen’ data-set: means calculated for each participant over all their responses\n\n\n\n\n\n\n\n\nlibrary(patchwork)\nlibrary(tidyverse)\n\np.acc &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.acc)) + \n           geom_histogram(binwidth = .1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.acc),\n                      size = 1.5, colour = \"red\") +\n           xlab(\"mean accuracy\") +\n           xlim(0, 1.1) +\n           theme_bw()\n\np.self &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.self)) + \n           geom_histogram(binwidth = 1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.self),\n                      size = 1.5, colour = \"red\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) +\n           theme_bw()\n\np.acc + p.self\n\nLet’s go through the code step-by-step.\n\n\n\n\n\n\nTip\n\n\n\n\nHere the code is broken down, line by line, and each line is numbered.\nThis presentation style is done to make it easier for you to see what each step is doing.\nNotice that when we use p.acc &lt;- study.one.gen we tell R to first create the plot (giving it the name p.acc) but to not show it yet.\n\n\n\n\nlibrary(patchwork) and library(tidyverse): We need to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid showing the plots next to each other. We use the library() function to get these libraries.\nWe construct two plots. We call the plots p.acc and p.self. Each plot is constructed in a similar way so we explain the main steps for one plot. The plots are constructed but not shown until the last line of code is run.\np.acc &lt;- ... creates a plot called p.acc, using the processes that are specified in the next lines of code that follow.\n... &lt;- study.one.gen tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is called the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(aes(x = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = .1) + tells R to produce a histogram then add a step, next.\ngeom_vline(...) + tells R we want to draw a vertical line.\nxintercept = mean(study.one.gen$mean.acc), ... tells R to draw the vertical line at the mean value of the variable mean.acc in the study.one.gen data-set.\nsize = 1.5, colour = \"red\" tells R we want the vertical line to be red, and 1.5 times the usual size.\nxlab(\"mean accuracy\") + tells R we want the x-axis label to say that the plot is of \"mean accuracy\".\nxlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy values shown in the plot.\ntheme_bw() lastly, we change the theme.\nThen we have code to construct the second plot p.self.\np.acc + p.self: tells R to put the two plots together so they appear side-by-side in a grid for easy comparison.\n\nIn using pipes in the code, I am structuring the code so that it works — and is presented — in a sequence of steps. There are different ways to write code but I find this way easier to work with and to read and I think you will too.\nWhat you can see is that each line ending in a %&gt; pipe passes something on to the next line. A following line takes the output of the process coded in the preceding line, and works with it.\nEach step is executed in turn, in strict sequence. This means that if I delete the line study.one.gen %&gt;% then the following lines cannot work because the ggplot() function will be looking for a variable average that does not yet exist.\n\n\n\n\n\n\nTip\n\n\n\n\nYou can see that in the data processing part of the code, successive steps in data processing end in a pipe %&gt;%.\nIn contrast, successive steps of the plotting code add ggplot elements line by line with each line (except the last) ending in a +.\n\n\n\nNotice that none of the processing steps actually changes the dataset called study.one.gen. The results of the process exist and can be used only within the sequence of steps coded to produce the plots.\n\nYou can read a clear explanation of pipes here.\nYou can read about the new geom_vline() here.\n\n\n\n\n\n\n\n\nWe have a sample of accuracy scores:\nMean accuracy scores vary between 0.0 and 1.0\nWe draw the plot by grouping together similar values in bins\nHeights of bars represent numbers of cases with similar values in same bin\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 4: Distribution of mean accuracy\n\n\n\n\n\n\n\n\nstudy.one.gen %&gt;%\n           ggplot(aes(x = mean.acc)) + \n           geom_histogram(binwidth = .1) +\n           geom_vline(xintercept = mean(study.one.gen$mean.acc),\n                      size = 1.5, colour = \"red\") +\n           annotate(\"text\", x = 0.6, y = 60,\n                    colour = \"red\",\n                    label = \"average value\\nshown in red\") +\n           xlab(\"mean accuracy\") +\n           xlim(0, 1.1) +\n           theme_bw()\n\nWe go through the code line by line. It will be useful to identify some differences between this chunk of code and the previous chunk of code.\n\nWe are going to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid. I assume you have already run the library() function to get these libraries. We do not need to do it again in the same R session.\nWe construct one plot here. We do not give it a name. Run the code and R will show the plot in the plot window immediately.\nstudy.one.gen %&gt;% tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(aes(x = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as locations on the x-axis: this is the aesthetic mapping.\ngeom_histogram(binwidth = .1) + tells R to produce a histogram then add a step, next.\ngeom_vline(...) + tells R we want to draw a vertical line.\nxintercept = mean(study.one.gen$mean.acc), ... tells R to draw the vertical line at the mean value of the variable mean.acc in the study.one.gen data-set.\nsize = 1.5, colour = \"red\" tells R we want the vertical line to be red, and 1.5 times the usual size.\nannotate(\"text\", ...** tells R to write some text.\nx = 0.6, y = 60** tells R where to write the text.\ncolour = \"red\"** tells R what colour to write the text.\nlabel = \"average value\\nshown in red\"** tells R what text to write.\nxlab(\"mean accuracy\") + tells R we want the x-axis label to say that the plot is about \"mean accuracy\".\nxlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy values shown in the plot.\ntheme_bw() lastly, we change the theme.\n\n\nYou can read about the new annotate() function here.\n\n\n\n\n\n\n\n\nThe average of these mean accuracy scores is marked with a red line where \\(\\bar{x} =\\) 0.8\nThe accuracy score for the person in row 1 is located at \\(x = .49\\), marked in blue\n\n\n\n\n\n\n\n\n\nFigure 5: Distribution of mean accuracy\n\n\n\n\n\n\n\n\n\nIn comparison, the mean accuracy score for the person in row 4 is located at \\(x = .94\\), marked in blue\n\n\n\n\n\n\n\n\n\nFigure 6: Distribution of mean accuracy\n\n\n\n\n\n\n\n\n\nIf the person at row 1 has a mean.accuracy score of .49, lower than the average\nAnd the person at row 4 has a mean.accuracy score of .94, higher than the average\nWhat will their mean.self scores be: will they be higher or lower than the average mean.self score?\n\n\n\n\n\nIs variation in the mean accuracy of understanding (of health information) associated with variation in mean self-rated accuracy of understanding?\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 7: Scatterplots showing whether values on mean accuracy (mean.acc) vary together with values on mean self-rated accuracy (mean.self) for the participants in this sample\n\n\n\n\n\n\n\n\np.acc &lt;- study.one.gen %&gt;%\n           ggplot(aes(x = mean.self, y = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           ylab(\"mean accuracy\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) + ylim(0, 1.1) +\n           theme_bw()\n\np.self &lt;- study.one.gen %&gt;%\n           ggplot(aes(y = mean.self, x = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           xlab(\"mean accuracy\") +\n           ylab(\"mean self-rated accuracy\") +\n           ylim(0, 10) + xlim(0, 1.1) +\n           theme_bw()\n\np.acc + p.self\n\n\nWe are going to use {tidyverse} library functions to construct the plots and {patchwork} library functions to assemble the plots into a grid. I assume you have already run the library() function to get these libraries. We do not need to do it again in the same R session.\nWe construct two plots. We call the plots p.acc and p.self again. Each plot is constructed in a similar way so we explain the main steps for one plot. The plots are constructed but not shown until the last line of code is run.\np.acc &lt;- ... creates a plot called p.acc, using the processes that are specified in the next lines of code that follow.\n... &lt;- study.one.gen tells R that we are working with the data-set study.one.gen that we read in earlier.\n%&gt;% is called the pipe and it is code telling R to work with the study.one.gen data in the next plot processing steps.\nggplot(...) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.self, ...) tells R that in the plot we want it to show the mean.self variable values as horizontal (left to right) locations on the x-axis: this is one aesthetic mapping.\naes(... , y = mean.acc) tells R that in the plot we want it to show the mean.acc variable values as vertical (low to high) locations on the y-axis: this is the second aesthetic mapping.\naes(x = mean.self, y = mean.acc) thus encodes two aesthetic mappings, telling R the position of the things it will draw (it will draw points, next): the vertical height, and the horizontal left-to-right position.\ngeom_point(...) tells R to produce a scatterplot, representing data values as points.\nsize = 2, alpha = .5 tells R we want the points to be 2 times the usual size with size = 2, and half the usual level of opacity (i.e. how solid the colour is) with alpha = .5.\nylab(\"mean accuracy\") + tells R we want the y-axis label to say that the plot is of \"mean accuracy\".\nxlab(\"mean self-rated accuracy\") + tells R we want the y-axis label to say that the plot is of \"mean self-rated accuracy\".\nylim(0, 10) + xlim(0, 1.1) + sets limits on the minimum and maximum mean accuracy and mean self-rated accuracy values shown in the plot.\ntheme_bw() changes the theme.\nThen we have code to construct the second plot p.self.\np.acc + p.self: tells R to put the two plots together so they appear side-by-side in a grid for easy comparison.\n\n\nYou can read about the geom_point() function here.\n\n\n\n\n\n\n\n\nMean accuracy scores vary between 0.0 and 1.0\n\n\nThe height of each point shows the observed value of accuracy on the y-axis\n\n\nSelf-rated accuracy scores vary between 1 and 9\n\n\nThe horizontal position of each point shows the observed value of self-rated accuracy on the x-axis\n\n\nPlotNotes\n\n\n\n\n\n\n\n\n\n\nFigure 8: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\n\nstudy.one.gen %&gt;%\n           ggplot(aes(x = mean.self, y = mean.acc)) +\n           geom_point(size = 2, alpha = .5) +\n           ylab(\"mean accuracy\") +\n           xlab(\"mean self-rated accuracy\") +\n           xlim(0, 10) + ylim(0, 1.1) +\n           theme_bw()\n\nWe use mostly the same code to draw Figure 8, compared to the code we used to draw Figure 7, but there is one difference. I do not walk through every line of code, here, but highlight the difference.\n\nWe construct one plot here. We do not give it a name. Run the code and R will show the plot in the plot window immediately.\nstudy.one.gen %&gt;% tells R that we are working with the data-set study.one.gen that we read in earlier.\nggplot(aes(x = mean.self, y = mean.acc)) + takes the study.one.gen data and asks R to use the ggplot() function to produce a plot.\naes(x = mean.self, y = mean.acc) thus encodes two aesthetic mappings, telling R the position of the things it will draw (it will draw points, next): the vertical height, and the horizontal left-to-right position.\n\n\n\n\nWe can focus in one point, showing the data for one person.\n\nWe have a sample of 170 people\nFor each person, we have a value for the mean accuracy and a paired value for the mean self-rated accuracy\nEach point shows the paired data values for a person\nIn red: someone scored 3.48 on mean self-rated accuracy, 0.57 on mean accuracy\n\n\n\n\n\n\n\n\n\nFigure 9: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\n\n\ncor.test(study.one.gen$mean.acc,\n         study.one.gen$mean.self,\n         method = \"pearson\")\n\n\nWe specify the cor.test function, and name one variable study.one.gen$mean.acc\nThen we name the second variable study.one.gen$mean.self\nLast we specify the correlation method = \"pearson\" because we have a choice (we can apply other methods to estimate the correlation, e.g., Spearmans)\n\n\n\n\n\nWe look at the value of the correlation (here, cor) and the p-value\nWe can see that the correlation statistic is positive cor = .4863771 which we round to \\(cor = .49\\)\nAnd p-value = 2.026e-11 indicating that the correlation is significant \\(p &lt; .001\\)\n\n\ncor.test(study.one.gen$mean.acc,\n         study.one.gen$mean.self,\n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  study.one.gen$mean.acc and study.one.gen$mean.self\nt = 7.1936, df = 167, p-value = 2.026e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3619961 0.5937425\nsample estimates:\n      cor \n0.4863771 \n\n\n\n\n\n\nUsually, we report a correlation like this:\n\n\nMean accuracy and mean self-rated accuracy were significantly correlated (\\(r (167 \\text{ df}) = .49, p &lt; .001\\)). Higher mean accuracy scores are associated with higher mean self-rated accuracy scores.\n\n\n\n\n\nThe correlation statistic is positive in sign and moderate in size, about \\(r = .49\\)\nWe can see that higher mean accuracy (mean.acc) scores are associated with higher mean self-rated accuracy (mean.self) scores\n\n\n\n\n\n\n\n\n\nFigure 10: Scatterplot showing how values on mean accuracy and mean self-rated accuracy vary together\n\n\n\n\n\n\n\n\nWe can simulate data to demonstrate [what scatterplots look like if]: (left) the correlation is positive, \\(r = .5\\); (right) the correlation is negative, \\(r = -.5\\)\n\n\n\n\n\n\n\n\nFigure 11: Scatterplots showing how simulated data values on mean accuracy and mean self-rated accuracy could vary together given positive or negative correlations\n\n\n\n\n\n\n\n\n\nNotice how, as you compare the plots, going from left to right\nAs the correlation increases, the points cluster together more closely\n\n\n\n\n\n\n\n\n\nFigure 12: Scatterplots showing how simulated data values on mean accuracy and mean self-rated accuracy could vary together given positive correlations of increasing size"
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html#summary",
    "href": "PSYC411/part2/hypotheses-associations.html#summary",
    "title": "Hypotheses and associations",
    "section": "",
    "text": "We are often interested in whether or how variation in the values of two variables are associated\nWe can visualize the distribution of values in any one variable using histograms\nWe visualize the association of values in two variables using scatterplots\nWe conduct correlation tests to examine the sign (positive or negative) and the strength of the association\nBut we always need to think about our research questions, about where our data come from and about whether our measures are any good\n\n\n\n\nEvery problem you ever have: someone has had it before, solved it, and written a blog (or tweet or toot) about it\n\n\n\n\n\nR is free open statistical software: everything you use is contributed, discussed and taught by a community of R users online, in open forums\nLearning to navigate this knowledge is an introduction to the future of knowledge sharing"
  },
  {
    "objectID": "PSYC411/part2/hypotheses-associations.html#footnotes",
    "href": "PSYC411/part2/hypotheses-associations.html#footnotes",
    "title": "Hypotheses and associations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe write the slides and this book in Quarto in R-Studio. Quarto scripts can be rendered as .html to share web-books like this one, or to share slides like those we use in presenting the lecture. One advantage of using Quarto is that we can share a plot and the code we used to generate the plot in the same page.↩︎"
  },
  {
    "objectID": "PSYC411/part2/index.html",
    "href": "PSYC411/part2/index.html",
    "title": "Preface: Our approach",
    "section": "",
    "text": "Preface: Our approach\nWe can, here, explain a development in the approach we take in teaching this course. Naturally, this development in approach will require a parallel development in your approach to learning.\nWe are going to focus on working in research in context (see Figure 1).\n\n\n\n\n\n\n\n\nG\n\n\n\nreading\n\nreading\n\n\n\nknowledge\n\nknowledge\n\n\n\nreading--knowledge\n\n\n\n\nconventions\n\nconventions\n\n\n\nknowledge--conventions\n\n\n\n\nconcepts\n\nconcepts\n\n\n\nknowledge--concepts\n\n\n\n\npractices\n\npractices\n\n\n\nknowledge--practices\n\n\n\n\n\n\n\nFigure 1: Working in research in context.\n\n\n\n\n\nYou have been introduced to R. We know that some of you are new to R so we will practice the skills you are learning. We will consolidate, revise, and extend these skills.\nWe will encounter — some, for the first time – the linear model also known as regression analysis. But the big change is this focus on context. The reason is that not talking about the context is risky for how you approach, do, or think about data analysis.\nIn traditional methods teaching, the schedule of classes will progress through a series of tests, one test a week, from simpler to more complex tests. In this approach, the presentation is often brief about the context: the question the researchers are investigating; the methods they use to collect data; and, critically, the assumptions they make about how your reasoning can get you from the things you measure to the things you are trying to understand.\nThis approach is understandable but it presents a misleading view. It implies that if you learn the method, and can match the textbook example to your context then all you need to do is to apply the analysis code to get the right result. This style of working is common, and it is often a reasonable place to start, but the isolation from context reduces the application of judgment, and limits critical evaluation of measurement, analysis assumptions, and sources of uncertainty.\n\n\n\n\n\n\nTip\n\n\n\nWe can do better.\n\n\nA more productive approach – this is the approach we will take – is to expose, and talk about some of the real challenges that anybody who handles data, or quantitative evidence, deals with in professional life:\n\nThinking about the mapping from our concerns to the research questions, to the things we measure, the analysis we do, and then the conclusions we make.\nSelecting or constructing valid measures that can be assumed to measure the things they are supposed to measure.\nTaking samples of observations, and making conclusions about the population.\nMaking estimates and linking these estimates to an account that is explicit about causes.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC411/part2/how.html",
    "href": "PSYC411/part2/how.html",
    "title": "How you can do it",
    "section": "",
    "text": "The PSYC401 Research Report assignment requires students to locate, access, analyse and report previously collected data.\n\n\n\n\n\n\nTip\n\n\n\nHere, we answer the question:\n\nHow can the assignment be done?\n\n\n\nWe outline the workflow you can follow, proceeding through a series of steps, to complete the essential tasks. Look at this outline, make a plan, and then follow the advice, taking it one step at a time.\nIf you want to understand why we think you will benefit from doing this, you can read the explanation in ?@sec-intro-why.\nIf you want to know more about what you are expected to do, you can read about that in ?@sec-what.\nWe provide information on assessment criteria and our approach to marking in ?@sec-marking.\n\n\nStudents have taken a variety of approaches to the assignment.\n\nUsing demonstration data — Some students choose to complete an analysis of one of the data-sets used for practical exercises in class: the example or demonstration data we collect together as curated data-sets.\nAnalyzing public data that have been previously analysed — Some students choose to complete an analysis of a publicly available data-set that has been analysed previously, where the analysis report has been published in a journal article.\nAnalyzing public data that have not been previously analysed — Some students choose to complete an analysis of a publicly available data-set where an analysis report has not been published in a journal article.\n\nAsk in class or on the Moodle discussion forum for advice about any one of these approaches.\nI consider, first, working with data-sets where an analysis of the data has been presented in the article (see Section 1.2). I then look at working with data-sets where the data are presented without an analysis (see Section 1.3). Our advice on working with data-sets presented without an analysis will overlap in key respects with our advice on working with curated demonstration data.\n\n\n\nIn the following, I split our guidance into two parts.\n\nI look next at the task of locating, accessing and checking the data (Section 1.2.1).\nThen I look at the task of figuring out what analysis you can do with the data (see Section 1.2.2).\n\nObviously, you cannot consider an analysis if you cannot be sure that you can work with the data [@minocher].\n\n\nAt the start of your work on the assignment, you will need to (1.) locate then (2.) access data for analysis, and then you will need to (3.) check that the data are usable. I set out advice on doing each step, following. Work through the steps: one step at a time.\n\n\nIt is usually helpful to find a data-set where the data have been collected in a study within a topic area you care about, or could be interested in. It is helpful because you will need to work with the data and it will be motivating if you are interested in what the data concern. And it is helpful because, often, you will need to do a bit of reading on related research to learn about the context for the data collection, and you will usually want to read research sources that interest you.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nDo a search: look for an article with usable data in a topic area that interests you.\n\n\n\nThere are at least two ways you can do this. Both should be reasonably quick methods to get to a usable data-set.\n\nDo a search on Google scholar).\nDo a search on the webpages of a journal.\n\nMost psychological research is published in journals like Psychological Science. If you want, you can look at a list of psychology journals here.\nIn a journal like Psychological Science you can look through lists of previously published articles (in issues, volumes, by year) on the journal webpage. Here is the list of issues for Psychological Science..\n\n\nIn both methods, you are looking for an article associated with data (and maybe analysis code) you can access and that you are sure you can use. In both methods, you need to first think about some key words to use in your search. Ask yourself:\n\nWhat are you interested in? What population, intervention or effect, comparison, or outcome?\n\nThen:\n\nWhat words do people use, in articles you have seen, when they talk about this thing?\n\nYou can use these words, and maybe consider alternate terms. For example, I am interested in reading comprehension or development reading comprehension but researchers working on reading development might also refer to children reading comprehension.\nYou want to be as efficient as possible so combine your search for articles in an interesting topic area with your search for accessible data. We can learn from the research we discussed on data sharing practices (?@sec-sharing) by looking for specific markers that data associated with an article should be accessible.\nIf you are doing a search (1.) on Google scholar), I would use the key words related to your topic plus words like: open data badge; open science badge. So, I would do a search for the words: reading comprehension open data badge. I have done this: you can try it. The search results will list articles related to the topic of reading comprehension, where the authors claim to have earned the open data badge because they have made data available.\nIf you are doing a search (2.) in a journal list of articles, then what you are looking for are articles that interest you and which are listed with open data badges. In the listing for Psychological Science (here)) a quick read of the journal issue articles index shows that article titles are listed together with symbols representing the open science badges that authors have claimed.\nIn other journals (e.g., PLOS ONE, PeerJ, Collabra), you may be looking for interesting articles with the words Data Availability Statement, Data Accessibility Statement, Supplementary data or Supplementary materials in the article webpage somewhere. Journals like PeerJ or Collabra, in particular, make it easy to locate data associated with published articles on their web pages.\nIn Collabra, you can find published articles through the journal webpage (here). If you click on the title of any article, and look at the article webpage, then on the left of the article text, you can see an index of article contents and that index lists the Data Availability Statement. Click on that and you are often taken to a link to a data repository.\n\n\n\n\nIf you have located an interesting article with evidence (an open data badge or a data accessibility statement) that the authors have shared their data, you need to check that you can access the data. Most of the time, now, you are looking for a link you can use to go directly to the shared data. The link is often presented as a hyperlink on a webpage, associated with Digital Object Identifiers (DOIs) or Universal resource locators (URLs). Or, increasingly, you are looking for a link to a data repository on a site like the Open Science Framework (OSF).\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nAccess the data associated with the article you have found.\n\n\n\nHere are some recent examples from my work that you can check, to give you a sense of where or how to find the accessible link to the shared data.\n\nRicketts, J., Dawson, N., & Davies, R. (2021). The hidden depths of new word knowledge: Using graded measures of orthographic and semantic learning to measure vocabulary acquisition. Learning and Instruction, 74, 101468. https://doi.org/10.1016/j.learninstruc.2021.101468\n\n\nRodríguez-Ferreiro, J., Aguilera, M., & Davies, R. (2020). Semantic priming and schizotypal personality: Reassessing the link between thought disorder and enhanced spreading of semantic activation. PeerJ, 8, e9511. https://doi.org/10.7717/peerj.9511\n\nThese are both open access articles.\nIf you look at the webpage for, @rodríguez-ferreiro2020, (here)), you can do a search in the article text for the keyword OSF (on the article webpage, use keys CMD-F plus OSF). You are checking to see if you can click on the link and and if clicking on the link takes you to a repository listing the data for the article. The @rodríguez-ferreiro2020 article is associated with a data plus analysis code repository (OSF))\nNotice that on the repository webpage, you can see a description of the project plus .pdf files and a folder data-set and Code. If you can click through to the folders, and download the datafiles, you have accessed the data successfully.\nI have guided you, here, through to the @rodríguez-ferreiro2020 data repository, can you find the data for the @ricketts2021 repository?\n\n\n\nIf you have located an interesting article with data that you can access, and if you have read the introductory notes (?@sec-checkanalyses), then you will next need to make sure that you can use the data.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nCheck the data and the data documentation to make sure you can understand what you have got and whether you can use it.\n\n\n\nWhat make data usable are:\n\nInformation in the article, or in the data repository documentation, on the study design and data collection methods: you need to be able to understand where the data came from, how they were collected, and why.\nClear data documentation: you need to find information on the variables, the observations, the scoring, the coding, and whether and how the data were processed to get them from raw data state to the data ready for analysis.\n\nData documentation is often presented as a note or a wiki page or a miniature paper and may be called a codebook, data dictionary, guide to materials or something similar. You will need to check that you can find information on (examples shown are from the @rodríguez-ferreiro2020 OSF guide to materials):\n\nwhat the data files are called e.g. PrimDir-111019.csv;\nhow the named data files correspond to the studies presented in the report;\nwhat the data file columns are called and what variables the column data represent e.g. relation, coding for prime-target relatedness condition ...;\nhow scores or responses in columns were collected or calculated e.g. age, giving the age in years ...;\nhow coding was done, if coding was used e.g. biling, giving the bilingualism status;\nwhether data were processed, how missing values were coded, whether participants or observations were excluded before analysis e.g. Missing values in the rt column ... coded as NA\n\n\n\n\n\n\n\nWarning\n\n\n\nIf these information are not presented, or are not clear: walk away.\n\n\n\n\n\n\nAfter you have found an interesting article, and have confirmed that you can use the associated data, you will need to plan what analysis you want to do.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nIdentify and understand the analysis in the article.\nWork out what analysis you want to do.\n\n\n\nStudents have taken a variety of approaches to the assignment.\n\nSome students choose to complete a reanalysis of the data, in an attempt to reproduce the results presented in the article (?@sec-methodsrepro).\nSome students choose to complete an alternate analysis of the data, varying elements of the analysis (?@sec-multiverse).\n\nEither way, you will want to first make sure you can identify exactly what the authors of the original study did, how they did it, and why they did it.\nYou can process the key article information efficiently using the QALMRI method we discussed in the class on graduate writing skills [@brosowsky; @kosslyn2005]. You are first aiming to locate information on the broad and the specific question the study addresses, the methods the study authors used to collect data, the results they report, and the conclusions they present given the results. Can you find these bits of information?\n\n\nAre you interested in attempting a methods reproducibility test?\nFollowing Hardwicke and colleagues [@hardwicke2018; @hardwicke], it would be sensible to focus on identifying the primary or substantive result for a study in an article.\n\nThe result is substantive if the researchers state that it is (e.g., “Our critical analysis is…”), if it is emphasized in the abstract, or if it is presented in a table or figure.\n\nAs we discussed in the class on graduate writing skills, the article authors should signal what they consider to be the primary result for a study by telling you that a result is critical or key or that a result is the or an answer to their research question.\n\n\n\n\n\n\nTip\n\n\n\n\nAn article may present multiple studies: focus on one.\nThe results section of an article, for a study, may list multiple results: identify the primary or substantive result.\n\n\n\nYou will want to identify a result that is both substantive and straightforward [@hardwicke2018; @hardwicke].\n\nThe result is Straightforward if the outcome could be calculated using the kind of test you have been learning about or will learn about (e.g., t-test, correlation, the linear model)\n\nPsychological science researchers use a variety of data analysis methods and not all the analyses that you read about will be analyses done using methods that you know about. The use of the methods we teach — t-test, correlation, and the linear model — are very very common; that is why we teach them. But you may also see reports of analyses done using methods like ANOVA, and multilevel or (increasingly) linear mixed-effects models [@meteyard2020].\nIn research on the reproducibility of results in the literature (?@sec-checkanalyses), the researchers attempting to reproduce results often focused on answering the research question the original authors stated using the data the original authors shared. This does not mean that they always tried to exactly reproduce an analysis or an analysis result. Sometimes, that was not possible.\nSometimes, you will encounter an article and a data-set you are interested in but the analysis presented in the article looks a bit complicated, or more complex than the methods you have learned would allow you to do. In this situation, don’t give up.\nWhat you can do – maybe with our advice – is identify a part of the primary result that you can try to reproduce. For example, what if the original study authors report a linear mixed-effects analysis of the effects of both prime relatedness and schizotypy score on response reaction time [@rodríguez-ferreiro2020]? Maybe you have not learned about mixed-effects models, or you have not learned about analysing the effects of two variables but you have (you will) learn about analysing the effect of one variable using the linear model method: OK then, do an analysis of the shared data using the method you know.\nYou may be helped, here, by knowing about two good-enough (mostly true) insights from statistical analysis:\n\nMany of the common analysis methods you see used in psychological science can be coded as a linear model.\nMore advanced common analysis methods — (Generalized) Linear Mixed-effects Models (GLMMs) — can be understood as more sophisticated versions of the linear model. (Conversely, the linear model can be understood as an approximation of a GLMM.)\n\nThere is a nice discussion of the idea that common statistical tests are linear models here.\n\n\n\n\n\n\nTip\n\n\n\n\nIdentify the analysis method used to get the result you are interested in.\nIf it is complex or unfamiliar, discuss whether a simpler method can be used.\nIf the result is complex, discuss whether you can attempt to reproduce a part or a simpler result.\n\n\n\n\n\n\nAre you interested in attempting a different analysis than the analysis you see in the journal article?\nIt can be interesting and important work to complete a simpler analysis of shared data. Sometimes, we learn that a simpler analysis provides a good account of the behaviour we observe, perhaps as good an account as that produced using other, more complex, analyses. This can happen if, for example, our theory predicts that two effects should work together but an analysis shows that we can explain behaviour in an account in which the two effects are independent. For example, @ricketts2021 predicted that children should learn words more effectively if they were shown the spellings of the words and they were told they would be helped by seeing the spelling but, in our data, we found that just seeing the spellings was enough to explain the learning we observed.\nIn completing analyses that vary from original analyses, we are engaging in the kind of work people do when they do multiverse analyses or robustness checks (?@sec-multiverse).\n\n\n\n\n\n\nTip\n\n\n\nIn planning an alternate or multiverse analysis, do not suppose that you need to do multiple analyses: you do not.\n\n\nIn planning an alternate or multiverse analysis, you will want to begin by critically evaluating the analysis you see described in the published article. I talk about how to do this, next.\nBefore we go on, note that I previously discussed an example of how to critically evaluate the results of published research in the context of @rodríguez-ferreiro2020. Take a look at the Introduction of that article. There, we summarised the analyses researchers did previously and used the information about the analyses to explain inconsistencies in the research literature. We found limitations in the analyses that people did that had (negative) consequences for the strength of the conclusions we can take from the data.\n\n\nIf you revisit our discussion of multiverse analyses, you will see that we discussed two things: (1.) analyses of the impact on results of varying how you construct data-sets for analysis (?@sec-multiversedata) and (2.) analyses of the impact on results of varying what analysis method you use, or how you use the method (?@sec-multiverseanalysis). These are both good ways to approach thinking about the description of the analysis you see in a published article.\nAs we noted in ?@sec-multiversedata, you almost always have to process the data you collect (in an experiment or a survey) before you can analyse the data. Often, this means you need to code for responses to survey questions e.g. asking people to self-report their gender, or you need to identify and code for people making errors when they try to do the experimental task you set them, or you need to process the data to exclude participants who took too long to do the task (if taking too long is a problem). Not all of these processing steps will have an impact on the results but some might. This is why you can sometimes do useful and sometimes original research work in reanalysing previously published data.\nYou can begin your analysis planning work by first identifying exactly what data processing the original study authors did then identifying what different data processing they could have done. Remember the research we discussed in relation to reproducibility studies, you need to be prepared for the possibility that it is challenging to identify what researchers did to process their data for analysis ?@sec-datachallenges. To identify the information you need, look for keywords like code, exclude, process, tidy, transform in the text of the article, or look for words like this in the documentation you find in the data repository.\nWhen you have identified this information, you can then consider three questions:\n\nWhat data processing steps were completed before analysis?\nWhat were the reasons given explaining why these processing steps were completed?\nWhat could happen to the results if different choices were made?\n\nWorking through these questions can then get you to a good plan for an analysis of the data. For example, a simple but useful analysis you can do is to check what happens to the results if you do an analysis with data from all the participants tested, if participants are excluded (for some reason) in the data processing step. Obviously, if the original study authors only share processed data (after exclusions), you cannot do this kind of work. Another simple but useful analysis you can do is to check what happens to the results if you change the coding of variables. Sometimes different coding of categorical variables (e.g., ethnicity) are reasonable. For example, you can ask: what happens if you analyse the impact of the variable given a different coding? (In case you are reading these notes and thinking about recoding a factor, there are some useful functions you can use; read about them here.)\n\n\n\n\n\n\nTip\n\n\n\n\nDo you want to check the impact of varying data processing choices: check, do you need and have access to the raw data? can you see how to recode variables?\n\n\n\nAs we noted in ?@sec-multiverseanalysis, when we consider how to answer a research question with a data-set, it is often possible to imagine multiple different analysis methods: reasonable alternatives. Most often, this is most clearly apparent when we are looking at an observational data-set or data collected given a cross-sectional study design.\nIn cross-sectional or observational studies, we typically are not manipulating experimental conditions, and we are often analysed data using some kind of linear model. We often collect data or have access to data on a number of different variables relevant to our interests. For example, in studies I have done on how people read [@davies2013; @davies2017], we wanted to know what factors would predict or influence how people do basic reading tasks like reading aloud. We collected information on many different kinds of word properties and on the attributes of the participants we tested. (Note: the papers are associated with data repositories in Supplementary Materials.) It is often an open question which variables should be included in a prediction model of the observed outcome (reading response reaction times). Therefore, if you are interested in a study like this, and can access usable data from the study, it will typically be true that you are able to sensibly motivate a different analysis of the study data using a different choice of variables.\nAs discussed in a number of interesting analyses over the years [e.g., @patel2015], researchers may be interested in the specific impact of one particular predictor variable (e.g., we may be interested in whether it is easier to read words we learned early in life), but will need to include in their analysis that variable plus other variables known to affect the outcome. In that situation, the effect of the variable of interest may appear to be different depending on what other variables are also analysed. This makes it interesting and useful to check the impact of different analysis choices.\nWe will look at data like these, for analyses involving the linear model, in our classes on this method.\n\n\n\n\n\n\nTip\n\n\n\n\nDo you want to check the impact of different analysis choices: check, do you need and have access to a choice of variables?\nCan you think of some reasons to justify using a different choice of variables in your analysis.\n\n\n\n\n\n\n\n\nHere’s a quick summary of the advice we have discussed so far.\n\nAt the start of your work, you will need to (1.) locate then (2.) access data for analysis, and then you will need to (3.) check that the data are usable.\nOnce you have confirmed you have found interesting data you can use, you should plan your analysis.\nStudents do a variety of kinds of analysis. Whatever your interest, you first will want to first make sure you can identify exactly what the authors of the original study did, how they did it, and why they did it.\nIf you are interested in completing a reanalysis, attempting a methods reproducibility test (can you repeat a result, given shared data?) you will perhaps benefit from focusing on a result that is both substantive and straightforward.\nIf you are interested in doing an alternate or multiverse analysis, you can critically evaluate the data processing and the data analysis choices that the original study authors made. You can consider whether other choices would be appropriate, and might sensibly motivate a (limited) investigation of the impact of different analysis choices on the results.\n\nWhat if you access interesting data that were shared but that are not associated with a published analysis? We talk about that situation, next.\n\n\n\n\nA number of data-sets have been published online with information about the data but with no analysis. You can look for data that may be interest you in a number of different places, now, but I would focus on one. I talk about that next. Then I offer some guidance on how you might approach analyzing such data Section 1.3.2.\n\n\nWicherts and colleagues set up the Journal of Open Psychology Data (JOPD) to make it easier for Psychologists to share experimental data. A link to the journal webpage is here) Usually, a data paper reports a study and provides a link to a downloadable data-set.\nSome data-sets that I have looked at in JOPD and other places include the following. I identify these examples because they present interesting, rich, and readily accessible data-sets that could be used in a variety of different kinds of analyses.\n\n\nWicherts did what he recommended and put a large data-set online here\nYou can analyse these data in a number of different interesting ways. You can explore relationships between gender, intelligence and personality differences.\nThe data file and an explanatory document are located at the end of the article. Read the article, it’s worth your time. Wicherts reports:\n\nThe file includes data from our freshman-testing program called “Testweek” (Busato et al., 2000, Smits et al., 2011 and Wicherts and Vorst, 2010) in which 537 students (age: M = 21.0, SD = 4.3) took the Advanced Progressive Matrices ( Raven, Court, & Raven, 1996), a test of Arithmetic, a Number Series test, a Hidden Figures Test, a test of Vocabulary, a test of Verbal Analogies, and a Logical Reasoning test (Elshout, 1976).\nAlso included are data from a Dutch big five personality inventory (Elshout & Akkerman, 1975), the NEO-PI-R (Hoekstra, Ormel, & Fruyt, 1996), scales of social desirability and impression management (based on work by Paulhus, 1984 and Wicherts, 2002), sex of the participants, and grade point averages of the freshmen’s first trimester that may act as outcome variable.\n\n\n\n\nSmits and colleagues (including Wicherts) put an even larger data-set online at the Journal of Open Psychology Data here)\nYou will need to register to be able to download the data but the process is simple.\nThe Smits data-set includes Big-5 personality scores for several thousand individuals recorded over a series of years. You can analyse these data in interesting ways including examining changes in personality scores among students over different years.\n\n\n\nTjew A Sin and colleagues shared a data-set at the Journal of Open Psychology Data on an interesting study they did to test the idea that interpersonal touch or simulated interpersonal touch can relieve existential concerns (fear of death) among individuals with low self-esteem. The data can be found here)\nThe Tjew A Sin can be downloaded from a link to a repository location, given at the end of the article. You will likely need to register to download the data. Note that the spreadsheets holding the study data include 999 values to code for missing data. Note also that the data spreadsheets include (in different columns) scores per participant for various measures e.g. mortality anxiety or self-esteem. The measures are explained in the paper. To use the data, you will need to work out the simple process of how to sum the scores across items to get e.g. a measure of self-esteem for each person.\n\n\n\nBerger and Anaki shared data on the disgust sensitivity of a large sample of individuals. The data are from the administration of the Disgust Scale to a set of Hebrew speakers. They can be found here)\nThe experimenters collected data on participants’ characteristics so that analyses of the way in which sensitivity varies in relation to demographic attributes is possible. You will see that the disgust scale is explained in the paper. The different disgust scores, for each item in the disgust scale, can be found in different columns. The disgust scores, for person, are calculated overall as values: Mean_general_ds, Mean_core, Mean_Animal_reminder, Mean_Contamination\nWhen you download the data-set, you may need to change the file name — adding a suffix: .txt (for the tab delimited file), to be opened in Excel, or .sav (for the SPSS data file), to be opened in SPSS — to the file name to allow you to open it in the appropriate application.\n\n\n\n\nThe availability of rich, curated, clearly usable data-sets with many variables can make it challenging to decide what to do.\nI would advise beginning with an exploratory analysis of the data you have accessed. You will want to begin by using the data visualization skills we have taught you to examine:\n\nThe distributions of the variables that interest you using histograms, density plots or bar charts.\nThe potential relationship between variables using scatterplots.\n\nIn such Exploratory Data analyses, you are interested in what the data visualization tells you about the nature of the data-set you have accessed. The papers associated with the data-sets can sometimes offer only outline information: how the data were collected, coded, and processed. You may need to satisfy yourself that there is nothing odd or surprising about the distributions of scores. This stage can help you to identify problems like survey responses with implausible scores.\nThe work you do in exploring, and summarizing, the data variables that interest you will often constitute a substantial element of the work you can do and present for your report. You may discuss, for advice, what parts of this work will be interesting or useful to present.\nThen, our advice is simple.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen working with open data-sets, consider keeping the analysis simple.\n\n\n\nNote that simple is relative. Do what interests you. Work with the methods you have learned or will learn (the linear model).\nIn practice, you will find that part of the challenge is located not in using the data or in running an analysis like a linear model, it is in (1.) justifying or motivating the analysis and (2.) explaining the implications of your findings.\nWorking on the thinking you must develop to motivate an analysis or to explain implications requires you to do some (limited) reading of relevant research. (Relevant sources will be cited in data papers, as part of their outline of the background for their data collection.) If you consider the advice we discussed in the graduate class on developing writing skills, you will see that there I talked about how you might extract data from a set of relevant sources (papers) to get an understanding of the questions people ask, the assumptions they make. That is the kind of process you can follow to develop your thinking around the analysis you will do. What you are looking for is information you can use so that you can say something brief about, for example, why it might be interesting to analyse, say, whether personality (measured using the Big-5) varies given differences in gender or differences between population cohorts. The reading and the conceptual development should be fairly limited, not extensive, but should be sufficient that you can write something sensible when you introduce and then when you discuss your analysis results.\n\n\n\n\nIn this chapter, I have outlined some advice on how you might approach the task of locating, accessing, and analyzing previously collected data.\n\n\n\n\n\n\nTip\n\n\n\nThe main advice is to think about your workflow in stages, then progress through the work one step at a time.\n\n\nYou will need to begin by assuring yourself that you can find a data-set that interests you, and that you can access and use the data. The usability of data will require clear, understandable, descriptions in the published article (if any) about the research question and hypothesis, the study design, the data collection methods, the data processing steps, and the data analysis (if any). Sometimes, useful information about data processing and data analysis can be found in detail in repository documentation (e.g., in guides to materials) but only referenced in the text of the article.\nIf you know you can locate, access and have checked data as usable, you will want to think about what analysis you want to do the data. The approach you take depending on what aims you would like to pursue.\nIf you are interested in attempting a methods reproducibility test (i.e. checking if you can repeat presented results, given shared data), then you will first need to identify a substantive and straightforward result to try to reproduce. If you identify a primary result to examine, you will want to check that you can work with the data that have been shared, and then that you can use the analysis methods you have learned to reproduce some or all of the result that interests you.\nIf you are interested in doing an alternate or a different analysis (from what may be presented), you may need to consider the information you can locate on data processing and on data analysis choices. Did the original study authors process the data before sharing it, how? are the raw data available? What analyses did the authors do and why? When you consider this information, you may critically evaluate the choices made. In the context of this critical evaluation, you may find good reasons to justify doing a different analysis, whether to examine the impact of making different data processing choices, or to examine the impact of using a different analysis method, or of applying the same method differently (e.g., by including different variables).\nIn considering an analysis of data shared without a published set of results, you may want to keep your approach simple. Focus on what analysis you can do using the methods you have learned. And think about the understanding you will need to develop, to justify the analysis you do, and to make sense, in the discussion of your report of the analysis results you will present.\nIt is always a good idea to explore your data using visualization techniques throughout your workflow.\n\n\n\n\n\n\nTip\n\n\n\n\nYou can always get advice, do not hesitate to ask.\nWe are happy to discuss your thinking, especially in class."
  },
  {
    "objectID": "PSYC411/part2/how.html#sec-how-variety",
    "href": "PSYC411/part2/how.html#sec-how-variety",
    "title": "How you can do it",
    "section": "",
    "text": "Students have taken a variety of approaches to the assignment.\n\nUsing demonstration data — Some students choose to complete an analysis of one of the data-sets used for practical exercises in class: the example or demonstration data we collect together as curated data-sets.\nAnalyzing public data that have been previously analysed — Some students choose to complete an analysis of a publicly available data-set that has been analysed previously, where the analysis report has been published in a journal article.\nAnalyzing public data that have not been previously analysed — Some students choose to complete an analysis of a publicly available data-set where an analysis report has not been published in a journal article.\n\nAsk in class or on the Moodle discussion forum for advice about any one of these approaches.\nI consider, first, working with data-sets where an analysis of the data has been presented in the article (see Section 1.2). I then look at working with data-sets where the data are presented without an analysis (see Section 1.3). Our advice on working with data-sets presented without an analysis will overlap in key respects with our advice on working with curated demonstration data."
  },
  {
    "objectID": "PSYC411/part2/how.html#sec-publishedanalysis",
    "href": "PSYC411/part2/how.html#sec-publishedanalysis",
    "title": "How you can do it",
    "section": "",
    "text": "In the following, I split our guidance into two parts.\n\nI look next at the task of locating, accessing and checking the data (Section 1.2.1).\nThen I look at the task of figuring out what analysis you can do with the data (see Section 1.2.2).\n\nObviously, you cannot consider an analysis if you cannot be sure that you can work with the data [@minocher].\n\n\nAt the start of your work on the assignment, you will need to (1.) locate then (2.) access data for analysis, and then you will need to (3.) check that the data are usable. I set out advice on doing each step, following. Work through the steps: one step at a time.\n\n\nIt is usually helpful to find a data-set where the data have been collected in a study within a topic area you care about, or could be interested in. It is helpful because you will need to work with the data and it will be motivating if you are interested in what the data concern. And it is helpful because, often, you will need to do a bit of reading on related research to learn about the context for the data collection, and you will usually want to read research sources that interest you.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nDo a search: look for an article with usable data in a topic area that interests you.\n\n\n\nThere are at least two ways you can do this. Both should be reasonably quick methods to get to a usable data-set.\n\nDo a search on Google scholar).\nDo a search on the webpages of a journal.\n\nMost psychological research is published in journals like Psychological Science. If you want, you can look at a list of psychology journals here.\nIn a journal like Psychological Science you can look through lists of previously published articles (in issues, volumes, by year) on the journal webpage. Here is the list of issues for Psychological Science..\n\n\nIn both methods, you are looking for an article associated with data (and maybe analysis code) you can access and that you are sure you can use. In both methods, you need to first think about some key words to use in your search. Ask yourself:\n\nWhat are you interested in? What population, intervention or effect, comparison, or outcome?\n\nThen:\n\nWhat words do people use, in articles you have seen, when they talk about this thing?\n\nYou can use these words, and maybe consider alternate terms. For example, I am interested in reading comprehension or development reading comprehension but researchers working on reading development might also refer to children reading comprehension.\nYou want to be as efficient as possible so combine your search for articles in an interesting topic area with your search for accessible data. We can learn from the research we discussed on data sharing practices (?@sec-sharing) by looking for specific markers that data associated with an article should be accessible.\nIf you are doing a search (1.) on Google scholar), I would use the key words related to your topic plus words like: open data badge; open science badge. So, I would do a search for the words: reading comprehension open data badge. I have done this: you can try it. The search results will list articles related to the topic of reading comprehension, where the authors claim to have earned the open data badge because they have made data available.\nIf you are doing a search (2.) in a journal list of articles, then what you are looking for are articles that interest you and which are listed with open data badges. In the listing for Psychological Science (here)) a quick read of the journal issue articles index shows that article titles are listed together with symbols representing the open science badges that authors have claimed.\nIn other journals (e.g., PLOS ONE, PeerJ, Collabra), you may be looking for interesting articles with the words Data Availability Statement, Data Accessibility Statement, Supplementary data or Supplementary materials in the article webpage somewhere. Journals like PeerJ or Collabra, in particular, make it easy to locate data associated with published articles on their web pages.\nIn Collabra, you can find published articles through the journal webpage (here). If you click on the title of any article, and look at the article webpage, then on the left of the article text, you can see an index of article contents and that index lists the Data Availability Statement. Click on that and you are often taken to a link to a data repository.\n\n\n\n\nIf you have located an interesting article with evidence (an open data badge or a data accessibility statement) that the authors have shared their data, you need to check that you can access the data. Most of the time, now, you are looking for a link you can use to go directly to the shared data. The link is often presented as a hyperlink on a webpage, associated with Digital Object Identifiers (DOIs) or Universal resource locators (URLs). Or, increasingly, you are looking for a link to a data repository on a site like the Open Science Framework (OSF).\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nAccess the data associated with the article you have found.\n\n\n\nHere are some recent examples from my work that you can check, to give you a sense of where or how to find the accessible link to the shared data.\n\nRicketts, J., Dawson, N., & Davies, R. (2021). The hidden depths of new word knowledge: Using graded measures of orthographic and semantic learning to measure vocabulary acquisition. Learning and Instruction, 74, 101468. https://doi.org/10.1016/j.learninstruc.2021.101468\n\n\nRodríguez-Ferreiro, J., Aguilera, M., & Davies, R. (2020). Semantic priming and schizotypal personality: Reassessing the link between thought disorder and enhanced spreading of semantic activation. PeerJ, 8, e9511. https://doi.org/10.7717/peerj.9511\n\nThese are both open access articles.\nIf you look at the webpage for, @rodríguez-ferreiro2020, (here)), you can do a search in the article text for the keyword OSF (on the article webpage, use keys CMD-F plus OSF). You are checking to see if you can click on the link and and if clicking on the link takes you to a repository listing the data for the article. The @rodríguez-ferreiro2020 article is associated with a data plus analysis code repository (OSF))\nNotice that on the repository webpage, you can see a description of the project plus .pdf files and a folder data-set and Code. If you can click through to the folders, and download the datafiles, you have accessed the data successfully.\nI have guided you, here, through to the @rodríguez-ferreiro2020 data repository, can you find the data for the @ricketts2021 repository?\n\n\n\nIf you have located an interesting article with data that you can access, and if you have read the introductory notes (?@sec-checkanalyses), then you will next need to make sure that you can use the data.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nCheck the data and the data documentation to make sure you can understand what you have got and whether you can use it.\n\n\n\nWhat make data usable are:\n\nInformation in the article, or in the data repository documentation, on the study design and data collection methods: you need to be able to understand where the data came from, how they were collected, and why.\nClear data documentation: you need to find information on the variables, the observations, the scoring, the coding, and whether and how the data were processed to get them from raw data state to the data ready for analysis.\n\nData documentation is often presented as a note or a wiki page or a miniature paper and may be called a codebook, data dictionary, guide to materials or something similar. You will need to check that you can find information on (examples shown are from the @rodríguez-ferreiro2020 OSF guide to materials):\n\nwhat the data files are called e.g. PrimDir-111019.csv;\nhow the named data files correspond to the studies presented in the report;\nwhat the data file columns are called and what variables the column data represent e.g. relation, coding for prime-target relatedness condition ...;\nhow scores or responses in columns were collected or calculated e.g. age, giving the age in years ...;\nhow coding was done, if coding was used e.g. biling, giving the bilingualism status;\nwhether data were processed, how missing values were coded, whether participants or observations were excluded before analysis e.g. Missing values in the rt column ... coded as NA\n\n\n\n\n\n\n\nWarning\n\n\n\nIf these information are not presented, or are not clear: walk away.\n\n\n\n\n\n\nAfter you have found an interesting article, and have confirmed that you can use the associated data, you will need to plan what analysis you want to do.\n\n\n\n\n\n\nTip\n\n\n\nThe task here is:\n\nIdentify and understand the analysis in the article.\nWork out what analysis you want to do.\n\n\n\nStudents have taken a variety of approaches to the assignment.\n\nSome students choose to complete a reanalysis of the data, in an attempt to reproduce the results presented in the article (?@sec-methodsrepro).\nSome students choose to complete an alternate analysis of the data, varying elements of the analysis (?@sec-multiverse).\n\nEither way, you will want to first make sure you can identify exactly what the authors of the original study did, how they did it, and why they did it.\nYou can process the key article information efficiently using the QALMRI method we discussed in the class on graduate writing skills [@brosowsky; @kosslyn2005]. You are first aiming to locate information on the broad and the specific question the study addresses, the methods the study authors used to collect data, the results they report, and the conclusions they present given the results. Can you find these bits of information?\n\n\nAre you interested in attempting a methods reproducibility test?\nFollowing Hardwicke and colleagues [@hardwicke2018; @hardwicke], it would be sensible to focus on identifying the primary or substantive result for a study in an article.\n\nThe result is substantive if the researchers state that it is (e.g., “Our critical analysis is…”), if it is emphasized in the abstract, or if it is presented in a table or figure.\n\nAs we discussed in the class on graduate writing skills, the article authors should signal what they consider to be the primary result for a study by telling you that a result is critical or key or that a result is the or an answer to their research question.\n\n\n\n\n\n\nTip\n\n\n\n\nAn article may present multiple studies: focus on one.\nThe results section of an article, for a study, may list multiple results: identify the primary or substantive result.\n\n\n\nYou will want to identify a result that is both substantive and straightforward [@hardwicke2018; @hardwicke].\n\nThe result is Straightforward if the outcome could be calculated using the kind of test you have been learning about or will learn about (e.g., t-test, correlation, the linear model)\n\nPsychological science researchers use a variety of data analysis methods and not all the analyses that you read about will be analyses done using methods that you know about. The use of the methods we teach — t-test, correlation, and the linear model — are very very common; that is why we teach them. But you may also see reports of analyses done using methods like ANOVA, and multilevel or (increasingly) linear mixed-effects models [@meteyard2020].\nIn research on the reproducibility of results in the literature (?@sec-checkanalyses), the researchers attempting to reproduce results often focused on answering the research question the original authors stated using the data the original authors shared. This does not mean that they always tried to exactly reproduce an analysis or an analysis result. Sometimes, that was not possible.\nSometimes, you will encounter an article and a data-set you are interested in but the analysis presented in the article looks a bit complicated, or more complex than the methods you have learned would allow you to do. In this situation, don’t give up.\nWhat you can do – maybe with our advice – is identify a part of the primary result that you can try to reproduce. For example, what if the original study authors report a linear mixed-effects analysis of the effects of both prime relatedness and schizotypy score on response reaction time [@rodríguez-ferreiro2020]? Maybe you have not learned about mixed-effects models, or you have not learned about analysing the effects of two variables but you have (you will) learn about analysing the effect of one variable using the linear model method: OK then, do an analysis of the shared data using the method you know.\nYou may be helped, here, by knowing about two good-enough (mostly true) insights from statistical analysis:\n\nMany of the common analysis methods you see used in psychological science can be coded as a linear model.\nMore advanced common analysis methods — (Generalized) Linear Mixed-effects Models (GLMMs) — can be understood as more sophisticated versions of the linear model. (Conversely, the linear model can be understood as an approximation of a GLMM.)\n\nThere is a nice discussion of the idea that common statistical tests are linear models here.\n\n\n\n\n\n\nTip\n\n\n\n\nIdentify the analysis method used to get the result you are interested in.\nIf it is complex or unfamiliar, discuss whether a simpler method can be used.\nIf the result is complex, discuss whether you can attempt to reproduce a part or a simpler result.\n\n\n\n\n\n\nAre you interested in attempting a different analysis than the analysis you see in the journal article?\nIt can be interesting and important work to complete a simpler analysis of shared data. Sometimes, we learn that a simpler analysis provides a good account of the behaviour we observe, perhaps as good an account as that produced using other, more complex, analyses. This can happen if, for example, our theory predicts that two effects should work together but an analysis shows that we can explain behaviour in an account in which the two effects are independent. For example, @ricketts2021 predicted that children should learn words more effectively if they were shown the spellings of the words and they were told they would be helped by seeing the spelling but, in our data, we found that just seeing the spellings was enough to explain the learning we observed.\nIn completing analyses that vary from original analyses, we are engaging in the kind of work people do when they do multiverse analyses or robustness checks (?@sec-multiverse).\n\n\n\n\n\n\nTip\n\n\n\nIn planning an alternate or multiverse analysis, do not suppose that you need to do multiple analyses: you do not.\n\n\nIn planning an alternate or multiverse analysis, you will want to begin by critically evaluating the analysis you see described in the published article. I talk about how to do this, next.\nBefore we go on, note that I previously discussed an example of how to critically evaluate the results of published research in the context of @rodríguez-ferreiro2020. Take a look at the Introduction of that article. There, we summarised the analyses researchers did previously and used the information about the analyses to explain inconsistencies in the research literature. We found limitations in the analyses that people did that had (negative) consequences for the strength of the conclusions we can take from the data.\n\n\nIf you revisit our discussion of multiverse analyses, you will see that we discussed two things: (1.) analyses of the impact on results of varying how you construct data-sets for analysis (?@sec-multiversedata) and (2.) analyses of the impact on results of varying what analysis method you use, or how you use the method (?@sec-multiverseanalysis). These are both good ways to approach thinking about the description of the analysis you see in a published article.\nAs we noted in ?@sec-multiversedata, you almost always have to process the data you collect (in an experiment or a survey) before you can analyse the data. Often, this means you need to code for responses to survey questions e.g. asking people to self-report their gender, or you need to identify and code for people making errors when they try to do the experimental task you set them, or you need to process the data to exclude participants who took too long to do the task (if taking too long is a problem). Not all of these processing steps will have an impact on the results but some might. This is why you can sometimes do useful and sometimes original research work in reanalysing previously published data.\nYou can begin your analysis planning work by first identifying exactly what data processing the original study authors did then identifying what different data processing they could have done. Remember the research we discussed in relation to reproducibility studies, you need to be prepared for the possibility that it is challenging to identify what researchers did to process their data for analysis ?@sec-datachallenges. To identify the information you need, look for keywords like code, exclude, process, tidy, transform in the text of the article, or look for words like this in the documentation you find in the data repository.\nWhen you have identified this information, you can then consider three questions:\n\nWhat data processing steps were completed before analysis?\nWhat were the reasons given explaining why these processing steps were completed?\nWhat could happen to the results if different choices were made?\n\nWorking through these questions can then get you to a good plan for an analysis of the data. For example, a simple but useful analysis you can do is to check what happens to the results if you do an analysis with data from all the participants tested, if participants are excluded (for some reason) in the data processing step. Obviously, if the original study authors only share processed data (after exclusions), you cannot do this kind of work. Another simple but useful analysis you can do is to check what happens to the results if you change the coding of variables. Sometimes different coding of categorical variables (e.g., ethnicity) are reasonable. For example, you can ask: what happens if you analyse the impact of the variable given a different coding? (In case you are reading these notes and thinking about recoding a factor, there are some useful functions you can use; read about them here.)\n\n\n\n\n\n\nTip\n\n\n\n\nDo you want to check the impact of varying data processing choices: check, do you need and have access to the raw data? can you see how to recode variables?\n\n\n\nAs we noted in ?@sec-multiverseanalysis, when we consider how to answer a research question with a data-set, it is often possible to imagine multiple different analysis methods: reasonable alternatives. Most often, this is most clearly apparent when we are looking at an observational data-set or data collected given a cross-sectional study design.\nIn cross-sectional or observational studies, we typically are not manipulating experimental conditions, and we are often analysed data using some kind of linear model. We often collect data or have access to data on a number of different variables relevant to our interests. For example, in studies I have done on how people read [@davies2013; @davies2017], we wanted to know what factors would predict or influence how people do basic reading tasks like reading aloud. We collected information on many different kinds of word properties and on the attributes of the participants we tested. (Note: the papers are associated with data repositories in Supplementary Materials.) It is often an open question which variables should be included in a prediction model of the observed outcome (reading response reaction times). Therefore, if you are interested in a study like this, and can access usable data from the study, it will typically be true that you are able to sensibly motivate a different analysis of the study data using a different choice of variables.\nAs discussed in a number of interesting analyses over the years [e.g., @patel2015], researchers may be interested in the specific impact of one particular predictor variable (e.g., we may be interested in whether it is easier to read words we learned early in life), but will need to include in their analysis that variable plus other variables known to affect the outcome. In that situation, the effect of the variable of interest may appear to be different depending on what other variables are also analysed. This makes it interesting and useful to check the impact of different analysis choices.\nWe will look at data like these, for analyses involving the linear model, in our classes on this method.\n\n\n\n\n\n\nTip\n\n\n\n\nDo you want to check the impact of different analysis choices: check, do you need and have access to a choice of variables?\nCan you think of some reasons to justify using a different choice of variables in your analysis.\n\n\n\n\n\n\n\n\nHere’s a quick summary of the advice we have discussed so far.\n\nAt the start of your work, you will need to (1.) locate then (2.) access data for analysis, and then you will need to (3.) check that the data are usable.\nOnce you have confirmed you have found interesting data you can use, you should plan your analysis.\nStudents do a variety of kinds of analysis. Whatever your interest, you first will want to first make sure you can identify exactly what the authors of the original study did, how they did it, and why they did it.\nIf you are interested in completing a reanalysis, attempting a methods reproducibility test (can you repeat a result, given shared data?) you will perhaps benefit from focusing on a result that is both substantive and straightforward.\nIf you are interested in doing an alternate or multiverse analysis, you can critically evaluate the data processing and the data analysis choices that the original study authors made. You can consider whether other choices would be appropriate, and might sensibly motivate a (limited) investigation of the impact of different analysis choices on the results.\n\nWhat if you access interesting data that were shared but that are not associated with a published analysis? We talk about that situation, next."
  },
  {
    "objectID": "PSYC411/part2/how.html#sec-noanalysis",
    "href": "PSYC411/part2/how.html#sec-noanalysis",
    "title": "How you can do it",
    "section": "",
    "text": "A number of data-sets have been published online with information about the data but with no analysis. You can look for data that may be interest you in a number of different places, now, but I would focus on one. I talk about that next. Then I offer some guidance on how you might approach analyzing such data Section 1.3.2.\n\n\nWicherts and colleagues set up the Journal of Open Psychology Data (JOPD) to make it easier for Psychologists to share experimental data. A link to the journal webpage is here) Usually, a data paper reports a study and provides a link to a downloadable data-set.\nSome data-sets that I have looked at in JOPD and other places include the following. I identify these examples because they present interesting, rich, and readily accessible data-sets that could be used in a variety of different kinds of analyses.\n\n\nWicherts did what he recommended and put a large data-set online here\nYou can analyse these data in a number of different interesting ways. You can explore relationships between gender, intelligence and personality differences.\nThe data file and an explanatory document are located at the end of the article. Read the article, it’s worth your time. Wicherts reports:\n\nThe file includes data from our freshman-testing program called “Testweek” (Busato et al., 2000, Smits et al., 2011 and Wicherts and Vorst, 2010) in which 537 students (age: M = 21.0, SD = 4.3) took the Advanced Progressive Matrices ( Raven, Court, & Raven, 1996), a test of Arithmetic, a Number Series test, a Hidden Figures Test, a test of Vocabulary, a test of Verbal Analogies, and a Logical Reasoning test (Elshout, 1976).\nAlso included are data from a Dutch big five personality inventory (Elshout & Akkerman, 1975), the NEO-PI-R (Hoekstra, Ormel, & Fruyt, 1996), scales of social desirability and impression management (based on work by Paulhus, 1984 and Wicherts, 2002), sex of the participants, and grade point averages of the freshmen’s first trimester that may act as outcome variable.\n\n\n\n\nSmits and colleagues (including Wicherts) put an even larger data-set online at the Journal of Open Psychology Data here)\nYou will need to register to be able to download the data but the process is simple.\nThe Smits data-set includes Big-5 personality scores for several thousand individuals recorded over a series of years. You can analyse these data in interesting ways including examining changes in personality scores among students over different years.\n\n\n\nTjew A Sin and colleagues shared a data-set at the Journal of Open Psychology Data on an interesting study they did to test the idea that interpersonal touch or simulated interpersonal touch can relieve existential concerns (fear of death) among individuals with low self-esteem. The data can be found here)\nThe Tjew A Sin can be downloaded from a link to a repository location, given at the end of the article. You will likely need to register to download the data. Note that the spreadsheets holding the study data include 999 values to code for missing data. Note also that the data spreadsheets include (in different columns) scores per participant for various measures e.g. mortality anxiety or self-esteem. The measures are explained in the paper. To use the data, you will need to work out the simple process of how to sum the scores across items to get e.g. a measure of self-esteem for each person.\n\n\n\nBerger and Anaki shared data on the disgust sensitivity of a large sample of individuals. The data are from the administration of the Disgust Scale to a set of Hebrew speakers. They can be found here)\nThe experimenters collected data on participants’ characteristics so that analyses of the way in which sensitivity varies in relation to demographic attributes is possible. You will see that the disgust scale is explained in the paper. The different disgust scores, for each item in the disgust scale, can be found in different columns. The disgust scores, for person, are calculated overall as values: Mean_general_ds, Mean_core, Mean_Animal_reminder, Mean_Contamination\nWhen you download the data-set, you may need to change the file name — adding a suffix: .txt (for the tab delimited file), to be opened in Excel, or .sav (for the SPSS data file), to be opened in SPSS — to the file name to allow you to open it in the appropriate application.\n\n\n\n\nThe availability of rich, curated, clearly usable data-sets with many variables can make it challenging to decide what to do.\nI would advise beginning with an exploratory analysis of the data you have accessed. You will want to begin by using the data visualization skills we have taught you to examine:\n\nThe distributions of the variables that interest you using histograms, density plots or bar charts.\nThe potential relationship between variables using scatterplots.\n\nIn such Exploratory Data analyses, you are interested in what the data visualization tells you about the nature of the data-set you have accessed. The papers associated with the data-sets can sometimes offer only outline information: how the data were collected, coded, and processed. You may need to satisfy yourself that there is nothing odd or surprising about the distributions of scores. This stage can help you to identify problems like survey responses with implausible scores.\nThe work you do in exploring, and summarizing, the data variables that interest you will often constitute a substantial element of the work you can do and present for your report. You may discuss, for advice, what parts of this work will be interesting or useful to present.\nThen, our advice is simple.\n\n\n\n\n\n\nTip\n\n\n\n\nWhen working with open data-sets, consider keeping the analysis simple.\n\n\n\nNote that simple is relative. Do what interests you. Work with the methods you have learned or will learn (the linear model).\nIn practice, you will find that part of the challenge is located not in using the data or in running an analysis like a linear model, it is in (1.) justifying or motivating the analysis and (2.) explaining the implications of your findings.\nWorking on the thinking you must develop to motivate an analysis or to explain implications requires you to do some (limited) reading of relevant research. (Relevant sources will be cited in data papers, as part of their outline of the background for their data collection.) If you consider the advice we discussed in the graduate class on developing writing skills, you will see that there I talked about how you might extract data from a set of relevant sources (papers) to get an understanding of the questions people ask, the assumptions they make. That is the kind of process you can follow to develop your thinking around the analysis you will do. What you are looking for is information you can use so that you can say something brief about, for example, why it might be interesting to analyse, say, whether personality (measured using the Big-5) varies given differences in gender or differences between population cohorts. The reading and the conceptual development should be fairly limited, not extensive, but should be sufficient that you can write something sensible when you introduce and then when you discuss your analysis results."
  },
  {
    "objectID": "PSYC411/part2/how.html#sec-how-summary",
    "href": "PSYC411/part2/how.html#sec-how-summary",
    "title": "How you can do it",
    "section": "",
    "text": "In this chapter, I have outlined some advice on how you might approach the task of locating, accessing, and analyzing previously collected data.\n\n\n\n\n\n\nTip\n\n\n\nThe main advice is to think about your workflow in stages, then progress through the work one step at a time.\n\n\nYou will need to begin by assuring yourself that you can find a data-set that interests you, and that you can access and use the data. The usability of data will require clear, understandable, descriptions in the published article (if any) about the research question and hypothesis, the study design, the data collection methods, the data processing steps, and the data analysis (if any). Sometimes, useful information about data processing and data analysis can be found in detail in repository documentation (e.g., in guides to materials) but only referenced in the text of the article.\nIf you know you can locate, access and have checked data as usable, you will want to think about what analysis you want to do the data. The approach you take depending on what aims you would like to pursue.\nIf you are interested in attempting a methods reproducibility test (i.e. checking if you can repeat presented results, given shared data), then you will first need to identify a substantive and straightforward result to try to reproduce. If you identify a primary result to examine, you will want to check that you can work with the data that have been shared, and then that you can use the analysis methods you have learned to reproduce some or all of the result that interests you.\nIf you are interested in doing an alternate or a different analysis (from what may be presented), you may need to consider the information you can locate on data processing and on data analysis choices. Did the original study authors process the data before sharing it, how? are the raw data available? What analyses did the authors do and why? When you consider this information, you may critically evaluate the choices made. In the context of this critical evaluation, you may find good reasons to justify doing a different analysis, whether to examine the impact of making different data processing choices, or to examine the impact of using a different analysis method, or of applying the same method differently (e.g., by including different variables).\nIn considering an analysis of data shared without a published set of results, you may want to keep your approach simple. Focus on what analysis you can do using the methods you have learned. And think about the understanding you will need to develop, to justify the analysis you do, and to make sense, in the discussion of your report of the analysis results you will present.\nIt is always a good idea to explore your data using visualization techniques throughout your workflow.\n\n\n\n\n\n\nTip\n\n\n\n\nYou can always get advice, do not hesitate to ask.\nWe are happy to discuss your thinking, especially in class."
  },
  {
    "objectID": "PSYC411/part2/what.html",
    "href": "PSYC411/part2/what.html",
    "title": "What you have to do",
    "section": "",
    "text": "We present the following guidelines to help you to complete the coursework assessment. If you have any questions, you can contact:\n\nPadraic Monaghan at p.monaghan@lancaster.ac.uk\nRob Davies at r.davies1@lancaster.ac.uk\n\nIn this section, we explain what you are expected to do.\nIf you want to understand why we think you will benefit from doing this, you can read the explanation in ?@sec-intro-why.\nIf you want to know more about how to do this work, you can read about how in ?@sec-how.\nWe provide information on assessment criteria and our approach to marking in Section 1.2.\n\n\nNote that the following information mirrors exactly the information provided on Moodle:\nhttps://modules.lancaster.ac.uk/mod/page/view.php?id=2212445\n\n\nReports will concern, usually, findings from analyses of data-sets we have provided to you. Some students may wish to analyse data collected in previous studies or data accessed from online sources: they should correspond with Padraic Monaghan or Rob Davies if they wish to do so.\nThe evaluation of reports will focus on clarity, read the following for discussion of what is required.\nWe expect students to use one of the analysis methods taught in the module. Marks will be awarded depending:\n\non how appropriate the method is to the context, to the study design, to answering the research question, and to the features of the data; the appropriateness of methods to contexts will be taught in class;\non how effectively the analysis is explained; students must explain the motivations for their decisions, explain their methods, and explain their findings effectively to gain points.\n\n\n\n\n\nThe reports should include abstract, introduction, methods, results, discussion and references sections, like a short research article in the journal Psychological Science. You can view examples of articles here\n\nhttps://journals.sagepub.com/home/pss\n\nWord count limit: no more than 1500 words are allowed for all materials.\nUnlike a published research article, for PSYC401, the Results and Discussion sections must be written in full, but the Introduction and Methods sections can be written in the form of notes.\n\n\n\n\n\n\nThe focus of marking will be on the quality of the Results and Discussion sections. This means you can write your notes in the Introduction and Methods sections as short answers to the following questions:-\n\n\n\nWhat did the researchers do and why did the researchers do it?\nWhat was the question addressed in the study and why is it interesting?\nWhat were the hypotheses?\nWhat results were expected and how would they relate to the hypotheses?\n\nHow can you write this as a set of notes? We require main points of information on the hypotheses concerning expected results. We will ignore the absence of citations, or of explanations of critical previous experimental work, in the Introduction.\n\n\n\nNote the origin of the data at the start of the method section. As for the Introduction, your method section writing needs to furnish answers to questions like the following:-\n\nWhat was done to collect the data?\nWho were tested (Participants)?\nWhat materials were used in testing (Materials)?\nWhat was the design of the study?\nWhat procedure was used?\n\nHow can you write this as a set of notes? We require main points of information, especially the main features of the data analyzed – what were the variables, how many observations were recorded, what exclusions or other data treatment steps were applied?\n\n\n\n\nThe focus of marking will be on the quality of the Results and Discussion sections. This means you must write in complete sentences in full paragraphs in a style appropriate for a research article appearing in a journal like Psychological Science. You must not use notes for these sections. You must write text that explains to the reader the analysis you did, why you did it, the results you found, and the implications of those results. You should write the text for the sections so that the questions listed following are answered fully.\nIf you use a data set that is already published in a journal such as Psychological Science, then your presentation of the results must differ from that in the article in ways that highlight new features of the data.\n\n\nBe clear on what the outcome measure or dependent variable for analysis was, and on what factors or predictor variables were brought into the analysis of that outcome. You then need to ensure the Results section answers the following questions:-\n\nWhat hypotheses were tested?\nWhat methods were used to test the hypotheses?\nWhy are they appropriate?\nWhat were the results? What were the direction and relative size of effects?\n\nDo what seems reasonable using one or more of the analysis methods practiced in class, or practiced in association with the workbooks, and explain your reasoning.\n\n\n\nWhat the reader must be able to do, given your report, is understand the answer to the following questions:\n\nWhat are the theoretical implications of the study findings?\nWhat are the practical implications?\n\nReports should present enough information that the reader can understand: the background and motivation for a study; the features of the data analyzed and the methods of data collection; the approach taken in analysis, the analysis steps, and the results; the relationship between the observed results and the expected results, and the interpretation of findings in relation to previous work.\nTo be clear about clarity: explain, spell things out (decisions, reasoning, interpretations) as if you were explaining them to a reasonably intelligent reader, a Psychologist who is not a specialist in the area of study occupied by the study reported. The main point is that you should keep in mind what the reader should get out of (what benefit) reading your report.\n\n\n\n\n\n\n\nSee here for a free guide.\nFor general APA formatting of reports: https://owl.purdue.edu/owl/research_and_citation/apa_style/apa_style_introduction.html\nAnd for APA formatting of statistics and numbers:\nhttps://owl.purdue.edu/owl/research_and_citation/apa_style/apa_formatting_and_style_guide/apa_numbers_statistics.html\nThough the APA guidelines are the authoritative guide.\n\n\n\n\n\n\n\n\nNote that the following information mirrors exactly the information provided on Moodle on assessment criteria:\nhttps://modules.lancaster.ac.uk/mod/page/view.php?id=2212446\nThese assessment criteria relate to the short research report:\nThe marks for the report will be depend primarily on the quality of the Results and Discussion sections of the report. This is because, in most cases, you will be using data for your analysis that were collected, previously, by other authors for an already published report. We cannot give you much credit for writing about the background research literature in the Introduction or about the Method of data collection because the authors of the original report did that work if you are using published data, or because I [or others] did that work if you are using demonstration data. We can give you credit for writing brief notes in the Introduction and Method sections, in your report, that present concise, clear, summaries of the background research literature and method of data collection.\nMarks will be awarded on the basis of the quality of the Results and Discussion sections. You can use whatever analysis approach you feel is justified. We will award marks for:-\n\nThe clarity and sense of the reasoning you describe for the approach you take. Explain your decisions. Why did you use the analysis method you chose to use?\nThe clarity of the description of the analysis method and results. Follow the APA style guide on how you should present tables and how you should report statistics in the text of the report. You must say not just whether a difference between conditions or the effect of a variable is significant. You must also describe the nature of the difference or of the effect. What is the size and the direction of the difference or the effect?\nHow effectively you make sense of the results in the context of the background research, and the research question. Explain how the reader should interpret the results. What are the theoretical or practical implications of the results?\n\n\n\nRead the guide to postgraduate marking criteria, in the Masters handbook.\nSome things will be more important than others in determining your marks. What will be especially important for this assessment are the following.\nA distinction requires … Clear conceptual structure; a thorough understanding of the topic and its implications; a clearly expressed and convincing argument that is used to develop a coherent and logical answer to the question, and is effectively based in existing theory and research; evidence of independent research; an insightful argument showing evidence of original thinking; and mastery of analytic techniques or methods.\nWhat is required is mastery. To evidence mastery, we will want to see:\n\nthe ability to evaluate methodologies critically;\ncritical awareness of current problems or new insights from current research;\ndemonstration that you can handle complex issues systematically, making excellent judgements.\n\nMastery is about choices. Data analysis requires you to make choices. Those choices require awareness of alternative approaches, an evaluation of the relative appropriateness of one method compared to others, and an explanation motivating the approach you choose to take. To get to this level, you will need to work with our materials, and read more widely, perhaps even looking at primary and secondary literature on statistics in independent reading.\nOf course, you can get a distinction by doing what we teach you but you will evidence, in addition, some reflection on the relevant concerns, some creativity or original thinking or reading about the relevant issues.\nA merit requires … Clear conceptual structure; a good understanding of the topic and its implications; an ability to select and organize material to provide a clear and logical line of argument; some (limited) evidence of independent thought or reading; general competence in analytic techniques or methods.\nWhat is required is a good level of competence overall. To evidence good competence, we will want to see:\n\na clear correspondence between the research question, hypotheses or predictions, and the chosen analytic method, which must be applied in a clearly appropriate manner;\nan awareness of the concerns relevant to the data analysis required to address the research question;\na comprehensive understanding of the techniques, and the skilful application of those techniques where appropriate.\n\nGeneral competence is about skill and understanding. We expect you to be able to identify the appropriate method to analyse data to address a research question. To evidence a good level of competence, your explanation of why you use the method you use will need to show an understanding of the appropriateness of the method in the context of the research question. We may see some critical evaluation, or reflection, on the appropriateness of the method, or its limits, but less than we might see in work of distinction standard. We expect to see a skillful use of the techniques we taught you. We expect to see an effective communication of your explanation for why you use the method, and what the results show.\nA pass requires … Basic competence in the application of research methods or analytic techniques. It is distinguished from work in the Merit category by the level of analysis displayed and by the coherence with which the material is organized. There may be some errors, misjudgments or omissions of important details.\nWhat is required is basic competence overall. To evidence basic competence, we will want to see:\n\na clear correspondence between the research question, hypotheses or predictions, and the chosen analytic method, which must be applied in an appropriate manner;\nreasonably well-structured account of the key information, concepts or findings;\nevidence of understanding of and some skill in using the appropriate techniques, though there may be evidence of limitations in understanding, perhaps some minor errors or omissions in the use of techniques or in the reporting of results."
  },
  {
    "objectID": "PSYC411/part2/what.html#sec-what-expected",
    "href": "PSYC411/part2/what.html#sec-what-expected",
    "title": "What you have to do",
    "section": "",
    "text": "Note that the following information mirrors exactly the information provided on Moodle:\nhttps://modules.lancaster.ac.uk/mod/page/view.php?id=2212445\n\n\nReports will concern, usually, findings from analyses of data-sets we have provided to you. Some students may wish to analyse data collected in previous studies or data accessed from online sources: they should correspond with Padraic Monaghan or Rob Davies if they wish to do so.\nThe evaluation of reports will focus on clarity, read the following for discussion of what is required.\nWe expect students to use one of the analysis methods taught in the module. Marks will be awarded depending:\n\non how appropriate the method is to the context, to the study design, to answering the research question, and to the features of the data; the appropriateness of methods to contexts will be taught in class;\non how effectively the analysis is explained; students must explain the motivations for their decisions, explain their methods, and explain their findings effectively to gain points.\n\n\n\n\n\nThe reports should include abstract, introduction, methods, results, discussion and references sections, like a short research article in the journal Psychological Science. You can view examples of articles here\n\nhttps://journals.sagepub.com/home/pss\n\nWord count limit: no more than 1500 words are allowed for all materials.\nUnlike a published research article, for PSYC401, the Results and Discussion sections must be written in full, but the Introduction and Methods sections can be written in the form of notes.\n\n\n\n\n\n\nThe focus of marking will be on the quality of the Results and Discussion sections. This means you can write your notes in the Introduction and Methods sections as short answers to the following questions:-\n\n\n\nWhat did the researchers do and why did the researchers do it?\nWhat was the question addressed in the study and why is it interesting?\nWhat were the hypotheses?\nWhat results were expected and how would they relate to the hypotheses?\n\nHow can you write this as a set of notes? We require main points of information on the hypotheses concerning expected results. We will ignore the absence of citations, or of explanations of critical previous experimental work, in the Introduction.\n\n\n\nNote the origin of the data at the start of the method section. As for the Introduction, your method section writing needs to furnish answers to questions like the following:-\n\nWhat was done to collect the data?\nWho were tested (Participants)?\nWhat materials were used in testing (Materials)?\nWhat was the design of the study?\nWhat procedure was used?\n\nHow can you write this as a set of notes? We require main points of information, especially the main features of the data analyzed – what were the variables, how many observations were recorded, what exclusions or other data treatment steps were applied?\n\n\n\n\nThe focus of marking will be on the quality of the Results and Discussion sections. This means you must write in complete sentences in full paragraphs in a style appropriate for a research article appearing in a journal like Psychological Science. You must not use notes for these sections. You must write text that explains to the reader the analysis you did, why you did it, the results you found, and the implications of those results. You should write the text for the sections so that the questions listed following are answered fully.\nIf you use a data set that is already published in a journal such as Psychological Science, then your presentation of the results must differ from that in the article in ways that highlight new features of the data.\n\n\nBe clear on what the outcome measure or dependent variable for analysis was, and on what factors or predictor variables were brought into the analysis of that outcome. You then need to ensure the Results section answers the following questions:-\n\nWhat hypotheses were tested?\nWhat methods were used to test the hypotheses?\nWhy are they appropriate?\nWhat were the results? What were the direction and relative size of effects?\n\nDo what seems reasonable using one or more of the analysis methods practiced in class, or practiced in association with the workbooks, and explain your reasoning.\n\n\n\nWhat the reader must be able to do, given your report, is understand the answer to the following questions:\n\nWhat are the theoretical implications of the study findings?\nWhat are the practical implications?\n\nReports should present enough information that the reader can understand: the background and motivation for a study; the features of the data analyzed and the methods of data collection; the approach taken in analysis, the analysis steps, and the results; the relationship between the observed results and the expected results, and the interpretation of findings in relation to previous work.\nTo be clear about clarity: explain, spell things out (decisions, reasoning, interpretations) as if you were explaining them to a reasonably intelligent reader, a Psychologist who is not a specialist in the area of study occupied by the study reported. The main point is that you should keep in mind what the reader should get out of (what benefit) reading your report.\n\n\n\n\n\n\n\nSee here for a free guide.\nFor general APA formatting of reports: https://owl.purdue.edu/owl/research_and_citation/apa_style/apa_style_introduction.html\nAnd for APA formatting of statistics and numbers:\nhttps://owl.purdue.edu/owl/research_and_citation/apa_style/apa_formatting_and_style_guide/apa_numbers_statistics.html\nThough the APA guidelines are the authoritative guide."
  },
  {
    "objectID": "PSYC411/part2/what.html#sec-marking",
    "href": "PSYC411/part2/what.html#sec-marking",
    "title": "What you have to do",
    "section": "",
    "text": "Note that the following information mirrors exactly the information provided on Moodle on assessment criteria:\nhttps://modules.lancaster.ac.uk/mod/page/view.php?id=2212446\nThese assessment criteria relate to the short research report:\nThe marks for the report will be depend primarily on the quality of the Results and Discussion sections of the report. This is because, in most cases, you will be using data for your analysis that were collected, previously, by other authors for an already published report. We cannot give you much credit for writing about the background research literature in the Introduction or about the Method of data collection because the authors of the original report did that work if you are using published data, or because I [or others] did that work if you are using demonstration data. We can give you credit for writing brief notes in the Introduction and Method sections, in your report, that present concise, clear, summaries of the background research literature and method of data collection.\nMarks will be awarded on the basis of the quality of the Results and Discussion sections. You can use whatever analysis approach you feel is justified. We will award marks for:-\n\nThe clarity and sense of the reasoning you describe for the approach you take. Explain your decisions. Why did you use the analysis method you chose to use?\nThe clarity of the description of the analysis method and results. Follow the APA style guide on how you should present tables and how you should report statistics in the text of the report. You must say not just whether a difference between conditions or the effect of a variable is significant. You must also describe the nature of the difference or of the effect. What is the size and the direction of the difference or the effect?\nHow effectively you make sense of the results in the context of the background research, and the research question. Explain how the reader should interpret the results. What are the theoretical or practical implications of the results?\n\n\n\nRead the guide to postgraduate marking criteria, in the Masters handbook.\nSome things will be more important than others in determining your marks. What will be especially important for this assessment are the following.\nA distinction requires … Clear conceptual structure; a thorough understanding of the topic and its implications; a clearly expressed and convincing argument that is used to develop a coherent and logical answer to the question, and is effectively based in existing theory and research; evidence of independent research; an insightful argument showing evidence of original thinking; and mastery of analytic techniques or methods.\nWhat is required is mastery. To evidence mastery, we will want to see:\n\nthe ability to evaluate methodologies critically;\ncritical awareness of current problems or new insights from current research;\ndemonstration that you can handle complex issues systematically, making excellent judgements.\n\nMastery is about choices. Data analysis requires you to make choices. Those choices require awareness of alternative approaches, an evaluation of the relative appropriateness of one method compared to others, and an explanation motivating the approach you choose to take. To get to this level, you will need to work with our materials, and read more widely, perhaps even looking at primary and secondary literature on statistics in independent reading.\nOf course, you can get a distinction by doing what we teach you but you will evidence, in addition, some reflection on the relevant concerns, some creativity or original thinking or reading about the relevant issues.\nA merit requires … Clear conceptual structure; a good understanding of the topic and its implications; an ability to select and organize material to provide a clear and logical line of argument; some (limited) evidence of independent thought or reading; general competence in analytic techniques or methods.\nWhat is required is a good level of competence overall. To evidence good competence, we will want to see:\n\na clear correspondence between the research question, hypotheses or predictions, and the chosen analytic method, which must be applied in a clearly appropriate manner;\nan awareness of the concerns relevant to the data analysis required to address the research question;\na comprehensive understanding of the techniques, and the skilful application of those techniques where appropriate.\n\nGeneral competence is about skill and understanding. We expect you to be able to identify the appropriate method to analyse data to address a research question. To evidence a good level of competence, your explanation of why you use the method you use will need to show an understanding of the appropriateness of the method in the context of the research question. We may see some critical evaluation, or reflection, on the appropriateness of the method, or its limits, but less than we might see in work of distinction standard. We expect to see a skillful use of the techniques we taught you. We expect to see an effective communication of your explanation for why you use the method, and what the results show.\nA pass requires … Basic competence in the application of research methods or analytic techniques. It is distinguished from work in the Merit category by the level of analysis displayed and by the coherence with which the material is organized. There may be some errors, misjudgments or omissions of important details.\nWhat is required is basic competence overall. To evidence basic competence, we will want to see:\n\na clear correspondence between the research question, hypotheses or predictions, and the chosen analytic method, which must be applied in an appropriate manner;\nreasonably well-structured account of the key information, concepts or findings;\nevidence of understanding of and some skill in using the appropriate techniques, though there may be evidence of limitations in understanding, perhaps some minor errors or omissions in the use of techniques or in the reporting of results."
  },
  {
    "objectID": "PSYC411/part2/visualization-intro.html",
    "href": "PSYC411/part2/visualization-intro.html",
    "title": "Introduction to visualization",
    "section": "",
    "text": "Welcome to our overview of the materials you will work with in our data visualization class in PSYC401 Week 8. This week, we will focus on perspectives and practices in data visualization.\nOur materials are designed to help you to think about what you are doing, to understand the aims of the practical steps, as well as to learn about producing professional effective data visualizations.\nWe will continue to work with data collected for the Clearly understood project because we think that working with these data in this research context will help you to make sense of the data, and to see why we ask you to practise the skills we are teaching.\nYou can read a bit more about the project and the project data in ?@sec-associations.\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills.\n\n\n\nThis week, we focus on both developing your critical thinking and strengthening your practical skills in data visualization.\nOur learning objectives: — what are we learning about?\nWe are working together to help you:\n\nGoals — Formulate questions you can ask yourself to help you to work effectively\nAudience — Understand the psychological factors that affect your impact\nDevelopment — Work reflectively through a development process\nImplement — Produce visualizations in line with best practice\n\nOur assessment targets: — how do you know if you have learned?\nWe are working together so you can:\n\nGoals — Identify a set of targets for a development process in your professional teams\nAudience — Explain what you need to do to make a visualization effective\nDevelopment — Locate yourself within the stages of the development process\nImplement — Produce visualizations that look good and are useful\n\n\n\n\nYou will see next links to the lectures we created to explain the concepts we want you to learn about and the practical visualization skills we want you to develop (Section 1.3.1), then information about the practical materials we have provided to help you to practise your skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 8 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points. We do this here because we can share the code we used to generate the plots we use in some of the slides 1\n\n\n\n\n\n\nTip\n\n\n\nLinked resources include:\n\nIn ?@sec-visualization, we present a more extensive discussion of data visualization, elaborating on some ideas, incorporating additional example plots and enabling you to work with alternate data-sets. This is provided as optional reading and may support more advanced development for students interested in future professional roles involving data analysis or data visualization.\nIn the PSYC403 Week 8, I present a lecture that outlines some perspectives or useful ways of thinking about data visualization: the history; the context in professional work; and what research suggests are effective ways to produce visualizations. You can access the resources for that class here.\n\n\n\n\n\nThe lecture material for this week is presented in four short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 4\nPart 2 of 4\nPart 3 of 4\nPart 4 of 4\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-visualization-how-to.R\n401-visualization-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-visualization-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-visualization-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-visualization-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions.\nFor this class on data visualization practices, our practical materials have two aims:\n\nHelping you to learn about data visualization;\nHelping you to learn how to help yourself by accessing, evaluating and exploiting the rich R knowledge ecosystem.\n\nThis means that in both the how-to and the workbook the different parts concern different sources of online information and how to access each.\nIn the how-to and the workbook we look at methods to produce visualizations that display information about both summary statistics (e.g., the average outcome) and raw or individual outcome variability. We explain why we should visualize data like this in the lecture (as you can see in Section 1.3.1 or Section 1.4).\nSpecifically, the materials are written to support learning how to work with visualizations called boxplots and rain cloud plots. These are popular data visualization techniques so it is important to learn how to build them and how to interpret them. If you have already been introduced to them, you will find that our materials here show how to edit or polish the visualizations to make them more effective.\nThere are three main sources of information you can access for free online.\n\nThe people who write software like the {tidyverse} or {ggplot2} libraries provide manuals, reference guides and tutorials. This information is often written as free web books, or as hard copy books.\nThese people, and often ther people, may write tutorials or guides or teaching materials designed to show learners (like us) how to use R functions or do certain things using R. They may present these tutorials or guides as web books, blog sites or video tutorials e.g. on Youtube or TikTok.\nMany post questions and answers to discussion forums like Stackoverflow.\n\nLearning how to find, understand and use this information teaches two lessons:\n\nA lot of scholarly and technical information is online and free.\nLearning how to access this information is a key way that most professionals work out what they want to do and how they can do it.\n\nIn our practical materials, we look at how you can:\n\nsearch for and find relevant information;\nlearn how to understand the tools using the information shared through online sources;\nwork with example or demonstration code, adapting it for your own purposes.\n\n\n\n\n\n\n\nTip\n\n\n\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\nPart 3 in the workbook focuses on locating and using {ggplot2} reference information to learn how to build box plots.\nPart 4 in the workbook focuses on locating and using online tutorial information or how-to guides to build rain cloud plots. This kind of plot incorporates elements of the boxplot, the scatterplot and the density plot to give the viewer summary information about the distribution of scores on a variable while also giving information about the variability of outcomes.\nPart 5 in the workbook focuses on using information available in the public discussion Stackoverflow so that you can learn how to export the plots you make, in order to include them in reports.\nThe activity 401-visualization-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-visualization-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\n\n\n\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study-two-general-participants.csv looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful.\n\n\n\n\nSome people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\nTip\n\n\n\nIn these notes, I provide notes on the code steps that result in plots.\n\nClick on the Notes tab to see them.\n\n\n\n\n\n\nIdentify your goals\nThink about your audience\nDevelop reflectively\nImplement good practice\n\n\n\n\nWe are working together to help you:\n\nGoals — Formulate questions you can ask yourself to help you to work effectively\nAudience — Understand the psychological factors that affect your impact\nDevelopment — Work reflectively through a development process\nImplement — Produce visualizations in line with best practice\n\n\n\n\nWe are working together so you can:\n\nGoals — Identify a set of targets for a development process in your professional teams\nAudience — Explain what you need to do to make a visualization effective\nDevelopment — Locate yourself within the stages of the development process\nImplement — Produce visualizations that look good and are useful\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe begin by thinking about the questions you will ask yourself when you need to decide what you will do\nWe build, here, on the insights developed by @gelman2013.\n\n\n\n\n\n\n\nWhy don’t we just use the good enough easy to produce plots in Excel? \\(\\rightarrow\\) Why bother?\nWhy don’t we just produce a summary table? \\(\\rightarrow\\) Why bother?\nAre we engaged in making beautiful graphics or informative displays or both? \\(\\rightarrow\\) What are we doing?\nIn PSYC403, we look at \\(\\rightarrow\\) Perspectives: the context and history of thinking about visualization\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Scatterplot of the relation between reaction time and days in the sleepstudy data\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: The relation between reaction time and days: here, we plot the data for each participant separately\n\n\n\n\n\n\n\n\n\nData visualization workers: we may aim to get and keep the attention of our audience, to tell a story, to persuade our viewers\nData analysis workers: we may aim to enable our audience to understand our data, our findings, and to discover more for themselves\n\n\n\n\n\nSometimes in a workflow, we are quickly sketching draft visualizations: exploring, for ourselves, or with others, what we can see in our data\nSometimes, we are ready to present our visualization to a wider audience: we aim to share a polished visual object\n\n\n\n\nDiscovery goals\n\nDo we need an overview? – To get a sense of what is in the data, and to check our assumptions\nAre we looking for the unexpected? – Comparing groups to check for variability, exploring data open to surprises\n\n\n\n\nCommunication goals\n\nWhat do we need our audience to understand?\nWhat story are we telling?\nDo we need to attract attention or stimulate interest?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe will produce more effective visualizations if we think about how our audience sees, and what they expect [@franconeri2021]\nCheck out the PSYC403 Perspectives lecture for more in-depth explanation; here, I present a selective summary\n\n\n\n\n\n\n\nYour audience can look at your visualization\nAnd quickly and easily extract statistical information from what you show\nYou look at a scatterplot and see the minimum, maximum and mean heights of the points\n\n\n\n\n@franconeri2021 Fig. 2\n\n\n\n\n\n\n\nAs scientists, we think about uncertainty all the time\nWe quantify and typically show uncertainty over estimates e.g. average differences\nWe should also show and think about outcome variability\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n\nThe first row shows a scatterplot encoded with two colors, green and orange\nPeople with typical vision can see that the green dots have a steep positive correlation and the orange dots make a flat line\nWe use colour blindness friendly colour palettes\n\n\n\n\n@franconeri2021 Fig.5\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nYour first question is always going to be: (why) do we need to make a plot?\nYour answer will evolve through a development process that will gradually reveal the characteristics of your data\n\n\n\n\n\n\n\nIdentifying your goals enables you to understand what you are doing and why\nThrough the development process, you may create different versions — iterations — of a plot\nThis iterative work benefits both you and your audience [@gelman2002; @kastellec2007]\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nAs you iterate, reflect on what your goals are, what your audience needs and expects, and how each plot version moves you closer to effective discovery or communication\nThis reflection uncovers what is interesting, useful and beautiful about your data\n\n\n\n\n\n\nWe can use text and tables to communicate specific values but visualizations help us to:\n\nstimulate thinking\ndiscover what is unexpected\ncommunicate scale and complexity\nmake comparisons to show how results vary\ndisplay uncertainty about estimates\n\n\n\n\n\ndata columnsx-variablesy-variables\n\n\n\n\n\n\n\n\n\n\nx1\n\n\nx2\n\n\nx3\n\n\nx4\n\n\ny1\n\n\ny2\n\n\ny3\n\n\ny4\n\n\n\n\n\n\n10\n\n\n10\n\n\n10\n\n\n8\n\n\n8.04\n\n\n9.14\n\n\n7.46\n\n\n6.58\n\n\n\n\n8\n\n\n8\n\n\n8\n\n\n8\n\n\n6.95\n\n\n8.14\n\n\n6.77\n\n\n5.76\n\n\n\n\n13\n\n\n13\n\n\n13\n\n\n8\n\n\n7.58\n\n\n8.74\n\n\n12.74\n\n\n7.71\n\n\n\n\n9\n\n\n9\n\n\n9\n\n\n8\n\n\n8.81\n\n\n8.77\n\n\n7.11\n\n\n8.84\n\n\n\n\n11\n\n\n11\n\n\n11\n\n\n8\n\n\n8.33\n\n\n9.26\n\n\n7.81\n\n\n8.47\n\n\n\n\n14\n\n\n14\n\n\n14\n\n\n8\n\n\n9.96\n\n\n8.10\n\n\n8.84\n\n\n7.04\n\n\n\n\n6\n\n\n6\n\n\n6\n\n\n8\n\n\n7.24\n\n\n6.13\n\n\n6.08\n\n\n5.25\n\n\n\n\n4\n\n\n4\n\n\n4\n\n\n19\n\n\n4.26\n\n\n3.10\n\n\n5.39\n\n\n12.50\n\n\n\n\n12\n\n\n12\n\n\n12\n\n\n8\n\n\n10.84\n\n\n9.13\n\n\n8.15\n\n\n5.56\n\n\n\n\n7\n\n\n7\n\n\n7\n\n\n8\n\n\n4.82\n\n\n7.26\n\n\n6.42\n\n\n7.91\n\n\n\n\n5\n\n\n5\n\n\n5\n\n\n8\n\n\n5.68\n\n\n4.74\n\n\n5.73\n\n\n6.89\n\n\n\n\n\n\nFigure 3: Data table view of Anscombe’s Quartet dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1\n\n\nx2\n\n\nx3\n\n\nx4\n\n\n\n\n\n\n\n\nMin. : 4.0\n\n\nMin. : 4.0\n\n\nMin. : 4.0\n\n\nMin. : 8\n\n\n\n\n\n\n1st Qu.: 6.5\n\n\n1st Qu.: 6.5\n\n\n1st Qu.: 6.5\n\n\n1st Qu.: 8\n\n\n\n\n\n\nMedian : 9.0\n\n\nMedian : 9.0\n\n\nMedian : 9.0\n\n\nMedian : 8\n\n\n\n\n\n\nMean : 9.0\n\n\nMean : 9.0\n\n\nMean : 9.0\n\n\nMean : 9\n\n\n\n\n\n\n3rd Qu.:11.5\n\n\n3rd Qu.:11.5\n\n\n3rd Qu.:11.5\n\n\n3rd Qu.: 8\n\n\n\n\n\n\nMax. :14.0\n\n\nMax. :14.0\n\n\nMax. :14.0\n\n\nMax. :19\n\n\n\n\n\n\nFigure 4: Summary table view of descriptive statistics for x variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny1\n\n\ny2\n\n\ny3\n\n\ny4\n\n\n\n\n\n\n\n\nMin. : 4.260\n\n\nMin. :3.100\n\n\nMin. : 5.39\n\n\nMin. : 5.250\n\n\n\n\n\n\n1st Qu.: 6.315\n\n\n1st Qu.:6.695\n\n\n1st Qu.: 6.25\n\n\n1st Qu.: 6.170\n\n\n\n\n\n\nMedian : 7.580\n\n\nMedian :8.140\n\n\nMedian : 7.11\n\n\nMedian : 7.040\n\n\n\n\n\n\nMean : 7.501\n\n\nMean :7.501\n\n\nMean : 7.50\n\n\nMean : 7.501\n\n\n\n\n\n\n3rd Qu.: 8.570\n\n\n3rd Qu.:8.950\n\n\n3rd Qu.: 7.98\n\n\n3rd Qu.: 8.190\n\n\n\n\n\n\nMax. :10.840\n\n\nMax. :9.260\n\n\nMax. :12.74\n\n\nMax. :12.500\n\n\n\n\n\n\nFigure 5: Summary table view of descriptive statistics for y variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: All 4 of the @anscombe1973 x,y datasets are identical when examined using summary statistics but we see how they vary when we use scatterplots to visualize them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: All 12 @matejka2017 x,y datasets (via @jumpingrivers) have the same mean and standard deviation summary statistics but we only understand how the data are structured when we plot them and can look at the structure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: In this plot we show data on the impact of sleep deprivation on reaction time, from @belenky2003 [via @R-lme4]. We can see how reaction time slows with increasing deprivation on average (grey line) but that the rate of slowing varies between individuals\n\n\n\n\n\n\n\n\n\nScientists are often faced with the challenge of conveying uncertainty to their audiences [@hofman2020]:\n\n\nInferential uncertainty — the degree to which a particular summary statistic (e.g., a population mean) is known to the scientist\nOutcome uncertainty — how much individual outcomes vary (e.g., around the mean, regardless of how well it has been estimated)\n\n\nInferential uncertainty can be reduced by collecting and analyzing more data, whereas outcome uncertainty cannot\n\n\n\n\n\n\n\nThe process through which we understand the world is characterized by assumptions, limitations, extrapolations, and generalizations, and this brings uncertainty [@vanderbles2019]\nWe often face the challenge of communicating this\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n\nNon-expert people will tend to overstate the impact of interventions and understate the variability of outcomes\nwhen they see visualizations like error bars that show\nmean and standard error values, that focus on inferential uncertainty [@hofman2020]\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n\nExpert scientists also overestimate the impact of interventions when they see standard visualizations that focus on inferential uncertainty: the illusion of predictability\nWe can stimulate more accurate understanding if we show outcome variability [@zhang2023]\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n@vasishth2021:\n\nThe most difficult idea to digest in data analysis is that conclusions based on data are almost always uncertain, regardless of whether the outcome of the statistical test is statistically significant or not\n\n\n\n\n@Gelman2015:\n\nWe must move beyond the idea that effects are ‘there’ or not and the idea that the goal of a study is to reject a null hypothesis. As many observers have noted, these attitudes lead to trouble because they deny the variation inherent in real social phenomena, and they deny the uncertainty inherent in statistical inference\n\n\n\n\n\nResults will vary: we should expect changes over time, or differences between individuals or between groups\nKnowledge is uncertain: outcomes will vary even when the average effect is precisely estimated\nWe have the responsibility to accept and to express this uncertainty\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe combine our creative thinking with the flexibility of the Grammar of Graphics to produce effective plots\n\n\n\n\n\n\n\nWhen we use the {ggplot2} to draw plots, we are using tools developed with a philosophy of visualization in mind [@wickham2010; @wilkinson2013]: The Grammar of Graphics\nA grammar is a system of rules that allows people to collaborate and individuals to create\nWe do not need to think about the grammar when we produce visualizations\nBut it will help you to know that when we puzzle over how we do things, there are always reasons why we do things\n\n\n\n\n\ndata and aesthetic mappings\nstatistical transformations\ngeometric objects\nscales\n\n\n\n\n\n\n\n\n\nFigure 9: A scatterplot showing the potential association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudyone.1\n0.49\n7.96\nstudyone\n34\n33\n7\n53\n11\nNon-binary\nHigher\nWhite\n\n\nstudyone.10\n0.85\n7.28\nstudyone\n25\n33\n7\n60\n11\nFemale\nHigher\nWhite\n\n\nstudyone.100\n0.82\n7.36\nstudyone\n43\n40\n8\n46\n12\nMale\nFurther\nWhite\n\n\nstudyone.101\n0.94\n7.88\nstudyone\n46\n33\n11\n51\n15\nMale\nHigher\nWhite\n\n\nstudyone.102\n0.58\n6.96\nstudyone\n18\n32\n3\n51\n12\nMale\nSecondary\nMixed\n\n\nstudyone.103\n0.84\n7.88\nstudyone\n19\n37\n13\n45\n19\nFemale\nFurther\nAsian\n\n\n\n\n\nFigure 10: Data table view of Health Comprehension project Study One dataset\n\n\n\n\n\n\n\n\nPlot with no objectsCode for the plot\n\n\n\nWhen we code a plot, we tell R we want:\nto use ggplot() to create a plot\nusing the data-set clearly.one.subjects\nand the variables SHIPLEY, HLVA\n\n\n\n\n\n\n\n\n\nFigure 11: Scatterplot showing association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n  ggplot(data = clearly.one.subjects, aes(x = SHIPLEY, y = HLVA))\n\n\nWe bring the data-set and the variables\nWe declare the aesthetic mappings:\n\n\nSHIPLEY score \\(\\rightarrow\\) x-axis (horizontal: left-to-right position)\nHLVA score \\(\\rightarrow\\) y-axis (vertical: bottom-to-top position)\n\n\n\n\n\n\n\n\nPlot with only objectsCode for the plot\n\n\n\nWhen we code a plot, we tell R we want:\nto use a geometric object, like geom_point\nto display the data aesthetic mappings\n\n\n\n\n\n\n\n\n\nFigure 12: Scatterplot showing association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n  ggplot(data = clearly.one.subjects, aes(x = SHIPLEY, y = HLVA)) +\n  geom_point()\n\n\nWe add the geom_point() to tell R to draw the information about the SHIPLEY and HLVA scores as points\nEach point represents information about one participant in the clearly.one.subjects data-set\n\n\nSHIPLEY score \\(\\rightarrow\\) x-axis (horizontal: left-to-right position)\nHLVA score \\(\\rightarrow\\) y-axis (vertical: bottom-to-top position)\n\n\n\n\n\n\n\n\nThe grammar of graphics define the components of a plot: the data, the mappings, and the geometric object\nTogether, the data, mappings, and geometric object form a layer\nA plot may have multiple layers\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nHaving a system of graphics: with components, layers and rules\nReleases us to be creative: changing a single feature at a time\n\n\n\n\n\n\n\nPlot with smootherCode for the plot\n\n\n\nBuild a plot layer by layer\nWe can begin by using points to display the vocabulary and health literacy scores for each person\nWe add a layer using a smoother to show the average association between vocabulary and literacy\n\n\n\n\n\n\n\n\n\nFigure 13: Scatterplot showing association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n  ggplot(data = clearly.one.subjects, aes(x = SHIPLEY, y = HLVA)) +\n  geom_point() +\n  geom_smooth()\n\n\nWe add the geom_smooth() to tell R to represent the average trend for the association between SHIPLEY and HLVA scores\nThe line is drawn by {ggplot2} which calculates a statistical transformation\nHere, the transformation summarizes the association for different ranges of SHIPLEY vocabulary scores\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(SHIPLEY, HLVA)) +\n  geom_smooth() +\n  geom_point()\n\n\nThe {ggplot2} library supplies default values\nSo we do not need to tell R how to do every thing\nWe do not need to tell R that the points in a scatterplot:\nshould represent the data aesthetic mappings in Cartesian (x-horizontal, y-vertical) 2-dimensional space\nand should be black in colour\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(SHIPLEY, HLVA)) +\n  geom_smooth() +\n  geom_point(colour = \"darkgrey\", size = 3)\n\n\nWe can over-ride the defaults by supplying arguments, entering values inside the brackets in the function calls\ngeom_point(colour = \"darkgrey\", size = 3) tells R we want:\n\n\ndark grey points when the default is black\npoints that are 3x larger than the default size\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe can add layers, control the appearance of each component\nTo construct more effective plots\nThe plots can be more effective because we develop them in an iterative process\nin which we reflect on our goals and the needs of our audience\n\n\n\n\n\n\n\nUsing colourCode for the plot\n\n\n\nWhen we code a plot, we tell R we want:\nto display data about people with different education levels\ndistinguishing education level by colour\n\n\n\n\n\n\n\n\n\nFigure 14: Using colour\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA, \n             group = EDUCATION, colour = EDUCATION)) +\n  geom_smooth(method = \"lm\", se = FALSE, \n              linewidth = 2, alpha = .75) +\n  geom_point(size = 3)\n\n\ngroup = EDUCATION, colour = EDUCATION tells R to:\n\n\ngroup the data by EDUCATION level\ncolour the points for people with different levels of education in different colours\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA, \n             group = EDUCATION, colour = EDUCATION)) +\n  geom_smooth(method = \"lm\", se = FALSE, \n              linewidth = 2, alpha = .75) +\n  geom_point(size = 3)\n\n\nmethod = \"lm\", se = FALSE tells R what method to use to draw the smoother line\nlinewidth = 2 makes the width of the smoother line 2 x larger than the default\nalpha = .75 makes the line .75 x the opacity of the default (i.e. a. bit more transparent)\nLearn to edit: shape, size, transparency and colour\n\n\n\n\n\nUsing facetsCode for the plot\n\n\n\nIt is often easier to compare trends\nBy presenting a separate plot for each condition or group\nShowing the separate plots in a grid side-by-side\n\n\n\n\n\n\n\n\n\nFigure 15: The association between health literacy and vocabulary varies by education level\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA, \n             group = EDUCATION, colour = EDUCATION)) +\n  geom_smooth(method = \"lm\", se = FALSE, \n              linewidth = 2, alpha = .75) +\n  geom_point(size = 3) +\n  facet_wrap(~ EDUCATION)\n\n\nfacet_wrap(~ EDUCATION) tells R to split the data by EDUCATION level\nAnd show a separate plot for each EDUCATION level group side-by-side for easy comparison\n\n\n\n\n\n\n\n\nLabelled plotCode for the plot\n\n\n\nWe do not present visualizations in isolation\nWe present plots embedded in the context of labels and titles\nWe use the text to guide the viewer\n\n\n\n\n\n\n\n\n\nFigure 16: A labelled plot\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA)) +\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"darkgreen\", linewidth = 2, alpha = .75) +\n  geom_point(size = 3, colour = \"lightgreen\") +\n  labs(x = \"Vocabulary (Shipley)\", y = \"Health literacy (HLVA)\",\n       title = \"Scatterplot showing how higher vocabulary\\npredicts higher health literacy on average\")\n\n\nWe use the labs() function to add: the plot title and the labels for the x-axis and y-axis\nWe edit the title so that the viewer can see what we want them to see\nWe use \\n to make the title fit on two lines\n\n\n\n\n\n\n\n\nAnnotated plotCode for the plot\n\n\n\nWe can direct the attention of our audience to key features of our data\nBy adding annotations like text and lines\n\n\n\n\n\n\n\n\n\nFigure 17: An annotated plot\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA)) +\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"darkgreen\", linewidth = 2, alpha = .75) +\n  geom_point(size = 3, colour = \"lightgreen\") +\n  labs(x = \"Vocabulary (Shipley)\", y = \"Health literacy (HLVA)\") +\n  geom_hline(yintercept = mean(clearly.one.subjects$HLVA),\n             linetype = \"dashed\",\n             linewidth = 2,\n             colour = \"grey\",\n             alpha = .85) +\n  annotate(\"text\", x = 27, y = 9.3, label = \"Mean HLVA\", colour = \"grey\") +\n  theme_bw()\n\n\ngeom_hline() adds a line to show mean health literacy\nannotate(\"text\" ...) adds a text label\n\n\n\n\n\n\n\n\nComplex plotCode for the plot\n\n\n\nThe power of the Grammar of Graphics lies in the rules\nDevelopers can use the rules to expand our capacity to visualize data\nWe add marginal histograms to our scatterplot to visualize associations and distributions\n\n\n\n\n\n\n\n\n\nFigure 18: A scatterplot showing the potential association between health literacy and vocabulary\n\n\n\n\n\n\n\n\nplot &lt;- clearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA)) +\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"darkgreen\", linewidth = 2, alpha = .75) +\n  geom_point(size = 3, colour = \"lightgreen\") +\n  labs(x = \"Vocabulary (Shipley)\", y = \"Health literacy (HLVA)\")\n\nggMarginal(plot, type = \"histogram\", fill = \"lightgreen\", \n           xparams = list(binwidth=2), yparams = list(binwidth=1))\n\n\nggMarginal(plot, type = \"histogram\") enables us to show the distribution of scores on each variable\nThis helps our viewer to process the association and information about each variable [@franconeri2021]\n\n\n\n\n\n\n\n\nWe can choose a theme to adapt the look of the whole plot to suit our needs or the needs of our audience\n\n\n\n\n\n\n\n\n\nFigure 19: Different themes: (left) theme_dark(); (middle) theme_bw(); and (right) theme_classic()\n\n\n\n\n\n\n\n\nYou start your work with these questions:\n\nWhat are our goals?\nWhat does our audience need or expect?\n\nYou develop your visualization in a reflective process:\n\nBegin with a quick draft to show the distributions or make the comparisons you think about first\nThen reflect, and edit: does this enable me to discover sources of variability in my data?\nThen reflect, and edit: does this enable me to effectively communicate what I want to communicate?\nThen reflect, and edit: does this look good? – do my viewers tell me this works well?\n\n\n\n\n\n\n\nTip\n\n\n\nI can only show you the potential for creative and effective visualization\n\nexperiment and find what looks good and is useful to you\nseek out information – good places to start are:\n\nhttps://ggplot2.tidyverse.org/index.html\nhttps://r-graph-gallery.com"
  },
  {
    "objectID": "PSYC411/part2/visualization-intro.html#sec-vis-intro-overview",
    "href": "PSYC411/part2/visualization-intro.html#sec-vis-intro-overview",
    "title": "Introduction to visualization",
    "section": "",
    "text": "Welcome to our overview of the materials you will work with in our data visualization class in PSYC401 Week 8. This week, we will focus on perspectives and practices in data visualization.\nOur materials are designed to help you to think about what you are doing, to understand the aims of the practical steps, as well as to learn about producing professional effective data visualizations.\nWe will continue to work with data collected for the Clearly understood project because we think that working with these data in this research context will help you to make sense of the data, and to see why we ask you to practise the skills we are teaching.\nYou can read a bit more about the project and the project data in ?@sec-associations.\nAs we work together, we will be revisiting some of the ideas and techniques you have seen in previous classes. This is to give you the opportunity to consolidate your learning. We will be extending your development with some new ideas to strengthen your skills."
  },
  {
    "objectID": "PSYC411/part2/visualization-intro.html#sec-vis-intro-goals",
    "href": "PSYC411/part2/visualization-intro.html#sec-vis-intro-goals",
    "title": "Introduction to visualization",
    "section": "",
    "text": "This week, we focus on both developing your critical thinking and strengthening your practical skills in data visualization.\nOur learning objectives: — what are we learning about?\nWe are working together to help you:\n\nGoals — Formulate questions you can ask yourself to help you to work effectively\nAudience — Understand the psychological factors that affect your impact\nDevelopment — Work reflectively through a development process\nImplement — Produce visualizations in line with best practice\n\nOur assessment targets: — how do you know if you have learned?\nWe are working together so you can:\n\nGoals — Identify a set of targets for a development process in your professional teams\nAudience — Explain what you need to do to make a visualization effective\nDevelopment — Locate yourself within the stages of the development process\nImplement — Produce visualizations that look good and are useful"
  },
  {
    "objectID": "PSYC411/part2/visualization-intro.html#sec-vis-intro-resources",
    "href": "PSYC411/part2/visualization-intro.html#sec-vis-intro-resources",
    "title": "Introduction to visualization",
    "section": "",
    "text": "You will see next links to the lectures we created to explain the concepts we want you to learn about and the practical visualization skills we want you to develop (Section 1.3.1), then information about the practical materials we have provided to help you to practise your skills (Section 1.3.2).\nAll the links to the lecture videos, the lecture slides, and everything you need for your practical work can also be found in the Week 8 files folder on Moodle here\nIn Section 1.4, we present the lecture slide points. We do this here because we can share the code we used to generate the plots we use in some of the slides 1\n\n\n\n\n\n\nTip\n\n\n\nLinked resources include:\n\nIn ?@sec-visualization, we present a more extensive discussion of data visualization, elaborating on some ideas, incorporating additional example plots and enabling you to work with alternate data-sets. This is provided as optional reading and may support more advanced development for students interested in future professional roles involving data analysis or data visualization.\nIn the PSYC403 Week 8, I present a lecture that outlines some perspectives or useful ways of thinking about data visualization: the history; the context in professional work; and what research suggests are effective ways to produce visualizations. You can access the resources for that class here.\n\n\n\n\n\nThe lecture material for this week is presented in four short parts. Click on a link and your browser should open a tab showing the Panopto video for the lecture part.\nPart 1 of 4\nPart 2 of 4\nPart 3 of 4\nPart 4 of 4\nYou can download the slides we presented in the lecture in two different formats, depending on what you think will be most useful to you:\n\nDownload the slides exactly as they appear in the lecture from this link. The .html file can be opened and viewed in any web browser (e.g., Chrome, Firefox, Safari).\nOr you can download a printable Word .docx presentation of the slides from this link. The .docx can be opened in Microsoft Word. The figures will not appear exactly as they do in the lecture recording because Word cannot cope with images so well but the trade-off is that you get a document you can print and edit to add notes.\n\n\n\n\nWe have collected the practical materials together into a folder.\nThe folder includes the data files:\n\nstudy-one-general-participants.csv\nstudy-two-general-participants.csv\n\nand .R code files:\n\n401-visualization-how-to.R\n401-visualization-workbook.R\n\nYou will use these files for your practical learning.\nYou can download the .R files and the data .csv files in a single folder, using the link here.\nOr you can download the files as individual files from the module Moodle page for PSYC401.\nOnce you have downloaded the file folder, you will need to upload it to the R-Studio server to access and use the R files.\n\n\nIn the how-to guide:\n\n401-visualization-how-to.R\n\nwe show you how to do everything you need to do in the practical workbook (see Section 1.3.3). The guide comprises an .R file 401-visualization-how-to.R with code and advice.\nThe code in the .R file was written to work with the data file\n\nstudy-one-general-participants.csv.\n\n\n\n\n\n\n\nTip\n\n\n\n\nWork through the steps in the how-to guide first, this practice will help you to understand what you need to do for the workbook tasks.\nThe how-to guide and the workbook have similar structures. This is intentional: so that you can copy and adapt code from the how-to guide to do the practical tasks in the workbook.\n\n\n\n\n\n\n\nIn the workbook:\n\n401-visualization-workbook.R\n\nyou will work with the data file\n\nstudy-two-general-participants.csv\n\nWe split .R scripts into parts, tasks and questions.\nFor this class on data visualization practices, our practical materials have two aims:\n\nHelping you to learn about data visualization;\nHelping you to learn how to help yourself by accessing, evaluating and exploiting the rich R knowledge ecosystem.\n\nThis means that in both the how-to and the workbook the different parts concern different sources of online information and how to access each.\nIn the how-to and the workbook we look at methods to produce visualizations that display information about both summary statistics (e.g., the average outcome) and raw or individual outcome variability. We explain why we should visualize data like this in the lecture (as you can see in Section 1.3.1 or Section 1.4).\nSpecifically, the materials are written to support learning how to work with visualizations called boxplots and rain cloud plots. These are popular data visualization techniques so it is important to learn how to build them and how to interpret them. If you have already been introduced to them, you will find that our materials here show how to edit or polish the visualizations to make them more effective.\nThere are three main sources of information you can access for free online.\n\nThe people who write software like the {tidyverse} or {ggplot2} libraries provide manuals, reference guides and tutorials. This information is often written as free web books, or as hard copy books.\nThese people, and often ther people, may write tutorials or guides or teaching materials designed to show learners (like us) how to use R functions or do certain things using R. They may present these tutorials or guides as web books, blog sites or video tutorials e.g. on Youtube or TikTok.\nMany post questions and answers to discussion forums like Stackoverflow.\n\nLearning how to find, understand and use this information teaches two lessons:\n\nA lot of scholarly and technical information is online and free.\nLearning how to access this information is a key way that most professionals work out what they want to do and how they can do it.\n\nIn our practical materials, we look at how you can:\n\nsearch for and find relevant information;\nlearn how to understand the tools using the information shared through online sources;\nwork with example or demonstration code, adapting it for your own purposes.\n\n\n\n\n\n\n\nTip\n\n\n\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in working with data in psychological science.\n\n\nPart 3 in the workbook focuses on locating and using {ggplot2} reference information to learn how to build box plots.\nPart 4 in the workbook focuses on locating and using online tutorial information or how-to guides to build rain cloud plots. This kind of plot incorporates elements of the boxplot, the scatterplot and the density plot to give the viewer summary information about the distribution of scores on a variable while also giving information about the variability of outcomes.\nPart 5 in the workbook focuses on using information available in the public discussion Stackoverflow so that you can learn how to export the plots you make, in order to include them in reports.\nThe activity 401-visualization-workbook.R file takes you through the tasks, one by one.\nIf you are unsure about what you need to do, check the advice in 401-visualization-how-to.R.\nYou will see that you can match a task in the activity to the same task in the how-to. The how-to shows you what function you need and how you should write the function code. You will need to change the names of the data-set or the variables to complete the tasks in the activity.\n\n\n\nEach of the data files we will work with has a similar structure.\nHere are what the first few rows in the data file study-two-general-participants.csv looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudytwo.1\n0.4107143\n6.071429\nstudytwo\n26\n27\n6\n50\n9\nFemale\nHigher\nAsian\n\n\nstudytwo.10\n0.6071429\n8.500000\nstudytwo\n38\n24\n9\n58\n15\nFemale\nSecondary\nWhite\n\n\nstudytwo.100\n0.8750000\n8.928571\nstudytwo\n66\n40\n13\n60\n20\nFemale\nHigher\nWhite\n\n\nstudytwo.101\n0.9642857\n8.500000\nstudytwo\n21\n31\n11\n59\n14\nFemale\nHigher\nWhite\n\n\nstudytwo.102\n0.7142857\n7.071429\nstudytwo\n74\n35\n7\n52\n18\nMale\nHigher\nWhite\n\n\nstudytwo.103\n0.7678571\n5.071429\nstudytwo\n18\n40\n11\n54\n15\nFemale\nFurther\nWhite\n\n\n\n\n\nYou can see the columns:\n\nparticipant_ID participant code\nmean.acc average accuracy of response to questions testing understanding of health guidance\nmean.self average self-rated accuracy of understanding of health guidance\nstudy variable coding for what study the data were collected in\nAGE age in years\nHLVA health literacy test score\nSHIPLEY vocabulary knowledge test score\nFACTOR3 reading strategy survey score\nGENDER gender code\nEDUCATION education level code\nETHNICITY ethnicity (Office National Statistics categories) code\n\n\n\n\nAfter the practical class, you will be able to download the answers version of the workbook here.\n\nThe answers version will present my answers for questions, and some extra information where that is helpful."
  },
  {
    "objectID": "PSYC411/part2/visualization-intro.html#sec-vis-intro-notes",
    "href": "PSYC411/part2/visualization-intro.html#sec-vis-intro-notes",
    "title": "Introduction to visualization",
    "section": "",
    "text": "Some people find it easier to read notes than to watch video recordings. This is why we also include the lecture notes here.\n\n\n\n\n\n\nTip\n\n\n\nIn these notes, I provide notes on the code steps that result in plots.\n\nClick on the Notes tab to see them.\n\n\n\n\n\n\nIdentify your goals\nThink about your audience\nDevelop reflectively\nImplement good practice\n\n\n\n\nWe are working together to help you:\n\nGoals — Formulate questions you can ask yourself to help you to work effectively\nAudience — Understand the psychological factors that affect your impact\nDevelopment — Work reflectively through a development process\nImplement — Produce visualizations in line with best practice\n\n\n\n\nWe are working together so you can:\n\nGoals — Identify a set of targets for a development process in your professional teams\nAudience — Explain what you need to do to make a visualization effective\nDevelopment — Locate yourself within the stages of the development process\nImplement — Produce visualizations that look good and are useful\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe begin by thinking about the questions you will ask yourself when you need to decide what you will do\nWe build, here, on the insights developed by @gelman2013.\n\n\n\n\n\n\n\nWhy don’t we just use the good enough easy to produce plots in Excel? \\(\\rightarrow\\) Why bother?\nWhy don’t we just produce a summary table? \\(\\rightarrow\\) Why bother?\nAre we engaged in making beautiful graphics or informative displays or both? \\(\\rightarrow\\) What are we doing?\nIn PSYC403, we look at \\(\\rightarrow\\) Perspectives: the context and history of thinking about visualization\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Scatterplot of the relation between reaction time and days in the sleepstudy data\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: The relation between reaction time and days: here, we plot the data for each participant separately\n\n\n\n\n\n\n\n\n\nData visualization workers: we may aim to get and keep the attention of our audience, to tell a story, to persuade our viewers\nData analysis workers: we may aim to enable our audience to understand our data, our findings, and to discover more for themselves\n\n\n\n\n\nSometimes in a workflow, we are quickly sketching draft visualizations: exploring, for ourselves, or with others, what we can see in our data\nSometimes, we are ready to present our visualization to a wider audience: we aim to share a polished visual object\n\n\n\n\nDiscovery goals\n\nDo we need an overview? – To get a sense of what is in the data, and to check our assumptions\nAre we looking for the unexpected? – Comparing groups to check for variability, exploring data open to surprises\n\n\n\n\nCommunication goals\n\nWhat do we need our audience to understand?\nWhat story are we telling?\nDo we need to attract attention or stimulate interest?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe will produce more effective visualizations if we think about how our audience sees, and what they expect [@franconeri2021]\nCheck out the PSYC403 Perspectives lecture for more in-depth explanation; here, I present a selective summary\n\n\n\n\n\n\n\nYour audience can look at your visualization\nAnd quickly and easily extract statistical information from what you show\nYou look at a scatterplot and see the minimum, maximum and mean heights of the points\n\n\n\n\n@franconeri2021 Fig. 2\n\n\n\n\n\n\n\nAs scientists, we think about uncertainty all the time\nWe quantify and typically show uncertainty over estimates e.g. average differences\nWe should also show and think about outcome variability\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n\nThe first row shows a scatterplot encoded with two colors, green and orange\nPeople with typical vision can see that the green dots have a steep positive correlation and the orange dots make a flat line\nWe use colour blindness friendly colour palettes\n\n\n\n\n@franconeri2021 Fig.5\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nYour first question is always going to be: (why) do we need to make a plot?\nYour answer will evolve through a development process that will gradually reveal the characteristics of your data\n\n\n\n\n\n\n\nIdentifying your goals enables you to understand what you are doing and why\nThrough the development process, you may create different versions — iterations — of a plot\nThis iterative work benefits both you and your audience [@gelman2002; @kastellec2007]\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nAs you iterate, reflect on what your goals are, what your audience needs and expects, and how each plot version moves you closer to effective discovery or communication\nThis reflection uncovers what is interesting, useful and beautiful about your data\n\n\n\n\n\n\nWe can use text and tables to communicate specific values but visualizations help us to:\n\nstimulate thinking\ndiscover what is unexpected\ncommunicate scale and complexity\nmake comparisons to show how results vary\ndisplay uncertainty about estimates\n\n\n\n\n\ndata columnsx-variablesy-variables\n\n\n\n\n\n\n\n\n\n\nx1\n\n\nx2\n\n\nx3\n\n\nx4\n\n\ny1\n\n\ny2\n\n\ny3\n\n\ny4\n\n\n\n\n\n\n10\n\n\n10\n\n\n10\n\n\n8\n\n\n8.04\n\n\n9.14\n\n\n7.46\n\n\n6.58\n\n\n\n\n8\n\n\n8\n\n\n8\n\n\n8\n\n\n6.95\n\n\n8.14\n\n\n6.77\n\n\n5.76\n\n\n\n\n13\n\n\n13\n\n\n13\n\n\n8\n\n\n7.58\n\n\n8.74\n\n\n12.74\n\n\n7.71\n\n\n\n\n9\n\n\n9\n\n\n9\n\n\n8\n\n\n8.81\n\n\n8.77\n\n\n7.11\n\n\n8.84\n\n\n\n\n11\n\n\n11\n\n\n11\n\n\n8\n\n\n8.33\n\n\n9.26\n\n\n7.81\n\n\n8.47\n\n\n\n\n14\n\n\n14\n\n\n14\n\n\n8\n\n\n9.96\n\n\n8.10\n\n\n8.84\n\n\n7.04\n\n\n\n\n6\n\n\n6\n\n\n6\n\n\n8\n\n\n7.24\n\n\n6.13\n\n\n6.08\n\n\n5.25\n\n\n\n\n4\n\n\n4\n\n\n4\n\n\n19\n\n\n4.26\n\n\n3.10\n\n\n5.39\n\n\n12.50\n\n\n\n\n12\n\n\n12\n\n\n12\n\n\n8\n\n\n10.84\n\n\n9.13\n\n\n8.15\n\n\n5.56\n\n\n\n\n7\n\n\n7\n\n\n7\n\n\n8\n\n\n4.82\n\n\n7.26\n\n\n6.42\n\n\n7.91\n\n\n\n\n5\n\n\n5\n\n\n5\n\n\n8\n\n\n5.68\n\n\n4.74\n\n\n5.73\n\n\n6.89\n\n\n\n\n\n\nFigure 3: Data table view of Anscombe’s Quartet dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1\n\n\nx2\n\n\nx3\n\n\nx4\n\n\n\n\n\n\n\n\nMin. : 4.0\n\n\nMin. : 4.0\n\n\nMin. : 4.0\n\n\nMin. : 8\n\n\n\n\n\n\n1st Qu.: 6.5\n\n\n1st Qu.: 6.5\n\n\n1st Qu.: 6.5\n\n\n1st Qu.: 8\n\n\n\n\n\n\nMedian : 9.0\n\n\nMedian : 9.0\n\n\nMedian : 9.0\n\n\nMedian : 8\n\n\n\n\n\n\nMean : 9.0\n\n\nMean : 9.0\n\n\nMean : 9.0\n\n\nMean : 9\n\n\n\n\n\n\n3rd Qu.:11.5\n\n\n3rd Qu.:11.5\n\n\n3rd Qu.:11.5\n\n\n3rd Qu.: 8\n\n\n\n\n\n\nMax. :14.0\n\n\nMax. :14.0\n\n\nMax. :14.0\n\n\nMax. :19\n\n\n\n\n\n\nFigure 4: Summary table view of descriptive statistics for x variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny1\n\n\ny2\n\n\ny3\n\n\ny4\n\n\n\n\n\n\n\n\nMin. : 4.260\n\n\nMin. :3.100\n\n\nMin. : 5.39\n\n\nMin. : 5.250\n\n\n\n\n\n\n1st Qu.: 6.315\n\n\n1st Qu.:6.695\n\n\n1st Qu.: 6.25\n\n\n1st Qu.: 6.170\n\n\n\n\n\n\nMedian : 7.580\n\n\nMedian :8.140\n\n\nMedian : 7.11\n\n\nMedian : 7.040\n\n\n\n\n\n\nMean : 7.501\n\n\nMean :7.501\n\n\nMean : 7.50\n\n\nMean : 7.501\n\n\n\n\n\n\n3rd Qu.: 8.570\n\n\n3rd Qu.:8.950\n\n\n3rd Qu.: 7.98\n\n\n3rd Qu.: 8.190\n\n\n\n\n\n\nMax. :10.840\n\n\nMax. :9.260\n\n\nMax. :12.74\n\n\nMax. :12.500\n\n\n\n\n\n\nFigure 5: Summary table view of descriptive statistics for y variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: All 4 of the @anscombe1973 x,y datasets are identical when examined using summary statistics but we see how they vary when we use scatterplots to visualize them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: All 12 @matejka2017 x,y datasets (via @jumpingrivers) have the same mean and standard deviation summary statistics but we only understand how the data are structured when we plot them and can look at the structure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: In this plot we show data on the impact of sleep deprivation on reaction time, from @belenky2003 [via @R-lme4]. We can see how reaction time slows with increasing deprivation on average (grey line) but that the rate of slowing varies between individuals\n\n\n\n\n\n\n\n\n\nScientists are often faced with the challenge of conveying uncertainty to their audiences [@hofman2020]:\n\n\nInferential uncertainty — the degree to which a particular summary statistic (e.g., a population mean) is known to the scientist\nOutcome uncertainty — how much individual outcomes vary (e.g., around the mean, regardless of how well it has been estimated)\n\n\nInferential uncertainty can be reduced by collecting and analyzing more data, whereas outcome uncertainty cannot\n\n\n\n\n\n\n\nThe process through which we understand the world is characterized by assumptions, limitations, extrapolations, and generalizations, and this brings uncertainty [@vanderbles2019]\nWe often face the challenge of communicating this\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n\nNon-expert people will tend to overstate the impact of interventions and understate the variability of outcomes\nwhen they see visualizations like error bars that show\nmean and standard error values, that focus on inferential uncertainty [@hofman2020]\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n\nExpert scientists also overestimate the impact of interventions when they see standard visualizations that focus on inferential uncertainty: the illusion of predictability\nWe can stimulate more accurate understanding if we show outcome variability [@zhang2023]\n\n\n\n\n@zhang2023: The difference between uncertainty over estimates and uncertainty over the predictability of outcomes\n\n\n\n\n\n@vasishth2021:\n\nThe most difficult idea to digest in data analysis is that conclusions based on data are almost always uncertain, regardless of whether the outcome of the statistical test is statistically significant or not\n\n\n\n\n@Gelman2015:\n\nWe must move beyond the idea that effects are ‘there’ or not and the idea that the goal of a study is to reject a null hypothesis. As many observers have noted, these attitudes lead to trouble because they deny the variation inherent in real social phenomena, and they deny the uncertainty inherent in statistical inference\n\n\n\n\n\nResults will vary: we should expect changes over time, or differences between individuals or between groups\nKnowledge is uncertain: outcomes will vary even when the average effect is precisely estimated\nWe have the responsibility to accept and to express this uncertainty\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe combine our creative thinking with the flexibility of the Grammar of Graphics to produce effective plots\n\n\n\n\n\n\n\nWhen we use the {ggplot2} to draw plots, we are using tools developed with a philosophy of visualization in mind [@wickham2010; @wilkinson2013]: The Grammar of Graphics\nA grammar is a system of rules that allows people to collaborate and individuals to create\nWe do not need to think about the grammar when we produce visualizations\nBut it will help you to know that when we puzzle over how we do things, there are always reasons why we do things\n\n\n\n\n\ndata and aesthetic mappings\nstatistical transformations\ngeometric objects\nscales\n\n\n\n\n\n\n\n\n\nFigure 9: A scatterplot showing the potential association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_ID\nmean.acc\nmean.self\nstudy\nAGE\nSHIPLEY\nHLVA\nFACTOR3\nQRITOTAL\nGENDER\nEDUCATION\nETHNICITY\n\n\n\n\nstudyone.1\n0.49\n7.96\nstudyone\n34\n33\n7\n53\n11\nNon-binary\nHigher\nWhite\n\n\nstudyone.10\n0.85\n7.28\nstudyone\n25\n33\n7\n60\n11\nFemale\nHigher\nWhite\n\n\nstudyone.100\n0.82\n7.36\nstudyone\n43\n40\n8\n46\n12\nMale\nFurther\nWhite\n\n\nstudyone.101\n0.94\n7.88\nstudyone\n46\n33\n11\n51\n15\nMale\nHigher\nWhite\n\n\nstudyone.102\n0.58\n6.96\nstudyone\n18\n32\n3\n51\n12\nMale\nSecondary\nMixed\n\n\nstudyone.103\n0.84\n7.88\nstudyone\n19\n37\n13\n45\n19\nFemale\nFurther\nAsian\n\n\n\n\n\nFigure 10: Data table view of Health Comprehension project Study One dataset\n\n\n\n\n\n\n\n\nPlot with no objectsCode for the plot\n\n\n\nWhen we code a plot, we tell R we want:\nto use ggplot() to create a plot\nusing the data-set clearly.one.subjects\nand the variables SHIPLEY, HLVA\n\n\n\n\n\n\n\n\n\nFigure 11: Scatterplot showing association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n  ggplot(data = clearly.one.subjects, aes(x = SHIPLEY, y = HLVA))\n\n\nWe bring the data-set and the variables\nWe declare the aesthetic mappings:\n\n\nSHIPLEY score \\(\\rightarrow\\) x-axis (horizontal: left-to-right position)\nHLVA score \\(\\rightarrow\\) y-axis (vertical: bottom-to-top position)\n\n\n\n\n\n\n\n\nPlot with only objectsCode for the plot\n\n\n\nWhen we code a plot, we tell R we want:\nto use a geometric object, like geom_point\nto display the data aesthetic mappings\n\n\n\n\n\n\n\n\n\nFigure 12: Scatterplot showing association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n  ggplot(data = clearly.one.subjects, aes(x = SHIPLEY, y = HLVA)) +\n  geom_point()\n\n\nWe add the geom_point() to tell R to draw the information about the SHIPLEY and HLVA scores as points\nEach point represents information about one participant in the clearly.one.subjects data-set\n\n\nSHIPLEY score \\(\\rightarrow\\) x-axis (horizontal: left-to-right position)\nHLVA score \\(\\rightarrow\\) y-axis (vertical: bottom-to-top position)\n\n\n\n\n\n\n\n\nThe grammar of graphics define the components of a plot: the data, the mappings, and the geometric object\nTogether, the data, mappings, and geometric object form a layer\nA plot may have multiple layers\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nHaving a system of graphics: with components, layers and rules\nReleases us to be creative: changing a single feature at a time\n\n\n\n\n\n\n\nPlot with smootherCode for the plot\n\n\n\nBuild a plot layer by layer\nWe can begin by using points to display the vocabulary and health literacy scores for each person\nWe add a layer using a smoother to show the average association between vocabulary and literacy\n\n\n\n\n\n\n\n\n\nFigure 13: Scatterplot showing association between health literacy and vocabulary\n\n\n\n\n\n\n\n\n  ggplot(data = clearly.one.subjects, aes(x = SHIPLEY, y = HLVA)) +\n  geom_point() +\n  geom_smooth()\n\n\nWe add the geom_smooth() to tell R to represent the average trend for the association between SHIPLEY and HLVA scores\nThe line is drawn by {ggplot2} which calculates a statistical transformation\nHere, the transformation summarizes the association for different ranges of SHIPLEY vocabulary scores\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(SHIPLEY, HLVA)) +\n  geom_smooth() +\n  geom_point()\n\n\nThe {ggplot2} library supplies default values\nSo we do not need to tell R how to do every thing\nWe do not need to tell R that the points in a scatterplot:\nshould represent the data aesthetic mappings in Cartesian (x-horizontal, y-vertical) 2-dimensional space\nand should be black in colour\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(SHIPLEY, HLVA)) +\n  geom_smooth() +\n  geom_point(colour = \"darkgrey\", size = 3)\n\n\nWe can over-ride the defaults by supplying arguments, entering values inside the brackets in the function calls\ngeom_point(colour = \"darkgrey\", size = 3) tells R we want:\n\n\ndark grey points when the default is black\npoints that are 3x larger than the default size\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe can add layers, control the appearance of each component\nTo construct more effective plots\nThe plots can be more effective because we develop them in an iterative process\nin which we reflect on our goals and the needs of our audience\n\n\n\n\n\n\n\nUsing colourCode for the plot\n\n\n\nWhen we code a plot, we tell R we want:\nto display data about people with different education levels\ndistinguishing education level by colour\n\n\n\n\n\n\n\n\n\nFigure 14: Using colour\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA, \n             group = EDUCATION, colour = EDUCATION)) +\n  geom_smooth(method = \"lm\", se = FALSE, \n              linewidth = 2, alpha = .75) +\n  geom_point(size = 3)\n\n\ngroup = EDUCATION, colour = EDUCATION tells R to:\n\n\ngroup the data by EDUCATION level\ncolour the points for people with different levels of education in different colours\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA, \n             group = EDUCATION, colour = EDUCATION)) +\n  geom_smooth(method = \"lm\", se = FALSE, \n              linewidth = 2, alpha = .75) +\n  geom_point(size = 3)\n\n\nmethod = \"lm\", se = FALSE tells R what method to use to draw the smoother line\nlinewidth = 2 makes the width of the smoother line 2 x larger than the default\nalpha = .75 makes the line .75 x the opacity of the default (i.e. a. bit more transparent)\nLearn to edit: shape, size, transparency and colour\n\n\n\n\n\nUsing facetsCode for the plot\n\n\n\nIt is often easier to compare trends\nBy presenting a separate plot for each condition or group\nShowing the separate plots in a grid side-by-side\n\n\n\n\n\n\n\n\n\nFigure 15: The association between health literacy and vocabulary varies by education level\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA, \n             group = EDUCATION, colour = EDUCATION)) +\n  geom_smooth(method = \"lm\", se = FALSE, \n              linewidth = 2, alpha = .75) +\n  geom_point(size = 3) +\n  facet_wrap(~ EDUCATION)\n\n\nfacet_wrap(~ EDUCATION) tells R to split the data by EDUCATION level\nAnd show a separate plot for each EDUCATION level group side-by-side for easy comparison\n\n\n\n\n\n\n\n\nLabelled plotCode for the plot\n\n\n\nWe do not present visualizations in isolation\nWe present plots embedded in the context of labels and titles\nWe use the text to guide the viewer\n\n\n\n\n\n\n\n\n\nFigure 16: A labelled plot\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA)) +\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"darkgreen\", linewidth = 2, alpha = .75) +\n  geom_point(size = 3, colour = \"lightgreen\") +\n  labs(x = \"Vocabulary (Shipley)\", y = \"Health literacy (HLVA)\",\n       title = \"Scatterplot showing how higher vocabulary\\npredicts higher health literacy on average\")\n\n\nWe use the labs() function to add: the plot title and the labels for the x-axis and y-axis\nWe edit the title so that the viewer can see what we want them to see\nWe use \\n to make the title fit on two lines\n\n\n\n\n\n\n\n\nAnnotated plotCode for the plot\n\n\n\nWe can direct the attention of our audience to key features of our data\nBy adding annotations like text and lines\n\n\n\n\n\n\n\n\n\nFigure 17: An annotated plot\n\n\n\n\n\n\n\n\nclearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA)) +\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"darkgreen\", linewidth = 2, alpha = .75) +\n  geom_point(size = 3, colour = \"lightgreen\") +\n  labs(x = \"Vocabulary (Shipley)\", y = \"Health literacy (HLVA)\") +\n  geom_hline(yintercept = mean(clearly.one.subjects$HLVA),\n             linetype = \"dashed\",\n             linewidth = 2,\n             colour = \"grey\",\n             alpha = .85) +\n  annotate(\"text\", x = 27, y = 9.3, label = \"Mean HLVA\", colour = \"grey\") +\n  theme_bw()\n\n\ngeom_hline() adds a line to show mean health literacy\nannotate(\"text\" ...) adds a text label\n\n\n\n\n\n\n\n\nComplex plotCode for the plot\n\n\n\nThe power of the Grammar of Graphics lies in the rules\nDevelopers can use the rules to expand our capacity to visualize data\nWe add marginal histograms to our scatterplot to visualize associations and distributions\n\n\n\n\n\n\n\n\n\nFigure 18: A scatterplot showing the potential association between health literacy and vocabulary\n\n\n\n\n\n\n\n\nplot &lt;- clearly.one.subjects %&gt;%\n  ggplot(aes(x = SHIPLEY, y = HLVA)) +\n  geom_smooth(method = \"lm\", se = FALSE,\n              colour = \"darkgreen\", linewidth = 2, alpha = .75) +\n  geom_point(size = 3, colour = \"lightgreen\") +\n  labs(x = \"Vocabulary (Shipley)\", y = \"Health literacy (HLVA)\")\n\nggMarginal(plot, type = \"histogram\", fill = \"lightgreen\", \n           xparams = list(binwidth=2), yparams = list(binwidth=1))\n\n\nggMarginal(plot, type = \"histogram\") enables us to show the distribution of scores on each variable\nThis helps our viewer to process the association and information about each variable [@franconeri2021]\n\n\n\n\n\n\n\n\nWe can choose a theme to adapt the look of the whole plot to suit our needs or the needs of our audience\n\n\n\n\n\n\n\n\n\nFigure 19: Different themes: (left) theme_dark(); (middle) theme_bw(); and (right) theme_classic()\n\n\n\n\n\n\n\n\nYou start your work with these questions:\n\nWhat are our goals?\nWhat does our audience need or expect?\n\nYou develop your visualization in a reflective process:\n\nBegin with a quick draft to show the distributions or make the comparisons you think about first\nThen reflect, and edit: does this enable me to discover sources of variability in my data?\nThen reflect, and edit: does this enable me to effectively communicate what I want to communicate?\nThen reflect, and edit: does this look good? – do my viewers tell me this works well?\n\n\n\n\n\n\n\nTip\n\n\n\nI can only show you the potential for creative and effective visualization\n\nexperiment and find what looks good and is useful to you\nseek out information – good places to start are:\n\nhttps://ggplot2.tidyverse.org/index.html\nhttps://r-graph-gallery.com"
  },
  {
    "objectID": "PSYC411/part2/visualization-intro.html#footnotes",
    "href": "PSYC411/part2/visualization-intro.html#footnotes",
    "title": "Introduction to visualization",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe write the slides and this book in Quarto in R-Studio. Quarto scripts can be rendered as .html to share web-books like this one, or to share slides like those we use in presenting the lecture. One advantage of using Quarto is that we can share a plot and the code we used to generate the plot in the same page.↩︎"
  },
  {
    "objectID": "PSYC411/part2/report-preface.html",
    "href": "PSYC411/part2/report-preface.html",
    "title": "6.1. Thinking about the research report",
    "section": "",
    "text": "In the Department of Psychology at Lancaster University, in the MSc programme module PSYC401, we ask students to analyse a previously collected dataset and write a report about their findings. This is the research report assignment.\nWe are providing materials to support your work. Because you are here, in the book, I start by identifying the chapters, but see Section 1.2, below, for information on lectures.\n\n\n\n\n\n\nTip\n\n\n\nDifferent people prefer to take different approaches to course materials. We have designed the materials to allow you to take the approach you prefer.\n\nYou can begin by viewing the lecture recording then read some or all of the chapters. The lecture mostly focuses on an explanation of the context and motivations for the exercise — explaining why you will benefit — to help you understand what you should do.\nOr you can jump right in, and get reading here for an in-depth explanation on what we want you to do, why and how we want you to do it.\nIn class, we will be ready to talk about your questions and your ideas with you. Be sure to come to class ready to call on our help.\n\n\n\n\n\nWe have written a series of chapters to support your learning in depth. The chapters are oriented around our answers to three questions that students might ask themselves.\n\nWhy: what will you learn about, what is our motivation?\nWhat do we expect students to do?\nHow can the assignment be done?\n\nYou can read the chapters in whatever order you like.\nSome may wish to start with our information on what we expect students to do ?@sec-what and on how the work can be done ?@sec-how. It may then be useful to come back to our information on the context and the motivations for the exercise ?@sec-intro-why. Of course, you can also start with our explanation for the motivations.\n\n\n\nThe lecture material is presented in three short parts.\n\n\nClick on a link and your browser should open a tab showing the Panopto video for the lecture part. You should be able to access the videos anywhere; you should not need to be on campus or logged on to the university VPN to view the videos.\nPart 1 of 3; about 15 minutes\nPart 2 of 3; about 20 minutes\nPart 3 of 3; about 20 minutes\n\n\n\nYou can download the lecture slides in two different forms.\n\nYou can download the slides as a .html file: 401-research-report.html. This can be opened in a browser and presents the slides as they are delivered.\nYou can download the slides as a Word .docx file: 401-research-report-printable.docx. This can be opened in Microsoft Word. You can edit the file to write your own notes. And you can print the document.\n\nThere will be some slight variation in how the images appear in the .html and .docx versions. This is because I wrote the slides in {Quarto}, in R-Studio, and {Quarto} is designed to render natively to .html (so that images look nice in a browser).",
    "crumbs": [
      "Home",
      "PSYC411",
      "6.1. Thinking about the research report"
    ]
  },
  {
    "objectID": "PSYC411/part2/report-preface.html#sec-report-intro-chapters",
    "href": "PSYC411/part2/report-preface.html#sec-report-intro-chapters",
    "title": "6.1. Thinking about the research report",
    "section": "",
    "text": "We have written a series of chapters to support your learning in depth. The chapters are oriented around our answers to three questions that students might ask themselves.\n\nWhy: what will you learn about, what is our motivation?\nWhat do we expect students to do?\nHow can the assignment be done?\n\nYou can read the chapters in whatever order you like.\nSome may wish to start with our information on what we expect students to do ?@sec-what and on how the work can be done ?@sec-how. It may then be useful to come back to our information on the context and the motivations for the exercise ?@sec-intro-why. Of course, you can also start with our explanation for the motivations.",
    "crumbs": [
      "Home",
      "PSYC411",
      "6.1. Thinking about the research report"
    ]
  },
  {
    "objectID": "PSYC411/part2/report-preface.html#sec-report-intro-lecture",
    "href": "PSYC411/part2/report-preface.html#sec-report-intro-lecture",
    "title": "6.1. Thinking about the research report",
    "section": "",
    "text": "The lecture material is presented in three short parts.\n\n\nClick on a link and your browser should open a tab showing the Panopto video for the lecture part. You should be able to access the videos anywhere; you should not need to be on campus or logged on to the university VPN to view the videos.\nPart 1 of 3; about 15 minutes\nPart 2 of 3; about 20 minutes\nPart 3 of 3; about 20 minutes\n\n\n\nYou can download the lecture slides in two different forms.\n\nYou can download the slides as a .html file: 401-research-report.html. This can be opened in a browser and presents the slides as they are delivered.\nYou can download the slides as a Word .docx file: 401-research-report-printable.docx. This can be opened in Microsoft Word. You can edit the file to write your own notes. And you can print the document.\n\nThere will be some slight variation in how the images appear in the .html and .docx versions. This is because I wrote the slides in {Quarto}, in R-Studio, and {Quarto} is designed to render natively to .html (so that images look nice in a browser).",
    "crumbs": [
      "Home",
      "PSYC411",
      "6.1. Thinking about the research report"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html",
    "href": "PSYC411/part1/Week2.html",
    "title": "2. Manipulating data",
    "section": "",
    "text": "This week, there are three mini lectures, and then a practical workbook to get you going with R-studio. Before the practical on Tuesday, please try to work through the practical workbook in your group.\nBring your questions (and/or answers) to the practical.",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-zero-making-and-opening-an-r-script-file",
    "href": "PSYC411/part1/Week2.html#task-zero-making-and-opening-an-r-script-file",
    "title": "2. Manipulating data",
    "section": "Task Zero: making and opening an R script file",
    "text": "Task Zero: making and opening an R script file\n\nOpen up the R server at psy-rstudio.lancaster.ac.uk\nIn R studio, at the File menu, select New File, then R script. Now, we can put in our favourite sum to check it’s working. At the top of the R script window type 10.5 + 7. With the cursor on the same line as the sum click on the Run button (or press Ctrl+Enter on Windows, Cmd+Enter on Mac). In the console, you should see the sum being run, and the answer produced.\nSave the R source. Click on the Save icon, call the R script “psyc401_week2.r”. The .r subscript indicates to R studio that this is an R script file.\nClose the R script, by clicking on the little x next to the R script filename just above the R script window.\nNow open it again. In the R studio window File menu, select Open File, and browse to where you saved your R script file and open it.\nTo make it easier to save and open files we can set what is called the “working directory” for R studio. Click “Session” in the menu at the top of the R studio screen, select “Working directory”, then select “Choose directory”. Browse to the Folder where you are going to save your PSYC401 R studio files (for me this is Documents/PSYC401), and click Open. Over on the right lower panel, you should now see all the files that are in this Folder - including psyc401_week2.r",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-one-open-and-check-practical-week1-workbook-answers-script-file",
    "href": "PSYC411/part1/Week2.html#task-one-open-and-check-practical-week1-workbook-answers-script-file",
    "title": "2. Manipulating data",
    "section": "Task One: open and check Practical week1 workbook answers script file",
    "text": "Task One: open and check Practical week1 workbook answers script file\n\nDownload the answers file by right-clicking the link and saving it. psyc401_week1_workbook_answers.r\nOpen psyc401_week1_workbook_answers.r in R studio (File &gt; Open File). You can now look through this document, check your commands and answers to the tasks from last week.\nClose the file psyc401_week1_workbook_answers.r",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-two-opening-a-data-file",
    "href": "PSYC411/part1/Week2.html#task-two-opening-a-data-file",
    "title": "2. Manipulating data",
    "section": "Task Two: Opening a data file",
    "text": "Task Two: Opening a data file\n\nReopen your script file psyc401_week2.r in R studio.\nIt’s always a good idea to refresh and clear out R studio when you start a new session, so add this line to the beginning of your R studio file, rm(list=ls())\nNow we are going to open a new data file. Download the file “PSYC401-shipley-scores-anonymous-17_18.csv” from moodle PSYC401 site, from the Practical Week2 folder. Note: DO NOT OPEN THIS FILE IN EXCEL – IF YOU DO, DELETE IT THEN DOWNLOAD IT AGAIN. Each row is one person’s data, and each column is a measure taken from the person. Columns are separated by commas, which is what the “csv” refers to” comma-separated values.\nIn R studio, we open csv files using a function called read_csv() which comes from a set of functions called “tidyverse”, we can install these functions by putting library(tidyverse) at the very top of our R file. Type this command in the script file and then run it:\n\n\n\n\n\n\n\nWant to know more about library()?\n\n\n\n\n\nR comes with certain functions pre-installed, such as mean(), but part of the charm of R is that we can install different functions that give us the opportunity to do almost anything! Collections of functions are called packages, and collections of packages are called libraries, but for the purpose of practicality, we typically refer to them interchangably. We install libraries using library() and enter the name of the library in the brackets.\n\n\n\n\nlibrary(tidyverse)\n\ndat &lt;- read_csv(\"PSYC401-shipley-scores-anonymous-17_18.csv\")\n\nRemember the dat &lt;- notation, which means we put the data into an object called “dat”\n\nIf all went well, we can then look at the data, using the function View: In the script file type View(dat) and run it. It should open a spreadsheet where we can see the data.\nNext, we just focus on two variables from the data: subject_ID which is the participants’ anonymised number, and Gent_1_score, which is the participants’ score on the Gent vocabulary test, the first time they had a go (that’s what the 1 stands for). We do this using the command select. The command select is in the library “tidyverse”. In the script file type and run:\n\n\nsummarydat &lt;- select(.data = dat, subject_ID, Gent_1_score)\n\n\nFinally, let’s just have a quick look at these data. In the script file type hist(summarydat$Gent_1_score) and run it.\nThis will draw a histogram of the Gent vocabulary scores. summarydat$Gent_1_score means that we look at the Gent_1_score values from the summarydat data – the $ indicates that this is one of the measures from the data. What kind of pattern does the histogram show?",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-four-examining-and-manipulating-data",
    "href": "PSYC411/part1/Week2.html#task-four-examining-and-manipulating-data",
    "title": "2. Manipulating data",
    "section": "Task Four: Examining and manipulating data",
    "text": "Task Four: Examining and manipulating data\n\nLet’s have a look at the data now. Type View(dat) in the source and Run it in the console, and you should see the data appear above the console window. Have a good long hard look at it.\nThe data shows id which is the participant number, occasion which is whether this is the first (0), second (1), up to sixth (5) time they filled in the questionnaires, intervention is which intervention they took part in with respect to attempting to promote their mood, ahi01-ahi24 are the 24 items on the AHI happiness scale, cesd01-cesd20 are the 20 items on the CESD depression scale. Way over on the right are the total scores on the AHI and the CESD questionnaires.\nNow, view the pinfo data. How can you look at it?\nLooking at the data replaced the source window, but the source is still there. Just above the View panel you should see a tab named “psyc401_week2.r”, click on that to get your source panel back. It will have a star/asterisk after the file name if it is unsaved. Remember it’s a good idea to regularly save your source file so you don’t lose work.\nNow, we are going to join together the two files. Type this:\n\n\nall_dat &lt;- inner_join(x = dat, y = pinfo, by = c('id', 'intervention'))\n\n\nQuestion: what does the c(“id”, “intervention”) bit mean?\n\n::: {.callout-warning icon=false collapse=“true”} ## Answer this means we match by two variables – id and intervention. We use the c() notation to indicate that this is a list of things.\nWe’ve now made a new data set called “all_dat”. The “x = dat” bit is the name of the first datafile we want to join, the “y = pinfo” is the name of the second datafile we want to join, the “by = ‘id’, ‘intervention’” bit is the names of variables that the two datasets have in common. :::\n\nHow would you join two data sets one called “datamad” the other called “datasane” together if they both have the variable “participantname” in common?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ndata_full &lt;- inner_join(x = datamad, y = datasane, by = c(\"participantname\"))\n\n\n\n\n\nNow we just want to keep a few of the variables – we’re not interested in the individual questionnaire items. So, let’s select the variables we want to keep:\n\n\nsummarydata &lt;- select(.data = all_dat, ahiTotal, cesdTotal, sex, age, educ, income, occasion, intervention)\n\nWhere “all_dat” is the name of the object to take data from, and “ahiTotal, cesdTotal, sex, age, educ, income, occasion, intervention” are all the variables we want to keep.\n\nHave a look at the summarydata in the View. How do you do that?",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-five-investigate-data",
    "href": "PSYC411/part1/Week2.html#task-five-investigate-data",
    "title": "2. Manipulating data",
    "section": "Task Five: Investigate data",
    "text": "Task Five: Investigate data\n\nThe next task is to have a closer look at the distributions of the data. Let’s focus on the age of participants. To investigate one column of data from a dataset, you have to refer to it using the “$” symbol. So, to investigate the “age” column from the “summarydata” dataset, you would look at summarydata$age. Draw a histogram (bar graph) of the distribution of age in the participant sample.\nNow, let’s look at how the AHI and the CESD scores relate. To gain an impression of how two variables relate we can draw a scatter graph. In the console, type plot(summarydata$ahiTotal, summarydata$cesdTotal), press Return. What does the “$” do in this command? What relationship do you find between these two variables?\nNow make sure you save psyc401_week2.r that contains all these commands that you ran. Close Rstudio, and Open Rstudio and make sure its saved all your work. The list of commands is extremely useful for making science open and accessible to other researchers. It’s more and more common for psychology articles to make the R source files available so other researchers can reproduce the data manipulations and analyses used in the paper precisely.",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-six-wide-to-long-format-conversion",
    "href": "PSYC411/part1/Week2.html#task-six-wide-to-long-format-conversion",
    "title": "2. Manipulating data",
    "section": "Task Six: Wide to long format conversion",
    "text": "Task Six: Wide to long format conversion\n\nLet’s go back to the psyc401-shipley-scores-anonymous-17_18.csv data. This should still be in the object called “dat”. If it’s not, then load the data again into dat, using the read_csv() function.\nMake sure the library(tidyverse) is loaded, if not, run the command library(tidyverse).\nThe aim here is to convert the data so that each Gent vocabulary score is on a separate line, we use the pivot_longer function for this. First we specify what the new object should be (datlong), then we say where the old data is (dat), then we make a new variable to keep the names of the tests (names_to = “test”), then we make a new variable to keep the scores from the tests (values_to = “vocab”), then we specify the list of old variables to combine into the new scores variable (c(“Gent_1_score”, “Gent_2_score”) ) – remember lists are written as c(). So, run this command:\n\n\ndatlong &lt;- pivot_longer(dat, names_to = \"test\", values_to = \"vocab\", cols = c(\"Gent_1_score\", \"Gent_2_score\")) \n\n\nHave a look at the new object datlong that results: View(datlong). This function pivot_longer has taken as input the data in dat, it has created a new variable called “test” which reports whether it is the Gent_1_score or the Gent_2_score that is the measurement, and a new variable called “vocab” where the actual scores are listed. Then, the following list of variables let’s the function pivot_longer know which variables from the object dat we are converting (or lengthening). It also includes all the other variables, but unconverted. How many rows of data are there now corresponding to data from subject_ID number 1?\nLet’s tidy things up so we only have subject_ID, and the Gent vocabulary scores by using select:\n\n\ndatlongsummary &lt;- select(datlong, subject_ID, test, vocab)",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#task-seven-long-to-wide-format-conversion",
    "href": "PSYC411/part1/Week2.html#task-seven-long-to-wide-format-conversion",
    "title": "2. Manipulating data",
    "section": "Task Seven: Long to wide format conversion",
    "text": "Task Seven: Long to wide format conversion\n\nNow, we will have a go at converting from long to wide format. Let’s start with the datlongsummary object. We will convert this so that Gent_1_score and Gent_2_score are listed alongside each other – one row per person. The command for this is the reverse of pivot_longer, called pivot_wider. Run this command: datwide &lt;- pivot_wider(datlongsummary, names_from = \"test\", values_from = \"vocab\"). This command takes the data from datlongsummary and puts the different measures reported in the variable test into different columns again, filling in the values from the variable vocab.",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html",
    "href": "PSYC411/part1/Week4.html",
    "title": "4. Testing nominal data",
    "section": "",
    "text": "Watch Lecture week 4 part 1, slides here\nPart 2, slides here.\nPart 3, slides here.\nTake the quiz (not assessed) on the lecture materials.\nSee the guides to reporting numbers and statistical tests in American Psychological Association format (the format that we use in Psychology for all reports).\nWork through the materials for the Practical week 4 below.\nCome to the practical.\nPop into the drop in (optional).\nComplete Assignment 2 by Friday 4th November 8pm (this requires the two Assignment 2 data files as well).\nWatch the clip of the Titanic film if you like (not assessed!).\nRead what is a p-value\n\nThe materials in this workbook share some material with Glasgow University Psychology Department Teaching in R website",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-1-your-data-from-the-paper-in-psychological-science",
    "href": "PSYC411/part1/Week4.html#task-1-your-data-from-the-paper-in-psychological-science",
    "title": "4. Testing nominal data",
    "section": "Task 1: Your data from the paper in Psychological Science",
    "text": "Task 1: Your data from the paper in Psychological Science\n\nYour take-home task was to produce some graphs of the data set downloaded from a paper in Psychological Science. Show your graphs and R script to the rest of your group.",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-2-load-in-the-data",
    "href": "PSYC411/part1/Week4.html#task-2-load-in-the-data",
    "title": "4. Testing nominal data",
    "section": "Task 2: Load in the Data",
    "text": "Task 2: Load in the Data\n\nRemember to clear out R first:\n\n\nrm(list=ls())\n\nThe data set on the Shipley and Gent vocabulary scores is now updated with the data from your group, so it now contains five years of PSYC401 students’ data. I’ve omitted Age as this might impact anonymity of the data. Download the data from the week 4 moodle folder: “PSYC401-shipley-scores-anonymous-17_22.csv” and read the data into an object in R studio called vdat (for vocabulary data).\n\nAs a reminder, when we want to look at a particular variable (a column) in an object in R studio, we refer to it using the $ notation. So, for the object vdat and the variable academic_year you would refer to it as vdat$academic_year. For this data set, we need to change academic year to be a nominal (factor) variable. Why does academic year have to be nominal and not interval/ratio?:\n\n\nvdat$academic_year &lt;- as.factor(vdat$academic_year)\n\nview(vdat) #view the data\n\n\nMake sure the tidyverse library is loaded. Select all the variables apart from Dyslexia_diagnosis and Age and save as a new object called “summaryvdat”. We will omit these variables because they are not complete for the dataset.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nlibrary(tidyverse)\n\nsummaryvdat &lt;- select(vdat, -c(Dyslexia_diagnosis, Age))\n\n-c(Dyslexia_diagnosis, Age) is a quicker way to “unselect” variables. The negative sign means select all columns except for these listed in c(). The alternative is to type every column you want to keep.\n\n\n\n\nArrange the data according to Gent_2_score, from highest to lowest. Save this as a new object called “summaryvdat_sort”",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-3-draw-graphs-of-the-vocabulary-data",
    "href": "PSYC411/part1/Week4.html#task-3-draw-graphs-of-the-vocabulary-data",
    "title": "4. Testing nominal data",
    "section": "Task 3: Draw Graphs of the Vocabulary Data",
    "text": "Task 3: Draw Graphs of the Vocabulary Data\n\nDraw graphs of the following relations:\n\n\nEnglish status and academic year\nGender and academic year\nVocabulary score and academic year\n\n\nSave your script file.",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-4-loading-and-joining-data-in-r-studio",
    "href": "PSYC411/part1/Week4.html#task-4-loading-and-joining-data-in-r-studio",
    "title": "4. Testing nominal data",
    "section": "Task 4: Loading and joining data in R studio",
    "text": "Task 4: Loading and joining data in R studio\n\nNow, let’s clear out R-studio before we get started again using rm(list=ls()).\nGo to the data files from week 2 and load them into Rstudio again (“ahicesd.csv”, and “participantinfo.csv”). You can redownload them here.\n\n\nRemember these data come from this study: Woodworth, R.J., O’Brien-Malone, A., Diamond, M.R. and Schuz, B. (2018). Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness”. Journal of Open Psychology Data, 6(1).\nRemind yourself of the aim of the study and the variables that are in the data set (see end of this script file for repeat description on the study).\n\n\nNext, load and join the ahicesd.csv and participantinfo.csv data in R studio. Call the joined data set “all_dat” (see week 2 workbook for reminders about this)",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-5-selecting-and-manipulating-data",
    "href": "PSYC411/part1/Week4.html#task-5-selecting-and-manipulating-data",
    "title": "4. Testing nominal data",
    "section": "Task 5: Selecting and manipulating data",
    "text": "Task 5: Selecting and manipulating data\n\nWe’re not interested in the individual questionnaire items. So, let’s select all the variables we want to keep (omitting the individual questionnaire items), and save this to an object called summary_all_dat (again see week 2 workbook for reminder)\nNext, we will add another variable to the data. We use the function mutate() for this. Let’s scale the ahiTotal and cesdTotal values and add them to the summary_all_dat set.\n\n\nsummary_all_dat_scale &lt;- mutate(.data = summary_all_dat, ahiTotalscale = scale(ahiTotal), cesdTotalscale = scale(cesdTotal))\n\n\nWhat are the minimum and maximum values of the new variable ahiTotalscale?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nhint: use the arrange() function, or the min() and max() functions.\n\n\n\n\nWhat do these scale values mean? (reminder: they are Z scores).\n\n\nThe next way we will work with the data is to organise the observations into different groups. First of all, here is the function summarise(). This works by summarising the results of a data set according to a particular measure. So, instead of mean(summary_all_dat_scale$ahiTotal) you can use this, which turns out to be a much more powerful way of looking at the data:\n\n\nsummarise(.data = summary_all_dat_scale, mean(ahiTotal))\n\n\nThey should give the same results - check that they do. This function summarise() is more powerful because you can look at several values at the same time, e.g.:\n\n\nsummarise(.data = summary_all_dat_scale, mean(ahiTotal), sd(ahiTotal), mean(cesdTotal), sd(cesdTotal))\n\n\nWhat is the result of this command?\n\n\nBut now let’s think about what kind of patterns we’d like to investigate in the data. There are four interventions conducted in this study. Let’s look at each of these interventions and their effect of ahiTotal and cesdTotal. We can look at subgroups of data either by using the filter() function, or by using the function group_by(). The advantage of group_by() is that we can look at several groups at the same time, rather than dividing up the data file into pieces. Let’s organise by the different interventions.\n\n\nsummary_all_dat_scale_intervention &lt;- group_by(.data = summary_all_dat_scale, intervention)\n\n\nThis command takes the data summary_all_dat_scale, and then groups it according to the four interventions in the data. We can’t yet see any difference in summary_all_dat_scale_intervention but it’s in there, lurking, just waiting. Now, we can look at the means for each intervention using the summary function again. Run the summary function on summarydata_scale_intervention. What happens?\n\n\nYou can also group by several factors at the same time. We can group by intervention and get means and standard deviations, but that is not going to give us a huge amount of insight into how the interventions affect the happiness measure because we are combining the mean of ahiTotal across all occasions of testing, including testing before the intervention has been applied.\n\nSo, let’s group by intervention and occasion of testing:\n\nsummary_all_dat_intocc &lt;- group_by(.data = summary_all_dat_scale, intervention, occasion)\n\n\nNow produce the means and standard deviations of the happiness score (ahiTotal) for each intervention at each testing occasion.\n\n\nThis doesn’t print all the lines out, so you can make a new object (e.g., called sum_output) and view that, or you can filter out some of the lines so we only look at the first and second occasion of testing.\n\n\nsum_output &lt;- summarise(.data = summary_all_dat_intocc, mean(ahiTotal), sd(ahiTotal))\nView(sum_output)",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-6-graph-some-groups",
    "href": "PSYC411/part1/Week4.html#task-6-graph-some-groups",
    "title": "4. Testing nominal data",
    "section": "Task 6: Graph some groups",
    "text": "Task 6: Graph some groups\n\nDraw a scatter plot of ahiTotal and cesdTotal values for the whole data set.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the ggplot() function with geom_point()\n\n\n\n\nMake it a bit more beautiful using the labs() addition.\n\n\nNow redraw the plot, but colour the points according to whether they are first, second, third, etc occasion of testing. Add in col = \"occasion\" into the aes() part of the geom_point function, so that this part looks like this: aes(x = ahiTotal, y = cesdTotal, col = occasion)",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-7-chi-squared-and-cramers-v",
    "href": "PSYC411/part1/Week4.html#task-7-chi-squared-and-cramers-v",
    "title": "4. Testing nominal data",
    "section": "Task 7: Chi-squared and Cramer’s V",
    "text": "Task 7: Chi-squared and Cramer’s V\n\nLet’s now have a look at running Chi-squared and Cramer’s V tests in R. download this week’s data from here. Read titanic.csv into an object called “titanic”. View the data. It should correspond to the data in the overhead slides.\nMake a bar graph to count the numbers of survived and died by class.\nNow let’s see if there is a significant relation between class and survival using Chi-squared:\n\n\nchisq.test(x = titanic$class, y = titanic$survival)\n\n\nThe results give the chi-squared value, the number of degrees of freedom, and the p-value. P = 2.2e-16 means p = .0000000000000022. That’s highly significant. That means the observations are divided across the categories in a way that is very unlikely to be due to chance (for this number (P = 2.2e-16), it means there’s a 2 in a quadrillion chance that titanic survival was not related to class). In a report, you would write: Chi-squared(2, N= 1309) = 127.86, p &lt; .001.\n\n\nNow, let’s compute Cramer’s V. First, we need to make sure we have the package lsr.\n\n\nlibrary(lsr)\n\n\nThen run the test:\n\n\ncramersV(x = titanic$class, y = titanic$survival)\n\n\nYour next task is to run some Chi-squared and Cramer’s V tests on some of the other nominal data. Open the data “PSYC401-shipley-scores-anonymous-17_22.csv” again. Investigate the association between gender and year (are there different distributions of males and females in each of our masters’ year cohorts) using Chi-squared and Cramer’s V. Is it significant?\nWhat about the association between english_status and Gender?\nWhat about the association between english_status and academic year?",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week4.html#task-8-more-chi-squared-and-cramers-v-tests",
    "href": "PSYC411/part1/Week4.html#task-8-more-chi-squared-and-cramers-v-tests",
    "title": "4. Testing nominal data",
    "section": "Task 8: More Chi-squared and Cramer’s V tests",
    "text": "Task 8: More Chi-squared and Cramer’s V tests\n\nLook at the “ahicesd.csv” and “participantinfo.csv” data sets from week 2 again. Which nominal measures could you look at an association between? Report the Chi-squared test and Cramer’s V results for these associations. Are these associations significant? How do you interpret the significant associations?\nHave a further browse of Psychological Science for data sets that you can download and begin to explore. Practise applying the data manipulation and graphing functions to these data sets.\n\nDescription of Woodworth, R.J., O’Brien-Malone, A., Diamond, M.R. and Schuz, B. (2018). Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness”. Journal of Open Psychology Data, 6(1).\n\nIn our study we attempted a partial replication of the study of Seligman, Steen, Park, and Peterson (2005) which had suggested that the web-based delivery of positive psychology exercises could, as the consequence of containing specific, powerful therapeutic ingredients, effect greater increases in happiness and greater reductions in depression than could a placebo control. Participants (n=295) were randomly allocated to one of four intervention groups referred to, in accordance with the terminology in Seligman et al. (2005) as 1: Using Signature Strengths; 2: Three Good Things; 3: Gratitude Visit; 4: Early Memories (placebo control). At the commencement of the study, participants provided basic demongraphic information (age, sex, education, income) in addition to completing a pretest on the Authentic Happiness Inventory (AHI) and the Center for Epidemiologic Studies-Depression (CES-D) scale. Participants were asked to complete intervention-related activities during the week following the pretest. Futher measurements were then made on the AHI and CESD immediately after the intervention period (‘posttest’) and then 1 month after the posttest (day 38), 3 months after the posttest (day 98), and 6 months after the posttest (day 189). Participants were not able to to complete a follow-up questionnaire prior to the time that it was due but might have completed at either at the time that it was due, or later. We recorded the date and time at which follow-up questionnaires were completed.",
    "crumbs": [
      "Home",
      "PSYC411",
      "4. Testing nominal data"
    ]
  },
  {
    "objectID": "PSYC411/index.html",
    "href": "PSYC411/index.html",
    "title": "Analysing and Interpreting Psychological Data I",
    "section": "",
    "text": "Welcome\nWelcome to this module PSYC411: Analysing and interpreting psychological data I!\nTo get started with the module:\n\nClick on PSYC411 at the top left of this window to access the menu.\nThen go to Week 0. Welcome to this module! to get going with preparations.\n\nIf you have any issues with finding or following the links, please get in touch with us.\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nPadraic Monaghan\np.monaghan at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC411/part1/Week0.html",
    "href": "PSYC411/part1/Week0.html",
    "title": "Week 0. Welcome to this module!",
    "section": "",
    "text": "Welcome\nWelcome to this module PSYC411! Very glad to have you here!!\nRob Davies  and Padraic Monaghan  are the lecturers on this module.\nWe are looking forward to meeting you!\nThis module is designed for students who have never done data analysis or statistics before, as well as those who have background in this.\nWe have set up the module so that there are different exercises depending on your background.\n\nFor those who are new to data analysis and statistics, there is a week-by-week step-by-step guide to all you need to know to become a masters-level expert in interpreting and analysing psychological data.\nFor those of you who have already used our software (R-studio) for analysis before, after revising the foundations of what you need to know you can move on quickly to the extra explorative exercises where you can hone and broaden your skills.\n\n\n\nSteps to get ready\nHere are the steps to go through before the module begins, to help you prepare for the course:\nFirst: Watch this first video which is a chat between Rob Davies and Padraic Monaghan giving you a bit of an insight into what we’d like you to take from this module and what our philosophy is for teaching.\n\nSecond: Watch this welcome video (part 1) to give you an outline of how this module works:\n\nThird: Then watch this welcome video (part 2) on how to access the software for this module. Basically, what you need to do is in a web browser go to: http://psy-rstudio.lancaster.ac.uk and login with your university account name, and your university account password:\n\nNote that you can only access this website from on campus, or via the University’s VPN. For information on connecting to the VPN, see here: ISS help for VPN\n\n\nNext steps\nNext step is to go to the Week 1 materials, once they are released. We aim to release materials for the following week by Thursday of the previous week. You can navigate to the relevant week via the top left corner of the webpage.\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nPadraic Monaghan\np.monaghan@lancaster.ac.uk\n\n\nRob Davies\nr.davies@lancaster.ac.uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "PSYC411",
      "Week 0. Welcome to this module!"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#overview",
    "href": "PSYC411/part1/Week1.html#overview",
    "title": "Statistics for Psychologists",
    "section": "",
    "text": "This week, there are three mini lectures, and then a practical workbook to get you going with R-studio.\nBefore the practical on Tuesday, please try to work through the practical workbook (in the first practical we will form groups of people to work together on the workbooks, for now you can work on the practical workbook individually or with anyone else on the course you are in touch with!).\nBring your questions (and/or answers) to the practical.",
    "crumbs": [
      "Home",
      "PSYC411",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#learning-goals",
    "href": "PSYC411/part1/Week1.html#learning-goals",
    "title": "Statistics for Psychologists",
    "section": "1.2 Learning Goals",
    "text": "1.2 Learning Goals\nBy the end of Week 1, you should be able to:\n\nUnderstand the importance of data analysis and statistics\nIdentify types of data in psychology (nominal, ordinal, interval, ratio)\nUnderstand means and standard deviations\nUnderstand standardized scores (Z-scores)\nUse R-studio to begin to manipulate data, investigate means and standard deviations, and convert scores into Z-scores",
    "crumbs": [
      "Home",
      "PSYC411",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#lectures",
    "href": "PSYC411/part1/Week1.html#lectures",
    "title": "Statistics for Psychologists",
    "section": "1.3 Lectures",
    "text": "1.3 Lectures\nWatch Lecture week1 part1.\nWatch Lecture week1 part2, stop halfway through and do the Lecture week1 part2 quiz (not assessed), by clicking here\nThen come back and watch the end of Lecture week 1 part2.\n\nWatch Lecture week1 part3.\n\nTake the quiz on the lecture material (not assessed), by clicking here\nDownload the lecture slides for part 1 here and part 2 here",
    "crumbs": [
      "Home",
      "PSYC411",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#practical-materials",
    "href": "PSYC411/part1/Week1.html#practical-materials",
    "title": "Statistics for Psychologists",
    "section": "1.4 Practical Materials",
    "text": "1.4 Practical Materials\n\n1.4.1 Workbook\nIn your group (or on your own until you’ve formed a group), work through this workbook, note any problems and questions you have, and come prepared to the online practical class to go through the tasks and ask your questions.\nIf you’ve done statistics using R-studio before then Parts 1 and 2 will be just revision for you. In which case, Part 3 is where you can focus your work.\nPart 1 of this workbook reproduces what you saw in the week 1 part 3 lecture.\nPart 2 gives you some more exercises in using R studio for finding means, standard deviations, z scores, and drawing histograms.\nPart 3 provides some more extended tasks you can do to practise exploring what R -studio can do and develop your skills further. If you are new to R-studio then parts 1 and 2 cover what you need to know, and Part 3 contains some more extending, optional exercises.\n\n1.4.1.1 Part One: repeat the steps from lecture 1 part 3\n\nTask One: Open Rstudio\n\nStartup Rstudio\n\nTo log in to the R server, first make sure that you have the VPN switched on, or you will need to be connected to the university network (Eduroam). To set up the VPN, follow ISS instructions here or connecting to Eduroam here.\nWhen you are connected, navigate to https://psy-rstudio.lancaster.ac.uk, where you will be shown a login screen that looks like the below. Click the option that says “Sign in with SAML”.\n \nThis will take you through to the University login screen, where you should enter your username (e.g. ivorym) and then your university password. This will then redirect you to the R server where you can start using RStudio!\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have already logged in through the university login already, perhaps to get to the portal, then you may not see the username/password screen. When you click login, you will be redirected straight to RStudio. This is because the server shares the login information securely across the university.\n\n\n\nWhat does RStudio look like?\nWhen RStudio starts, it will look something like this: \nRStudio has three panels or windows: there are tabs for Console (taking up the left hand side), Environment (and History top right), Current file (bottom right). You will also see a 4th window for a script or set of commands you develop, also (on the left hand side).\n\n\n\nTask Two: using the console\n\n\n\n\n\n\nTip\n\n\n\nText that is highlighted with a grey background denotes code, rather than typical prose. Code is different to other forms of writing, such as essays, because the syntax, order and words need to be quite specific. For some longer chunks of code, as you will see below, they are formatted slightly differently.\n\n\n\nIn the “console” part of the R window, next to the &gt;, type 10 + 30. Press return.\n\n\n10 + 30                        \n\n\n\n\n\n\n\nTip\n\n\n\nIf you hover your mouse over the box that includes the code snippet, a ‘copy to clipboard’ icon will appear in the top right corner of the box. Click that to copy the code. Now you can easily paste it into your script.\n\n\nIt should give you the answer 40.\n\nIn the console, type a &lt;- 40 and press Return.\n\n\na &lt;- 40                      \n\n\nNow type a and press return. It should give you the answer 40. a is called an object, think of it like a bucket that you can keep a number, or some numbers, or actually all kinds of stuff in.\nNow let’s look at a function, sqrt. sqrt is a function that takes the square root of whatever is inside the brackets. In the console, type sqrt(13). Press Return.\nNow find the square root of the object a by typing sqrt(a). Press return.\n\n\n\n\nTask Three: finding distributions\n\nMake a new object b, and put the following list of children’s attachment scores into it\n\n\nb &lt;- c( 4, 1, 5, 3, 8, 2, 2, 6, 8, 5, 4, 1, 6, 5, 4, 5, 7, 9, 10, 1, 1, 3, 5, 4, 6, 4, 8, 6, 5, 5, 7, 8, 9, 8, 8, 2, 1, 4, 3, 2, 5, 1, 5, 6, 8, 6, 7, 2, 7)\n\n\nCheck it works by typing b, press return.\nFind the mean of these numbers by typing mean(b).\nFind the median of these numbers by typing median(b).\nFind the standard deviation of these numbers by typing sd(b).\nDraw a histogram of these numbers by typing hist(b).\n\n\n\n\nTask Four: z scores\n\nMake a new object b_z and assign to it the z scores of the values from b:\n\n\nb_z &lt;- scale(b)\n\n\nCheck that it worked by typing b_z.\nDraw a histogram of b_z by typing hist(b_z).\n\n\n\n\n1.4.1.2 Part Two: extra practice\n\nTask Five: investigating distributions\n\nLet’s make three new objects, with the marks from three people’s university masters courses. They are called annie, saj, and carrie and they took 10 courses each. We use the special notation c() to indicate a list, each number in the list is separated by a comma. Type the following into the console:\n\n\nannie &lt;- c(55, 95, 85, 65, 65, 85, 65, 95, 65, 75)\nsaj &lt;- c(65, 85, 95, 75, 65, 55, 55, 75, 95, 85)\ncarrie &lt;- c(75, 65, 95, 95, 55, 85, 75, 55, 95, 55)\n\n\nWho has the highest average (mean) score for their course?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nuse the mean() function\n\n\n\n\n\nWho has the most variable scores for their course?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nuse the sd() function\n\n\n\n\n\nWhat is the median score for each student?. What does this mean about the distribution of each students’ scores? Use the function hist() to draw the distributions to help you see.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nyou can use the summary() function, or the median() function\n\n\n\n\n\n\nTask Six: standardised scores: Z scores\n\nMake a new object called annie_z and use the function scale to convert annie’s scores to z-scores: in the console type:\n\n\nannie_z &lt;- scale(annie)\n\n\nYou can have a look at the standardised scores of annie, by just typing annie_z. To what did annie’s highest initial score of 95 convert to?\n\n\n\nWhat is the mean and standard deviation of annie_z’s standardised scores?\n\n\n\nDraw a histogram of annie’s standardised scores, in the console type hist(annie_z). What is the peak frequency value?\n\n\n\nBonus extra: If you want to find out the proportion of scores lower than a particular score you can do it like this in R-studio: pnorm(x) where x is the z-score you’re interested in. What is the proportion of scores lower than annie’s highest grade score?\n\n\n\n\n\n1.4.1.3 Part Three: Extras\nIf you’ve whizzed through the previous tasks, then you can move on to the following activities to explore further the functionality of R studio.\n\nTask Seven: Exploring operators.\nSo far, we’ve just looked at + as an operator. Go to this page: https://www.statmethods.net/management/operators.html\n\nIn the console, assign the object d to be 100 multiplied by 246.\nIn the console, assign the object e to be 84 divided by 32.1.\nAssign the variable f to 8 to the power of 4 (in R this is called exponentiation).\nWhat is the result of d added to e all divided by f\n\n\n\n\nTask Eight: Exploring functions\nSo far, we’ve just looked at the square root function sqrt(). Go to this page: https://www.statmethods.net/management/functions.html\n\nWhat is the result of abs(-5.3)? What does the abs function do?\n\n\n\nUsing the seq() function, generate a sequence of numbers from 0 to 30 in intervals of 3.\nAssign the sequence generated in step 28 to a new object. Now compute the mean of the sequence of numbers. (remember that objects can be a single number, or a sequence of numbers (called an array or a vector) or anything you want to put into it – remember, think of objects as buckets).\n\n\n\n\n\n\n\nStuck? Here’s the solution\n\n\n\n\n\nTry out the following code, pay special attention to how the sentences above “convert” into R code.\n\nsequence &lt;- seq(0,30, 3)\nmean(sequence)\n\n\n\n\n\nAssign the sequence generated in 31 to a new object. Now compute the mean of the sequence of numbers. (remember that objects can be a single number, or a sequence of numbers (called an array or a vector) or anything you want to put into it – remember, think of objects as buckets).\n\n\n\n\nTask Nine: Exploring others’ data\nHave a look at this article: Scullin, M. K., Gao, C., & Fillmore, P. (2021). Bedtime music, involuntary musical imagery, and sleep. Psychological Science, 32(7), 985-997. https://journals.sagepub.com/doi/10.1177/0956797621989724\nAbstract Many people listen to music for hours every day, often near bedtime. We investigated whether music listening affects sleep, focusing on a rarely explored mechanism: involuntary musical imagery (earworms). In Study 1 (N = 199, mean age = 35.9 years), individuals who frequently listen to music reported persistent nighttime earworms, which were associated with worse sleep quality. In Study 2 (N = 50, mean age = 21.2 years), we randomly assigned each participant to listen to lyrical or instrumental-only versions of popular songs before bed in a laboratory, discovering that instrumental music increased the incidence of nighttime earworms and worsened polysomnography-measured sleep quality. In both studies, earworms were experienced during awakenings, suggesting that the sleeping brain continues to process musical melodies. Study 3 substantiated this possibility by showing a significant increase in frontal slow oscillation activity, a marker of sleep-dependent memory consolidation. Thus, some types of music can disrupt nighttime sleep by inducing long-lasting earworms that are perpetuated by spontaneous memory-reactivation processes.\nThe data from the study is available on this osf website. The data we will look at is from the first study, the data set called “Earworm_MTurk_OSF.sav” on the osf site. These data are saved in spss format, which is not great for R-studio. We can still read it in, though, using a function called spss.get()\n\nBrowse the paper to see what it is about. Focus on Study 1.\nFrom the osf website download the data file: Earworm_MTurk_OSF.sav, and also download the codebook file: Earworm_MTurk_Codebook.xlsx. The codebook tells you what each of the measures are in the data file.\nLoad the data into R-studio: in the bottom right panel of R-studio, click on Upload, and browse to the Earworm_MTurk_OSF.sav file. It should then appear in the list of files in that bottom right panel.\nThat step means we can access the data, but it isn’t yet loaded into R-studio.\n\nSo, next load the data file into R-studio so we can work on it. You might have noticed that the data file is in SPSS format (that’s what the .sav ending to the file means). But, we can still load that in to R-studio.\nTo do that first, load the library Hmisc: library(Hmisc)\n\nlibrary(Hmisc)\n\n\nThen, use the function spss.get():\n\n\ndat &lt;- spss.get(\"Earworm_MTurk_OSF.sav\")\n\n\nThat should have made you a new object in R-studio called “dat” which contains the data from the study.\nNext, we can have a look at the data. Here are a few questions to get you going:\n\n\nHow many male, how many female participants?\n\n\n\nHow many people never have earworms in the middle of the night?\n\n\n\nFor the Stanford Sleepiness Scale, how many participants felt “Somewhat foggy, let down”?\n\n\n\nWhat was the mean, SD and range of age of the participants? Does your calculation of mean age correspond to that given in the paper?\n\n\n\nCan you work out the mean age of the male and female participants separately?\n\n\n\nExplore the data, see if you can remember tasks for separating different subgroups, graphing relations, comparing groups.\n\n\n\n\n\n\n1.4.2 Data\n(There are no data that you need for today’s practical, other than the link to the data for the earworm study, but when there are data sets you need, you will find them in this data section.)\n\n\n1.4.3 Answers\nThe answers to the workbook will appear below each question in the workbook, above, after the practical has finished, so you can check your answers.\nIt’s really important for your learning that you have a go first of all at the workbook before looking at the answers.",
    "crumbs": [
      "Home",
      "PSYC411",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week1.html#extras",
    "href": "PSYC411/part1/Week1.html#extras",
    "title": "Statistics for Psychologists",
    "section": "1.5 Extras",
    "text": "1.5 Extras\nOptionally, watch the lecture by Tim Harford on the importance of understanding statistics. Note this video is hosted on facebook.",
    "crumbs": [
      "Home",
      "PSYC411",
      "Statistics for Psychologists"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#overview",
    "href": "PSYC411/part1/Week2.html#overview",
    "title": "2. Manipulating data",
    "section": "",
    "text": "This week, there are three mini lectures, and then a practical workbook to get you going with R-studio. Before the practical on Tuesday, please try to work through the practical workbook in your group.\nBring your questions (and/or answers) to the practical.",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#learning-goals",
    "href": "PSYC411/part1/Week2.html#learning-goals",
    "title": "2. Manipulating data",
    "section": "2.2 Learning Goals",
    "text": "2.2 Learning Goals\nBy the end of Week 2, you should be able to:\n\nUnderstand the importance of open data in psychology\nUnderstand different types of data and how best to represent them\nUnderstand bar graphs, scatter plots, and interpret patterns in these graphs\nOpen data sets in R-studio and manipulate those data\nUse R-studio to make simple graphs",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#lectures",
    "href": "PSYC411/part1/Week2.html#lectures",
    "title": "2. Manipulating data",
    "section": "2.3 Lectures",
    "text": "2.3 Lectures\nWatch Lecture week2 part1.\n\nWatch Lecture week2 part2\n\nWatch Lecture week2 part3\n\nTake the quiz on the lecture material (not assessed).\nDownload the lecture slides for part 1 here, part 2 here, and part 3 here.",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  },
  {
    "objectID": "PSYC411/part1/Week2.html#practical-materials",
    "href": "PSYC411/part1/Week2.html#practical-materials",
    "title": "2. Manipulating data",
    "section": "2.4 Practical Materials",
    "text": "2.4 Practical Materials\n\n2.4.1 Workbook\nIn your group (or on your own until you’ve formed a group), work through this workbook, note any problems and questions you have, and come prepared to the online practical class to go through the tasks and ask your questions.\nIf you’ve done statistics using R-studio before then Parts 1 and 2 will be again largely revision for you. In this case, Part 3 is where you can focus your work.\nPart 1 of this workbook reproduces what you saw in the week 2 part 3 lecture.\nPart 2 gives you some more exercises in using R studio for **.\nPart 3 provides some more extended tasks you can do to practise exploring what R -studio can do and develop your skills further. If you are new to R-studio then parts 1 and 2 cover the essentials of what you need to know, and Part 3 contains some more optional, extending material.\n\n2.4.1.1 Part One: repeat the steps from lecture 2 part 3\n******UP TO HERE********\n\nTask Zero: making and opening an R script file\n\nOpen up the R server at psy-rstudio.lancaster.ac.uk\nIn R studio, at the File menu, select New File, then R script. Now, we can put in our favourite sum to check it’s working. At the top of the R script window type 10.5 + 7. With the cursor on the same line as the sum click on the Run button (or press Ctrl+Enter on Windows, Cmd+Enter on Mac). In the console, you should see the sum being run, and the answer produced.\nSave the R source. Click on the Save icon, call the R script “psyc401_week2.r”. The .r subscript indicates to R studio that this is an R script file.\nClose the R script, by clicking on the little x next to the R script filename just above the R script window.\nNow open it again. In the R studio window File menu, select Open File, and browse to where you saved your R script file and open it.\nTo make it easier to save and open files we can set what is called the “working directory” for R studio. Click “Session” in the menu at the top of the R studio screen, select “Working directory”, then select “Choose directory”. Browse to the Folder where you are going to save your PSYC401 R studio files (for me this is Documents/PSYC401), and click Open. Over on the right lower panel, you should now see all the files that are in this Folder - including psyc401_week2.r",
    "crumbs": [
      "Home",
      "PSYC411",
      "2. Manipulating data"
    ]
  }
]