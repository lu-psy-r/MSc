---
title: Week 17. Workbook introduction to mixed-effects models
subtitle: Written by Rob Davies
order: 9
bibliography: references.bib
csl: psychological-bulletin.csl
---

# Week 17 Mixed-effects models workbook overview {#sec-mixed-effects-workbook-overview}

Welcome to your overview of the work we will do together in **Week 17**.

Many Psychologists conduct studies with **repeated-measures designs** where the experimenter presents a sample of multiple stimuli, for response, to each participant in a sample of multiple participants.
Studies with repeated-measures designs will produce data with a structure that requires the use of mixed-effects models.

We are going to learn about this kind of data, and build on the analysis methods we learned about in the [Conceptual introduction to multilevel data](../part2/01-multilevel.qmd#sec-intro-multilevel) and the [workbook introduction to multilevel data](../part2/01-multilevel-workbook.qmd#sec-multilevel-workbook-overview) . 

We use the same procedure we did for multilevel data but with **one significant change** which we shall explore and seek to understand in-depth.

## Targets {#sec-mixed-effects-workbook-targets}

Our learning objectives again include the development of both concepts and skills.

1.  **skills** -- practice how to tidy experimental data for mixed-effects analysis.
2.  **concepts** -- begin to develop an understanding of crossed random effects of participants and stimuli.
3.  **skills and concepts** -- practice fitting linear mixed-effects models incorporating random effects of participants and stimuli.

## Learning resources {#sec-mixed-effects-workbook-resources}

You will see, next, the lectures we share to explain the concepts you will learn about, and the practical data analysis skills you will develop. Then you will see information about the practical materials you can use to build and practise your skills.

Every week, you will learn best if you *first* watch the lectures *then* do the practical exercises.

::: callout-tip
### Linked resources

To help your learning, you can read about the ideas and the practical coding required for analyses in the chapters I wrote for this course.

- The [chapter: Introduction to linear mixed-effects models](../part2/02-mixed.qmd#sec-intro-mixed)
:::

### Lectures {#sec-mixed-effects-workbook-lectures}

The lecture materials for this week are presented in three short parts.

Click on a link and your browser should open a tab showing the *Panopto* video for the lecture part.

1. Part 1 (17 minutes) **Mixed-effects models**: Repeated measures data and the what, when and how of mixed-effects models.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=2fa60b12-2eca-4412-8672-acd60104da1d&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player" aria-description="02-mixed-1-of-3" ></iframe>
```

2. Part 2 (21 minutes): Working with an example from a study with a repeated measures design, recognizing how people or how stimuli vary, and identifying the motivation for using mixed-effects models, compared to alternative methods.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=7f31cef0-1e39-4712-b2a1-acd601195c78&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player" aria-description="02-mixed-2-of-3" ></iframe>
```

3. Part 3 (15 minutes): What mixed-effects models can do for us, how we can describe the logic, how we code mixed-effects models, what the bits of code do, what the results look like, what the results tell us, and how we should report our models and our findings.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=58ab0c0c-37be-491f-a9e5-acd6011c38dd&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player" aria-description="02-mixed-3-of-3" ></iframe>
```

### Lecture slides {#sec-mixed-effects-workbook-slides}

::: callout-tip
## Download the lecture slides
The slides presented in the videos can be downloaded here:

- [402-week-18-LME-2.pdf](files/402-week-18-LME-2.pdf): high resolution .pdf, exactly as delivered [6 MB];
- [402-week-18-LME-2_1pp-lo.pdf](files/402-week-18-LME-2_1pp-lo.pdf): lower resolution .pdf, printable version, one-slide-per-page [about 900 KB];
- [402-week-18-LME-2_6pp-lo.pdf](files/402-week-18-LME-2_6pp-lo.pdf): lower resolution .pdf, printable version, six-slides-per-page [about 900 KB].

The high resolution version is the version delivered for the lecture recordings. Because the images are produced to be high resolution, the file size is quite big (6 MB) so, to make the slides easier to download, I produced low resolution versions: 1pp and 6pp. These should be easier to download and print out if that is what you want to do.
:::

### Practical materials: data and R-Studio {#sec-mixed-effects-workbook-practical}

we will be working with the **CP reading study** dataset. 
CP tested 62 children (aged 116-151 months) on reading aloud in English. 
In the experimental reading task, she presented 160 words as stimuli. 
The same 160 words were presented to all children. 
The words were presented one at a time on a computer screen. 
Each time a word was shown, each child had to read the word out loud and their response was recorded. 
Thus, the CP reading study dataset comprised observations about the responses made by 62 children to 160 words.

You can read more about these data in the [chapter: Introduction to linear mixed-effects models](../part2/02-mixed.qmd#sec-intro-mixed).

The critical features of the study are that:

-   We have an outcome measure -- the reading response -- observed multiple times.

1.  We have *multiple responses recorded for each participant*: they make one response to each stimulus (here, each stimulus word), for the multiple stimuli that they see in the experimental reading task.
2.  And we have *multiple responses recorded for each stimulus*: one response is made to each stimulus by each participant, for all the participants who completed the task, in a sample of multiple participants.

The presence of these features is the reason why we need to use mixed-effects models in our analysis.

::: callout-important
**Get the data**: get the data file and the .R script you can use to do the exercises that will support your learning.

- You can download the files folder for this chapter by clicking on the link [02-mixed.zip](files/02-mixed.zip).
:::

The practical materials folder includes data files and an `.R` script:

-   `CP study word naming rt 180211.dat`
-   `CP study word naming acc 180211.dat`
-   `words.items.5 120714 150916.csv`
-   `all.subjects 110614-050316-290518.csv`
-   `long.all.noNAs.csv`
-   `402-02-mixed-workbook.R` the workbook you will need to do the practical exercises.

The `.dat` files are *tab delimited* files holding behavioural data: the latency or reaction time `rt` (in milliseconds) and the accuracy `acc` of response made by each participant to each stimulus.

The `.csv` files are *comma separated values* files.
The `words.items` file holds information about the 160 stimulus words presented in the experimental reading (word naming) task. 
The `all.subjects` file holds information about the 62 participants who volunteered to take part in the experiment.

In the following, I will describe a series of steps through which we get the data ready for analysis. However, as we shall see, you can avoid these steps by using the pre-tidied dataset:

-   `long.all.noNAs.csv`

The data files are collected together through the steps set out in the .R script:

-   `402-02-mixed-workbook.R`.

::: callout-important
You can access the sign-in page for [R-Studio Server here](https://psy-rstudio.lancaster.ac.uk/auth-sign-in?appUri=%2F)
:::

#### Practical materials guide {#sec-mixed-effects-workbook-practical-guide}

Here, our learning targets are:

- Practice how to tidy experimental data for mixed-effects analysis.
- Begin to develop an understanding of crossed random effects of subjects and stimuli.
- Practice fitting linear mixed-effects models incorporating random effects of subjects and stimuli.

The aims of the lab session work are:

- Get practice running the code required to tidy and prepare experimental data for analysis.
- Exercise skills by varying model code -- changing variables, changing options -- so that you can see how the code works.
- Use the opportunity to reflect on and evaluate results -- so that we can support growth in development of understanding of main ideas.
- Optional -- get practice running the code: so that you can reproduce the figures and results from the lecture and in the book chapter.

#### The practical exercises {#sec-mixed-effects-workbook-practical-workbook}

Now you will progress through a series of tasks, and challenges, to aid your learning.

::: callout-warning
We will work with the data files:

-   `CP study word naming rt 180211.dat`
-   `CP study word naming acc 180211.dat`
-   `words.items.5 120714 150916.csv`
-   `all.subjects 110614-050316-290518.csv`
-   `long.all.noNAs.csv`
:::

We again split the steps into into parts, tasks and questions.

We are going to work through the following workflow steps: **each step is labelled as a practical part**.

1. Set-up
2. Load the data
3. Tidy the data
4. Read in pre-tidied data
5. Analyze data with lm
6. Analyze data with lmer
7. Optional: reproduce the plots in the chapter and slides

In the following, we will guide you through the tasks and questions step by step.

::: callout-important
An answers version of the workbook will be provided after the practical class.
:::

#### Practical Part 1: Set-up

To begin, we set up our environment in R.

##### Practical Task 1 -- Run code to load relevant libraries

Use the `library()` function to make the functions we need available to you.

:::{.callout-tip collapse="true"}
## Code
```{r}
library(broom)
library(gridExtra)
library(here)
library(lme4)
library(patchwork)
library(sjPlot)
library(tidyverse)
```
:::

#### Practical Part 2: Load the data

##### Practical Task 2 -- Read in the data file we will be using

Read the data files into R:

:::{.callout-tip collapse="true"}
## Code
```{r}
behaviour.rt <- read_tsv("CP study word naming rt 180211.dat", na = "-999")
behaviour.acc <- read_tsv("CP study word naming acc 180211.dat", na = "-999")
subjects <- read_csv("all.subjects 110614-050316-290518.csv", na = "-999")
words <- read_csv("words.items.5 120714 150916.csv", na = "-999")
```
:::

>**Pract.Q.1.** Can you identify the differences between the functions used to read different kinds of data files?

:::{.callout-tip collapse="true"}
## Hint
These different functions respect the different ways in which the `.dat` and `.csv` file formats work. 

- We need `read_tsv()` when data files consist of tab separated values. 
- We need `read_csv()` when data files consist of comma separated values.

You can read more about the `{tidyverse}` `{readr}` library of helpful functions [here](https://readr.tidyverse.org/).

It is *very* common to get experimental data in all sorts of different formats. Learning to use **tidyverse** functions will make it easier to cope with this when you do research.
:::

>**Pract.Q.2.** Can you explain what the `read_` functions are doing, or what you are doing with them when you code them?

:::{.callout-tip collapse="true"}
## Hint
It will help your understanding to examine an example. Take a look at what this line of code includes, element by element.

```{r}
#| label: readin-demo
#| eval: false
#| warning: false
#| message: false
behaviour.rt <- read_tsv("CP study word naming rt 180211.dat", na = "-999")
```

1.  We write `behaviour.rt <- read_tsv(...)` to create an object in the R environment, which we call `behaviour.rt`: the object with this name is the dataset we read into R using `read_tsv(...)`.
2.  When we write the function `read_tsv(...)` we include two arguments inside it.
3.  `read_tsv("CP study word naming rt 180211.dat", ...` first, the name of the file, given in quotes `""` and then a comma.
4.  `read_tsv(..., na = "-999")` second, we tell R that there are some missing values `na` which are coded with the value `"-999"`.
:::

#### Practical Part 3: Tidy the data

Tidying the data involves a number of tasks, some essential and some things we do for our convenience.

##### Practical Task 3 -- Transform the `rt` and `acc` data from wide to long using `pivot_longer()`

To get ready for later analyses, we need to ensure that reaction time (`rt`) and accuracy (`acc`) observations are in *tidy* format. 

When we first encounter the data files, the data are untidy because, here, the reaction time (`rt`) and accuracy (`acc`) observations are in separate multiple columns.
We *pivot* the data to solve this problem.

- You can read more about what we are doing and why, here, in the [chapter: Introduction to linear mixed-effects models](../part2/02-mixed.qmd#sec-intro-mixed-data-restructure).

>**Pract.Q.3.** How do we do this?

- You can try out some solutions, based on what you have done before.
- You can open the `Hint` box for a detailed walk-through of the process, and then adapt the hint information.
- And you can open the `Code` box for the example code.

:::{.callout-tip collapse="true"}
## Hint
We use a function you may have seen before: `pivot_longer()`.

```{r}
#| label: widetolong-demo
#| eval: false
rt.long <- behaviour.rt %>%
             pivot_longer(2:62, names_to = "subjectID", values_to = "RT")
```

The name of the function comes from the fact that we are starting with data in wide format e.g. `behaviour.rt` where we have what should be a single variable of observations (RTs) arranged in a wide series of multiple columns, side-by-side (one column for each participant). But we want to take those wide data and *lengthen* the dataset, increasing the number of rows and decreasing the number of columns.

Let's look at this line of code bit by bit.

1.  `rt.long <- behaviour.rt %>%`

-   At the start, I tell R that I am going to create a new longer dataset (more rows, fewer columns) that I shall call `rt.long`.
-   I will create this longer dataset from `<-` the original wide dataset `behaviour.rt`.
-   and I will create the new longer dataset by taking the original wide dataset and piping it `%>%` to the pivot function coded on the next line:

2.  `pivot_longer(2:62, names_to = "subjectID", values_to = "RT")`

-   On this next line, I tell R how to do the pivoting by using three arguments.

a.  `pivot_longer(2:62...)`

-   First, I tell R that I want to re-arrange all the columns that can be found in the dataset from the second column to the sixty-second column.
-   In a spreadsheet, we have a number of columns.
-   Columns can be identified by their position in the spreadsheet.
-   The position of a column in a spreadsheet can be identified by number, from the leftmost column (column number 1) to the rightmost column (here, column number 62) in our dataset.
-   So this argument tells R exactly which columns I want to pivot.

b.  `pivot_longer(..., names_to = "subjectID", ...)`

-   Second, I tell R that I want it to take the column labels and put them into a new column, called `subjectID`.
-   In the wide dataset `behaviour.rt`, each column holds a list of numbers (RTs) but begins with a word in the topmost cell, the name code for a participant, in the column label position.
-   We want to keep the information about which participant produces which response when we pivot the wide data to a longer structure.
-   We do this by asking R to take the column labels (the participant names) and listing them in a new column, called `subjectID` which now holds the names as participant ID codes.

c.  `pivot_longer(...values_to = "RT")`

-   Third, we tell R that all the RT values should be put in a single column.
-   We can understand that this new column `RT` will hold RT observations in a vertical stack, one cell for each response by a person to a word, with rows ordered by `subjectID`.

There are 61 columns of data listed by participant though 62 children were tested because we lost one child's data through an administrative error. As a result, in the wide data sets there are 62 columns, with the first column holding `item_name` data.

You can find more information about pivoting data [here](https://tidyr.tidyverse.org/articles/pivot.html)

And you can find more information specifically about the `pivot_longer()` operation [here](https://tidyr.tidyverse.org/articles/pivot.html)
:::

:::{.callout-tip collapse="true"}
## Code
```{r}
#| label: widetolong
#| warning: false
#| message: false
rt.long <- behaviour.rt %>%
             pivot_longer(2:62, names_to = "subjectID", values_to = "RT")

acc.long <- behaviour.acc %>%
              pivot_longer(2:62, names_to = "subjectID", values_to = "accuracy")
```
:::

##### Practical Task 4 -- Join data from different sources

To answer our research question, we next need to combine the **RT** with the **accuracy** data, and then the combined behavioural data with **participant** information and with **stimulus** information. 

In common practice, in psychological research, we have to deal with the fact that information about behavioural responses, and about participant attributes or stimulus word properties, are located in separate files.
This is a problem where we need, as here, to analyse outcome behavioural responses using information about participant attributes or stimulus word properties.

>**Pract.Q.4.** How do we solve this problem?

:::{.callout-tip collapse="true"}
## Hint
We need to join the data from the different sources: 

1. join RT with accuracy then
2. join those response data with data about subject attributes
3. then join those response plus subjects data
4. with item properties data

We can combine the datasets, in the way that we need, using the `{tidyverse}` `full_join()` function.
:::

:::{.callout-tip collapse="true"}
## Code
First, we join RT and accuracy data together.

```{r}
#| label: gatherall
#| message: false
#| warning: false
long <- rt.long %>% 
          full_join(acc.long)

```
:::

:::{.callout-tip collapse="true"}
## Code
Then, we join subject and item information to the behavioural data.

```{r}
#| label: gathersubjects
#| message: false
#| warning: false
long.subjects <- long %>% 
                   full_join(subjects, by = "subjectID")

long.all <- long.subjects %>%
              full_join(words, by = "item_name")

```
:::

>**Pract.Q.4.** Can you explain what you are doing, or what the code you use is doing, to solve the problem of putting the separate sets of data together?

:::{.callout-tip collapse="true"}
## Hint
Here, in a series of steps, we take one dataset and join it (merge it) with the second dataset. Let's look at an example element by element to better understand how this is accomplished.

```{r}
#| label: demo-join
#| eval: false
long <- rt.long %>% 
           full_join(acc.long)
```

The code work as follows.

1.  `long <- rt.long %>%`

-   We create a new dataset we call `long`.
-   We do this by taking one original dataset `rt.long` and `%>%` piping it to the operation defined in the second step.

2.  `full_join(acc.long)`

-   In this second step, we use the function `full_join()` to add observations from a second original dataset `acc.long` to those already from `rt.long`

The addition of observations from one database joining to those from another happens through a matching process.

-   R looks at the datasets being merged.
-   It identifies if the two datasets have columns in common. Here, the datasets have `subjectID` and `item_name` in common).
-   R can use these common columns to identify rows of data. Here, each row of data will be identified by both `subjectID` and `item_name` i.e. as data about the response made by a participant to a word.
-   R will then do a series of identity checks, comparing one dataset with the other and, row by row, looking for matching values in the columns that are common to both datasets.
-   If there is a match then R joins the corresponding rows of data together.
-   If there isn't a match then it creates `NAs` where there are missing entries in one row for one dataset which cannot be matched to a row from the joining dataset.
:::

- You can read more about what we are doing here in [chapter: Introduction to linear mixed-effects models](../part2/02-mixed.qmd#sec-intro-mixed-data-relational) and [chapter: Introduction to linear mixed-effects models](../part2/02-mixed.qmd#sec-intro-mixed-data-join-functions).

##### Practical Task 5 -- Select just the variables we need

If the pivoting and joining steps have gone according to plan then we should now be looking at a big, long and wide, dataset. But we do not actually require all of the dataset for the analyses we are going to do.

For our own convenience, we are going to want to select just the variables we need.

We want the variables:

- `item_name, subjectID, RT, accuracy`
- `Lg.UK.CDcount, brookesIMG, AoA_Kup_lem`
- `Ortho_N, regularity, Length, BG_Mean`
- `Voice,	Nasal,	Fricative,	Liquid_SV`	
- `Bilabials,	Labiodentals,	Alveolars`
- `Palatals,	Velars,	Glottals, age.months`
- `TOWREW_skill, TOWRENW_skill, spoonerisms, CART_score`

>**Pract.Q.5.** How we get to a data-set with just these variables in it?

:::{.callout-tip collapse="true"}
## Hint
We are going to select just the variables we need using the `select()` function.
:::

:::{.callout-tip collapse="true"}
## Code
```{r}
#| label: selectcols
long.all.select <- long.all %>% 
                        select(item_name, subjectID, RT, accuracy, 
                               Lg.UK.CDcount, brookesIMG, AoA_Kup_lem, 
                               Ortho_N, regularity, Length, BG_Mean, 
                               Voice,	Nasal,	Fricative,	Liquid_SV,
                               Bilabials,	Labiodentals,	Alveolars,
                               Palatals,	Velars,	Glottals, 
                               age.months, TOWREW_skill, TOWRENW_skill, 
                               spoonerisms, CART_score)

```
:::

>**Pract.Q.6.** What if you wanted to analyze a different set of variables, could you select different variables?

##### Practical Task 6 -- Filter the observations

The dataset includes missing values, designated `NA`. 

- Here, every error (coded `0`, in `accuracy`) corresponds to an `NA` in the `RT` column.

The dataset also includes outlier data. 

- In this context, $RT < 200$ are probably response errors or equipment failures. We will want to analyse `accuracy` later, so we shall need to be careful about getting rid of `NAs`.

>**Pract.Q.7.** How do we exclude `NA`s and outliers so that we can do our analysis

:::{.callout-tip collapse="true"}
## Hint
We can exclude two sets of observations:

-   observations corresponding to correct response reaction times that are too short: $RT < 200$.
-   plus observations corresponding to the word *false* which (because of stupid Excel auto-formatting) dropped item attribute data.

We can do this using the `filter()` function, setting conditions on rows, as arguments.

:::

:::{.callout-tip collapse="true"}
## Code
```{r}
#| label: filterrows
# step 1
long.all.select.filter <- long.all.select %>% 
                            filter(item_name != 'FALSE')

# step 2
long.all.select.filter <- long.all.select.filter %>%
                            filter(RT >= 200)

```
:::

>**Pract.Q.8.** Do you understand what is going on when you code R to exclude observations?

:::{.callout-tip collapse="true"}
## Hint
We can do the exclusions we need to do using the `filter()` function, setting conditions on rows, as arguments.

```{r}
#| label: filterrows
# step 1
long.all.select.filter <- long.all.select %>% 
                            filter(item_name != 'FALSE')

# step 2
long.all.select.filter <- long.all.select.filter %>%
                            filter(RT >= 200)

```

Here, I am using the function `filter()` to ...

-   Create a new dataset `long.all.select.filter <- ...` by
-   Using functions to work on the data named immediately to the right of the assignment arrow: `long.all.select`
-   An observation is included in the new dataset if it matches the condition specified as an argument in the `filter()` function call, thus:

1.  `filter(item_name !='FALSE')` means: include in the new dataset `long.all.select.filter` all observations from the old dataset `long.all.select` that are not `!=` (`!` not `=` equal to) the value `FALSE` in the variable `item_name`,
2.  then recreate the `long.all.select.filter` as a version of itself (with no name change) by including in the new version only those observations where RT was greater than or equal to 200ms using `RT >= 200`.
:::

>**Pract.Q.9.** Do you understand what the difference is between `=` and `==`.

:::{.callout-tip collapse="true"}
## Hint
You need to be careful to distinguish these signs.

-   `=` assigns a value, so `x = 2` means "x equals 2"
-   `==` tests a match so `x == 2` means: "is x equal to 2?"
:::

>**Pract.Q.10.** Can you vary the filter conditions: in different ways?

1.  Change the threshold for including RTs from `RT >= 200` to something else?
2.  Can you assess what impact the change has? Note that you can count the number of observations (rows) in a dataset using e.g. `length(data.set.name$variable.name)?`?

##### Practical Task 7 -- Remove missing (`NA`) values

The data-set includes missing values, designated `NA`. We have not yet dealt with these.

>**Pract.Q.11.** How do you remove missing values?

:::{.callout-tip collapse="true"}
## Hint
We can remove missing values before we go any further, using the `na.omit()` function.
:::

:::{.callout-tip collapse="true"}
## Code
```{r}
#| label: readinglongallc5
long.all.noNAs <- na.omit(long.all.select.filter)
```
:::

>**Pract.Q.12.** Can you explain how the code function works, when we exclude missing `NA` values?

:::{.callout-tip collapse="true"}
## Hint

The `na.omit()` function is powerful.

Look at the example code:

```{r}
#| eval: false
long.all.noNAs <- na.omit(long.all.select.filter)
```

-   In using this function, I am asking R to create a new data-set `long.all.noNAs` from the old dataset `long.all.select.filter` in a process in which the new data-set will have *no* rows in which there is a missing value `NA` in *any* column.
-   You need to be reasonably sure, when you use this function, where your `NAs` may be because, otherwise, you may end the process with a new filtered data-set that has many fewer rows in it than you expected.
:::

#### Practical Part 4: Read in pre-tidied data

We have a learnt in following the process of tidying data, step-by-step.

If we wanted to, we could complete the process, check that what we have done is correct, and then write the final version of the data-set out to a new `.csv` using the `write_csv()` function.

```{r}
#| eval: false
write_csv(long.all.noNAs, "long.all.noNAs.csv")
```

##### Practical Task 8 -- Read in `.csv` of pre-tidied data

>**Pract.Q.13.** If you want to skip the tidying process steps, assuming you have written the tidied data-set out to a new `.csv` file, what would you do?

:::{.callout-tip collapse="true"}
## Code
```{r}
#| label: readinglongallc5
long.all.noNAs <- read_csv("long.all.noNAs.csv", 
                           col_types = cols(
                             subjectID = col_factor(),
                             item_name = col_factor()
                           )
                          ) 
```
:::

>**Pract.Q.14.** Take a look at the example code, can you explain what it is doing?

:::{.callout-tip collapse="true"}
## Hint
```{r}
#| eval: false
long.all.noNAs <- read_csv("long.all.noNAs.csv", 
                           col_types = cols(
                             subjectID = col_factor(),
                             item_name = col_factor()
                           )
                          ) 
```

Notice that I am using `read_csv()` with an additional argument `col_types = cols(...)`.

-   Here, I am requesting that `read_csv()` treats `subjectID` and `item_name` as factors.
-   We use `col_types = cols(...)` to control how `read_csv()` interprets specific column variables in the data.

Controlling the way that `read_csv()` handles variables is a very useful capacity, and a more efficient way to work than, say, first reading in the data and then using *coercion* to ensure that variables are assigned appropriate types. You can read more about it [here](https://readr.tidyverse.org/articles/readr.html).
:::

#### Practical Part 5: Analyze data with lm

We begin our data analysis by asking if reading reaction time (RT) varies in association with word frequency.

- We ignore, here, the multilevel structure or clustering in the data.

##### Practical Task 9 -- 










##### Practical Task 7 -- Visualize the relationship between portuguese and english grades using a scatterplot

This should be a revision exercise for you.

- Do you notice any changes in the way in which the plotting code is laid out?

:::{.callout-tip collapse="true"}
## Code
```{r}
brazil %>%
  ggplot(aes(x = portuguese, y = english)) +
  geom_point(colour = "black", size = 2.5, alpha = .5) +
  geom_smooth(method = "lm", size = 1.5, se = FALSE, colour = "red") +
  xlab("Portuguese") + ylab("English") + theme_bw() 
```
:::

##### Practical Task 8 -- Exercise -- edit plots

1. Change the x and y variables to math and physics
2. Change the theme from `theme_bw()` to something different
3. Change the appearance of the points, try different colour, shape, size

:::{.callout-tip collapse="true"}
## Hint
Use the ggplot reference documentation to help you make choices:

- <https://ggplot2.tidyverse.org/reference/>

You should be using webpages like the reference page often in your work.
:::

#### Practical Part 5: Visualize the relationship

We move next to analyzing the relationship between variation in grades in different subjects, across the children in our sample.

##### Practical Task 9 -- Analyze the relationship between english and portuguese grades in the brazil data

You should be able to reproduce the results shown in the slides and the book chapter.

:::{.callout-tip collapse="true"}
## Code
```{r}
summary(lm(english ~ portuguese, data = brazil))
```
:::

##### Practical Task 10 -- Exercise -- adapt the `lm()` code to do a different analysis

Change the outcome and predictor variables to math and physics.

:::{.callout-tip collapse="true"}
## Code
```{r}
summary(lm(physics ~ math, data = brazil))
```
:::

>**Pract.Q.4.** What is the estimated coefficient of the "effect" of math ability (grade) on physics grade?

<!-- > Pract.A.4. The summary shows that physics grades are on average 1.3 higher for unit increase in math grade. -->

>**Pract.Q.5.** Draw a scatterplot showing the relationship between math and physics grades. Does the trend you see in the plot reflect the coefficient you see in the linear model summary?

<!-- > Pract.A.5. The plot shows the positive association between math and physics grade also indicated by the estimated coefficient of the math effect. -->

:::{.callout-tip collapse="true"}
## Code
```{r}
brazil %>%
  ggplot(aes(x = math, y = physics)) +
  geom_point(colour = "black", size = 2.5, alpha = .5) +
  geom_smooth(method = "lm", size = 1.5, se = FALSE, colour = "red") +
  theme_bw() 
```
:::

>**Pract.Q.6.** How does the strength of the math-physics relationship compare with the english-portuguese relationship?

<!-- > Pract.A.6. Both the linear model and the plots indicate that the math-physics relationship is much stronger. -->

#### Practical Part 6: Visualize the relationship for each class

##### Practical Task 11 -- Plot the relationship between english and portuguese grades separately for each class using `facet_wrap()`

:::{.callout-tip collapse="true"}
## Code
```{r}
ggplot(data = brazil, aes(x = portuguese, y = english)) +
  geom_point(colour = "darkgrey") + 
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  xlab("Portuguese") + ylab("English") + theme_bw() +
  scale_x_continuous(breaks=c(25,50,75)) + scale_y_continuous(breaks=c(0,50,100)) +
  facet_wrap(~ class_number) 
```
:::

##### Practical Task 12 -- Exercises to practice your `facet_wrap()` skills

1. Change the x and y variables to math and physics and draw a facetted scatterplot again
2. Experiment with showing the differences between classes in a different way: instead of using `facet_wrap()`, in `aes()` add `colour = class_number`, and remove colour from `geom_point` and `geom_smooth`

:::{.callout-tip collapse="true"}
## Code
```{r}
ggplot(data = brazil, aes(x = math, y = physics)) +
  geom_point(colour = "darkgrey") + 
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  facet_wrap(~ class_number) 

ggplot(data = brazil, aes(x = math, y = physics, colour = class_number)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE)
```
:::

>**Pract.Q.8.** Evaluate the consistency between classes of the relationship between math and physics grades: what do the plots show? how does this compare with what you see of the relationship between english and portuguese grades?

<!-- > Pract.A.8. The plots show that the relationship between math and physics is very consistent between classes, and more consistent than the relationship between english and portuguese grades appears to be. -->

#### Practical Part 7: Mixed-effects analysis

##### Practical Task 13 -- Run a linear mixed-effects analysis of the relationship between english and portuguese grades using `lmer()`

You should be able to replicate the results shown in the slides and the book chapter.

:::{.callout-tip collapse="true"}
## Code
```{r}
porto.lmer1 <- lmer(english ~ portuguese +
                      (portuguese + 1|class_number),
                      data = brazil)
summary(porto.lmer1)
```
:::

##### Practical Task 14 - Exercise mixed-effects model coding

1. Vary the random effects part of the model, while keeping this bit the same: `lmer(english ~ portuguese + ...)`
2. Change the random effect from `(portuguese + 1 | class_number)` to `(1 | class_number)`: what you are doing is asking R to ignore the differences in the slope of the effect of Portuguese grades.
3. Change the random effect from `(portuguese + 1 | class_number)` to `(portuguese + 0 | class_number)`: what you are doing is asking R to ignore the differences  in the intercept

:::{.callout-tip collapse="true"}
## Code
```{r}
porto.lmer1 <- lmer(english ~ portuguese +
                      (portuguese + 1|class_number),
                    data = brazil)
summary(porto.lmer1)

#

porto.lmer2 <- lmer(english ~ portuguese +
                      (1|class_number),
                    data = brazil)
summary(porto.lmer2)

#

porto.lmer3 <- lmer(english ~ portuguese +
                      (portuguese + 0|class_number),
                    data = brazil)
summary(porto.lmer3)
```
:::

>**Pract.Q.9.** Compare the results of the different versions of the model. Can you identify where the results are different?

<!-- > Pract.A.9. It can be seen that Rhe estimated effect of portuguese varies between the models but the estimate is more similar, around .65, where the random effect is specified as  -->
<!--  `(portuguese + 1|class_number)` or `(portuguese + 0|class_number)`. -->
<!-- > The residual variance term is different between the models. -->
<!-- > Which random effects variances are shown is also different. -->
<!-- > There is a convergence warning for: -->

<!-- `english ~ portuguese + (portuguese + 0 | class_number)` -->

##### Practical Task 15 - Exercise mixed-effects model coding

Change the outcome (from english) and the predictor (from portuguese) -- this is about changing the fixed effect part of the model.

- Note that you will need to change the random effect part as well.

:::{.callout-tip collapse="true"}
## Code
```{r}
porto.lmer1 <- lmer(physics ~ math +
                      (math + 1|class_number),
                    data = brazil)
summary(porto.lmer1)
```
:::

>**Pract.Q.10.** What elements of the model summary stand out for you? It will help to see what you should notice if you compare the math-physics model with the first english-portuguese model.

<!-- > Pract.A.10. You may notice that: -->

<!-- - The summary comes with a fit is singular? warning. -->
<!-- - The variance terms for intercept or the math effect by class number and the residual are very very small: much smaller than for the english-portuguese model. -->

#### Practical Part 8: Extension

##### Practical Task Optional

In the lecture materials, I display a plot showing the estimated intercept and coefficient for  each class, estimated using separate models for different classes.

- Some of you may be interested in how I did that, you can run the following code to see.

1. Use the `{dplyr}` `%>%` syntax to run a model for each class separately, collect together the results into a dataframe.

:::{.callout-tip collapse="true"}
## Code
```{r}
brazlm <- brazil %>% group_by(class_number) %>% do(tidy(lm(english ~ portuguese, data=.)))
brazlm$term <- as.factor(brazlm$term)
```
:::

2. Extract the per-class estimates of the intercepts and the 'portuguese' effect coefficient estimates.

:::{.callout-tip collapse="true"}
## Code
```{r}
brazlmint <- filter(brazlm, term == '(Intercept)')
brazlmport <- filter(brazlm, term == 'portuguese')
```
:::

3. Plot the estimates.

:::{.callout-tip collapse="true"}
## Code
```{r}
pbrazlmint <- ggplot(brazlmint, aes(x = class_number, y = estimate, ymin = estimate - std.error, ymax = estimate + std.error))
pbrazlmint <- pbrazlmint + geom_point(size = 2) + geom_linerange() + theme_bw() 
pbrazlmint <- pbrazlmint + ggtitle("Intercept") + ylab("Estimated coefficient +/- SE") + xlab("Class")
pbrazlmint <- pbrazlmint + theme(axis.title.y = element_text(size = 10), axis.text.x = element_blank(), panel.grid = element_blank())
# pbrazlmint

pbrazlmport <- ggplot(brazlmport, aes(x = class_number, y = estimate, ymin = estimate - std.error, ymax = estimate + std.error))
pbrazlmport <- pbrazlmport + geom_point(size = 2) + geom_linerange() + theme_bw() 
pbrazlmport <- pbrazlmport + ggtitle("Portuguese effect") + ylab("Estimated coefficient +/- SE") + xlab("Class")
pbrazlmport <- pbrazlmport + theme(axis.title.y = element_text(size = 10), axis.text.x = element_blank(), panel.grid = element_blank())
# pbrazlmport

# -- ask R to make a grid:

grid.arrange(pbrazlmint, pbrazlmport,
             ncol = 2)
```
:::

Challenge: Can you change the code to show the estimates for the relationship between physics and math grades?

### The answers

After the practical class, we will reveal the answers that are currently hidden.

The answers version of the webpage will present my answers for questions, and some extra information where that is helpful.

